"""
PRISM Phase 3.1 - OCR Text Extractor

âœ… ê¸°ëŠ¥:
1. ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (pytesseract)
2. ì„¹ì…˜ í—¤ë” ìë™ ê°ì§€
3. í…ìŠ¤íŠ¸ ì˜ì—­ Layout ë¶„ì„
4. VLMê³¼ í†µí•© ê°€ëŠ¥í•œ êµ¬ì¡°

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-22
Version: 3.1
"""

import cv2
import numpy as np
from typing import List, Dict, Tuple
import logging
import re

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
except ImportError:
    PYTESSERACT_AVAILABLE = False
    print("âš ï¸  pytesseract not installed. OCR ê¸°ëŠ¥ ì œí•œë¨.")

logger = logging.getLogger(__name__)


class OCRTextExtractor:
    """
    OCR ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°
    
    ê¸°ëŠ¥:
    - ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - ì„¹ì…˜ í—¤ë” ê°ì§€
    - í…ìŠ¤íŠ¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ ë¶„ì„
    """
    
    def __init__(self, lang: str = 'kor+eng'):
        """
        ì´ˆê¸°í™”
        
        Args:
            lang: OCR ì–¸ì–´ (ê¸°ë³¸: í•œêµ­ì–´+ì˜ì–´)
        """
        self.lang = lang
        self.available = PYTESSERACT_AVAILABLE
        
        # ì„¹ì…˜ í—¤ë” íŒ¨í„´
        self.section_patterns = [
            r'^\d{1,2}\s+.+',  # "06 ì‘ë‹µì íŠ¹ì„±"
            r'^[â˜‰â—‹â—â—â—‰âŠ™]\s+.+',  # "â˜‰ ì‘ë‹µì ì„±ë³„"
            r'^[ê°€-í£]{2,10}\s*íŠ¹ì„±',  # "ì‘ë‹µì íŠ¹ì„±"
            r'^Chapter\s+\d+',  # "Chapter 1"
            r'^ì œ\s*\d+\s*[ì¥ì ˆ]',  # "ì œ 1 ì¥"
        ]
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ íŒŒë¼ë¯¸í„°
        self.text_region_params = {
            'min_height': 30,
            'max_height': 200,
            'min_width': 200,
            'text_density_threshold': 0.01
        }
        
        if self.available:
            logger.info("âœ… OCRTextExtractor ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ OCRTextExtractor ì œí•œ ëª¨ë“œ (pytesseract ì—†ìŒ)")
    
    def extract_full_text(self, image: np.ndarray) -> Dict:
        """
        ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            image: í˜ì´ì§€ ì´ë¯¸ì§€ (numpy array)
            
        Returns:
            {
                'full_text': str,
                'lines': List[str],
                'blocks': List[Dict],
                'confidence': float
            }
        """
        if not self.available:
            return self._mock_extraction(image)
        
        # ì „ì²˜ë¦¬
        processed = self._preprocess_for_ocr(image)
        
        # OCR ì‹¤í–‰ (ìƒì„¸ ì •ë³´ í¬í•¨)
        data = pytesseract.image_to_data(
            processed,
            lang=self.lang,
            output_type=pytesseract.Output.DICT
        )
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ êµ¬ì„±
        blocks = []
        current_block = []
        current_block_num = -1
        
        for i in range(len(data['text'])):
            text = data['text'][i].strip()
            conf = int(data['conf'][i])
            
            if conf < 30 or not text:  # ì‹ ë¢°ë„ ë‚®ì€ ê²ƒ ì œì™¸
                continue
            
            block_num = data['block_num'][i]
            
            if block_num != current_block_num:
                if current_block:
                    blocks.append({
                        'text': ' '.join(current_block),
                        'bbox': self._get_block_bbox(data, current_block_num),
                        'type': 'text_block'
                    })
                current_block = [text]
                current_block_num = block_num
            else:
                current_block.append(text)
        
        # ë§ˆì§€ë§‰ ë¸”ë¡ ì¶”ê°€
        if current_block:
            blocks.append({
                'text': ' '.join(current_block),
                'bbox': self._get_block_bbox(data, current_block_num),
                'type': 'text_block'
            })
        
        # ì „ì²´ í…ìŠ¤íŠ¸
        full_text = '\n'.join([block['text'] for block in blocks])
        
        # ë¼ì¸ë³„ ë¶„ë¦¬
        lines = [line.strip() for line in full_text.split('\n') if line.strip()]
        
        # í‰ê·  ì‹ ë¢°ë„
        confidences = [int(c) for c in data['conf'] if int(c) >= 0]
        avg_confidence = np.mean(confidences) if confidences else 0
        
        return {
            'full_text': full_text,
            'lines': lines,
            'blocks': blocks,
            'confidence': float(avg_confidence)
        }
    
    def extract_section_titles(self, image: np.ndarray) -> List[Dict]:
        """
        ì„¹ì…˜ í—¤ë” ìë™ ê°ì§€
        
        Args:
            image: í˜ì´ì§€ ì´ë¯¸ì§€
            
        Returns:
            [
                {
                    'title': '06 ì‘ë‹µì íŠ¹ì„±',
                    'bbox': [x, y, w, h],
                    'level': 1,
                    'confidence': 0.95
                },
                ...
            ]
        """
        if not self.available:
            return []
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ocr_result = self.extract_full_text(image)
        
        section_titles = []
        
        for i, line in enumerate(ocr_result['lines']):
            # ì„¹ì…˜ íŒ¨í„´ ë§¤ì¹­
            for pattern in self.section_patterns:
                if re.match(pattern, line):
                    # ë ˆë²¨ ì¶”ì •
                    level = self._estimate_section_level(line)
                    
                    section_titles.append({
                        'title': line,
                        'bbox': self._estimate_line_bbox(ocr_result['blocks'], i),
                        'level': level,
                        'confidence': 0.85,
                        'type': 'section_header'
                    })
                    break
        
        return section_titles
    
    def extract_text_regions(self, image: np.ndarray) -> List[Dict]:
        """
        í…ìŠ¤íŠ¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ ë¶„ì„
        
        Args:
            image: í˜ì´ì§€ ì´ë¯¸ì§€
            
        Returns:
            í…ìŠ¤íŠ¸ ì˜ì—­ ë¦¬ìŠ¤íŠ¸ (bbox í¬í•¨)
        """
        if not self.available:
            return []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
        
        # ìˆ˜í‰ í™•ì¥ (í…ìŠ¤íŠ¸ ë¼ì¸ ì—°ê²°)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))
        dilated = cv2.dilate(binary, kernel, iterations=1)
        
        # ìœ¤ê³½ì„  ê²€ì¶œ
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # í¬ê¸° í•„í„°ë§
            if h < self.text_region_params['min_height'] or \
               h > self.text_region_params['max_height'] or \
               w < self.text_region_params['min_width']:
                continue
            
            # í…ìŠ¤íŠ¸ ë°€ë„ ì²´í¬
            roi = binary[y:y+h, x:x+w]
            text_density = np.sum(roi) / (w * h * 255)
            
            if text_density < self.text_region_params['text_density_threshold']:
                continue
            
            # OCR ì‹¤í–‰
            roi_image = image[y:y+h, x:x+w]
            text = pytesseract.image_to_string(roi_image, lang=self.lang).strip()
            
            if len(text) > 5:  # ìµœì†Œ 5ì ì´ìƒ
                text_regions.append({
                    'type': 'text_region',
                    'bbox': [int(x), int(y), int(w), int(h)],
                    'text': text,
                    'confidence': 0.80
                })
        
        return text_regions
    
    def _preprocess_for_ocr(self, image: np.ndarray) -> np.ndarray:
        """OCR ì „ì²˜ë¦¬"""
        # Grayscale ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def _get_block_bbox(self, data: Dict, block_num: int) -> List[int]:
        """OCR ë¸”ë¡ì˜ Bounding Box ê³„ì‚°"""
        xs, ys, ws, hs = [], [], [], []
        
        for i in range(len(data['block_num'])):
            if data['block_num'][i] == block_num:
                xs.append(data['left'][i])
                ys.append(data['top'][i])
                ws.append(data['width'][i])
                hs.append(data['height'][i])
        
        if not xs:
            return [0, 0, 0, 0]
        
        min_x = min(xs)
        min_y = min(ys)
        max_x = max([x + w for x, w in zip(xs, ws)])
        max_y = max([y + h for y, h in zip(ys, hs)])
        
        return [min_x, min_y, max_x - min_x, max_y - min_y]
    
    def _estimate_section_level(self, line: str) -> int:
        """ì„¹ì…˜ ë ˆë²¨ ì¶”ì •"""
        # ìˆ«ìë¡œ ì‹œì‘í•˜ë©´ Level 1
        if re.match(r'^\d{1,2}\s+', line):
            return 1
        
        # íŠ¹ìˆ˜ ê¸°í˜¸ë¡œ ì‹œì‘í•˜ë©´ Level 2
        if re.match(r'^[â˜‰â—‹â—â—â—‰âŠ™]\s+', line):
            return 2
        
        # ê¸°íƒ€ëŠ” Level 3
        return 3
    
    def _estimate_line_bbox(self, blocks: List[Dict], line_idx: int) -> List[int]:
        """ë¼ì¸ì˜ Bounding Box ì¶”ì •"""
        if line_idx < len(blocks):
            return blocks[line_idx].get('bbox', [0, 0, 0, 0])
        return [0, 0, 0, 0]
    
    def _mock_extraction(self, image: np.ndarray) -> Dict:
        """pytesseract ì—†ì„ ë•Œ Mock ê²°ê³¼"""
        logger.warning("âš ï¸ pytesseract ì—†ìŒ. Mock ëª¨ë“œ ì‹¤í–‰.")
        
        return {
            'full_text': '[OCR ë¶ˆê°€ - pytesseract ì„¤ì¹˜ í•„ìš”]',
            'lines': [],
            'blocks': [],
            'confidence': 0.0
        }


# â­ Phase 3.1 í†µí•© í´ë˜ìŠ¤
class Phase31LayoutDetector:
    """
    Phase 3.1 í†µí•© Layout Detector
    
    CV + OCR í•˜ì´ë¸Œë¦¬ë“œ
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        from layout_detector_phase31 import LayoutDetector as CVLayoutDetector
        
        self.cv_detector = CVLayoutDetector()
        self.ocr_extractor = OCRTextExtractor()
        
        logger.info("âœ… Phase 3.1 í†µí•© ì´ˆê¸°í™” ì™„ë£Œ (CV + OCR)")
    
    def detect_all_regions(self, image: np.ndarray, page_num: int = 0) -> Dict:
        """
        ëª¨ë“  ì˜ì—­ ê°ì§€ (CV + OCR)
        
        Returns:
            {
                'cv_regions': List[Dict],  # CV ê°ì§€ (ì°¨íŠ¸, í‘œ, ì§€ë„)
                'text_regions': List[Dict],  # OCR í…ìŠ¤íŠ¸ ì˜ì—­
                'section_titles': List[Dict],  # ì„¹ì…˜ í—¤ë”
                'full_text': str  # ì „ì²´ í…ìŠ¤íŠ¸
            }
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“„ Phase 3.1 í†µí•© ê°ì§€ (í˜ì´ì§€ {page_num + 1})")
        logger.info(f"{'='*60}\n")
        
        # 1. CV ê¸°ë°˜ ì˜ì—­ ê°ì§€
        logger.info("Stage 1: CV ê¸°ë°˜ Layout Detection")
        cv_regions = self.cv_detector.detect_regions(image, page_num)
        logger.info(f"   â†’ {len(cv_regions)}ê°œ CV ì˜ì—­ ê°ì§€\n")
        
        # 2. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        logger.info("Stage 2: OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        ocr_result = self.ocr_extractor.extract_full_text(image)
        logger.info(f"   â†’ {len(ocr_result['lines'])}ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        logger.info(f"   â†’ ì‹ ë¢°ë„: {ocr_result['confidence']:.1f}%\n")
        
        # 3. ì„¹ì…˜ í—¤ë” ê°ì§€
        logger.info("Stage 3: ì„¹ì…˜ í—¤ë” ê°ì§€")
        section_titles = self.ocr_extractor.extract_section_titles(image)
        logger.info(f"   â†’ {len(section_titles)}ê°œ ì„¹ì…˜ í—¤ë” ê°ì§€\n")
        
        # 4. í…ìŠ¤íŠ¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ
        logger.info("Stage 4: í…ìŠ¤íŠ¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ")
        text_regions = self.ocr_extractor.extract_text_regions(image)
        logger.info(f"   â†’ {len(text_regions)}ê°œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€\n")
        
        logger.info(f"{'='*60}")
        logger.info(f"âœ… ì´ ê°ì§€: CV {len(cv_regions)}ê°œ + OCR {len(text_regions)}ê°œ")
        logger.info(f"{'='*60}\n")
        
        return {
            'cv_regions': cv_regions,
            'text_regions': text_regions,
            'section_titles': section_titles,
            'full_text': ocr_result['full_text'],
            'ocr_lines': ocr_result['lines'],
            'ocr_confidence': ocr_result['confidence']
        }