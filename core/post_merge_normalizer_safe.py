"""
post_merge_normalizer_v033.py
PRISM Phase 0.3.3 - Post Merge Normalizer (ê°„ì†Œí™”)

âœ… Phase 0.3.3 ê°œì„ :
1. í˜ì´ì§€ ë§ˆì»¤ ì œê±°
2. ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°
3. ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°
4. ë¶ˆí•„ìš”í•œ ì˜ë¯¸ ì¹˜í™˜ ì™„ì „ ì œê±°

ì„¤ì¹˜: core/post_merge_normalizer_safe.py ëŒ€ì²´

Author: ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-07
Version: Phase 0.3.3
"""

import re
import logging

logger = logging.getLogger(__name__)


class PostMergeNormalizer:
    """
    Phase 0.3.3 í†µí•© í›„ ì •ê·œí™” (ê°„ì†Œí™”)
    
    âœ… í•µì‹¬ ê°œì„ :
    - í˜ì´ì§€ ë§ˆì»¤ ì œê±°
    - ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°
    - ì˜ë¯¸ ì¹˜í™˜ ì™„ì „ ì œê±°
    """
    
    VERSION = "Phase 0.3.3"
    
    # í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´
    PAGE_MARKER_PATTERNS = [
        r'^\s*\d{3,4}-\d{1,2}\s*$',      # 402-1
        r'^\s*_\d{3,4}-\d{1,2}_\s*$',    # _402-1_
        r'^\s*\*\d{3,4}-\d{1,2}\*\s*$',  # *402-1*
        r'^\s*í˜ì´ì§€\s+\d+\s*$',         # í˜ì´ì§€ 1
        r'^\s*Page\s+\d+\s*$',           # Page 1
    ]
    
    # ê°œì • ì´ë ¥ íŒ¨í„´
    REVISION_PATTERN = re.compile(
        r'(?:ì œ\s*)?(\d+)ì°¨\s*ê°œì •\s*(\d{4})\s*\.\s*(\d{1,2})\s*\.\s*(\d{1,2})',
        re.MULTILINE
    )
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.compiled_patterns = [
            re.compile(p, re.MULTILINE) for p in self.PAGE_MARKER_PATTERNS
        ]
        
        logger.info(f"âœ… PostMergeNormalizer {self.VERSION} ì´ˆê¸°í™”")
        logger.info(f"   ğŸ—‘ï¸ í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´: {len(self.PAGE_MARKER_PATTERNS)}ê°œ")
        logger.info(f"   ğŸ—‘ï¸ ê°œì •ì´ë ¥ dedup: í™œì„±í™”")
    
    def normalize(self, text: str, doc_type: str = 'statute') -> str:
        """
        í†µí•© Markdown ì •ê·œí™”
        
        Args:
            text: í†µí•©ëœ Markdown
            doc_type: ë¬¸ì„œ íƒ€ì…
        
        Returns:
            ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        logger.info(f"   ğŸ§¹ PostMergeNormalizer {self.VERSION} ì‹œì‘")
        
        original_len = len(text)
        
        # 1. í˜ì´ì§€ ë§ˆì»¤ ì œê±°
        text, marker_count = self._remove_page_markers(text)
        
        # 2. ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°
        text, revision_count = self._deduplicate_revisions(text)
        
        # 3. ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°
        text, fence_count = self._remove_inline_fences(text)
        
        # 4. ë¹ˆ ì¤„ ì •ë¦¬
        text = self._cleanup_empty_lines(text)
        
        final_len = len(text)
        
        logger.info(f"   âœ… ì •ê·œí™” ì™„ë£Œ:")
        logger.info(f"      í˜ì´ì§€ ë§ˆì»¤: {marker_count}ê°œ ì œê±°")
        logger.info(f"      ê°œì •ì´ë ¥: {revision_count}ê°œ ì¤‘ë³µ ì œê±°")
        logger.info(f"      ì½”ë“œíœìŠ¤: {fence_count}ê°œ ì œê±°")
        logger.info(f"      ê¸¸ì´: {original_len} â†’ {final_len} ({final_len - original_len:+d})")
        
        return text
    
    def _remove_page_markers(self, text: str):
        """í˜ì´ì§€ ë§ˆì»¤ ì œê±°"""
        count = 0
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            is_marker = False
            for pattern in self.compiled_patterns:
                if pattern.match(line):
                    is_marker = True
                    count += 1
                    break
            
            if not is_marker:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines), count
    
    def _deduplicate_revisions(self, text: str):
        """ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°"""
        revisions = {}
        
        def replacer(match):
            key = (match.group(1), match.group(2), match.group(3), match.group(4))
            if key not in revisions:
                revisions[key] = match.group(0)
                return match.group(0)
            else:
                return ''
        
        text = self.REVISION_PATTERN.sub(replacer, text)
        
        # ì¤‘ë³µ ì œê±°ëœ ê°œìˆ˜
        count = len([v for v in revisions.values() if v == ''])
        
        return text, count
    
    def _remove_inline_fences(self, text: str):
        """ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±° (ì‹œì‘/ë ì œì™¸)"""
        lines = text.split('\n')
        
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì½”ë“œíœìŠ¤ ìœ„ì¹˜ ì°¾ê¸°
        fence_positions = []
        for i, line in enumerate(lines):
            if line.strip().startswith('```'):
                fence_positions.append(i)
        
        if len(fence_positions) <= 2:
            # 2ê°œ ì´í•˜ë©´ ì œê±° ì•ˆ í•¨
            return text, 0
        
        # ì¤‘ê°„ íœìŠ¤ë§Œ ì œê±° (ì²«/ë§ˆì§€ë§‰ ì œì™¸)
        count = 0
        for i in fence_positions[1:-1]:
            if lines[i].strip().startswith('```'):
                lines[i] = ''
                count += 1
        
        return '\n'.join(lines), count
    
    def _cleanup_empty_lines(self, text: str) -> str:
        """ê³¼ë„í•œ ë¹ˆ ì¤„ ì •ë¦¬ (3ê°œ ì´ìƒ â†’ 2ê°œ)"""
        # 3ê°œ ì´ìƒì˜ ì—°ì† ë¹ˆ ì¤„ì„ 2ê°œë¡œ
        text = re.sub(r'\n{4,}', '\n\n\n', text)
        
        return text