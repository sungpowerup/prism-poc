"""
core/post_merge_normalizer_safe.py
PRISM Phase 0.3.2 - Safe Mode (ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°)

âœ… Phase 0.3.2 ê°œì„ :
1. ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±° ì¶”ê°€
2. í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´ í™•ì¥
3. ì˜ë¯¸ ì¹˜í™˜ ì™„ì „ ì œê±°

Author: ì´ì„œì˜ (Backend Lead) + ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-07
Version: Phase 0.3.2
"""

import re
import logging
from typing import Dict, Any, List, Set

logger = logging.getLogger(__name__)


class PostMergeNormalizer:
    """
    Phase 0.3.2 í†µí•© í›„ ì •ê·œí™” (ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°)
    
    âœ… Phase 0.3.2 ê°œì„ :
    - ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°
    - í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´ í™•ì¥
    """
    
    # ë²„ì „ ì •ë³´
    VERSION = "Phase 0.3.2"
    
    # í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´ (í™•ì¥)
    PAGE_MARKER_PATTERNS = [
        r'^\s*\d{3,4}-\d{1,2}\s*$',           # 402-1, 402-2
        r'^\s*_\d{3,4}-\d{1,2}_\s*$',         # _402-1_
        r'^\s*\*\d{3,4}-\d{1,2}\*\s*$',       # *402-1*
        r'^\s*í˜ì´ì§€\s+\d+\s*$',              # í˜ì´ì§€ 1
        r'^\s*Page\s+\d+\s*$',                # Page 1
        r'^\s*-\s*\d+\s*-\s*$',              # - 1 -
        r'^\s*\[\s*\d+\s*\]\s*$',            # [1]
    ]
    
    # ê°œì • ì´ë ¥ íŒ¨í„´
    REVISION_PATTERN = re.compile(
        r'(?:ì œ\s*)?(\d+)ì°¨\s*ê°œì •\s*(\d{4})\s*\.\s*(\d{1,2})\s*\.\s*(\d{1,2})',
        re.MULTILINE
    )
    
    # âš ï¸ Phase 0.3: ì˜ë¯¸ ì¹˜í™˜ ì™„ì „ ì œê±°
    COMMON_TYPOS = {}
    
    # ğŸš« Phase 0.3: ê¸ˆì§€ ì¹˜í™˜ ë¸”ë¡ë¦¬ìŠ¤íŠ¸
    BLOCKED_REPLACEMENTS = {
        'ê³µê¸ˆê´€ë¦¬', 'ìƒê¸‰ì¸ì‚¬',
        'ì¢…í•©ì¸ì‚¬ìœ„ì›íšŒ', 'ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ',
        'ì„±ê³¼ê³„ì•½ì „ë‹´ìƒì', 'ì„±ê³¼ê°œì„ ëŒ€ìƒì',
        'ì§•ê³„ìš”ê±´', 'ì œ9ì¡°ì˜',
        'ì‚¬ì§', 'ì‚­ì œ',
    }
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.compiled_patterns = [
            re.compile(p, re.MULTILINE) for p in self.PAGE_MARKER_PATTERNS
        ]
        
        logger.info(f"âœ… PostMergeNormalizer {self.VERSION} ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ğŸ“– ì˜ë¯¸ ì‚¬ì „: {len(self.COMMON_TYPOS)}ê°œ (ë¹„í™œì„±í™”)")
        logger.info(f"   ğŸš« ê¸ˆì§€ ì¹˜í™˜: {len(self.BLOCKED_REPLACEMENTS)}ê°œ")
        logger.info(f"   ğŸ” í˜ì´ì§€ ë§ˆì»¤ íŒ¨í„´: {len(self.PAGE_MARKER_PATTERNS)}ê°œ")
        logger.info(f"   ğŸ—‘ï¸ ê°œì •ì´ë ¥ dedup: í™œì„±í™”")
        logger.info(f"   ğŸ”„ 2ì°¨ ê²€ì¦: í™œì„±í™”")
        logger.info(f"   âš ï¸ ì˜ë¯¸ ì¹˜í™˜ ì œê±°: ì›ë³¸ ì¶©ì‹¤ë„ ìš°ì„ ")
    
    def normalize(self, text: str, doc_type: str = 'statute') -> str:
        """
        í†µí•© Markdown ì •ê·œí™”
        
        Args:
            text: í†µí•©ëœ Markdown
            doc_type: ë¬¸ì„œ íƒ€ì…
        
        Returns:
            ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        logger.info(f"   ğŸ”§ PostMergeNormalizer {self.VERSION} ì‹œì‘ (doc_type: {doc_type})")
        
        original_len = len(text)
        
        # âœ… 1ë‹¨ê³„: í˜ì´ì§€ ë§ˆì»¤ ì œê±°
        text, marker_count = self._remove_page_markers(text)
        
        # âœ… 2ë‹¨ê³„: ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°
        text = self._deduplicate_revisions(text)
        
        # âœ… Phase 0.3.2: 3ë‹¨ê³„: ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°
        text = self._remove_inline_codefence(text)
        
        final_len = len(text)
        
        logger.info(f"   âœ… ì •ê·œí™” ì™„ë£Œ: {original_len} â†’ {final_len} ê¸€ì")
        
        return text
    
    def _remove_page_markers(self, text: str) -> tuple:
        """
        í˜ì´ì§€ ë§ˆì»¤ ì œê±°
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            (ì •ê·œí™”ëœ í…ìŠ¤íŠ¸, ì œê±° íšŸìˆ˜)
        """
        lines = text.split('\n')
        cleaned_lines = []
        removed_count = 0
        
        for line in lines:
            is_marker = False
            for pattern in self.compiled_patterns:
                if pattern.match(line.strip()):
                    is_marker = True
                    removed_count += 1
                    break
            
            if not is_marker:
                cleaned_lines.append(line)
        
        if removed_count > 0:
            logger.info(f"   ğŸ—‘ï¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±°: {removed_count}ê°œ ë¼ì¸")
        
        return '\n'.join(cleaned_lines), removed_count
    
    def _deduplicate_revisions(self, text: str) -> str:
        """
        ê°œì •ì´ë ¥ ì¤‘ë³µ ì œê±°
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì¤‘ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        seen = set()
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            match = self.REVISION_PATTERN.search(line)
            if match:
                key = (match.group(1), match.group(2), match.group(3), match.group(4))
                if key in seen:
                    continue
                seen.add(key)
            
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _remove_inline_codefence(self, text: str) -> str:
        """
        âœ… Phase 0.3.2: ì¤‘ê°„ ì½”ë“œíœìŠ¤ ì œê±°
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì½”ë“œíœìŠ¤ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        # ì‹œì‘/ë ì½”ë“œíœìŠ¤ ì œê±° (ê¸°ì¡´)
        text = re.sub(r'^```markdown\n?', '', text, flags=re.MULTILINE)
        text = re.sub(r'\n?```$', '', text, flags=re.MULTILINE)
        
        # âœ… Phase 0.3.2: ì¤‘ê°„ ì½”ë“œíœìŠ¤ë„ ì œê±°
        text = re.sub(r'\n```markdown\n', '\n\n', text)
        text = re.sub(r'\n```\n', '\n\n', text)
        
        return text