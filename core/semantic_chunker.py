"""
core/semantic_chunker.py
PRISM Phase 5.2.0 - Semantic Chunker

ëª©ì : ì˜ë¯¸ ë‹¨ìœ„ ê¸°ë°˜ ì§€ëŠ¥í˜• ì²­í‚¹
- í˜ì´ì§€ ê²½ê³„ê°€ ì•„ë‹Œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• 
- í‘œ/ë‹¤ì´ì–´ê·¸ë¨ ë¬´ê²°ì„± ë³´ì¡´
- RAG ê²€ìƒ‰ ìµœì í™”

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-25
Version: 5.2.0
"""

import re
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)


class SemanticChunker:
    """
    ì˜ë¯¸ ë‹¨ìœ„ ê¸°ë°˜ ì²­í‚¹ ì—”ì§„
    
    ì „ëµ:
    1. í—¤ë” ê¸°ì¤€ ì„¹ì…˜ ë¶„í•  (##, ###)
    2. í‘œ/ë‹¤ì´ì–´ê·¸ë¨ ë¬´ê²°ì„± ë³´ì¡´
    3. ëª©í‘œ ì²­í¬ í¬ê¸° ìœ ì§€ (800-1000ì)
    4. ì²­í¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    """
    
    def __init__(
        self,
        min_chunk_size: int = 600,
        max_chunk_size: int = 1200,
        target_chunk_size: int = 900
    ):
        """
        Args:
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸°
            max_chunk_size: ìµœëŒ€ ì²­í¬ í¬ê¸°
            target_chunk_size: ëª©í‘œ ì²­í¬ í¬ê¸°
        """
        self.min_chunk_size = min_chunk_size
        self.max_chunk_size = max_chunk_size
        self.target_chunk_size = target_chunk_size
        
        logger.info(f"âœ… SemanticChunker ì´ˆê¸°í™”")
        logger.info(f"   ì²­í¬ í¬ê¸°: {min_chunk_size}-{max_chunk_size} (ëª©í‘œ: {target_chunk_size})")
    
    def chunk(self, markdown: str) -> List[Dict[str, Any]]:
        """
        Markdownì„ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì²­í‚¹
        
        Args:
            markdown: ì „ì²´ Markdown ë¬¸ìì—´
        
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸: [
                {
                    'chunk_id': str,
                    'content': str,
                    'char_count': int,
                    'type': 'section' | 'table' | 'mixed',
                    'headers': List[str],
                    'page_hint': int  # í˜ì´ì§€ ë²ˆí˜¸ íŒíŠ¸
                },
                ...
            ]
        """
        logger.info(f"ğŸ”— SemanticChunking ì‹œì‘: {len(markdown)} ê¸€ì")
        
        # Step 1: ì„¹ì…˜ ë¶„í• 
        sections = self._split_by_headers(markdown)
        logger.info(f"   ì„¹ì…˜ ë¶„í• : {len(sections)}ê°œ")
        
        # Step 2: ì²­í¬ ìƒì„±
        chunks = []
        for i, section in enumerate(sections):
            section_chunks = self._chunk_section(section, start_id=len(chunks))
            chunks.extend(section_chunks)
        
        logger.info(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        # Step 3: ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for chunk in chunks:
            self._add_metadata(chunk, markdown)
        
        return chunks
    
    def _split_by_headers(self, markdown: str) -> List[Dict[str, Any]]:
        """
        í—¤ë” ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ ë¶„í• 
        
        Returns:
            [
                {
                    'header': str,
                    'level': int,  # 1, 2, 3
                    'content': str,
                    'has_table': bool
                },
                ...
            ]
        """
        sections = []
        
        # í—¤ë” íŒ¨í„´ (##, ###)
        header_pattern = r'^(#{1,3})\s+(.+)$'
        
        lines = markdown.split('\n')
        current_section = None
        
        for line in lines:
            match = re.match(header_pattern, line)
            
            if match:
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section:
                    sections.append(current_section)
                
                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                level = len(match.group(1))
                header = match.group(2).strip()
                
                current_section = {
                    'header': header,
                    'level': level,
                    'content': line + '\n',
                    'has_table': False
                }
            else:
                if current_section:
                    current_section['content'] += line + '\n'
                    
                    # í‘œ ê°ì§€
                    if '|' in line and '---' not in line:
                        current_section['has_table'] = True
                else:
                    # í—¤ë” ì—†ëŠ” ì²« ë¶€ë¶„
                    if not sections:
                        current_section = {
                            'header': '(Intro)',
                            'level': 1,
                            'content': line + '\n',
                            'has_table': False
                        }
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜
        if current_section:
            sections.append(current_section)
        
        return sections
    
    def _chunk_section(
        self,
        section: Dict[str, Any],
        start_id: int
    ) -> List[Dict[str, Any]]:
        """
        ì„¹ì…˜ì„ ì ì ˆí•œ í¬ê¸°ë¡œ ì²­í‚¹
        
        ì „ëµ:
        - í‘œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ 1ê°œ ì²­í¬ (ë¬´ê²°ì„± ë³´ì¡´)
        - í‘œ ì—†ìœ¼ë©´ ëª©í‘œ í¬ê¸°ë¡œ ë¶„í• 
        """
        content = section['content']
        char_count = len(content)
        
        # í‘œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ 1ê°œ ì²­í¬
        if section['has_table']:
            return [{
                'chunk_id': f'chunk_{start_id}',
                'content': content,
                'char_count': char_count,
                'type': 'table',
                'headers': [section['header']],
                'page_hint': self._extract_page_hint(content)
            }]
        
        # í‘œ ì—†ê³  ëª©í‘œ í¬ê¸° ì´í•˜ë©´ 1ê°œ ì²­í¬
        if char_count <= self.max_chunk_size:
            return [{
                'chunk_id': f'chunk_{start_id}',
                'content': content,
                'char_count': char_count,
                'type': 'section',
                'headers': [section['header']],
                'page_hint': self._extract_page_hint(content)
            }]
        
        # í‘œ ì—†ê³  ëª©í‘œ í¬ê¸° ì´ˆê³¼ â†’ ë¶„í• 
        return self._split_long_section(section, start_id)
    
    def _split_long_section(
        self,
        section: Dict[str, Any],
        start_id: int
    ) -> List[Dict[str, Any]]:
        """
        ê¸´ ì„¹ì…˜ì„ ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• 
        
        ì „ëµ:
        - ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„í•  (\n\n)
        - ëª©í‘œ í¬ê¸° ìœ ì§€
        """
        content = section['content']
        paragraphs = content.split('\n\n')
        
        chunks = []
        current_chunk = ''
        chunk_headers = [section['header']]
        
        for para in paragraphs:
            if not para.strip():
                continue
            
            # í˜„ì¬ ì²­í¬ + ë¬¸ë‹¨
            test_chunk = current_chunk + '\n\n' + para if current_chunk else para
            
            if len(test_chunk) > self.max_chunk_size and current_chunk:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                chunks.append({
                    'chunk_id': f'chunk_{start_id + len(chunks)}',
                    'content': current_chunk.strip(),
                    'char_count': len(current_chunk),
                    'type': 'section',
                    'headers': chunk_headers.copy(),
                    'page_hint': self._extract_page_hint(current_chunk)
                })
                
                # ìƒˆ ì²­í¬ ì‹œì‘
                current_chunk = para
            else:
                current_chunk = test_chunk
        
        # ë§ˆì§€ë§‰ ì²­í¬
        if current_chunk.strip():
            chunks.append({
                'chunk_id': f'chunk_{start_id + len(chunks)}',
                'content': current_chunk.strip(),
                'char_count': len(current_chunk),
                'type': 'section',
                'headers': chunk_headers.copy(),
                'page_hint': self._extract_page_hint(current_chunk)
            })
        
        return chunks
    
    def _extract_page_hint(self, content: str) -> int:
        """
        ë‚´ìš©ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ íŒíŠ¸ ì¶”ì¶œ
        
        íŒ¨í„´: "# Page 3" â†’ 3
        """
        match = re.search(r'#\s+Page\s+(\d+)', content)
        if match:
            return int(match.group(1))
        return 0
    
    def _add_metadata(self, chunk: Dict[str, Any], full_markdown: str):
        """
        ì²­í¬ì— ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        
        ë©”íƒ€ë°ì´í„°:
        - position: ì „ì²´ ë¬¸ì„œ ë‚´ ìœ„ì¹˜ (0~1)
        - contains_numbers: ìˆ«ì ë°ì´í„° í¬í•¨ ì—¬ë¶€
        """
        # ìœ„ì¹˜ ê³„ì‚°
        chunk_start = full_markdown.find(chunk['content'])
        if chunk_start >= 0:
            chunk['position'] = chunk_start / len(full_markdown)
        else:
            chunk['position'] = 0.0
        
        # ìˆ«ì ë°ì´í„° ê²€ì¶œ
        content = chunk['content']
        number_patterns = [
            r'\d{1,2}:\d{2}',  # ì‹œê°„
            r'\d+ë¶„',          # ë¶„
            r'\d+ì›',          # ê¸ˆì•¡
            r'\d+%'            # í¼ì„¼íŠ¸
        ]
        
        chunk['contains_numbers'] = any(
            re.search(pattern, content) for pattern in number_patterns
        )