"""
core/semantic_chunker.py
PRISM Phase 5.7.4.1 - SemanticChunker ê¸´ê¸‰ íŒ¨ì¹˜

âœ… ìˆ˜ì • ë‚´ì—­:
1. buffer['article_title'] NoneType ì—ëŸ¬ ìˆ˜ì •
2. ì¡°ë¬¸ ë³‘í•© ë¡œì§ ì•ˆì •í™”
3. ë¹ˆ ì¡°ë¬¸ ì²˜ë¦¬ ê°•í™”

Author: ì´ì„œì˜ (Backend Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-11-02
Version: 5.7.4.1 Hotfix
"""

import re
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)


class SemanticChunker:
    """
    Phase 5.7.4.1 SemanticChunker (ê¸´ê¸‰ íŒ¨ì¹˜)
    
    âœ… ì¡°ë¬¸ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹
    âœ… NoneType ì—ëŸ¬ ìˆ˜ì •
    """
    
    def __init__(
        self,
        min_chunk_size: int = 600,
        max_chunk_size: int = 1200,
        target_chunk_size: int = 900  # â† target_size â†’ target_chunk_size
    ):
        """ì´ˆê¸°í™”"""
        self.min_size = min_chunk_size
        self.max_size = max_chunk_size
        self.target_size = target_chunk_size  # â† ë‚´ë¶€ì ìœ¼ë¡œëŠ” target_size ì‚¬ìš©
        
        logger.info("âœ… SemanticChunker v5.7.4.1 ì´ˆê¸°í™” (ê¸´ê¸‰ íŒ¨ì¹˜)")
        logger.info(f"   ì²­í¬ í¬ê¸°: {min_chunk_size}-{max_chunk_size} (ëª©í‘œ: {target_chunk_size})")
    
    def chunk(self, content: str) -> List[Dict[str, Any]]:
        """
        âœ… Phase 5.7.4.1: ì¡°ë¬¸ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹ (ê¸´ê¸‰ íŒ¨ì¹˜)
        
        Args:
            content: Markdown ì „ì²´ ë‚´ìš©
        
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ”— SemanticChunking v5.7.4.1 ì‹œì‘: {len(content)} ê¸€ì")
        
        # Step 1: ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ë¶„í• 
        article_sections = self._split_by_article(content)
        logger.info(f"   ì¡°ë¬¸ ë¶„í• : {len(article_sections['sections'])}ê°œ ì¡°ë¬¸")
        
        # Step 2: ê¸¸ì´ ê¸°ë°˜ ì¡°ì •
        adjusted_sections = self._adjust_by_length(article_sections['sections'])
        
        # Step 3: ì²­í¬ ìƒì„±
        chunks = []
        for i, section in enumerate(adjusted_sections, 1):
            chunk = {
                'id': f'chunk_{i}',
                'content': section['content'],
                'metadata': {
                    'article_no': section['article_no'],
                    'article_title': section['article_title'],
                    'char_count': len(section['content']),
                    'chunk_index': i
                }
            }
            chunks.append(chunk)
        
        logger.info(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        return chunks
    
    def _split_by_article(self, content: str) -> Dict[str, Any]:
        """
        âœ… Phase 5.7.4: ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ë¶„í• 
        
        ## ì œ1ì¡°(ëª©ì )
        ...
        ## ì œ2ì¡°(ì ìš©ë²”ìœ„)
        ...
        
        ê° ì¡°ë¬¸ì„ ë…ë¦½ëœ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• 
        """
        sections = []
        lines = content.split('\n')
        
        # ì¡°ë¬¸ íŒ¨í„´: ## ì œ1ì¡°(ëª©ì )
        article_pattern = re.compile(r'^##\s*(ì œ\s?\d+ì¡°(?:ì˜\s?\d+)?)\s*(?:\(([^)]+)\))?')
        
        current_section = None
        
        for line in lines:
            # ì¡°ë¬¸ ì‹œì‘ ê°ì§€
            match = article_pattern.match(line)
            
            if match:
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section:
                    sections.append(current_section)
                
                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                current_section = {
                    'article_no': match.group(1),  # ì œ1ì¡°
                    'article_title': match.group(2) or '',  # ëª©ì 
                    'content': line + '\n'
                }
            else:
                # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                if current_section:
                    current_section['content'] += line + '\n'
                else:
                    # ì¡°ë¬¸ ì‹œì‘ ì „ ë‚´ìš© (í—¤ë” ë“±)
                    if not sections:
                        sections.append({
                            'article_no': None,
                            'article_title': 'header',
                            'content': line + '\n'
                        })
                    else:
                        sections[-1]['content'] += line + '\n'
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section:
            sections.append(current_section)
        
        return {
            'sections': sections,
            'total': len(sections)
        }
    
    def _adjust_by_length(self, sections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        âœ… Phase 5.7.4.1: ê¸¸ì´ ê¸°ë°˜ ì¡°ì • (ê¸´ê¸‰ íŒ¨ì¹˜)
        
        - ë„ˆë¬´ ì§§ì€ ì¡°ë¬¸: ë‹¤ìŒ ì¡°ë¬¸ê³¼ ë³‘í•©
        - ë„ˆë¬´ ê¸´ ì¡°ë¬¸: ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¡°ë¬¸ ë‹¨ìœ„ ë³´ì¡´)
        - ì ë‹¹í•œ ì¡°ë¬¸: ê·¸ëŒ€ë¡œ ìœ ì§€
        
        âœ… NoneType ì—ëŸ¬ ìˆ˜ì •:
        - buffer['article_title'] ì´ˆê¸°í™”ë¥¼ None â†’ '' ë³€ê²½
        - ë³‘í•© ì‹œ None ì²´í¬ ì¶”ê°€
        """
        adjusted = []
        
        # âœ… ìˆ˜ì •: None ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”
        buffer = {
            'article_no': None,
            'article_title': '',  # â† Noneì—ì„œ '' ë³€ê²½
            'content': ''
        }
        
        for section in sections:
            section_size = len(section['content'])
            
            # Case 1: í—¤ë” ì„¹ì…˜ (ì¡°ë¬¸ ì—†ìŒ) â†’ ë²„í¼ì— ì¶”ê°€
            if section['article_no'] is None:
                buffer['content'] += section['content']
                continue
            
            # Case 2: ì‘ì€ ì¡°ë¬¸ â†’ ë²„í¼ì— ì¶”ê°€
            if section_size < self.min_size:
                # âœ… ìˆ˜ì •: None ì²´í¬ ì¶”ê°€
                if buffer['article_no'] is None:
                    buffer['article_no'] = section['article_no']
                else:
                    buffer['article_no'] += f', {section["article_no"]}'
                
                # âœ… ìˆ˜ì •: ë¹ˆ ë¬¸ìì—´ ì²´í¬
                if buffer['article_title']:
                    buffer['article_title'] += f', {section["article_title"]}'
                else:
                    buffer['article_title'] = section['article_title']
                
                buffer['content'] += section['content']
                
                # ë²„í¼ê°€ ìµœì†Œ í¬ê¸° ì´ìƒì´ë©´ ì²­í¬ ìƒì„±
                if len(buffer['content']) >= self.min_size:
                    adjusted.append(buffer.copy())
                    # âœ… ìˆ˜ì •: ì´ˆê¸°í™” ì‹œ ë¹ˆ ë¬¸ìì—´ ì‚¬ìš©
                    buffer = {
                        'article_no': None,
                        'article_title': '',
                        'content': ''
                    }
            
            # Case 3: ì ë‹¹í•œ í¬ê¸° ë˜ëŠ” í° ì¡°ë¬¸
            else:
                # ë²„í¼ì— ë‚´ìš©ì´ ìˆìœ¼ë©´ ë¨¼ì € ì €ì¥
                if buffer['content']:
                    adjusted.append(buffer.copy())
                    # âœ… ìˆ˜ì •: ì´ˆê¸°í™” ì‹œ ë¹ˆ ë¬¸ìì—´ ì‚¬ìš©
                    buffer = {
                        'article_no': None,
                        'article_title': '',
                        'content': ''
                    }
                
                # í˜„ì¬ ì¡°ë¬¸ ì €ì¥
                adjusted.append(section.copy())
        
        # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬
        if buffer['content']:
            adjusted.append(buffer)
        
        return adjusted


# âœ… í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ í´ë˜ìŠ¤ëª… ì§€ì›
class SemanticChunkerV574(SemanticChunker):
    """v5.7.4 í˜¸í™˜ì„± ë˜í¼"""
    pass