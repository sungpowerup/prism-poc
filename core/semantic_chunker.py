"""
core/semantic_chunker.py
PRISM Phase 0.2 Hotfix - SemanticChunker with Fail-safe Chunking

âœ… Phase 0.2 ê¸´ê¸‰ ìˆ˜ì •:
1. ì¡°ë¬¸ í—¤ë” íŒ¨í„´ í™•ì¥ (### ì§€ì›)
2. Fail-safe ê¸¸ì´ ë¶„í•  ê°€ë“œ (ì¡°ë¬¸ < 2ê°œ ì‹œ)
3. "ì¡°ì˜N" íŒ¨í„´ ì§€ì›
4. ë²ˆí˜¸ëª©ë¡ ê³¼ë°€ ë¶„í•  ê°•í™”

Author: ì´ì„œì˜ (Backend Lead) + GPT í”¼ë“œë°±
Date: 2025-11-06
Version: Phase 0.2 Hotfix
"""

import re
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)


class SemanticChunker:
    """
    Phase 0.2 SemanticChunker (Fail-safe + í—¤ë” íŒ¨í„´ í™•ì¥)
    
    âœ… Phase 0.2 ê°œì„ :
    - ì¡°ë¬¸ í—¤ë” íŒ¨í„´: ### í¬í•¨ (Markdown)
    - Fail-safe: ì¡°ë¬¸ < 2ê°œ ì‹œ ê¸¸ì´ ê¸°ë°˜ ë¶„í• 
    - "ì¡°ì˜N" íŒ¨í„´ ì§€ì›
    - ì²­í‚¹ í•˜ë“œ ê°€ë“œ (1200ì ê°•ì œ flush)
    """
    
    # âœ… Phase 0.2: ì¡°ë¬¸ íŒ¨í„´ (Markdown í—¤ë” í¬í•¨)
    ARTICLE_PATTERN = re.compile(
        r'^\s*#{0,6}\s*(ì œ\s?\d+ì¡°(?:ì˜\s?\d+)?)',
        re.MULTILINE
    )
    
    # ë²ˆí˜¸ëª©ë¡ íŒ¨í„´ (1. 2. 3.)
    NUMBER_LIST_PATTERN = re.compile(r'^\s*\d+\.\s', re.MULTILINE)
    
    def __init__(
        self,
        min_chunk_size: int = 600,
        max_chunk_size: int = 1200,
        target_chunk_size: int = 900
    ):
        """ì´ˆê¸°í™”"""
        self.min_size = min_chunk_size
        self.max_size = max_chunk_size
        self.target_size = target_chunk_size
        
        logger.info("âœ… SemanticChunker Phase 0.2 ì´ˆê¸°í™” (Fail-safe)")
        logger.info(f"   ì²­í¬ í¬ê¸°: {min_chunk_size}-{max_chunk_size} (ëª©í‘œ: {target_chunk_size})")
        logger.info("   í•˜ë“œ ê°€ë“œ: 1200ì ê°•ì œ flush")
        logger.info("   Fail-safe: ì¡°ë¬¸ < 2ê°œ ì‹œ ê¸¸ì´ ë¶„í• ")
        logger.info("   ì¡°ë¬¸ íŒ¨í„´: ### í—¤ë” ì§€ì›")
    
    def chunk(self, content: str) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.2: ì¡°ë¬¸ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹ (Fail-safe)
        
        Args:
            content: Markdown ì „ì²´ ë‚´ìš©
        
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ”— SemanticChunking Phase 0.2 ì‹œì‘: {len(content)} ê¸€ì")
        
        # Step 0: ì½”ë“œíœìŠ¤ ì œê±°
        content = self._strip_code_fences(content)
        
        # Step 1: ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ë¶„í• 
        article_sections = self._split_by_article(content)
        detected_articles = len(article_sections)
        
        logger.info(f"   ì¡°ë¬¸ ê°ì§€: {detected_articles}ê°œ")
        
        # âœ… Phase 0.2: Fail-safe - ì¡°ë¬¸ < 2ê°œ ì‹œ ê¸¸ì´ ê¸°ë°˜ ë¶„í• 
        if detected_articles < 2:
            logger.warning(f"  âš ï¸ ì¡°ë¬¸ ë¶€ì¡± ({detected_articles}ê°œ) â†’ Fail-safe ê¸¸ì´ ë¶„í• ")
            chunks = self._fallback_split_by_length(content)
            logger.info(f"   âœ… Fail-safe ì²­í¬ ìƒì„±: {len(chunks)}ê°œ")
            return chunks
        
        # Step 2: ê¸¸ì´ ê¸°ë°˜ ì¡°ì • + í•˜ë“œ ê°€ë“œ
        adjusted_sections = self._adjust_by_length(article_sections)
        
        logger.info(f"   ê¸¸ì´ ì¡°ì • í›„: {len(adjusted_sections)}ê°œ ì„¹ì…˜")
        
        # Step 3: ì²­í¬ ìƒì„±
        chunks = []
        for i, section in enumerate(adjusted_sections, 1):
            chunk = {
                'id': f'chunk_{i}',
                'content': section['content'],
                'metadata': {
                    'article_no': section['article_no'],
                    'article_title': section['article_title'],
                    'char_count': len(section['content']),
                    'chunk_index': i
                }
            }
            chunks.append(chunk)
        
        logger.info(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        return chunks
    
    def _strip_code_fences(self, content: str) -> str:
        """ì½”ë“œíœìŠ¤ ì œê±°"""
        # ì•ìª½ ì½”ë“œíœìŠ¤ ì œê±°
        content = re.sub(r'^```[a-z]*\s*\n', '', content, flags=re.MULTILINE)
        
        # ë’¤ìª½ ì½”ë“œíœìŠ¤ ì œê±°
        content = re.sub(r'\n```\s*$', '', content, flags=re.MULTILINE)
        
        # ì•ë’¤ ê³µë°± ì •ë¦¬
        content = content.strip()
        
        return content
    
    def _split_by_article(self, content: str) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.2: ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ë¶„í•  (### í—¤ë” ì§€ì›)
        
        íŒ¨í„´:
        - ### ì œ1ì¡°(ëª©ì )
        - ì œ1ì¡°(ëª©ì ) (í—¤ë” ì—†ìŒ)
        - ### ì œ7ì¡°ì˜2(ì™¸êµ­ì¸ì˜ ì±„ìš©)
        
        Args:
            content: Markdown í…ìŠ¤íŠ¸
        
        Returns:
            ì¡°ë¬¸ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        """
        sections = []
        
        # ì¡°ë¬¸ í—¤ë” ì°¾ê¸°
        matches = list(self.ARTICLE_PATTERN.finditer(content))
        
        if not matches:
            # ì¡°ë¬¸ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ
            return [{
                'content': content,
                'article_no': '',
                'article_title': ''
            }]
        
        # ê° ì¡°ë¬¸ë³„ë¡œ ë¶„í• 
        for i, match in enumerate(matches):
            article_full = match.group(1)  # "ì œ1ì¡°", "ì œ7ì¡°ì˜2"
            start_pos = match.start()
            
            # ë‹¤ìŒ ì¡°ë¬¸ê¹Œì§€ ë˜ëŠ” ëê¹Œì§€
            if i < len(matches) - 1:
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(content)
            
            article_content = content[start_pos:end_pos].strip()
            
            # ì¡°ë¬¸ ë²ˆí˜¸ì™€ ì œëª© ì¶”ì¶œ
            article_no, article_title = self._parse_article_header(article_content)
            
            sections.append({
                'content': article_content,
                'article_no': article_no,
                'article_title': article_title
            })
        
        return sections
    
    def _parse_article_header(self, content: str) -> tuple:
        """
        ì¡°ë¬¸ í—¤ë” íŒŒì‹±
        
        ì…ë ¥ ì˜ˆ:
        - "### ì œ1ì¡°(ëª©ì )"
        - "ì œ7ì¡°ì˜2(ì™¸êµ­ì¸ì˜ ì±„ìš©)"
        
        Returns:
            (article_no, article_title)
        """
        # ì²« ì¤„ ì¶”ì¶œ
        first_line = content.split('\n')[0].strip()
        
        # "### ì œ1ì¡°(ëª©ì )" â†’ "ì œ1ì¡°", "ëª©ì "
        match = re.search(
            r'(ì œ\s?\d+ì¡°(?:ì˜\s?\d+)?)\s*(?:\(([^)]*)\))?',
            first_line
        )
        
        if match:
            article_no = match.group(1).replace(' ', '')  # "ì œ1ì¡°"
            article_title = match.group(2) if match.group(2) else ''
            return article_no, article_title
        
        return '', ''
    
    def _adjust_by_length(self, sections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.2: ê¸¸ì´ ê¸°ë°˜ ì¡°ì • + í•˜ë“œ ê°€ë“œ
        
        ì „ëµ:
        1. ê° ì„¹ì…˜ì„ target_sizeì— ë§ì¶° ë¶„í• 
        2. í•˜ë“œ ê°€ë“œ: max_size ì´ˆê³¼ ì‹œ ê°•ì œ ë¶„í• 
        3. ë²ˆí˜¸ëª©ë¡ ê³¼ë°€ ì‹œ ë¶„í• 
        
        Args:
            sections: ì¡°ë¬¸ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì¡°ì •ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        """
        adjusted = []
        
        for section in sections:
            content = section['content']
            char_count = len(content)
            
            # 1) í•˜ë“œ ê°€ë“œ: max_size ì´ˆê³¼ ì‹œ ê°•ì œ ë¶„í• 
            if char_count > self.max_size:
                logger.debug(f"      í•˜ë“œ ê°€ë“œ ë°œë™: {char_count}ì â†’ ë¶„í• ")
                
                # ë²ˆí˜¸ëª©ë¡ ê³¼ë°€ ì²´í¬
                if self._is_number_list_dense(content):
                    logger.debug("      ë²ˆí˜¸ëª©ë¡ ê³¼ë°€ ê°ì§€ â†’ ë¶„í• ")
                    sub_sections = self._split_by_number_list(content, section)
                    adjusted.extend(sub_sections)
                else:
                    # ì¼ë°˜ ê¸¸ì´ ë¶„í• 
                    sub_sections = self._split_by_length(content, section)
                    adjusted.extend(sub_sections)
            
            # 2) target_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            else:
                adjusted.append(section)
        
        return adjusted
    
    def _is_number_list_dense(self, content: str) -> bool:
        """
        ë²ˆí˜¸ëª©ë¡ ê³¼ë°€ ì²´í¬
        
        ê¸°ì¤€: ì—°ì† ë²ˆí˜¸ëª©ë¡ 10ê°œ ì´ìƒ
        
        Args:
            content: í…ìŠ¤íŠ¸
        
        Returns:
            True if ê³¼ë°€
        """
        matches = list(self.NUMBER_LIST_PATTERN.finditer(content))
        return len(matches) >= 10
    
    def _split_by_number_list(
        self, 
        content: str, 
        section: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ë²ˆí˜¸ëª©ë¡ ê¸°ì¤€ ë¶„í• 
        
        ì „ëµ: 10ê°œ í•­ëª©ë§ˆë‹¤ ë¶„í• 
        
        Args:
            content: í…ìŠ¤íŠ¸
            section: ì›ë³¸ ì„¹ì…˜
        
        Returns:
            ë¶„í• ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        """
        lines = content.split('\n')
        sub_sections = []
        current_chunk = []
        number_count = 0
        
        for line in lines:
            current_chunk.append(line)
            
            # ë²ˆí˜¸ëª©ë¡ ì¹´ìš´íŠ¸
            if self.NUMBER_LIST_PATTERN.match(line):
                number_count += 1
            
            # 10ê°œë§ˆë‹¤ ë¶„í• 
            if number_count >= 10:
                chunk_content = '\n'.join(current_chunk)
                sub_sections.append({
                    'content': chunk_content,
                    'article_no': section['article_no'],
                    'article_title': section['article_title']
                })
                current_chunk = []
                number_count = 0
        
        # ë‚¨ì€ ë¶€ë¶„
        if current_chunk:
            chunk_content = '\n'.join(current_chunk)
            sub_sections.append({
                'content': chunk_content,
                'article_no': section['article_no'],
                'article_title': section['article_title']
            })
        
        return sub_sections
    
    def _split_by_length(
        self, 
        content: str, 
        section: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ì¼ë°˜ ê¸¸ì´ ê¸°ì¤€ ë¶„í• 
        
        Args:
            content: í…ìŠ¤íŠ¸
            section: ì›ë³¸ ì„¹ì…˜
        
        Returns:
            ë¶„í• ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        """
        lines = content.split('\n')
        sub_sections = []
        current_chunk = []
        current_length = 0
        
        for line in lines:
            line_length = len(line) + 1  # +1 for newline
            
            # target_size ì´ˆê³¼ ì‹œ ë¶„í• 
            if current_length + line_length > self.target_size and current_chunk:
                chunk_content = '\n'.join(current_chunk)
                sub_sections.append({
                    'content': chunk_content,
                    'article_no': section['article_no'],
                    'article_title': section['article_title']
                })
                current_chunk = [line]
                current_length = line_length
            else:
                current_chunk.append(line)
                current_length += line_length
        
        # ë‚¨ì€ ë¶€ë¶„
        if current_chunk:
            chunk_content = '\n'.join(current_chunk)
            sub_sections.append({
                'content': chunk_content,
                'article_no': section['article_no'],
                'article_title': section['article_title']
            })
        
        return sub_sections
    
    def _fallback_split_by_length(self, content: str) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.2: Fail-safe ê¸¸ì´ ê¸°ë°˜ ë¶„í• 
        
        ì¡°ë¬¸ì´ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ ì‚¬ìš©
        
        ì „ëµ:
        - target_size(900ì) ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
        - ë¬¸ë‹¨ ê²½ê³„ ìš°ì„ 
        
        Args:
            content: Markdown í…ìŠ¤íŠ¸
        
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        paragraphs = content.split('\n\n')
        
        current_chunk = []
        current_length = 0
        
        for para in paragraphs:
            para_length = len(para) + 2  # +2 for \n\n
            
            # target_size ì´ˆê³¼ ì‹œ ë¶„í• 
            if current_length + para_length > self.target_size and current_chunk:
                chunk_content = '\n\n'.join(current_chunk)
                chunks.append({
                    'id': f'chunk_{len(chunks) + 1}',
                    'content': chunk_content,
                    'metadata': {
                        'article_no': '',
                        'article_title': '',
                        'char_count': len(chunk_content),
                        'chunk_index': len(chunks) + 1,
                        'fallback': True
                    }
                })
                current_chunk = [para]
                current_length = para_length
            else:
                current_chunk.append(para)
                current_length += para_length
        
        # ë‚¨ì€ ë¶€ë¶„
        if current_chunk:
            chunk_content = '\n\n'.join(current_chunk)
            chunks.append({
                'id': f'chunk_{len(chunks) + 1}',
                'content': chunk_content,
                'metadata': {
                    'article_no': '',
                    'article_title': '',
                    'char_count': len(chunk_content),
                    'chunk_index': len(chunks) + 1,
                    'fallback': True
                }
            })
        
        logger.info(f"      Fail-safe ë¶„í• : {len(chunks)}ê°œ ì²­í¬ (í‰ê·  {sum(len(c['content']) for c in chunks) // len(chunks)}ì)")
        
        return chunks