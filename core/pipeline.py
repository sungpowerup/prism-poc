"""
core/pipeline.py
PRISM Phase 4.2 - Pipeline (ë©€í‹°ìŠ¤í… ê²€ì¦ ë° ì²­í‚¹)

âœ… Phase 4.2 ê°œì„ ì‚¬í•­:
1. 2-Pass VLM ì²˜ë¦¬
2. ìë™ í’ˆì§ˆ ê²€ì¦
3. ì¬ì‹œë„ ë¡œì§ ê°•í™”
4. ì²­í‚¹ ìë™ ìƒì„±

Author: ì´ì„œì˜ (Backend Lead), ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-23
Version: 4.2
"""

import logging
from typing import List, Dict, Any, Optional
import time
import uuid
import re

logger = logging.getLogger(__name__)


class Phase42Pipeline:
    """
    Phase 4.2 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    íŠ¹ì§•:
    - 2-Pass ë©€í‹°ìŠ¤í… ì²˜ë¦¬
    - ìë™ í’ˆì§ˆ ê²€ì¦
    - ê°•í™”ëœ ì¬ì‹œë„
    """
    
    def __init__(self, pdf_processor, vlm_service, storage):
        """
        Args:
            pdf_processor: PDFProcessor ì¸ìŠ¤í„´ìŠ¤
            vlm_service: VLMServiceV42 ì¸ìŠ¤í„´ìŠ¤
            storage: Storage ì¸ìŠ¤í„´ìŠ¤
        """
        self.pdf_processor = pdf_processor
        self.vlm_service = vlm_service
        self.storage = storage
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: int = 20,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (Phase 4.2)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        session_id = str(uuid.uuid4())[:8]
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ Phase 4.2 ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        logger.info(f"Session ID: {session_id}")
        logger.info(f"{'='*60}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 1: PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ“„ PDF ë³€í™˜ ì¤‘ (300 DPI)...", 0)
        
        logger.info("\n[Stage 1] PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜")
        images = self.pdf_processor.pdf_to_images(pdf_path, max_pages=max_pages, dpi=300)
        logger.info(f"âœ… {len(images)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        
        if not images:
            logger.error("âŒ PDF ë³€í™˜ ì‹¤íŒ¨")
            return {
                'status': 'error',
                'error': 'PDF ë³€í™˜ ì‹¤íŒ¨',
                'session_id': session_id
            }
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 2: 2-Pass VLM ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        results = []
        success_count = 0
        error_count = 0
        retry_count = 0
        low_confidence_count = 0
        
        for page_num, img_data in enumerate(images):
            if progress_callback:
                progress = int((page_num / len(images)) * 90)
                progress_callback(
                    f"ğŸ¯ í˜ì´ì§€ {page_num + 1}/{len(images)} 2-Pass ë¶„ì„ ì¤‘...",
                    progress
                )
            
            logger.info(f"\n[Stage 2] í˜ì´ì§€ {page_num + 1} - 2-Pass VLM ë¶„ì„")
            
            # ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3íšŒ)
            max_retries = 3
            attempt = 0
            best_result = None
            best_confidence = 0.0
            
            while attempt < max_retries:
                try:
                    logger.info(f"   ì‹œë„ {attempt + 1}/{max_retries}...")
                    
                    # 2-Pass VLM í˜¸ì¶œ
                    vlm_result = self.vlm_service.analyze_page_multipass(
                        image_data=img_data,
                        page_num=page_num + 1
                    )
                    
                    content = vlm_result.get('content', '')
                    confidence = vlm_result.get('confidence', 0.0)
                    
                    if not content:
                        logger.warning(f"   âš ï¸ VLM ê²°ê³¼ ì—†ìŒ")
                        attempt += 1
                        retry_count += 1
                        continue
                    
                    # í’ˆì§ˆ ê²€ì¦
                    is_valid, error_msg = self._validate_quality(content)
                    
                    if is_valid and confidence >= 0.8:
                        # ì„±ê³µ!
                        success_count += 1
                        logger.info(f"   âœ… ì„±ê³µ ({len(content)} ê¸€ì, ì‹ ë¢°ë„: {confidence:.2f})")
                        
                        results.append({
                            'page_num': page_num + 1,
                            'content': content,
                            'confidence': confidence,
                            'pass1_structure': vlm_result.get('pass1_structure', {}),
                            'retries': attempt
                        })
                        break  # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
                    
                    else:
                        # í’ˆì§ˆ ë¬¸ì œ - ì¬ì‹œë„
                        if confidence < 0.8:
                            logger.warning(f"   âš ï¸ ë‚®ì€ ì‹ ë¢°ë„: {confidence:.2f}")
                            low_confidence_count += 1
                        
                        if error_msg:
                            logger.warning(f"   âš ï¸ í’ˆì§ˆ ë¬¸ì œ: {error_msg}")
                        
                        # ìµœê³  ì ìˆ˜ ì €ì¥
                        if confidence > best_confidence:
                            best_result = vlm_result
                            best_confidence = confidence
                        
                        attempt += 1
                        retry_count += 1
                
                except Exception as e:
                    logger.error(f"   âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    attempt += 1
                    retry_count += 1
            
            # ìµœëŒ€ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ â†’ ìµœì„ ì˜ ê²°ê³¼ ì‚¬ìš©
            if attempt >= max_retries and best_result:
                logger.warning(f"   âš ï¸ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼, ìµœì„  ê²°ê³¼ ì‚¬ìš© (ì‹ ë¢°ë„: {best_confidence:.2f})")
                success_count += 1
                
                results.append({
                    'page_num': page_num + 1,
                    'content': best_result.get('content', ''),
                    'confidence': best_confidence,
                    'pass1_structure': best_result.get('pass1_structure', {}),
                    'retries': attempt,
                    'warning': 'low_confidence'
                })
            
            elif attempt >= max_retries:
                error_count += 1
                logger.error(f"   âŒ í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì™„ì „ ì‹¤íŒ¨")
        
        logger.info(f"\nâœ… VLM ë¶„ì„ ì™„ë£Œ:")
        logger.info(f"   - ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"   - ì‹¤íŒ¨: {error_count}ê°œ")
        logger.info(f"   - ì¬ì‹œë„: {retry_count}íšŒ")
        logger.info(f"   - ë‚®ì€ ì‹ ë¢°ë„: {low_confidence_count}ê°œ")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 3: Markdown í†µí•©
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ“ Markdown ìƒì„± ì¤‘...", 95)
        
        logger.info(f"\n[Stage 3] Markdown í†µí•©")
        
        # ì „ì²´ Markdown ìƒì„±
        full_markdown = self._generate_markdown(results)
        
        logger.info(f"âœ… Markdown ìƒì„± ì™„ë£Œ ({len(full_markdown)} ê¸€ì)")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 4: í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        avg_confidence = sum(r.get('confidence', 0.0) for r in results) / len(results) if results else 0.0
        quality_score = self._calculate_quality_score(results, full_markdown)
        
        logger.info(f"\n[í’ˆì§ˆ ì ìˆ˜]")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 5: ê²°ê³¼ ì €ì¥
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ’¾ ì €ì¥ ì¤‘...", 98)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        result = {
            'status': 'success',
            'session_id': session_id,
            'processing_time': processing_time,
            'pages_processed': len(images),
            'pages_success': success_count,
            'pages_error': error_count,
            'retry_count': retry_count,
            'low_confidence_count': low_confidence_count,
            'avg_confidence': avg_confidence,
            'quality_score': quality_score,
            'total_chars': len(full_markdown),
            'markdown': full_markdown,
            'page_results': results
        }
        
        # DB ì €ì¥
        try:
            self.storage.save_session(result)
            logger.info("âœ… DB ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        if progress_callback:
            progress_callback("âœ… ì™„ë£Œ!", 100)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ‰ Phase 4.2 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
        logger.info(f"   - í˜ì´ì§€ ì„±ê³µ: {success_count}/{len(images)}")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
        logger.info(f"   - ì´ ê¸€ì ìˆ˜: {len(full_markdown):,}")
        logger.info(f"{'='*60}\n")
        
        return result
    
    def _validate_quality(self, content: str) -> tuple[bool, Optional[str]]:
        """
        í’ˆì§ˆ ê²€ì¦
        
        Returns:
            (is_valid, error_message)
        """
        # 1. ìµœì†Œ ê¸¸ì´ í™•ì¸
        if len(content) < 100:
            return False, "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ"
        
        # 2. ë°±ë¶„ìœ¨ ê²€ì¦
        percentages = re.findall(r'(\d+\.?\d*)%', content)
        
        if len(percentages) >= 3:
            values = [float(p) for p in percentages]
            
            # ì—°ì†ëœ ë°±ë¶„ìœ¨ ê·¸ë£¹ ì°¾ê¸°
            valid_groups = 0
            for i in range(len(values)):
                group_sum = values[i]
                for j in range(i+1, min(i+10, len(values))):
                    group_sum += values[j]
                    
                    if 99.0 <= group_sum <= 101.0:
                        valid_groups += 1
                        break
                    
                    if group_sum > 105.0:
                        break
            
            # ë°±ë¶„ìœ¨ì´ ìˆëŠ”ë° ìœ íš¨í•œ ê·¸ë£¹ì´ ì—†ìœ¼ë©´ ë¬¸ì œ
            if valid_groups == 0 and len(values) >= 3:
                return False, f"ë°±ë¶„ìœ¨ í•©ê³„ ê²€ì¦ ì‹¤íŒ¨ (í•©ê³„: {sum(values):.1f}%)"
        
        # 3. ìˆ«ì íŒ¨í„´ í™•ì¸ (ìµœì†Œí•œì˜ ë°ì´í„° ì¡´ì¬)
        numbers = re.findall(r'\d+\.?\d*', content)
        if len(numbers) < 5:
            return False, "ìˆ«ì ë°ì´í„° ë¶€ì¡±"
        
        return True, None
    
    def _calculate_quality_score(self, results: List[Dict], markdown: str) -> float:
        """
        í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0~100)
        
        ê¸°ì¤€:
        - í‰ê·  ì‹ ë¢°ë„: 40%
        - ì²­í‚¹ í’ˆì§ˆ: 30%
        - ë°ì´í„° ë°€ë„: 30%
        """
        if not results:
            return 0.0
        
        # 1. í‰ê·  ì‹ ë¢°ë„ (40ì )
        avg_confidence = sum(r.get('confidence', 0.0) for r in results) / len(results)
        confidence_score = avg_confidence * 40
        
        # 2. ì²­í‚¹ í’ˆì§ˆ (30ì )
        sections = markdown.split('---')
        chunking_score = min(len(sections) * 5, 30)  # ì„¹ì…˜ë‹¹ 5ì , ìµœëŒ€ 30ì 
        
        # 3. ë°ì´í„° ë°€ë„ (30ì )
        numbers = re.findall(r'\d+\.?\d*', markdown)
        data_density = min(len(numbers) / 50 * 30, 30)  # ìˆ«ì 50ê°œë‹¹ 30ì 
        
        total_score = confidence_score + chunking_score + data_density
        
        return min(total_score, 100.0)
    
    def _generate_markdown(self, results: List[Dict[str, Any]]) -> str:
        """
        í˜ì´ì§€ë³„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ Markdownìœ¼ë¡œ í†µí•©
        
        Args:
            results: í˜ì´ì§€ë³„ VLM ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            í†µí•©ëœ Markdown ë¬¸ìì—´
        """
        markdown_parts = []
        
        for result in results:
            page_num = result['page_num']
            content = result['content']
            confidence = result.get('confidence', 0.0)
            retries = result.get('retries', 0)
            
            # ë””ë²„ê·¸ ì •ë³´ (ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
            if retries > 0:
                logger.info(f"   í˜ì´ì§€ {page_num}: {retries}íšŒ ì¬ì‹œë„, ì‹ ë¢°ë„ {confidence:.2f}")
            
            # í˜ì´ì§€ ë‚´ìš© ì¶”ê°€
            markdown_parts.append(content)
            markdown_parts.append("\n\n")
        
        return "".join(markdown_parts).strip()