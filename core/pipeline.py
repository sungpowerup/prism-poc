"""
core/pipeline.py
PRISM Phase 5.7.2.2 Hotfix - Pipeline (Empty Page Count + Diagnostic Logs)

âœ… Phase 5.7.2.2 ê¸´ê¸‰ ìˆ˜ì •:
1. ë¹ˆ í˜ì´ì§€ ì¹´ìš´íŠ¸ ì¶”ê°€ (empty_page_count)
2. DoD æ¯ìˆ˜ ê³„ì‚° ê°œì„ 
3. HybridExtractor v5.7.2.2 í†µí•©
4. ğŸ”´ ì§„ë‹¨ ë¡œê·¸ ì¶”ê°€ (DOD-DIAG)

Author: ì´ì„œì˜ (Backend Lead) + GPT(ë¯¸ì†¡) ì˜ê²¬ ë°˜ì˜
Date: 2025-10-31
Version: 5.7.2.2-diag
"""

import logging
from typing import List, Dict, Any, Optional
import time
import uuid
import json
from pathlib import Path
import statistics

# Phase 5.7.2.2: HybridExtractor v5.7.2.2
try:
    from .hybrid_extractor import HybridExtractor
    from .semantic_chunker import SemanticChunker
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from hybrid_extractor import HybridExtractor
    from semantic_chunker import SemanticChunker

logger = logging.getLogger(__name__)


class Phase53Pipeline:
    """
    Phase 5.7.2.2 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (Empty Page Count + ì§„ë‹¨ ë¡œê·¸)
    
    íŠ¹ì§•:
    - HybridExtractor v5.7.2.2 í†µí•© (í˜ì´ì§€ êµ¬ë¶„ì ì œê±°)
    - ë¹ˆ í˜ì´ì§€ ìë™ Skip (DoD æ¯ìˆ˜ ì œì™¸)
    - ë¹ˆ í˜ì´ì§€ ì¹´ìš´íŠ¸ ì¶”ì 
    - ğŸ”´ ì§„ë‹¨ ë¡œê·¸ (í˜ì´ì§€ ì²˜ë¦¬, DoD ë¶„ëª¨)
    - CV íŒíŠ¸ ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ
    - DSL ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸
    - ê°•í™”ëœ ê²€ì¦ + ì¬ì¶”ì¶œ
    - KVS ì •ê·œí™” + ë³„ë„ ì €ì¥
    - ê´€ì¸¡ì„± ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    - SemanticChunker ìœ ì§€
    """
    
    def __init__(self, pdf_processor, vlm_service, storage=None):
        """
        Args:
            pdf_processor: PDFProcessor ì¸ìŠ¤í„´ìŠ¤
            vlm_service: VLMServiceV50 ì¸ìŠ¤í„´ìŠ¤
            storage: Storage ì¸ìŠ¤í„´ìŠ¤ (Optional)
        """
        self.pdf_processor = pdf_processor
        self.vlm_service = vlm_service
        self.storage = storage
        
        # âœ… Phase 5.7.2.2: HybridExtractor v5.7.2.2 ì´ˆê¸°í™”
        self.extractor = HybridExtractor(vlm_service)
        
        # Phase 5.2.0: SemanticChunker
        self.chunker = SemanticChunker(
            min_chunk_size=600,
            max_chunk_size=1200,
            target_chunk_size=900
        )
        
        logger.info("âœ… Phase 5.7.2.2-diag Pipeline ì´ˆê¸°í™” ì™„ë£Œ (Empty Page Count + ì§„ë‹¨)")
        logger.info("   - HybridExtractor v5.7.2.2-diag: í˜ì´ì§€ êµ¬ë¶„ì ì œê±° + ë¹ˆ í˜ì´ì§€ Skip + ì§„ë‹¨")
        logger.info("   - SemanticChunker: ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹")
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: int = 20,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (Phase 5.7.2.2 + ì§„ë‹¨)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ (ì§„ë‹¨ ì •ë³´ í¬í•¨)
        """
        start_time = time.time()
        session_id = str(uuid.uuid4())[:8]
        
        logger.info(f"ğŸ¯ Phase 5.7.2.2-diag ì²˜ë¦¬ ì‹œì‘")
        logger.info(f"   íŒŒì¼: {pdf_path}")
        logger.info(f"   ì„¸ì…˜: {session_id}")
        logger.info(f"   ìµœëŒ€ í˜ì´ì§€: {max_pages}")
        
        # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ì²˜ë¦¬ ì‹œì‘
        logger.info(f"[DOD-DIAG] pipeline_start, session={session_id}, max_pages={max_pages}")
        
        try:
            # Step 1: PDF â†’ Images
            if progress_callback:
                progress_callback("PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘...", 0.1)
            
            logger.info("ğŸ“„ Step 1: PDF â†’ ì´ë¯¸ì§€ ë³€í™˜")
            images = self.pdf_processor.pdf_to_images(
                pdf_path=pdf_path,
                max_pages=max_pages,
                dpi=300
            )
            
            total_pages = len(images)
            logger.info(f"   âœ… {total_pages}í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
            
            # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ
            logger.info(f"[DOD-DIAG] images_converted, total_pages={total_pages}")
            
            # Step 2: í˜ì´ì§€ë³„ HybridExtractor ì²˜ë¦¬
            page_results = []
            kvs_files = []
            metrics_list = []
            empty_page_count = 0  # âœ… Phase 5.7.2.2: ë¹ˆ í˜ì´ì§€ ì¹´ìš´í„°
            
            for i, image_data in enumerate(images):
                page_num = i + 1
                progress = 0.1 + (0.7 * (i / max(1, total_pages)))
                
                if progress_callback:
                    progress_callback(
                        f"í˜ì´ì§€ {page_num}/{total_pages} ì²˜ë¦¬ ì¤‘...",
                        progress
                    )
                
                logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num}/{total_pages} ì²˜ë¦¬ ì‹œì‘")
                
                # âœ… Phase 5.7.2.2: HybridExtractor v5.7.2.2 í˜¸ì¶œ
                result = self.extractor.extract(image_data, page_num=page_num)
                
                # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: í˜ì´ì§€ë³„ ì²˜ë¦¬ ê²°ê³¼
                is_empty = result.get('is_empty', False)
                content_len = len(result.get('content', ''))
                logger.info(f"[DOD-DIAG] page={page_num}, is_empty={is_empty}, content_len={content_len}, quality={result.get('quality_score', 0):.0f}")
                
                # âœ… ë¹ˆ í˜ì´ì§€ ê°ì§€ (Phase 5.7.2.2)
                if result.get('is_empty', False):
                    empty_page_count += 1
                    logger.info(f"   â„¹ï¸ í˜ì´ì§€ {page_num}: ë¹ˆ í˜ì´ì§€ Skip")
                    
                    # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ë¹ˆ í˜ì´ì§€ Skip
                    logger.info(f"[DOD-DIAG] page={page_num}, action=skip_empty, empty_count={empty_page_count}")
                    
                    continue  # DoD æ¯æ•°ì—ì„œ ì œì™¸
                
                # í˜ì´ì§€ ê²°ê³¼ ìˆ˜ì§‘
                page_results.append({
                    'page_num': page_num,
                    'content': result['content'],
                    'doc_type': result.get('doc_type', 'unknown'),
                    'confidence': result.get('confidence', 0.0),
                    'quality_score': result.get('quality_score', 0.0)
                })
                
                # KVS ì €ì¥
                if result.get('kvs'):
                    kvs_file = f"kvs_page_{page_num}.json"
                    kvs_files.append(kvs_file)
                    # ì‹¤ì œ ì €ì¥ì€ storageê°€ ìˆì„ ë•Œë§Œ
                    if self.storage:
                        self.storage.save_json(kvs_file, result['kvs'])
                
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics_list.append(result['metrics'])
                
                logger.info(f"   âœ… í˜ì´ì§€ {page_num} ì™„ë£Œ: í’ˆì§ˆ {result['quality_score']:.0f}/100")
            
            valid_pages = len(page_results)
            
            # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ì „ì²´ í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ
            logger.info(f"[DOD-DIAG] pages_processed, total={total_pages}, empty={empty_page_count}, valid={valid_pages}")
            logger.info(f"ğŸ“Š ìœ íš¨ í˜ì´ì§€: {valid_pages}/{total_pages} (ë¹ˆ í˜ì´ì§€ {empty_page_count}ê°œ ì œì™¸)")
            
            # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: DoD ë¶„ëª¨ í™•ì¸
            logger.info(f"[DOD-DIAG] dod_denominator_check, pages_total={total_pages}, empty_page_count={empty_page_count}, pages_success={valid_pages}")
            
            # Step 3: Markdown í†µí•©
            if progress_callback:
                progress_callback("Markdown í†µí•© ì¤‘...", 0.8)
            
            logger.info("ğŸ“ Step 3: Markdown í†µí•©")
            markdown_pages = [p['content'] for p in page_results]
            markdown = "\n\n".join(markdown_pages)
            
            logger.info(f"   âœ… Markdown í†µí•© ì™„ë£Œ: {len(markdown)} ê¸€ì")
            
            # Step 4: SemanticChunking
            if progress_callback:
                progress_callback("ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ ì¤‘...", 0.9)
            
            logger.info("âœ‚ï¸ Step 4: SemanticChunking")
            chunks = self.chunker.chunk(markdown)
            
            logger.info(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            
            # Step 5: 5ê°€ì§€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€
            if progress_callback:
                progress_callback("í’ˆì§ˆ í‰ê°€ ì¤‘...", 0.95)
            
            logger.info("ğŸ“Š Step 5: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€")
            
            # 1. ì›ë³¸ ì¶©ì‹¤ë„
            avg_confidence = statistics.mean([p['confidence'] for p in page_results]) if page_results else 0.0
            fidelity_score = avg_confidence * 100
            
            # 2. ì²­í‚¹ í’ˆì§ˆ
            avg_chunk_size = statistics.mean([len(c['content']) for c in chunks]) if chunks else 0
            chunking_score = min(avg_chunk_size / 900 * 100, 100)
            
            # 3. RAG ì í•©ë„
            rag_score = min(len(chunks) / max(1, valid_pages) * 100, 100)
            
            # 4. ë²”ìš©ì„±
            universality_score = 95.0
            
            # 5. ê²½ìŸë ¥
            competitive_score = (fidelity_score + chunking_score + rag_score) / 3
            
            # ì¢…í•©
            overall_score = (
                fidelity_score * 0.3 +
                chunking_score * 0.2 +
                rag_score * 0.2 +
                universality_score * 0.15 +
                competitive_score * 0.15
            )
            
            logger.info(f"   âœ… ì›ë³¸ ì¶©ì‹¤ë„: {fidelity_score:.0f}/100")
            logger.info(f"   âœ… ì²­í‚¹ í’ˆì§ˆ: {chunking_score:.0f}/100")
            logger.info(f"   âœ… RAG ì í•©ë„: {rag_score:.0f}/100")
            logger.info(f"   âœ… ë²”ìš©ì„±: {universality_score:.0f}/100")
            logger.info(f"   âœ… ê²½ìŸë ¥: {competitive_score:.0f}/100")
            logger.info(f"   ğŸ¯ ì¢…í•©: {overall_score:.0f}/100")
            
            # ì™„ë£Œ
            processing_time = time.time() - start_time
            
            result = {
                'status': 'success',
                'version': '5.7.2.2-diag',  # âœ… Phase 5.7.2.2-diag
                'session_id': session_id,
                'pages_total': total_pages,
                'pages_success': valid_pages,  # âœ… ë¹ˆ í˜ì´ì§€ ì œì™¸
                'empty_page_count': empty_page_count,  # âœ… Phase 5.7.2.2 ì‹ ê·œ
                'processing_time': processing_time,
                'markdown': markdown,
                'chunks': chunks,
                'kvs_payloads': kvs_files,
                'metrics': metrics_list,
                'fidelity_score': fidelity_score,
                'chunking_score': chunking_score,
                'rag_score': rag_score,
                'universality_score': universality_score,
                'competitive_score': competitive_score,
                'overall_score': overall_score
            }
            
            # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ìµœì¢… ê²°ê³¼
            logger.info(f"[DOD-DIAG] pipeline_complete, status=success, valid_pages={valid_pages}, empty_pages={empty_page_count}, overall_score={overall_score:.0f}")
            
            logger.info(f"âœ… Phase 5.7.2.2-diag ì²˜ë¦¬ ì™„ë£Œ")
            logger.info(f"   - ìœ íš¨ í˜ì´ì§€: {valid_pages}/{total_pages}")
            logger.info(f"   - ë¹ˆ í˜ì´ì§€: {empty_page_count}")
            logger.info(f"   - ì‹œê°„: {processing_time:.1f}ì´ˆ")
            logger.info(f"   - ì¢…í•©: {overall_score:.0f}/100")
            
            return result
        
        except Exception as e:
            logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # ğŸ”´ ì§„ë‹¨ ë¡œê·¸: ì—ëŸ¬
            logger.error(f"[DOD-DIAG] pipeline_error, error={str(e)}")
            
            return {
                'status': 'error',
                'version': '5.7.2.2-diag',
                'session_id': session_id,
                'error': str(e),
                'pages_total': 0,
                'pages_success': 0,
                'empty_page_count': 0,
                'processing_time': time.time() - start_time
            }