"""
core/pipeline.py
PRISM Phase 0.2 Hotfix - Pipeline with DocType Hardening

âœ… Phase 0.2 ê¸´ê¸‰ ìˆ˜ì •:
1. DocType ì „ì—­ ê³ ì • (statute)
2. í˜ì´ì§€ë³„ page_roleê³¼ ë¶„ë¦¬
3. í›„ì²˜ë¦¬ì— ì¼ê´€ëœ doc_type ì „ë‹¬
4. ì½”ë“œíœìŠ¤ ì œê±° ìœ ì§€

Author: ì´ì„œì˜ (Backend Lead) + GPT í”¼ë“œë°±
Date: 2025-11-06
Version: Phase 0.2 Hotfix
"""

import logging
import time
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)


class Phase53Pipeline:
    """
    Phase 0.2 í†µí•© íŒŒì´í”„ë¼ì¸ (DocType ì¼ê´€ì„±)
    
    âœ… Phase 0.2 ê°œì„ :
    - DocType ì „ì—­ ê³ ì • (statute)
    - í˜ì´ì§€ ì—­í• (page_role)ê³¼ ë¶„ë¦¬
    - í›„ì²˜ë¦¬ ì¼ê´€ì„± ë³´ì¥
    - ì½”ë“œíœìŠ¤ ì œê±° ìœ ì§€
    - app.py í˜¸í™˜ì„± ìœ ì§€ (Phase53Pipeline)
    
    í”Œë¡œìš°:
    1. PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
    2. HybridExtractor: í˜ì´ì§€ë³„ ì¶”ì¶œ (page_role ì „ë‹¬)
    3. âœ… Markdown í†µí•© + ì½”ë“œíœìŠ¤ ì œê±°
    4. âœ… í›„ì²˜ë¦¬: doc_type=statute ê³ ì • ì „ë‹¬
    5. SemanticChunker: ì¡°ë¬¸ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹
    6. ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€
    """
    
    def __init__(
        self,
        pdf_processor,
        vlm_service,
        max_pages: int = 20,
        session_id: str = None
    ):
        """
        ì´ˆê¸°í™” (app.py í˜¸í™˜)
        
        Args:
            pdf_processor: PDFProcessor ì¸ìŠ¤í„´ìŠ¤
            vlm_service: VLMServiceV50 ì¸ìŠ¤í„´ìŠ¤ (classifier í¬í•¨)
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            session_id: ì„¸ì…˜ ID (ì„ íƒ)
        """
        self.pdf_processor = pdf_processor
        self.vlm_service = vlm_service
        self.max_pages = max_pages
        self.session_id = session_id or self._generate_session_id()
        
        # classifierëŠ” vlm_serviceì—ì„œ ê°€ì ¸ì˜´
        self.classifier = getattr(vlm_service, 'classifier', None)
        
        if not self.classifier:
            logger.warning("âš ï¸ VLM Serviceì— classifier ì—†ìŒ - ê¸°ë³¸ ë¶„ë¥˜ê¸° ì‚¬ìš©")
            try:
                from core.document_classifier import DocumentClassifierV50
                self.classifier = DocumentClassifierV50()
            except:
                logger.error("âŒ DocumentClassifierV50 ë¡œë“œ ì‹¤íŒ¨")
                self.classifier = None
        
        # Components
        from core.semantic_chunker import SemanticChunker
        self.chunker = SemanticChunker(
            min_chunk_size=600,
            max_chunk_size=1200,
            target_chunk_size=900
        )
        
        logger.info("âœ… Phase 0.2 Pipeline ì´ˆê¸°í™” ì™„ë£Œ (DocType ì¼ê´€ì„±)")
        logger.info("   - HybridExtractor: page_role ì „ë‹¬")
        logger.info("   - PostMerge/Typo: doc_type=statute ê³ ì •")
        logger.info("   - SemanticChunker: Fail-safe ì§€ì›")
    
    def process_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """
        âœ… app.py í˜¸í™˜ì„± ë©”ì„œë“œ
        
        ê¸°ì¡´ API:
            pipeline = Phase53Pipeline(pdf_processor, vlm_service)
            result = pipeline.process_pdf(pdf_path)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        return self.process(pdf_path)
    
    def process(self, pdf_path: str) -> Dict[str, Any]:
        """
        Phase 0.2 ì „ì²´ ì²˜ë¦¬ (DocType ì¼ê´€ì„±)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        logger.info(f"ğŸ¯ Phase 0.2 ì²˜ë¦¬ ì‹œì‘ (DocType ì¼ê´€ì„±)")
        logger.info(f"   íŒŒì¼: {pdf_path}")
        logger.info(f"   ì„¸ì…˜: {self.session_id}")
        logger.info(f"   ìµœëŒ€ í˜ì´ì§€: {self.max_pages}")
        
        start_time = time.time()
        
        # Step 1: PDF â†’ ì´ë¯¸ì§€
        logger.info("ğŸ“„ Step 1: PDF â†’ ì´ë¯¸ì§€ ë³€í™˜")
        images = self.pdf_processor.pdf_to_images(
            pdf_path=pdf_path,
            max_pages=self.max_pages
        )
        logger.info(f"   âœ… {len(images)}í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        
        # Step 2: ë¬¸ì„œ ë¶„ë¥˜ (ì „ì—­ doc_type ê²°ì •)
        logger.info("ğŸ“Š Step 2: ë¬¸ì„œ ë¶„ë¥˜")
        first_image = images[0][0] if images else None
        
        if first_image:
            doc_classification = self.classifier.classify(first_image)
            global_doc_type = doc_classification.get('domain', 'statute')
        else:
            global_doc_type = 'statute'
        
        logger.info(f"   âœ… ì „ì—­ doc_type: {global_doc_type}")
        
        # Step 3: HybridExtractor ì´ˆê¸°í™” (ì „ì—­ allow_tables)
        from core.hybrid_extractor import HybridExtractor
        
        allow_tables = (global_doc_type == 'statute')
        
        extractor = HybridExtractor(
            vlm_service=self.vlm_service,
            pdf_path=pdf_path,
            allow_tables=allow_tables
        )
        
        # Step 4: í˜ì´ì§€ë³„ ì¶”ì¶œ
        logger.info("ğŸ“ Step 3: í˜ì´ì§€ë³„ ì¶”ì¶œ (page_role ì „ë‹¬)")
        
        page_results = []
        empty_page_count = 0
        
        for i, (image_data, page_num) in enumerate(images, 1):
            result = extractor.extract(image_data, page_num)
            
            # ë¹ˆ í˜ì´ì§€ í•„í„°ë§
            if result['quality_score'] >= 50:
                page_results.append(result)
            else:
                empty_page_count += 1
                logger.debug(f"      ë¹ˆ í˜ì´ì§€ ì œì™¸: {page_num}")
        
        logger.info(f"ğŸ“Š ìœ íš¨ í˜ì´ì§€: {len(page_results)}/{len(images)} (ë¹ˆ í˜ì´ì§€ {empty_page_count}ê°œ ì œì™¸)")
        
        # Fallback í†µê³„
        fallback_count = sum(1 for r in page_results if r['source'] == 'fallback')
        fallback_rate = (fallback_count / len(page_results) * 100) if page_results else 0
        
        logger.info("ğŸ“Š Fallback í†µê³„:")
        logger.info(f"   - VLM ì„±ê³µ: {len(page_results) - fallback_count}í˜ì´ì§€")
        logger.info(f"   - Fallback ì‚¬ìš©: {fallback_count}í˜ì´ì§€")
        logger.info(f"   - Fallback ë¹„ìœ¨: {fallback_rate:.1f}%")
        
        # Step 5: Markdown í†µí•© + ì½”ë“œíœìŠ¤ ì œê±°
        logger.info("ğŸ“ Step 4: Markdown í†µí•© + ì½”ë“œíœìŠ¤ ì œê±°")
        
        markdown_parts = []
        for result in page_results:
            content = result['content']
            
            # ì½”ë“œíœìŠ¤ ì œê±°
            content = self._strip_code_fences(content)
            
            markdown_parts.append(content)
        
        full_markdown = '\n\n'.join(markdown_parts)
        
        logger.info(f"   âœ… Markdown í†µí•© ì™„ë£Œ: {len(full_markdown)} ê¸€ì")
        
        # âœ… Phase 0.2: í›„ì²˜ë¦¬ì— global_doc_type ì „ë‹¬
        logger.info(f"ğŸ”§ Step 5: í›„ì²˜ë¦¬ (doc_type={global_doc_type})")
        
        from core.post_merge_normalizer import PostMergeNormalizer
        from core.typo_normalizer import TypoNormalizer
        
        post_normalizer = PostMergeNormalizer()
        typo_normalizer = TypoNormalizer()
        
        # í›„ì²˜ë¦¬ ì ìš©
        full_markdown = post_normalizer.normalize(full_markdown, global_doc_type)
        full_markdown = typo_normalizer.normalize(full_markdown, global_doc_type)
        
        # Step 6: SemanticChunking
        logger.info("âœ‚ï¸ Step 6: SemanticChunking Phase 0.2 (Fail-safe)")
        
        chunks = self.chunker.chunk(full_markdown)
        
        logger.info(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        # Step 7: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€
        logger.info("ğŸ“Š Step 7: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€")
        
        checklist_score = self._evaluate_checklist(
            markdown=full_markdown,
            chunks=chunks,
            page_results=page_results,
            doc_type=global_doc_type
        )
        
        logger.info(f"   âœ… ì›ë³¸ ì¶©ì‹¤ë„: {checklist_score['fidelity']}/100")
        logger.info(f"   âœ… ì²­í‚¹ í’ˆì§ˆ: {checklist_score['chunking']}/100")
        logger.info(f"   âœ… RAG ì í•©ë„: {checklist_score['rag']}/100")
        logger.info(f"   âœ… ë²”ìš©ì„±: {checklist_score['generality']}/100")
        logger.info(f"   âœ… ê²½ìŸë ¥: {checklist_score['competitiveness']}/100")
        logger.info(f"   ğŸ¯ ì¢…í•©: {checklist_score['overall']}/100")
        
        # ì¢…ë£Œ
        elapsed_time = time.time() - start_time
        
        logger.info("âœ… Phase 0.2 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   - ìœ íš¨ í˜ì´ì§€: {len(page_results)}/{len(images)}")
        logger.info(f"   - ë¹ˆ í˜ì´ì§€: {empty_page_count}")
        logger.info(f"   - Fallback ì‚¬ìš©: {fallback_count}")
        logger.info(f"   - ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
        logger.info(f"   - ì¢…í•©: {checklist_score['overall']}/100")
        
        return {
            'session_id': self.session_id,
            'markdown': full_markdown,
            'chunks': chunks,
            'metadata': {
                'total_pages': len(images),
                'valid_pages': len(page_results),
                'empty_pages': empty_page_count,
                'fallback_count': fallback_count,
                'fallback_rate': fallback_rate,
                'doc_type': global_doc_type,
                'elapsed_time': elapsed_time
            },
            'checklist': checklist_score
        }
    
    def _strip_code_fences(self, content: str) -> str:
        """
        ì½”ë“œíœìŠ¤ ì œê±°
        
        Args:
            content: ì›ë³¸ Markdown
        
        Returns:
            ì½”ë“œíœìŠ¤ ì œê±°ëœ Markdown
        """
        # ì•ìª½ ì½”ë“œíœìŠ¤ ì œê±°
        content = re.sub(r'^```[a-z]*\s*\n', '', content, flags=re.MULTILINE)
        
        # ë’¤ìª½ ì½”ë“œíœìŠ¤ ì œê±°
        content = re.sub(r'\n```\s*$', '', content, flags=re.MULTILINE)
        
        # ì•ë’¤ ê³µë°± ì •ë¦¬
        content = content.strip()
        
        return content
    
    def _evaluate_checklist(
        self,
        markdown: str,
        chunks: List[Dict[str, Any]],
        page_results: List[Dict[str, Any]],
        doc_type: str
    ) -> Dict[str, int]:
        """
        5ëŒ€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€
        
        Args:
            markdown: í†µí•© Markdown
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            page_results: í˜ì´ì§€ë³„ ì¶”ì¶œ ê²°ê³¼
            doc_type: ë¬¸ì„œ íƒ€ì…
        
        Returns:
            ì²´í¬ë¦¬ìŠ¤íŠ¸ ì ìˆ˜
        """
        # 1) ì›ë³¸ ì¶©ì‹¤ë„ (Fidelity)
        fidelity_score = self._evaluate_fidelity(markdown, doc_type)
        
        # 2) ì²­í‚¹ í’ˆì§ˆ (Chunking Quality)
        chunking_score = self._evaluate_chunking(chunks, markdown)
        
        # 3) RAG ì í•©ë„ (RAG Suitability)
        rag_score = self._evaluate_rag(chunks, markdown)
        
        # 4) ë²”ìš©ì„± (Generality)
        generality_score = self._evaluate_generality(page_results)
        
        # 5) ê²½ìŸë ¥ (Competitiveness)
        competitiveness_score = self._evaluate_competitiveness(markdown, chunks)
        
        # ì¢…í•© ì ìˆ˜
        overall_score = int(
            fidelity_score * 0.3 +
            chunking_score * 0.2 +
            rag_score * 0.2 +
            generality_score * 0.15 +
            competitiveness_score * 0.15
        )
        
        return {
            'fidelity': fidelity_score,
            'chunking': chunking_score,
            'rag': rag_score,
            'generality': generality_score,
            'competitiveness': competitiveness_score,
            'overall': overall_score
        }
    
    def _evaluate_fidelity(self, markdown: str, doc_type: str) -> int:
        """ì›ë³¸ ì¶©ì‹¤ë„ í‰ê°€"""
        score = 100
        
        # ê°œì •ì´ë ¥ ì¡´ì¬ ì—¬ë¶€
        if doc_type == 'statute':
            if '| ì°¨ìˆ˜ | ë‚ ì§œ |' in markdown:
                revision_count = markdown.count('ì°¨ ê°œì •')
                
                if revision_count >= 15:
                    score += 0  # ë§Œì  ìœ ì§€
                elif revision_count >= 10:
                    score -= 5
                else:
                    score -= 10
            else:
                score -= 20  # ê°œì •ì´ë ¥ ëˆ„ë½
            
            # "ê¸°ë³¸ ì •ì‹ " ì¡´ì¬ ì—¬ë¶€
            if 'ê¸°ë³¸ ì •ì‹ ' in markdown or 'ê¸°ë³¸ì •ì‹ ' in markdown:
                score += 0  # ë§Œì  ìœ ì§€
            else:
                score -= 15  # ê¸°ë³¸ ì •ì‹  ëˆ„ë½
            
            # ì¡°ë¬¸ ì»¤ë²„ë¦¬ì§€
            article_count = len(re.findall(r'ì œ\s?\d+ì¡°', markdown))
            
            if article_count >= 3:
                score += 0
            elif article_count >= 1:
                score -= 10
            else:
                score -= 30
        
        return max(0, min(100, score))
    
    def _evaluate_chunking(self, chunks: List[Dict[str, Any]], markdown: str) -> int:
        """ì²­í‚¹ í’ˆì§ˆ í‰ê°€"""
        if not chunks:
            return 0
        
        score = 100
        
        # ì²­í¬ ê°œìˆ˜
        chunk_count = len(chunks)
        
        if chunk_count >= 3:
            score += 0  # ì´ìƒì 
        elif chunk_count >= 2:
            score -= 10
        elif chunk_count == 1:
            score -= 40  # ê³¼ì†Œë¶„í• 
        
        # ì²­í¬ í¬ê¸° ë¶„í¬
        chunk_sizes = [c['metadata']['char_count'] for c in chunks]
        avg_size = sum(chunk_sizes) / len(chunk_sizes)
        
        if 600 <= avg_size <= 1200:
            score += 0
        else:
            score -= 10
        
        # ì¡°ë¬¸ ë©”íƒ€ë°ì´í„°
        articles_with_meta = sum(
            1 for c in chunks 
            if c['metadata'].get('article_no', '')
        )
        
        if articles_with_meta >= chunk_count * 0.8:
            score += 0
        else:
            score -= 15
        
        return max(0, min(100, score))
    
    def _evaluate_rag(self, chunks: List[Dict[str, Any]], markdown: str) -> int:
        """RAG ì í•©ë„ í‰ê°€"""
        score = 100
        
        # ë…¸ì´ì¦ˆ ì²´í¬
        noise_patterns = [
            r'\d{3,4}-\d{1,2}',  # í˜ì´ì§€ ë²ˆí˜¸
            r'Page\s+\d+',
            r'[-â€”â€“_*]{3,}',
        ]
        
        for pattern in noise_patterns:
            matches = re.findall(pattern, markdown)
            if matches:
                score -= len(matches) * 2
        
        # ì¤‘ë³µ ì²´í¬
        if markdown.count('| ì°¨ìˆ˜ | ë‚ ì§œ |') > 1:
            score -= 20  # ì¤‘ë³µ í‘œ
        
        # ì²­í¬ ë…ë¦½ì„±
        if len(chunks) >= 3:
            score += 0  # ê²€ìƒ‰ ê°€ëŠ¥ì„± ë†’ìŒ
        elif len(chunks) == 1:
            score -= 30  # ê²€ìƒ‰ ê°€ëŠ¥ì„± ë‚®ìŒ
        
        return max(0, min(100, score))
    
    def _evaluate_generality(self, page_results: List[Dict[str, Any]]) -> int:
        """ë²”ìš©ì„± í‰ê°€"""
        score = 100
        
        # Fallback ë¹„ìœ¨
        fallback_count = sum(1 for r in page_results if r['source'] == 'fallback')
        fallback_rate = (fallback_count / len(page_results)) if page_results else 0
        
        if fallback_rate <= 0.1:
            score += 0  # ìš°ìˆ˜
        elif fallback_rate <= 0.3:
            score -= 5
        else:
            score -= 15
        
        return max(0, min(100, score))
    
    def _evaluate_competitiveness(self, markdown: str, chunks: List[Dict[str, Any]]) -> int:
        """ê²½ìŸë ¥ í‰ê°€"""
        score = 100
        
        # ê°œì •ì´ë ¥ í‘œ í˜•ì‹
        if '| ì°¨ìˆ˜ | ë‚ ì§œ |' in markdown:
            score += 0  # í‘œ í˜•ì‹ ìš°ìˆ˜
        else:
            score -= 20
        
        # ì¡°ë¬¸ í—¤ë” ì •ê·œí™”
        irregular_headers = len(re.findall(r'ì œ\s+\d+\s+ì¡°', markdown))
        
        if irregular_headers == 0:
            score += 0
        else:
            score -= irregular_headers * 3
        
        # ì²­í‚¹ í’ˆì§ˆ
        if len(chunks) >= 3:
            score += 0
        else:
            score -= 10
        
        return max(0, min(100, score))
    
    def _generate_session_id(self) -> str:
        """ì„¸ì…˜ ID ìƒì„±"""
        import random
        import string
        return ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))