"""
core/pipeline.py
PRISM Phase 4.3 - Pipeline (ì§€ëŠ¥í˜• ë¶„í•  ì²˜ë¦¬)

âœ… Phase 4.3 ê°œì„ ì‚¬í•­:
1. 3-Step ì²˜ë¦¬ (êµ¬ì¡°â†’ì „ëµâ†’ê²€ì¦)
2. ë³µì¡ë„ ê¸°ë°˜ ì „ëµ ë¶„ê¸°
3. ê°•í™”ëœ í’ˆì§ˆ ê²€ì¦
4. ìƒì„¸í•œ í’ˆì§ˆ ë©”íŠ¸ë¦­

Author: ì´ì„œì˜ (Backend Lead), ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-23
Version: 4.3
"""

import logging
from typing import List, Dict, Any, Optional
import time
import uuid
import re

logger = logging.getLogger(__name__)


class Phase43Pipeline:
    """
    Phase 4.3 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    íŠ¹ì§•:
    - 3-Step ì§€ëŠ¥í˜• ì²˜ë¦¬
    - ë³µì¡ë„ ê¸°ë°˜ ì „ëµ ë¶„ê¸°
    - ê°•í™”ëœ ê²€ì¦
    - ìƒì„¸í•œ í’ˆì§ˆ ë©”íŠ¸ë¦­
    """
    
    def __init__(self, pdf_processor, vlm_service, storage):
        """
        Args:
            pdf_processor: PDFProcessor ì¸ìŠ¤í„´ìŠ¤
            vlm_service: VLMServiceV43 ì¸ìŠ¤í„´ìŠ¤
            storage: Storage ì¸ìŠ¤í„´ìŠ¤
        """
        self.pdf_processor = pdf_processor
        self.vlm_service = vlm_service
        self.storage = storage
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: int = 20,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (Phase 4.3)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        session_id = str(uuid.uuid4())[:8]
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ Phase 4.3 ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        logger.info(f"Session ID: {session_id}")
        logger.info(f"{'='*60}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 1: PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ“„ PDF ë³€í™˜ ì¤‘ (300 DPI)...", 0)
        
        logger.info("\n[Stage 1] PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜")
        images = self.pdf_processor.pdf_to_images(pdf_path, max_pages=max_pages, dpi=300)
        logger.info(f"âœ… {len(images)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        
        if not images:
            logger.error("âŒ PDF ë³€í™˜ ì‹¤íŒ¨")
            return {
                'status': 'error',
                'error': 'PDF ë³€í™˜ ì‹¤íŒ¨',
                'session_id': session_id
            }
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 2: 3-Step ì§€ëŠ¥í˜• ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        results = []
        success_count = 0
        error_count = 0
        
        strategy_counts = {'simple': 0, 'complex': 0}
        validation_issues = []
        
        for page_num, img_data in enumerate(images):
            if progress_callback:
                progress = int((page_num / len(images)) * 90)
                progress_callback(
                    f"ğŸ¯ í˜ì´ì§€ {page_num + 1}/{len(images)} 3-Step ë¶„ì„ ì¤‘...",
                    progress
                )
            
            logger.info(f"\n[Stage 2] í˜ì´ì§€ {page_num + 1} - 3-Step ì§€ëŠ¥í˜• ë¶„ì„")
            
            try:
                # 3-Step VLM í˜¸ì¶œ
                vlm_result = self.vlm_service.analyze_page_intelligent(
                    image_data=img_data,
                    page_num=page_num + 1
                )
                
                content = vlm_result.get('content', '')
                confidence = vlm_result.get('confidence', 0.0)
                strategy = vlm_result.get('strategy', 'unknown')
                structure = vlm_result.get('structure', {})
                
                if not content:
                    logger.warning(f"   âš ï¸ VLM ê²°ê³¼ ì—†ìŒ")
                    error_count += 1
                    continue
                
                # ì„±ê³µ!
                success_count += 1
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
                
                logger.info(f"   âœ… ì„±ê³µ ({len(content)} ê¸€ì, ì‹ ë¢°ë„: {confidence:.2f}, ì „ëµ: {strategy})")
                
                # ê²€ì¦ ì´ìŠˆ ì²´í¬
                if 'âš ï¸ **í’ˆì§ˆ ì´ìŠˆ:**' in content:
                    validation_issues.append(f"í˜ì´ì§€ {page_num + 1}")
                
                results.append({
                    'page_num': page_num + 1,
                    'content': content,
                    'confidence': confidence,
                    'strategy': strategy,
                    'structure': structure
                })
                
            except Exception as e:
                logger.error(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                error_count += 1
        
        logger.info(f"\nâœ… VLM ë¶„ì„ ì™„ë£Œ:")
        logger.info(f"   - ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"   - ì‹¤íŒ¨: {error_count}ê°œ")
        logger.info(f"   - ì „ëµ: Simple {strategy_counts.get('simple', 0)}ê°œ, Complex {strategy_counts.get('complex', 0)}ê°œ")
        if validation_issues:
            logger.info(f"   - ê²€ì¦ ì´ìŠˆ: {', '.join(validation_issues)}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 3: Markdown í†µí•©
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ“ Markdown ìƒì„± ì¤‘...", 95)
        
        logger.info(f"\n[Stage 3] Markdown í†µí•©")
        
        full_markdown = self._generate_markdown(results)
        
        logger.info(f"âœ… Markdown ìƒì„± ì™„ë£Œ ({len(full_markdown)} ê¸€ì)")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 4: ìƒì„¸ í’ˆì§ˆ ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        quality_metrics = self._analyze_quality(results, full_markdown)
        
        logger.info(f"\n[í’ˆì§ˆ ë¶„ì„]")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {quality_metrics['avg_confidence']:.2f}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_metrics['quality_score']:.1f}/100")
        logger.info(f"   - ì›ë³¸ ì¶©ì‹¤ë„: {quality_metrics['fidelity_score']:.1f}/100")
        logger.info(f"   - ì²­í‚¹ í’ˆì§ˆ: {quality_metrics['chunking_score']:.1f}/100")
        logger.info(f"   - RAG ì í•©ë„: {quality_metrics['rag_score']:.1f}/100")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 5: ê²°ê³¼ ì €ì¥
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ğŸ’¾ ì €ì¥ ì¤‘...", 98)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        result = {
            'status': 'success',
            'session_id': session_id,
            'processing_time': processing_time,
            'pages_processed': len(images),
            'pages_success': success_count,
            'pages_error': error_count,
            'strategy_simple': strategy_counts.get('simple', 0),
            'strategy_complex': strategy_counts.get('complex', 0),
            'validation_issues': len(validation_issues),
            'markdown': full_markdown,
            'page_results': results,
            **quality_metrics
        }
        
        # DB ì €ì¥
        try:
            if hasattr(self.storage, 'save_session'):
                self.storage.save_session(result)
                logger.info("âœ… DB ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        if progress_callback:
            progress_callback("âœ… ì™„ë£Œ!", 100)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ‰ Phase 4.3 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
        logger.info(f"   - í˜ì´ì§€ ì„±ê³µ: {success_count}/{len(images)}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_metrics['quality_score']:.1f}/100")
        logger.info(f"   - ì´ ê¸€ì ìˆ˜: {len(full_markdown):,}")
        logger.info(f"{'='*60}\n")
        
        return result
    
    def _generate_markdown(self, results: List[Dict[str, Any]]) -> str:
        """í˜ì´ì§€ë³„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ Markdownìœ¼ë¡œ í†µí•©"""
        markdown_parts = []
        
        for result in results:
            page_num = result['page_num']
            content = result['content']
            
            markdown_parts.append(content)
            markdown_parts.append("\n\n")
        
        return "".join(markdown_parts).strip()
    
    def _analyze_quality(self, results: List[Dict], markdown: str) -> Dict[str, float]:
        """ìƒì„¸ í’ˆì§ˆ ë¶„ì„ (Phase 4.3)"""
        
        if not results:
            return {
                'avg_confidence': 0.0,
                'quality_score': 0.0,
                'fidelity_score': 0.0,
                'chunking_score': 0.0,
                'rag_score': 0.0
            }
        
        # 1. í‰ê·  ì‹ ë¢°ë„
        avg_confidence = sum(r.get('confidence', 0.0) for r in results) / len(results)
        
        # 2. ì›ë³¸ ì¶©ì‹¤ë„ (Fidelity)
        fidelity_score = self._calculate_fidelity(markdown)
        
        # 3. ì²­í‚¹ í’ˆì§ˆ
        chunking_score = self._calculate_chunking_quality(markdown)
        
        # 4. RAG ì í•©ë„
        rag_score = self._calculate_rag_suitability(markdown)
        
        # 5. ì¢…í•© í’ˆì§ˆ ì ìˆ˜
        quality_score = (
            avg_confidence * 30 +  # ì‹ ë¢°ë„ 30%
            fidelity_score * 30 +  # ì›ë³¸ ì¶©ì‹¤ë„ 30%
            chunking_score * 20 +  # ì²­í‚¹ í’ˆì§ˆ 20%
            rag_score * 20         # RAG ì í•©ë„ 20%
        )
        
        return {
            'avg_confidence': avg_confidence,
            'quality_score': min(quality_score, 100.0),
            'fidelity_score': fidelity_score,
            'chunking_score': chunking_score,
            'rag_score': rag_score
        }
    
    def _calculate_fidelity(self, markdown: str) -> float:
        """ì›ë³¸ ì¶©ì‹¤ë„ ê³„ì‚° (Phase 4.4: ë” ì—„ê²©í•œ ê¸°ì¤€)"""
        score = 100.0
        
        # 1. ë°˜ë³µ íŒ¨í„´ ê°ì§€ (í™˜ê°) - ë” ì—„ê²©í•˜ê²Œ!
        lines = markdown.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            # ğŸ”§ ë²„ê·¸ ìˆ˜ì •: ê¸¸ì´ ì²´í¬ ë¨¼ì €!
            if len(clean) > 5 and (clean.startswith('- ') or (len(clean) > 0 and clean[0].isdigit())):
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        # ğŸ”¥ Phase 4.4: ë” ì—„ê²©í•œ ê¸°ì¤€
        max_repeat = max(line_counts.values()) if line_counts else 1
        if max_repeat >= 20:
            score -= 90  # ì¹˜ëª…ì ! (ê¸°ì¡´ 50 â†’ 90)
        elif max_repeat >= 10:
            score -= 60  # ì‹¬ê° (ê¸°ì¡´ 30 â†’ 60)
        elif max_repeat >= 5:
            score -= 30  # ë¬¸ì œ (ê¸°ì¡´ 10 â†’ 30)
        elif max_repeat >= 3:
            score -= 10  # ê²½ë¯¸
        
        # 2. "ì½ê¸° ë¶ˆê°€" ê°œìˆ˜ (ì•½ê°„ ê°ì )
        unreadable = markdown.count('ì½ê¸° ë¶ˆê°€') + markdown.count('[ë¶ˆëª…í™•]')
        score -= min(20, unreadable * 2)
        
        # 3. ë°±ë¶„ìœ¨ ê²€ì¦
        percentages = re.findall(r'(\d+\.?\d*)%', markdown)
        if len(percentages) >= 3:
            values = [float(p) for p in percentages]
            
            valid_group = False
            for i in range(len(values)):
                group_sum = values[i]
                for j in range(i+1, min(i+10, len(values))):
                    group_sum += values[j]
                    if 99.0 <= group_sum <= 101.0:
                        valid_group = True
                        break
                if valid_group:
                    break
            
            if not valid_group and len(values) >= 5:
                score -= 10
        
        return max(0.0, score)
    
    def _calculate_chunking_quality(self, markdown: str) -> float:
        """ì²­í‚¹ í’ˆì§ˆ ê³„ì‚°"""
        score = 0.0
        
        # 1. ì„¹ì…˜ êµ¬ë¶„ (`---`)
        sections = markdown.split('---')
        section_count = len(sections)
        
        if section_count >= 3:
            score += 40
        elif section_count >= 2:
            score += 30
        elif section_count >= 1:
            score += 20
        
        # 2. ì„¹ì…˜ í—¤ë” (`####`)
        headers = re.findall(r'^####\s+(.+)$', markdown, re.MULTILINE)
        header_count = len(headers)
        
        if header_count >= 5:
            score += 30
        elif header_count >= 3:
            score += 20
        elif header_count >= 1:
            score += 10
        
        # 3. ê· í˜•ì¡íŒ ì„¹ì…˜ í¬ê¸°
        if section_count > 1:
            section_lengths = [len(s) for s in sections]
            avg_len = sum(section_lengths) / len(section_lengths)
            
            # ì„¹ì…˜ í¬ê¸°ê°€ ë¹„ìŠ·í•˜ë©´ ê°€ì‚°ì 
            variance = sum((l - avg_len) ** 2 for l in section_lengths) / len(section_lengths)
            if variance < (avg_len ** 2) * 0.5:  # ë¶„ì‚°ì´ ì‘ìœ¼ë©´
                score += 30
            elif variance < (avg_len ** 2) * 1.0:
                score += 20
        
        return min(100.0, score)
    
    def _calculate_rag_suitability(self, markdown: str) -> float:
        """RAG ì í•©ë„ ê³„ì‚°"""
        score = 100.0
        
        # 1. ë¶ˆí•„ìš”í•œ ì¤‘ë³µ (ê°ì )
        lines = markdown.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            if len(clean) > 5:
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        # ì¤‘ë³µì´ ë§ìœ¼ë©´ RAG í’ˆì§ˆ ì €í•˜
        max_repeat = max(line_counts.values()) if line_counts else 1
        if max_repeat >= 50:
            score -= 80
        elif max_repeat >= 20:
            score -= 50
        elif max_repeat >= 10:
            score -= 30
        
        # 2. ìì—°ì–´ ì„¤ëª… ë¹„ìœ¨ (ê°€ì‚°ì )
        total_lines = len([l for l in lines if l.strip()])
        data_lines = len([l for l in lines if l.strip().startswith('- ')])
        
        if total_lines > 0:
            description_ratio = 1.0 - (data_lines / total_lines)
            if description_ratio >= 0.3:  # 30% ì´ìƒ ìì—°ì–´
                score += 20
            elif description_ratio >= 0.2:
                score += 10
        
        # 3. ìˆ«ì ë°ì´í„° ë°€ë„ (ì ë‹¹íˆ)
        numbers = re.findall(r'\d+\.?\d*', markdown)
        if 10 <= len(numbers) <= 200:
            score += 10
        
        return max(0.0, min(100.0, score))