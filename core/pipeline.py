"""
core/pipeline.py
PRISM Phase 4.5 - Pipeline (í’ˆì§ˆ ì ìˆ˜ ìˆ˜ì •)

âœ… Phase 4.5 ê°œì„ ì‚¬í•­:
1. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë²„ê·¸ ìˆ˜ì •
2. VLM Service v4.5 í†µí•©
3. ê²€ì¦ ê°•í™”

Author: ì´ì„œì˜ (Backend Lead)
Date: 2025-10-23
Version: 4.5
"""

import logging
from typing import List, Dict, Any, Optional
import time
import uuid
import re

logger = logging.getLogger(__name__)


class Phase45Pipeline:
    """
    Phase 4.5 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    íŠ¹ì§•:
    - OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ
    - í’ˆì§ˆ ì ìˆ˜ ì •í™• ê³„ì‚°
    - ê²€ì¦ ê°•í™”
    """
    
    def __init__(self, pdf_processor, vlm_service, storage):
        """
        Args:
            pdf_processor: PDFProcessor ì¸ìŠ¤í„´ìŠ¤
            vlm_service: VLMServiceV45 ì¸ìŠ¤í„´ìŠ¤
            storage: Storage ì¸ìŠ¤í„´ìŠ¤
        """
        self.pdf_processor = pdf_processor
        self.vlm_service = vlm_service
        self.storage = storage
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: int = 20,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (Phase 4.5)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ íŽ˜ì´ì§€ ìˆ˜
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        session_id = str(uuid.uuid4())[:8]
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ðŸš€ Phase 4.5 ì²˜ë¦¬ ì‹œìž‘: {pdf_path}")
        logger.info(f"Session ID: {session_id}")
        logger.info(f"{'='*60}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 1: PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ðŸ“„ PDF ë³€í™˜ ì¤‘ (300 DPI)...", 0)
        
        logger.info("\n[Stage 1] PDF â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜")
        images = self.pdf_processor.pdf_to_images(pdf_path, max_pages=max_pages, dpi=300)
        logger.info(f"âœ… {len(images)}ê°œ íŽ˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        
        if not images:
            logger.error("âŒ PDF ë³€í™˜ ì‹¤íŒ¨")
            return {
                'status': 'error',
                'error': 'PDF ë³€í™˜ ì‹¤íŒ¨',
                'session_id': session_id
            }
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 2: OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        results = []
        success_count = 0
        error_count = 0
        
        strategy_counts = {'simple': 0, 'complex_ocr': 0}
        validation_issues = []
        
        for page_num, img_data in enumerate(images):
            if progress_callback:
                progress = int((page_num / len(images)) * 90)
                progress_callback(
                    f"ðŸŽ¯ íŽ˜ì´ì§€ {page_num + 1}/{len(images)} OCR + VLM ë¶„ì„ ì¤‘...",
                    progress
                )
            
            logger.info(f"\n[Stage 2] íŽ˜ì´ì§€ {page_num + 1} - OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„")
            
            try:
                # OCR + VLM í˜¸ì¶œ
                vlm_result = self.vlm_service.analyze_page_intelligent(
                    image_data=img_data,
                    page_num=page_num + 1
                )
                
                content = vlm_result.get('content', '')
                confidence = vlm_result.get('confidence', 0.0)
                strategy = vlm_result.get('strategy', 'unknown')
                structure = vlm_result.get('structure', {})
                
                if not content:
                    logger.warning(f"   âš ï¸ VLM ê²°ê³¼ ì—†ìŒ")
                    error_count += 1
                    continue
                
                # ì„±ê³µ!
                success_count += 1
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
                
                logger.info(f"   âœ… ì„±ê³µ ({len(content)} ê¸€ìž, ì‹ ë¢°ë„: {confidence:.2f}, ì „ëžµ: {strategy})")
                
                results.append({
                    'page_num': page_num + 1,
                    'content': content,
                    'confidence': confidence,
                    'strategy': strategy,
                    'structure': structure
                })
                
            except Exception as e:
                logger.error(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                error_count += 1
        
        logger.info(f"\nâœ… VLM ë¶„ì„ ì™„ë£Œ:")
        logger.info(f"   - ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"   - ì‹¤íŒ¨: {error_count}ê°œ")
        logger.info(f"   - ì „ëžµ: Simple {strategy_counts.get('simple', 0)}ê°œ, Complex OCR {strategy_counts.get('complex_ocr', 0)}ê°œ")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 3: Markdown í†µí•©
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ðŸ“ Markdown ìƒì„± ì¤‘...", 95)
        
        logger.info(f"\n[Stage 3] Markdown í†µí•©")
        
        full_markdown = self._generate_markdown(results)
        
        logger.info(f"âœ… Markdown ìƒì„± ì™„ë£Œ ({len(full_markdown)} ê¸€ìž)")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 4: ìƒì„¸ í’ˆì§ˆ ë¶„ì„ (ìˆ˜ì •!)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        quality_metrics = self._analyze_quality(results, full_markdown)
        
        logger.info(f"\n[í’ˆì§ˆ ë¶„ì„]")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {quality_metrics['avg_confidence']:.2f}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_metrics['quality_score']:.1f}/100")
        logger.info(f"   - ì›ë³¸ ì¶©ì‹¤ë„: {quality_metrics['fidelity_score']:.1f}/100")
        logger.info(f"   - ì²­í‚¹ í’ˆì§ˆ: {quality_metrics['chunking_score']:.1f}/100")
        logger.info(f"   - RAG ì í•©ë„: {quality_metrics['rag_score']:.1f}/100")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 5: ê²°ê³¼ ì €ìž¥
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if progress_callback:
            progress_callback("ðŸ’¾ ì €ìž¥ ì¤‘...", 98)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        result = {
            'status': 'success',
            'session_id': session_id,
            'processing_time': processing_time,
            'pages_processed': len(images),
            'pages_success': success_count,
            'pages_error': error_count,
            'strategy_simple': strategy_counts.get('simple', 0),
            'strategy_complex_ocr': strategy_counts.get('complex_ocr', 0),
            'validation_issues': len(validation_issues),
            'markdown': full_markdown,
            'page_results': results,
            **quality_metrics
        }
        
        # DB ì €ìž¥
        try:
            if hasattr(self.storage, 'save_session'):
                self.storage.save_session(result)
                logger.info("âœ… DB ì €ìž¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âš ï¸ DB ì €ìž¥ ì‹¤íŒ¨: {e}")
        
        if progress_callback:
            progress_callback("âœ… ì™„ë£Œ!", 100)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ðŸŽ‰ Phase 4.5 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
        logger.info(f"   - íŽ˜ì´ì§€ ì„±ê³µ: {success_count}/{len(images)}")
        logger.info(f"   - í’ˆì§ˆ ì ìˆ˜: {quality_metrics['quality_score']:.1f}/100")
        logger.info(f"   - ì´ ê¸€ìž ìˆ˜: {len(full_markdown):,}")
        logger.info(f"{'='*60}\n")
        
        return result
    
    def _generate_markdown(self, results: List[Dict[str, Any]]) -> str:
        """íŽ˜ì´ì§€ë³„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ Markdownìœ¼ë¡œ í†µí•©"""
        markdown_parts = []
        
        for result in results:
            page_num = result['page_num']
            content = result['content']
            
            markdown_parts.append(content)
            markdown_parts.append("\n\n")
        
        return "".join(markdown_parts).strip()
    
    def _analyze_quality(self, results: List[Dict], markdown: str) -> Dict[str, float]:
        """ìƒì„¸ í’ˆì§ˆ ë¶„ì„ (Phase 4.5 - ìˆ˜ì •!)"""
        
        if not results:
            return {
                'avg_confidence': 0.0,
                'quality_score': 0.0,
                'fidelity_score': 0.0,
                'chunking_score': 0.0,
                'rag_score': 0.0
            }
        
        # 1. í‰ê·  ì‹ ë¢°ë„
        avg_confidence = sum(r.get('confidence', 0.0) for r in results) / len(results)
        
        # 2. ì›ë³¸ ì¶©ì‹¤ë„ (Fidelity)
        fidelity_score = self._calculate_fidelity(markdown)
        
        # 3. ì²­í‚¹ í’ˆì§ˆ
        chunking_score = self._calculate_chunking_quality(markdown)
        
        # 4. RAG ì í•©ë„
        rag_score = self._calculate_rag_suitability(markdown)
        
        # 5. ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (ðŸ”§ ë²„ê·¸ ìˆ˜ì •!)
        quality_score = (
            avg_confidence * 100 * 0.30 +  # ì‹ ë¢°ë„ 30%
            fidelity_score * 0.30 +         # ì›ë³¸ ì¶©ì‹¤ë„ 30%
            chunking_score * 0.20 +         # ì²­í‚¹ í’ˆì§ˆ 20%
            rag_score * 0.20                # RAG ì í•©ë„ 20%
        )
        
        return {
            'avg_confidence': avg_confidence,
            'quality_score': min(quality_score, 100.0),
            'fidelity_score': fidelity_score,
            'chunking_score': chunking_score,
            'rag_score': rag_score
        }
    
    def _calculate_fidelity(self, markdown: str) -> float:
        """ì›ë³¸ ì¶©ì‹¤ë„ ê³„ì‚° (Phase 4.5)"""
        score = 100.0
        
        # 1. ë°˜ë³µ íŒ¨í„´ ê°ì§€ (í™˜ê°) - ë” ì—„ê²©!
        lines = markdown.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            if len(clean) > 5 and (clean.startswith('- ') or (len(clean) > 0 and clean[0].isdigit())):
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        max_repeat = max(line_counts.values()) if line_counts else 1
        if max_repeat >= 20:
            score -= 90  # ì¹˜ëª…ì !
        elif max_repeat >= 10:
            score -= 60  # ì‹¬ê°
        elif max_repeat >= 5:
            score -= 30  # ë¬¸ì œ
        elif max_repeat >= 3:
            score -= 10  # ê²½ë¯¸
        
        # 2. "ì½ê¸° ë¶ˆê°€" ê°œìˆ˜
        unreadable = markdown.count('ì½ê¸° ë¶ˆê°€') + markdown.count('[ë¶ˆëª…í™•]')
        score -= min(20, unreadable * 2)
        
        # 3. ë¶ˆí•„ìš”í•œ ë©”íƒ€ ì •ë³´ (Phase 4.5 ì‹ ê·œ)
        if 'âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸' in markdown:
            score -= 5
        if 'âš ï¸ **í’ˆì§ˆ ì´ìŠˆ:**' in markdown:
            score -= 5
        
        return max(0.0, score)
    
    def _calculate_chunking_quality(self, markdown: str) -> float:
        """ì²­í‚¹ í’ˆì§ˆ ê³„ì‚°"""
        score = 0.0
        
        # 1. ì„¹ì…˜ êµ¬ë¶„ (`---`)
        sections = markdown.split('---')
        section_count = len(sections)
        
        if section_count >= 3:
            score += 40
        elif section_count >= 2:
            score += 30
        elif section_count >= 1:
            score += 20
        
        # 2. ì„¹ì…˜ í—¤ë” (`####`)
        headers = re.findall(r'^####\s+(.+)$', markdown, re.MULTILINE)
        header_count = len(headers)
        
        if header_count >= 5:
            score += 30
        elif header_count >= 3:
            score += 20
        elif header_count >= 1:
            score += 10
        
        # 3. ê· í˜•ìž¡ížŒ ì„¹ì…˜ í¬ê¸°
        if section_count > 1:
            section_lengths = [len(s) for s in sections]
            avg_len = sum(section_lengths) / len(section_lengths)
            
            variance = sum((l - avg_len) ** 2 for l in section_lengths) / len(section_lengths)
            if variance < (avg_len ** 2) * 0.5:
                score += 30
            elif variance < (avg_len ** 2) * 1.0:
                score += 20
        
        return min(100.0, score)
    
    def _calculate_rag_suitability(self, markdown: str) -> float:
        """RAG ì í•©ë„ ê³„ì‚°"""
        score = 100.0
        
        # 1. ë¶ˆí•„ìš”í•œ ì¤‘ë³µ (ê°ì )
        lines = markdown.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            if len(clean) > 5:
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        max_repeat = max(line_counts.values()) if line_counts else 1
        if max_repeat >= 50:
            score -= 80
        elif max_repeat >= 20:
            score -= 50
        elif max_repeat >= 10:
            score -= 30
        
        # 2. ë¶ˆí•„ìš”í•œ ë©”íƒ€ ì •ë³´ (Phase 4.5 ì‹ ê·œ)
        if 'âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸' in markdown:
            score -= 10
        if 'âš ï¸ **í’ˆì§ˆ ì´ìŠˆ:**' in markdown:
            score -= 10
        if 'â”â”â”â”â”' in markdown:  # ìž¥ì‹ì„ 
            score -= 5
        
        # 3. ìžì—°ì–´ ì„¤ëª… ë¹„ìœ¨ (ê°€ì‚°ì )
        total_lines = len([l for l in lines if l.strip()])
        data_lines = len([l for l in lines if l.strip().startswith('- ')])
        
        if total_lines > 0:
            description_ratio = 1.0 - (data_lines / total_lines)
            if description_ratio >= 0.3:
                score += 20
            elif description_ratio >= 0.2:
                score += 10
        
        return max(0.0, min(100.0, score))