"""
core/typo_normalizer_safe.py
PRISM Phase 0.4.0 P0-1 ê¸´ê¸‰ íŒ¨ì¹˜ (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸)

âœ… í•µì‹¬ ê°œì„ :
1. ì¡°ë¬¸ ë²ˆí˜¸ ì˜ì—­ ì ˆëŒ€ ë³´í˜¸ (ì œNì¡°, ì œNì¡°ì˜N)
2. ë³´í˜¸ ì˜ì—­ ì™¸ë¶€ì—ì„œë§Œ OCR êµì •
3. ìˆ«ì ì™œê³¡ ì™„ì „ ì°¨ë‹¨ (7â†’73, 8â†’90 ë°©ì§€)

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ (ì´ì„œì˜ Backend Lead) + GPT ë³´ì •
Date: 2025-11-13
Version: Phase 0.4.0 P0-1 (Emergency Patch)
"""

import re
import logging
from typing import List, Tuple

logger = logging.getLogger(__name__)


class TypoNormalizer:
    """Phase 0.4.0 P0-1 ì˜¤íƒˆì ì •ê·œí™” (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸)"""
    
    # âœ… ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ íŒ¨í„´ (ìµœìš°ì„ )
    ARTICLE_PATTERN = re.compile(
        r'ì œ\s*\d+\s*ì¡°(?:\s*ì˜\s*\d+)?(?:\s*ì œ\s*\d+\s*(?:í•­|í˜¸))?',
        re.IGNORECASE
    )
    
    # CRITICAL_FIXES 10ê°œ (ê¸°ì¡´)
    CRITICAL_FIXES = {
        "ê²½ìš©ë²”ìœ„": "ì ìš©ë²”ìœ„",
        "ì„ìš©í•œ": "ì„ìš©ê¶Œ",
        "ì§„ë³¸ë³´ì •": "ì‹ ë¶„ë³´ì¥",
        "ì„±ê³¼ê³„ì¢ŒëŒ€ìƒì": "ì„±ê³¼ê°œì„ ëŒ€ìƒì",
        "ë”°ë¥¸ ì •í•œë‹¤": "ë”°ë¡œ ì •í•œë‹¤",
        "ì •ìš©ë²”ìœ„": "ì ìš©ë²”ìœ„",
        "ì§„ë³´ë³´ì •": "ì‹ ë¶„ë³´ì¥",
        "ê³µê¸‰ì¸ì‚¬ìœ„ì›íšŒ": "ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ",
        "ì„±ê³¼ê³„ì œì„ ë°œì": "ì„±ê³¼ê°œì„ ëŒ€ìƒì",
        "ì„±ê³¼ê³„ì œì„ ë°œì‹¬ì‚¬": "ì„±ê³¼ê°œì„ ëŒ€ìƒì",
    }
    
    # DOMAIN_FIXES 13ê°œ (ê¸°ì¡´)
    DOMAIN_FIXES = {
        "ê¸° ë³¸ ì • ì‹ ": "ê¸°ë³¸ì •ì‹ ",
        "ìš©ìƒ": "í†µìƒ",
        "ì „ì¡±": "ì „ì†",
        "í•´íŒŒêµ°ì§ì±„ìš©": "ì˜ˆë¹„êµ°ì§€íœ˜ê´€",
        "ìˆ˜ìŠµì„ìš©ì”ë£Œ": "ìˆ˜ìŠµì„ìš©ì",
        "ë³‘ì— ê³„ì‚°": "í¬í•¨ ê³„ì‚°",
        "ë¶€ë¬´": "ë³µë¬´",
        "ì „ì¼ì—°êµ¬ì›": "ì „ì„ì—°êµ¬ì›",
        "ë˜ëŠ”ì˜": "ê³ ë„ì˜",
        "ì‹œì²¨ì •": "ì‹œí—˜ì„±ì ",
        "ì±„ìš©ì†Œì”¨ê²°ê³¼": "ì±„ìš©ì‹ ì²´ê²€ì‚¬",
        "ì‹ ì›ì¡°ì§ê²°ê³¼": "ì‹ ì›ì¡°íšŒê²°ê³¼",
        "ê°ì‚¬ìœ„ì›": "ë¶€íŒ¨ë°©ì§€",
    }
    
    # OCR_FIXES 24ê°œ (ê¸°ì¡´)
    OCR_FIXES = [
        (re.compile(r'ì±„\s*ì±„\s*ê·œì •'), 'ì±„ìš©ê·œì •'),
        (re.compile(r'ì¸í„´\s*ì±„\s*í†µìƒ'), 'ì¸í„´Â·í†µìƒ'),
        (re.compile(r'ì„\s*í†µìƒ'), 'ì¸í„´Â·í†µìƒ'),
        (re.compile(r'ì„¤\s*ì°¨\s*ì '), 'ì ˆì°¨ì '),
        (re.compile(r'ì£¼ì‹\s*ë²•\s*ì²˜ë²Œ\s*ë²•'), 'ì„±í­ë ¥ë²”ì£„ ì²˜ë²Œ ë“±ì— ê´€í•œ íŠ¹ë¡€ë²•'),
        (re.compile(r'ì„±ê³¼\s*ê³„\s*ê±°\s*ì‹œ\s*ë‹¨\s*ìƒ'), 'ì„±ê³¼ê°œì„ ëŒ€ìƒì'),
        (re.compile(r'ì„±ê³¼\s*ê°œ\s*ê°œ\s*ì§„\s*ìƒ\s*ì'), 'ì„±ê³¼ê°œì„ ëŒ€ìƒì'),
        (re.compile(r'ë³€ê²½\s*ì‹œ\s*ì„\s*í•¨'), 'ë³€ê²½ì‹œí‚´'),
        (re.compile(r'ë³µì§\s*ì‹œ\s*ì„'), 'ë³µì§ì‹œí‚´'),
        (re.compile(r'ì±„ìš©\s*ì†Œ\s*ì¬\s*ê²°ê³¼'), 'ì±„ìš©ì‹ ì²´ê²€ì‚¬'),
        (re.compile(r'ì±„ìš©\s*ì†Œ\s*ì”¨\s*ê²°ê³¼'), 'ì±„ìš©ì‹ ì²´ê²€ì‚¬'),
        (re.compile(r'íŒê²°\s*íŒê²°'), 'ì§•ê³„íŒê²°'),
        (re.compile(r'ì €ì§ˆëŸ¬\s*ë¼\s*í•˜ë©´'), 'ì €ì§ˆëŸ¬ íŒŒë©´'),
        (re.compile(r'ë°˜\s*í•œ\s*ê²°ê²©'), 'ë¶ˆí•©ê²© ì²˜ë¦¬'),
        (re.compile(r'êµ°\s*ë²•ë¬´ê´€'), 'ë¶€íŒ¨ë°©ì§€'),
        (re.compile(r'ëŒ€\s*ì—°\s*ë³´ì•ˆ'), 'ëŒ€ì™¸ ë³´ì•ˆ'),
        (re.compile(r'íƒœ\s*ì—°\s*ë³´ì•ˆ'), 'ëŒ€ì™¸ ë³´ì•ˆ'),
        (re.compile(r'ìˆ˜ìŠµ\s*ì„ìš©\s*ì”\s*ë£Œ'), 'ìˆ˜ìŠµì„ìš©ì'),
        (re.compile(r'ì§ì›\s*ë°©ì‹\s*ì ˆì°¨'), 'ì§ê¶Œë©´ì§'),
        (re.compile(r'ë³‘í•´\s*ê³„ì‚°'), 'í¬í•¨ ê³„ì‚°'),
        (re.compile(r'ê³µê°œ\s*ê²½ì§„\s*ì‹¬ì‚¬'), 'ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ'),
        (re.compile(r'ê²½ë ¥\s*ì§\s*ì„ìš©'), 'ì§ì›ìœ¼ë¡œ ì„ìš©'),
        (re.compile(r'ì„ìš©\s*ê¶Œ\s*ë‹¤'), 'ì„ìš©í•œë‹¤'),
        (re.compile(r'ì‚¬\s*ì±„'), 'ì‚­ì œ'),
    ]
    
    SAFE_PATTERNS = [
        (r'\s+', ' '),
        (r'\n{3,}', '\n\n'),
        (r'^\s+', ''),
        (r'\s+$', ''),
    ]
    
    OCR_PATTERNS = [
        (r'(\d+)\s*\.\s*(\d+)\s*\.\s*(\d+)', r'\1.\2.\3'),
        (r'ì œ\s*(\d+)\s*ì¡°', r'ì œ\1ì¡°'),
        (r'ì œ\s*(\d+)\s*í•­', r'ì œ\1í•­'),
    ]
    
    def __init__(self):
        logger.info("âœ… TypoNormalizer Phase 0.4.0 P0-1 ì´ˆê¸°í™” (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸)")
        logger.info(f"   ğŸ“– CRITICAL_FIXES: {len(self.CRITICAL_FIXES)}ê°œ ë£°")
        logger.info(f"   ğŸ“– DOMAIN_FIXES: {len(self.DOMAIN_FIXES)}ê°œ ë£°")
        logger.info(f"   ğŸ“– OCR_FIXES: {len(self.OCR_FIXES)}ê°œ íŒ¨í„´")
        logger.info(f"   ğŸ“– Safe: {len(self.SAFE_PATTERNS)}ê°œ ë£°")
        logger.info(f"   ğŸ“– OCR: {len(self.OCR_PATTERNS)}ê°œ ë£°")
        logger.info("   ğŸ›¡ï¸ ì¡°ë¬¸ ë²ˆí˜¸ ì ˆëŒ€ ë³´í˜¸ í™œì„±í™”")
    
    def _extract_protected_zones(self, text: str) -> List[Tuple[int, int, str]]:
        """
        âœ… P0-1: ì¡°ë¬¸ ë²ˆí˜¸ ì˜ì—­ ì¶”ì¶œ (ì ˆëŒ€ ë³´í˜¸)
        
        ë³´í˜¸ ëŒ€ìƒ:
        - ì œNì¡°
        - ì œNì¡°ì˜N
        - ì œNì¡° ì œNí•­
        - ì œNì¡° ì œNí˜¸
        
        Returns:
            List[(start, end, matched_text)]
        """
        protected_zones = []
        
        for match in self.ARTICLE_PATTERN.finditer(text):
            start = match.start()
            end = match.end()
            matched = match.group(0)
            
            protected_zones.append((start, end, matched))
        
        if protected_zones:
            logger.info(f"   ğŸ›¡ï¸ ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ ì˜ì—­: {len(protected_zones)}ê°œ")
            # ìƒ˜í”Œ í‘œì‹œ (ì²˜ìŒ 3ê°œ)
            for i, (s, e, m) in enumerate(protected_zones[:3], 1):
                logger.debug(f"      [{i}] {m}")
        
        return protected_zones
    
    def _is_in_protected_zone(self, pos: int, protected_zones: List[Tuple[int, int, str]]) -> bool:
        """ìœ„ì¹˜ê°€ ë³´í˜¸ ì˜ì—­ ë‚´ë¶€ì¸ì§€ í™•ì¸"""
        for start, end, _ in protected_zones:
            if start <= pos < end:
                return True
        return False
    
    def _safe_replace(
        self,
        text: str,
        pattern: str,
        replacement: str,
        protected_zones: List[Tuple[int, int, str]],
        is_regex: bool = False
    ) -> Tuple[str, int]:
        """
        âœ… ë³´í˜¸ ì˜ì—­ì„ í”¼í•´ì„œ ì•ˆì „í•˜ê²Œ ì¹˜í™˜
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            pattern: ì¹˜í™˜ íŒ¨í„´ (ë¬¸ìì—´ ë˜ëŠ” ì •ê·œì‹)
            replacement: ì¹˜í™˜ ë¬¸ìì—´
            protected_zones: ë³´í˜¸ ì˜ì—­ ë¦¬ìŠ¤íŠ¸
            is_regex: ì •ê·œì‹ ì—¬ë¶€
        
        Returns:
            (ì¹˜í™˜ëœ í…ìŠ¤íŠ¸, ì¹˜í™˜ íšŸìˆ˜)
        """
        if not protected_zones:
            # ë³´í˜¸ ì˜ì—­ ì—†ìœ¼ë©´ ì¼ë°˜ ì¹˜í™˜
            if is_regex:
                matches = list(re.finditer(pattern, text))
                count = len(matches)
                text = re.sub(pattern, replacement, text)
            else:
                count = text.count(pattern)
                text = text.replace(pattern, replacement)
            return text, count
        
        # ë³´í˜¸ ì˜ì—­ì´ ìˆìœ¼ë©´ ì•ˆì „ ì¹˜í™˜
        if is_regex:
            matches = list(re.finditer(pattern, text))
        else:
            # ë¬¸ìì—´ íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ë³€í™˜
            escaped = re.escape(pattern)
            matches = list(re.finditer(escaped, text))
        
        # ì—­ìˆœìœ¼ë¡œ ì¹˜í™˜ (ì¸ë±ìŠ¤ ê¼¬ì„ ë°©ì§€)
        count = 0
        for match in reversed(matches):
            start = match.start()
            
            # ë³´í˜¸ ì˜ì—­ ì²´í¬
            if not self._is_in_protected_zone(start, protected_zones):
                text = text[:start] + replacement + text[match.end():]
                count += 1
        
        return text, count
    
    def normalize(self, text: str) -> str:
        """ì •ê·œí™” ì‹¤í–‰ (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸)"""
        if not text:
            return text
        
        original_len = len(text)
        result = text
        
        # âœ… 1. ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ ì˜ì—­ ì¶”ì¶œ
        protected_zones = self._extract_protected_zones(result)
        
        # 2. CRITICAL_FIXES (ë³´í˜¸ ì˜ì—­ í”¼í•´ì„œ)
        critical_count = 0
        critical_diffs = []
        for wrong, correct in self.CRITICAL_FIXES.items():
            new_result, count = self._safe_replace(
                result, wrong, correct, protected_zones
            )
            if count > 0:
                result = new_result
                critical_count += count
                critical_diffs.append(f"{wrong} â†’ {correct}")
        
        # 3. DOMAIN_FIXES (ë³´í˜¸ ì˜ì—­ í”¼í•´ì„œ)
        domain_count = 0
        domain_diffs = []
        for wrong, correct in self.DOMAIN_FIXES.items():
            new_result, count = self._safe_replace(
                result, wrong, correct, protected_zones
            )
            if count > 0:
                result = new_result
                domain_count += count
                domain_diffs.append(f"{wrong} â†’ {correct}")
        
        # 4. OCR_FIXES (ë³´í˜¸ ì˜ì—­ í”¼í•´ì„œ)
        ocr_fixes_count = 0
        ocr_fixes_diffs = []
        for pattern, replacement in self.OCR_FIXES:
            new_result, count = self._safe_replace(
                result, pattern, replacement, protected_zones, is_regex=True
            )
            if count > 0:
                # ìƒ˜í”Œ ë§¤ì¹˜ ì €ì¥
                matches = pattern.findall(result)
                sample = matches[0] if matches else ''
                result = new_result
                ocr_fixes_count += count
                ocr_fixes_diffs.append(f"{sample} â†’ {replacement}")
        
        # 5. Safe íŒ¨í„´ (ì¡°ë¬¸ ë²ˆí˜¸ì— ì˜í–¥ ì—†ìŒ)
        safe_count = 0
        for pattern, replacement in self.SAFE_PATTERNS:
            before = len(re.findall(pattern, result))
            if before > 0:
                result = re.sub(pattern, replacement, result)
                safe_count += before
        
        # 6. OCR íŒ¨í„´ (ì¡°ë¬¸ ë²ˆí˜¸ì— ì˜í–¥ ì—†ìŒ)
        ocr_count = 0
        for pattern, replacement in self.OCR_PATTERNS:
            before = len(re.findall(pattern, result))
            if before > 0:
                result = re.sub(pattern, replacement, result)
                ocr_count += before
        
        logger.info(f"âœ… ì •ê·œí™” ì™„ë£Œ (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸):")
        logger.info(f"   Critical: {len(self.CRITICAL_FIXES)}ê°œ ë£° / {critical_count}ê±´ ì¹˜í™˜")
        if critical_diffs:
            logger.info(f"      ì˜ˆ: {', '.join(critical_diffs[:3])}")
        
        logger.info(f"   Domain: {len(self.DOMAIN_FIXES)}ê°œ ë£° / {domain_count}ê±´ ì¹˜í™˜")
        if domain_diffs:
            logger.info(f"      ì˜ˆ: {', '.join(domain_diffs[:3])}")
        
        logger.info(f"   OCR_Fixes: {len(self.OCR_FIXES)}ê°œ íŒ¨í„´ / {ocr_fixes_count}ê±´ ì¹˜í™˜")
        if ocr_fixes_diffs:
            logger.info(f"      ì˜ˆ: {', '.join(ocr_fixes_diffs[:3])}")
        
        logger.info(f"   Safe: {len(self.SAFE_PATTERNS)}ê°œ ë£° / {safe_count}ê±´ ì¹˜í™˜")
        logger.info(f"   OCR: {len(self.OCR_PATTERNS)}ê°œ ë£° / {ocr_count}ê±´ ì¹˜í™˜")
        logger.info(f"   ê¸¸ì´: {original_len} â†’ {len(result)} ({len(result)-original_len:+d})")
        
        return result