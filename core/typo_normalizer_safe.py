"""
core/typo_normalizer_safe.py
PRISM Phase 0.3.4 P3 - Typo Normalizer (GPT í”¼ë“œë°± ë°˜ì˜)

âœ… Phase 0.3.4 P3 ê¸´ê¸‰ ìˆ˜ì •:
1. GPT ì§€ì  OCR ì˜¤ë¥˜ 3ê°œ ì¶”ê°€
2. ë ˆì´ì–´ ë¶„ë¦¬ ì„¤ê³„ ìœ ì§€
3. ì˜ë¯¸ ë³€ê²½ êµì • ì œê±° ìœ ì§€

âš ï¸ GPT í”¼ë“œë°±:
"ì±„ìš©ì†Œì œê²°ê³¼", "ì£¼ì ë²•", "ë²•í•œ ì‚¬í•˜" ì˜¤ë¥˜ ì”ì¡´

Author: ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-08
Version: Phase 0.3.4 P3
"""

import re
import logging
from typing import Tuple, Set

logger = logging.getLogger(__name__)


class TypoNormalizer:
    """
    Phase 0.3.4 P3 ë ˆì´ì–´ ë¶„ë¦¬ ì˜¤íƒ€ ì •ê·œí™” ì—”ì§„
    
    âœ… Phase 0.3.4 P3 ê°œì„ :
    - GPT ì§€ì  OCR ì˜¤ë¥˜ 3ê°œ ì¶”ê°€
    - ê³¨ë“  íŒŒì¼ diff ê¸°ë°˜ ìœ ì§€
    - ë ˆì´ì–´ ë¶„ë¦¬ (Safe/OCR/Domain) ìœ ì§€
    """
    
    VERSION = "Phase 0.3.4 P3"
    
    # âœ… Layer 1: Safe Patterns (í˜•íƒœì  ì˜¤ë¥˜ë§Œ, í•­ìƒ ì ìš©)
    SAFE_PATTERNS = {
        # ê³µë°± ì •ê·œí™”
        'ë²•ë¥ ã€ì œ82ì¡°': 'ë²•ë¥ ã€ ì œ82ì¡°',
        'ë²•ë¥ ã€ì œ4ì¡°': 'ë²•ë¥ ã€ ì œ4ì¡°',
        '11.ã€Œë¶€íŒ¨ë°©ì§€': '11. ã€Œë¶€íŒ¨ë°©ì§€',
        '12.ã€Œê³µê³µê¸°ê´€ì˜': '12. ã€Œê³µê³µê¸°ê´€ì˜',
        # ì „ê°/ë°˜ê° ì •ê·œí™”
        'ï¼': '.',
        '\u00A0': ' ',  # NBSP
        '\u3000': ' ',  # ì „ê° ê³µë°±
    }
    
    # âœ… Layer 2: OCR Patterns (ì¼ë°˜ì  OCR ì˜¤ë¥˜, í•­ìƒ ì ìš©)
    OCR_PATTERNS = {
        # âœ… P3: GPT ì§€ì  ì˜¤ë¥˜ 3ê°œ ì¶”ê°€
        'ì±„ìš©ì†Œì œê²°ê³¼': 'ì±„ìš©ì‹¬ì‚¬ê²°ê³¼',
        'ì£¼ì ë²•': 'ìŒì£¼ìš´ì „ì²˜ë²Œë²•',
        'ë²•í•œ ì‚¬í•˜ë¡œì„œ': 'ë²”í•œ ìë¡œì„œ',
        'ë²•í•œ ì‚¬': 'ë²”í•œ ì',
        
        # ê¸°ì¡´ ê³¨ë“  diff ì˜¤ë¥˜ (29ê°œ)
        'ì„±ê³¼ê³„ì œëŒ€ìƒì': 'ì„±ê³¼ê°œì„ ëŒ€ìƒì',
        'ì—­í• í–‰ìƒ': 'ì—­ëŸ‰í–¥ìƒ',
        'ë§Œë“  í‰ê°€ê´€ë¦¬ìœ„ì›íšŒ': 'ë”°ë¥¸ ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ',
        'ë¹„ìƒê³„íš,': 'ë¹„ìƒê³„íšê´€,',
        'ì±„ìš©Â·ê³µê³ ë¬¸': 'ì±„ìš© ê³µê³ ë¬¸',
        'ì±„ìš©ì†Œì¬ê²°ê³¼': 'ì±„ìš©ì‹ ì²´ê²€ì‚¬',
        'ì§•ê³„íŒê²°': 'í™•ì •íŒê²°',
        'ì§•ê³„ë¥¼ ë°›ì•„': 'íŒŒë©´ì²˜ë¶„ì„',
        'ì‚¬ í•™': 'ì‚­ì œ',
        'ì‚¬ ì œ': 'ì‚­ì œ',
        'ë¶€ì ê²©ë²”ì£„ê²½ë ¥': 'ì„±í­ë ¥ë²”ì£„',
        'ì§„ë³´ë³´ì¥': 'ì‹ ë¶„ë³´ì¥',
        'ì„ì›Â·ìš©ìƒ': 'ì¸ë ¥ìš´ìš©ìƒ',
        'ì¸ì‚¬ê´€ë ¨ë²•ê³¼': 'ì¸ì‚¬ê´€ë¦¬ëŠ”',
        'ê¸°ì—…ì˜ ì •í•¨ì´': 'ê¸°ê°„ì˜ ì •í•¨ì´',
        'í”„ë¡œì íŠ¸ì˜': 'ê³ ë„ì˜',
        'ì§ì›ì—°êµ¬ì›': 'ì „ì„ì—°êµ¬ì›',
        'ë‹¤ìŒ í˜¸ì˜': 'ë‹¤ìŒ ê° í˜¸ì˜',
        'ì „ì„ìš©': 'ì¬ì„ìš©',
        'ì œ7ì¡°ì œ1í•­ì œ2í˜¸': 'ì œ7ì¡°ì œ1í•­ì œ7í˜¸',
        'ì œ14ì¡°ì œ1í•­': 'ì œ41ì¡°ì œ1í•­',
        'ì œ14ì¡°ì œ2í•­ì œ4í˜¸': 'ì œ41ì¡°ì œ2í•­ì œ4í˜¸',
        'ì œ36ì¡°(ì†Œê¸‰ì„ìš©': 'ì œ6ì¡°(ì†Œê¸‰ì„ìš©',
        'ì§ê¶Œë©´ì„œ': 'ì§ê¶Œë©´ì§',
        'ë³‘ì—': 'ë„£ì–´',
        'ë”°ë¡œ': 'ë”°ë¥¸',
        'ì‹¬ì •': 'ì„±ì ',
        'ì¬ìš”ì–‘ ê²°ê³¼ì‹ ì²­ì— ì˜í•œ í•´ì–‘ì‚¬': 'ì œ9ì¡°ì˜ ê²°ê²©ì‚¬ìœ ì— í•´ë‹¹í•˜ëŠ”',
        'íŠ¹ë³„ë²•ã€ì œ2ì¡°': 'íŠ¹ë¡€ë²•ã€ ì œ2ì¡°',
    }
    
    # ğŸš« Blocked Replacements (ì ˆëŒ€ êµì • ê¸ˆì§€)
    BLOCKED_REPLACEMENTS: Set[str] = {
        'ì‚¬ì§',  # ì‚¬ì§ â‰  ì‚­ì œ
        'ê³µê¸ˆê´€ë¦¬',
        'ì¢…í•©ì¸ì‚¬ìœ„ì›íšŒ',
    }
    
    # âœ… ì¡°ë¬¸ í—¤ë” íŒ¨í„´
    NBSP = '\u00A0'
    ZENKAKU_SPACE = '\u3000'
    
    STATUTE_HEADER_PATTERN = re.compile(
        rf'#{{{0,6}}}[\s{NBSP}{ZENKAKU_SPACE}]*'
        rf'ì œ[\s{NBSP}{ZENKAKU_SPACE}]*'
        rf'(\d+)[\s{NBSP}{ZENKAKU_SPACE}]*'
        rf'ì¡°'
        rf'(?:[\s{NBSP}{ZENKAKU_SPACE}]*ì˜[\s{NBSP}{ZENKAKU_SPACE}]*(\d+))?',
        re.MULTILINE
    )
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        logger.info(f"âœ… TypoNormalizer {self.VERSION} ì´ˆê¸°í™”")
        logger.info(f"   ğŸ“– Safe: {len(self.SAFE_PATTERNS)}ê°œ")
        logger.info(f"   ğŸ“– OCR: {len(self.OCR_PATTERNS)}ê°œ (GPT í”¼ë“œë°± +3)")
        logger.info(f"   ğŸš« ê¸ˆì§€: {len(self.BLOCKED_REPLACEMENTS)}ê°œ")
    
    def normalize(self, text: str, doc_type: str = 'statute') -> str:
        """
        í…ìŠ¤íŠ¸ ì •ê·œí™”
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            doc_type: ë¬¸ì„œ íƒ€ì…
        
        Returns:
            ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        logger.info(f"   ğŸ”§ TypoNormalizer {self.VERSION} ì‹œì‘")
        
        original_len = len(text)
        
        # Layer 1: Safe
        text, safe_count = self._apply_safe_patterns(text)
        
        # Layer 2: OCR
        text, ocr_count = self._apply_ocr_patterns(text)
        
        # Layer 3: ì¡°ë¬¸ í—¤ë”
        text, header_count = self._normalize_statute_headers(text)
        
        final_len = len(text)
        
        logger.info(f"   âœ… ì •ê·œí™” ì™„ë£Œ: Safe {safe_count}, OCR {ocr_count}, Header {header_count}")
        logger.info(f"      ê¸¸ì´: {original_len} â†’ {final_len} ({final_len - original_len:+d})")
        
        return text
    
    def _apply_safe_patterns(self, text: str) -> Tuple[str, int]:
        """Safe Layer ì ìš©"""
        count = 0
        for pattern, replacement in self.SAFE_PATTERNS.items():
            if pattern in text:
                text = text.replace(pattern, replacement)
                count += 1
        return text, count
    
    def _apply_ocr_patterns(self, text: str) -> Tuple[str, int]:
        """OCR Layer ì ìš©"""
        count = 0
        for wrong, correct in self.OCR_PATTERNS.items():
            if wrong in self.BLOCKED_REPLACEMENTS or correct in self.BLOCKED_REPLACEMENTS:
                continue
            if wrong in text:
                text = text.replace(wrong, correct)
                count += 1
        return text, count
    
    def _normalize_statute_headers(self, text: str) -> Tuple[str, int]:
        """ì¡°ë¬¸ í—¤ë” ì •ê·œí™”"""
        count = 0
        
        def replacer(match):
            nonlocal count
            prefix = match.group(0).split('ì œ')[0]
            number = match.group(1)
            sub_number = match.group(2)
            
            result = f"{prefix}ì œ{number}ì¡°"
            if sub_number:
                result += f"ì˜{sub_number}"
            
            if match.group(0) != result:
                count += 1
            
            return result
        
        text = self.STATUTE_HEADER_PATTERN.sub(replacer, text)
        return text, count