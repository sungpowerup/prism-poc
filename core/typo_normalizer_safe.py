"""
core/typo_normalizer_safe.py
PRISM Phase 0.4.0 P0-3.1 - Hotfix (ìœ„í—˜ ë£° ì œê±°)

âœ… P0-3.1 ê¸´ê¸‰ ìˆ˜ì •:
1. "ë˜ëŠ”ì˜ â†’ ê³ ë„ì˜" ìœ„í—˜ ë£° ì œê±°
2. ì•ˆì „í•œ êµì •ë§Œ ìœ ì§€
3. ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ ìœ ì§€

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ + GPT í”¼ë“œë°± ë°˜ì˜
Date: 2025-11-13
Version: Phase 0.4.0 P0-3.1
"""

import re
import logging
from typing import Dict, List, Tuple

logger = logging.getLogger(__name__)


class TypoNormalizer:
    """Phase 0.4.0 P0-3.1 ì˜¤íƒˆì êµì • (ìœ„í—˜ ë£° ì œê±°)"""
    
    # ============================================
    # Critical Fixes (í•„ìˆ˜ êµì •)
    # ============================================
    CRITICAL_FIXES = {
        # ì¡°ë¬¸ í‘œê¸° ì˜¤ë¥˜
        "ì„ìš©í•œ": "ì„ìš©ê¶Œ",
        "ì¥ê´€": "ì •ê´€",
        
        # ê¸°ë³¸ì •ì‹  í•„ìˆ˜ ì •ê·œí™”
        "ê¸° ë³¸ ì • ì‹ ": "ê¸°ë³¸ì •ì‹ ",
        "ê¸°ë³¸ ì •ì‹ ": "ê¸°ë³¸ì •ì‹ ",
        
        # ëª…ë°±í•œ ì˜¤íƒ€
        "ì¹ìš©": "ì„ìš©",
        "ì§ì›ì˜ì˜": "ì§ì›ì˜",
        "ì‚¬í•­ì„ì„": "ì‚¬í•­ì„",
        "ê·œì •ì€ì€": "ê·œì •ì€",
        "í•œêµ­ë†ì–´ì´Œê³µì‚¬ê³µì‚¬": "í•œêµ­ë†ì–´ì´Œê³µì‚¬",
        "ë”°ë¼ë”°ë¼": "ë”°ë¼",
    }
    
    # ============================================
    # Domain Fixes (ë„ë©”ì¸ íŠ¹í™” êµì •)
    # âœ… P0-3.1: ìœ„í—˜ ë£° ì œê±°
    # ============================================
    DOMAIN_FIXES = {
        # âœ… ì•ˆì „í•œ êµì •ë§Œ ìœ ì§€
        "ìš©ìƒ": "í†µìƒ",
        "ì „ì¡±": "ì „ì†",
        "í•´íŒŒêµ°ì§ì±„ìš©": "ì˜ˆë¹„êµ°ì§€íœ˜ê´€",
        "ìˆ˜ìŠµì„ìš©ì”ë£Œ": "ìˆ˜ìŠµì„ìš©ì",
        "ë³‘ì— ê³„ì‚°": "í¬í•¨ ê³„ì‚°",
        "ì¹ë¬´": "ì—…ë¬´",
        "ê·œì¹™": "ê·œì •",
        "ì¸ì‚¬ê·œì •ì •": "ì¸ì‚¬ê·œì •",
        "í•œêµ­ë†ì–´ì´Œê³µì‚¬ì‚¬": "í•œêµ­ë†ì–´ì´Œê³µì‚¬",
        
        # âŒ ì œê±°ëœ ìœ„í—˜ ë£°
        # "ë˜ëŠ”ì˜": "ê³ ë„ì˜",  # ì˜ë¯¸ ì™œê³¡ ìœ„í—˜!
    }
    
    # ============================================
    # OCR Fixes (OCR ì˜¤ë¥˜ íŒ¨í„´)
    # ============================================
    OCR_FIXES = [
        # ì¡°ë¬¸ ë²ˆí˜¸ ì£¼ë³€ ì˜¤ë¥˜
        (r'ì œ(\d+)ì¡°ì˜(\d+)', r'ì œ\1ì¡°ì˜\2'),  # ì œ5ì¡°ì˜2
        (r'ì œ(\d+)ì£„', r'ì œ\1ì¡°'),
        (r'ì œ(\d+)ì¦ˆ', r'ì œ\1ì¡°'),
        (r'ì œ(\d+)ìª¼', r'ì œ\1ì¡°'),
        
        # ì¼ë°˜ ì˜¤ë¥˜
        (r'ê²¸ì…', 'ê²¸ì„'),
        (r'ì§ì›ì˜ì˜', 'ì§ì›ì˜'),
        (r'ì‚¬ì¥ì´ì´', 'ì‚¬ì¥ì´'),
        (r'ê·œì •ì€ì€', 'ê·œì •ì€'),
        (r'í•œêµ­ë†ì–´ì´Œê³µì‚¬ì‚¬', 'í•œêµ­ë†ì–´ì´Œê³µì‚¬'),
        
        # ë‚ ì§œ íŒ¨í„´ ì˜¤ë¥˜
        (r'(\d{4})\.(\d{1,2})\.(\d{1,2})\s*\)', r'\1.\2.\3'),
        
        # ê³µë°± ì˜¤ë¥˜
        (r'ì œ\s+(\d+)\s+ì¡°', r'ì œ\1ì¡°'),
        (r'ì œ\s+(\d+)\s+ì¥', r'ì œ\1ì¥'),
        (r'(\d+)\s*ê¸‰', r'\1ê¸‰'),
        
        # íŠ¹ìˆ˜ë¬¸ì ì˜¤ë¥˜
        (r'âŸ¨\s*(\d+)\s*âŸ©', r'\1'),
        (r'ï¼»\s*(\d+)\s*ï¼½', r'\1'),
        
        # OCR í˜¼ë™ ë¬¸ì
        (r'ì¹ìš©', 'ì„ìš©'),
        (r'ìš©ìƒ', 'í†µìƒ'),
        (r'ì „ì¡±', 'ì „ì†'),
        (r'ë³‘í•´ ê³„ì‚°', 'í¬í•¨ ê³„ì‚°'),
        (r'ì„ìš©ê¶Œë‹¤', 'ì„ìš©í•œë‹¤'),
        (r'ê·œì¹™ì—', 'ê·œì •ì—'),
    ]
    
    # ============================================
    # Safe Fixes (ì•ˆì „í•œ ì •ê·œí™”)
    # ============================================
    SAFE_FIXES = {
        "  ": " ",           # ì—°ì† ê³µë°±
        "ã€€": " ",           # ì „ê° ê³µë°±
        "ã€‚": ".",           # ì „ê° ë§ˆì¹¨í‘œ
        "\u3000": " ",       # ì „ê° ê³µë°± (ìœ ë‹ˆì½”ë“œ)
    }
    
    # ============================================
    # ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ íŒ¨í„´
    # ============================================
    ARTICLE_PATTERN = re.compile(r'ì œ\s*\d+\s*ì¡°(?:ì˜\s*\d+)?')
    
    def __init__(self):
        logger.info("âœ… TypoNormalizer Phase 0.4.0 P0-3.1 ì´ˆê¸°í™” (Hotfix)")
        logger.info(f"   ğŸ“– CRITICAL_FIXES: {len(self.CRITICAL_FIXES)}ê°œ ë£°")
        logger.info(f"   ğŸ“– DOMAIN_FIXES: {len(self.DOMAIN_FIXES)}ê°œ ë£°")
        logger.info(f"   ğŸ“– OCR_FIXES: {len(self.OCR_FIXES)}ê°œ íŒ¨í„´")
        logger.info(f"   ğŸ“– Safe: {len(self.SAFE_FIXES)}ê°œ ë£°")
        logger.info("   ğŸ›¡ï¸ ì¡°ë¬¸ ë²ˆí˜¸ ì ˆëŒ€ ë³´í˜¸ í™œì„±í™”")
        logger.info("   âš ï¸ ìœ„í—˜ ë£° ì œê±°: ë˜ëŠ”ì˜ â†’ ê³ ë„ì˜")
    
    def normalize(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™” (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸)"""
        
        # 1. ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ ì˜ì—­ ë§ˆí‚¹
        protected_regions = []
        for m in self.ARTICLE_PATTERN.finditer(text):
            protected_regions.append((m.start(), m.end()))
        
        logger.info(f"   ğŸ›¡ï¸ ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸ ì˜ì—­: {len(protected_regions)}ê°œ")
        
        original_len = len(text)
        
        # 2. Critical Fixes (ì¡°ë¬¸ ë²ˆí˜¸ ì œì™¸)
        critical_count = 0
        critical_examples = []
        
        for wrong, right in self.CRITICAL_FIXES.items():
            if wrong in text:
                # ì¡°ë¬¸ ë²ˆí˜¸ ë‚´ë¶€ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¹˜í™˜
                for m in re.finditer(re.escape(wrong), text):
                    pos = m.start()
                    # ë³´í˜¸ ì˜ì—­ ì²´í¬
                    in_protected = any(start <= pos < end for start, end in protected_regions)
                    if not in_protected:
                        text = text[:pos] + right + text[pos + len(wrong):]
                        critical_count += 1
                        if len(critical_examples) < 3:
                            critical_examples.append(f"{wrong} â†’ {right}")
        
        # 3. Domain Fixes (ì¡°ë¬¸ ë²ˆí˜¸ ì œì™¸)
        domain_count = 0
        domain_examples = []
        
        for wrong, right in self.DOMAIN_FIXES.items():
            if wrong in text:
                for m in re.finditer(re.escape(wrong), text):
                    pos = m.start()
                    in_protected = any(start <= pos < end for start, end in protected_regions)
                    if not in_protected:
                        text = text[:pos] + right + text[pos + len(wrong):]
                        domain_count += 1
                        if len(domain_examples) < 3:
                            domain_examples.append(f"{wrong} â†’ {right}")
        
        # 4. OCR Fixes (íŒ¨í„´ ê¸°ë°˜)
        ocr_count = 0
        ocr_examples = []
        
        for pattern, replacement in self.OCR_FIXES:
            matches = list(re.finditer(pattern, text))
            for m in matches:
                pos = m.start()
                in_protected = any(start <= pos < end for start, end in protected_regions)
                if not in_protected:
                    before = m.group(0)
                    after = re.sub(pattern, replacement, before)
                    text = text[:pos] + after + text[m.end():]
                    ocr_count += 1
                    if len(ocr_examples) < 3 and before != after:
                        ocr_examples.append(f"{before} â†’ {after}")
        
        # 5. Safe Fixes (ì „ì²´ ì ìš©)
        safe_count = 0
        for wrong, right in self.SAFE_FIXES.items():
            count = text.count(wrong)
            if count > 0:
                text = text.replace(wrong, right)
                safe_count += count
        
        # 6. OCR ê¸°ë³¸ ì •ë¦¬ (ì „ì²´ ì ìš©)
        ocr_basic_count = 0
        
        # ì—°ì† ê³µë°±
        before_spaces = text
        text = re.sub(r' {2,}', ' ', text)
        ocr_basic_count += len(before_spaces) - len(text)
        
        # ì—°ì† ì¤„ë°”ê¿ˆ (3ê°œ ì´ìƒ â†’ 2ê°œ)
        before_newlines = text
        text = re.sub(r'\n{3,}', '\n\n', text)
        ocr_basic_count += len(before_newlines) - len(text)
        
        # ì¡°ë¬¸ ë²ˆí˜¸ ê³µë°± ì •ë¦¬
        text = re.sub(r'ì œ\s+(\d+)\s+ì¡°', r'ì œ\1ì¡°', text)
        
        # 7. ë¡œê·¸ ì¶œë ¥
        logger.info("âœ… ì •ê·œí™” ì™„ë£Œ (ì¡°ë¬¸ ë²ˆí˜¸ ë³´í˜¸):")
        logger.info(f"   Critical: {len(self.CRITICAL_FIXES)}ê°œ ë£° / {critical_count}ê±´ ì¹˜í™˜")
        if critical_examples:
            logger.info(f"      ì˜ˆ: {', '.join(critical_examples)}")
        
        logger.info(f"   Domain: {len(self.DOMAIN_FIXES)}ê°œ ë£° / {domain_count}ê±´ ì¹˜í™˜")
        if domain_examples:
            logger.info(f"      ì˜ˆ: {', '.join(domain_examples)}")
        
        logger.info(f"   OCR_Fixes: {len(self.OCR_FIXES)}ê°œ íŒ¨í„´ / {ocr_count}ê±´ ì¹˜í™˜")
        if ocr_examples:
            logger.info(f"      ì˜ˆ: {', '.join(ocr_examples)}")
        
        logger.info(f"   Safe: {len(self.SAFE_FIXES)}ê°œ ë£° / {safe_count}ê±´ ì¹˜í™˜")
        logger.info(f"   OCR: 3ê°œ ë£° / {ocr_basic_count}ê±´ ì¹˜í™˜")
        
        final_len = len(text)
        logger.info(f"   ê¸¸ì´: {original_len} â†’ {final_len} ({final_len - original_len:+d})")
        
        return text