"""
PRISM Phase 3.3 - Layout Detector v3.3 (Balanced Filtering)

âœ… í•µì‹¬ ê°œì„ :
1. Ultra Filtering ì™„í™” (min_region_size: 20,000 â†’ 5,000)
2. í° í‘œ ê°ì§€ í—ˆìš© (max_table_size ëŒ€í­ ì¦ê°€)
3. ì›ê·¸ë˜í”„ ê°ì§€ ê¸°ì¤€ ì™„í™”
4. ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì¶”ê°€
5. ê²½ìŸì‚¬ ìˆ˜ì¤€ ë°ì´í„° ì¶”ì¶œ ëª©í‘œ

Author: ë°•ì¤€í˜¸ (AI/ML Lead) + ì´ì„œì˜ (Backend Lead)
Date: 2025-10-22
Version: 3.3 (Balanced Filtering)
"""

import cv2
import numpy as np
from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class LayoutDetectorV33:
    """
    Layout Detector v3.3 - Balanced Filtering
    
    Phase 3.3 í•µì‹¬ ë°¸ëŸ°ìŠ¤:
    - âœ… min_region_size: 5,000px (20,000 â†’ 5,000, ì ì ˆí•œ í¬ê¸°)
    - âœ… max_table_size: 10,000,000px (í° í‘œë„ í—ˆìš©)
    - âœ… pie_min_radius: 50px (100 â†’ 50, ì‘ì€ ì°¨íŠ¸ ê°ì§€)
    - âœ… ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì¶”ê°€
    - âœ… 3-Stage ìƒ‰ìƒ ê²€ì¦ (5-Stage â†’ 3-Stage, ì ì ˆí•œ ê²€ì¦)
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # â­ ê¸°ë³¸ íŒŒë¼ë¯¸í„° (Balanced)
        self.min_region_size = 5000  # 20,000 â†’ 5,000 (4ë°° ì™„í™”)
        self.confidence_threshold = 0.70
        
        # â­ ì›ê·¸ë˜í”„ íŒŒë¼ë¯¸í„° (ì™„í™”)
        self.pie_chart_params = {
            'dp': 1,
            'minDist': 200,      # 300 â†’ 200
            'param1': 100,
            'param2': 60,        # 80 â†’ 60 (ì™„í™”)
            'minRadius': 50,     # 100 â†’ 50 (ì‘ì€ ì°¨íŠ¸ ê°ì§€)
            'maxRadius': 500
        }
        
        # â­ ìƒ‰ìƒ ê²€ì¦ íŒŒë¼ë¯¸í„° (3-Stageë¡œ ê°„ì†Œí™”)
        self.color_params = {
            'min_sectors': 2,           # Stage 1: ìµœì†Œ ì„¹í„° ìˆ˜
            'min_hsv_range': 25,        # Stage 2: HSV ë²”ìœ„ (40 â†’ 25)
            'min_saturation': 20,       # Stage 3: í‰ê·  ì±„ë„ (30 â†’ 20)
        }
        
        # â­ í‘œ íŒŒë¼ë¯¸í„° (ëŒ€í­ ì™„í™”)
        self.table_params = {
            'min_width': 100,
            'max_width': 5000,      # 800 â†’ 5000 (í° í‘œ í—ˆìš©)
            'min_height': 100,
            'max_height': 10000,    # 1000 â†’ 10000 (í° í‘œ í—ˆìš©)
            'min_h_lines': 2,       # 3 â†’ 2
            'min_v_lines': 2        # 3 â†’ 2
        }
        
        # ë§‰ëŒ€ê·¸ë˜í”„ íŒŒë¼ë¯¸í„°
        self.bar_chart_params = {
            'min_bars': 2,          # 3 â†’ 2
            'max_y_diff': 50,
            'min_bar_area': 500     # 1000 â†’ 500
        }
        
        # â­ Map íŒŒë¼ë¯¸í„° (ì ì ˆí•œ ìˆ˜ì¤€)
        self.map_params = {
            'min_area': 30000,       # 100,000 â†’ 30,000
            'min_complexity': 15,    # 30 â†’ 15
            'max_circularity': 0.7,
            'aspect_ratio_min': 0.5,
            'aspect_ratio_max': 2.0
        }
        
        # â­ ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ íŒŒë¼ë¯¸í„° (ì‹ ê·œ)
        self.text_region_params = {
            'min_text_density': 0.02,
            'max_text_density': 0.30,
            'min_area': 5000,
            'max_aspect_ratio': 5.0
        }
        
        logger.info("ğŸš€ LayoutDetectorV33 ì´ˆê¸°í™” ì™„ë£Œ (Balanced Filtering)")
        logger.info(f"   - min_region_size: {self.min_region_size:,}px (ì™„í™”)")
        logger.info(f"   - pie_min_radius: {self.pie_chart_params['minRadius']}px (ì‘ì€ ì°¨íŠ¸ ê°ì§€)")
        logger.info(f"   - max_table_height: {self.table_params['max_height']:,}px (í° í‘œ í—ˆìš©)")
        logger.info(f"   - 3-Stage ìƒ‰ìƒ ê²€ì¦: ON (ê°„ì†Œí™”)")
        logger.info(f"   - ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€: ON (ì‹ ê·œ)")
    
    def detect_regions(self, image: np.ndarray, page_num: int = 0) -> List[Dict]:
        """
        ë ˆì´ì•„ì›ƒ ì˜ì—­ ê°ì§€ (Balanced Filtering)
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (numpy array, BGR)
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            ê°ì§€ëœ ì˜ì—­ ë¦¬ìŠ¤íŠ¸
        """
        regions = []
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num + 1} - Layout Detection v3.3 (Balanced)")
        logger.info(f"{'='*60}")
        
        # 1. í—¤ë” ê°ì§€
        logger.info("Stage 1: í—¤ë” ê°ì§€")
        headers = self._detect_headers(image)
        logger.info(f"   â†’ {len(headers)}ê°œ ê°ì§€")
        regions.extend(headers)
        
        # 2. ì›ê·¸ë˜í”„ ê°ì§€ (Balanced + 3-Stage ê²€ì¦)
        logger.info("Stage 2: ì›ê·¸ë˜í”„ ê°ì§€ (3-Stage ê²€ì¦)")
        pie_charts = self._detect_pie_charts_v33(image)
        logger.info(f"   â†’ {len(pie_charts)}ê°œ ê°ì§€")
        regions.extend(pie_charts)
        
        # 3. ë§‰ëŒ€ê·¸ë˜í”„ ê°ì§€
        logger.info("Stage 3: ë§‰ëŒ€ê·¸ë˜í”„ ê°ì§€")
        bar_charts = self._detect_bar_charts(image)
        logger.info(f"   â†’ {len(bar_charts)}ê°œ ê°ì§€")
        regions.extend(bar_charts)
        
        # 4. í‘œ ê°ì§€ (í° í‘œ í—ˆìš©)
        logger.info("Stage 4: í‘œ ê°ì§€ (í° í‘œ í—ˆìš©)")
        tables = self._detect_tables_v33(image)
        logger.info(f"   â†’ {len(tables)}ê°œ ê°ì§€")
        regions.extend(tables)
        
        # 5. Map ê°ì§€ (ì ì ˆí•œ í•„í„°)
        logger.info("Stage 5: Map ê°ì§€")
        maps = self._detect_maps(image)
        logger.info(f"   â†’ {len(maps)}ê°œ ê°ì§€")
        regions.extend(maps)
        
        # â­ 6. ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (ì‹ ê·œ)
        logger.info("Stage 6: ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (ì‹ ê·œ)")
        text_regions = self._detect_text_regions(image)
        logger.info(f"   â†’ {len(text_regions)}ê°œ ê°ì§€")
        regions.extend(text_regions)
        
        # 7. ì¤‘ë³µ ì œê±° ë° ë³‘í•©
        logger.info("Stage 7: ì¤‘ë³µ ì œê±° ë° ë³‘í•©")
        regions = self._merge_overlapping_regions(regions)
        logger.info(f"   â†’ ìµœì¢… {len(regions)}ê°œ ì˜ì—­")
        
        logger.info(f"\nâœ… ì´ {len(regions)}ê°œ ì˜ì—­ ê°ì§€ ì™„ë£Œ")
        logger.info(f"{'='*60}\n")
        
        return regions
    
    def _detect_headers(self, image: np.ndarray) -> List[Dict]:
        """í—¤ë” ì˜ì—­ ê°ì§€"""
        headers = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        h, w = gray.shape[:2]
        
        # ìƒë‹¨ 10% ì˜ì—­
        header_region = gray[:int(h * 0.1), :]
        
        # í…ìŠ¤íŠ¸ ë°€ë„ ì²´í¬
        _, binary = cv2.threshold(header_region, 200, 255, cv2.THRESH_BINARY_INV)
        text_density = np.sum(binary) / (header_region.shape[0] * header_region.shape[1])
        
        if text_density > 0.02:
            headers.append({
                'type': 'header',
                'bbox': [0, 0, int(w), int(h * 0.1)],
                'confidence': 0.8,
                'metadata': {'text_density': float(text_density)}
            })
        
        return headers
    
    def _detect_pie_charts_v33(self, image: np.ndarray) -> List[Dict]:
        """
        ì›ê·¸ë˜í”„ ê°ì§€ v3.3 (Balanced + 3-Stage ê²€ì¦)
        
        3-Stage ê²€ì¦ (ê°„ì†Œí™”):
        1. Sector Counting (ìµœì†Œ 2ê°œ ì„¹í„°)
        2. HSV Range Analysis (ìƒ‰ìƒ ë‹¤ì–‘ì„±, ì™„í™”)
        3. Saturation Check (í‰ê·  ì±„ë„ > 20, ì™„í™”)
        """
        pie_charts = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # Hough Circle ê°ì§€
        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            **self.pie_chart_params
        )
        
        if circles is None:
            return pie_charts
        
        circles = np.uint16(np.around(circles))
        
        for circle in circles[0, :]:
            x, y, r = int(circle[0]), int(circle[1]), int(circle[2])
            
            # Bbox ê³„ì‚°
            x1, y1 = max(0, x - r), max(0, y - r)
            x2, y2 = min(image.shape[1], x + r), min(image.shape[0], y + r)
            
            # ì˜ì—­ í¬ê¸° ì²´í¬
            area = (x2 - x1) * (y2 - y1)
            if area < self.min_region_size:
                continue
            
            # ROI ì¶”ì¶œ
            roi = image[y1:y2, x1:x2]
            if roi.size == 0:
                continue
            
            # â­ 3-Stage ìƒ‰ìƒ ê²€ì¦ (ê°„ì†Œí™”)
            stage1_pass = self._check_sectors(roi)
            if not stage1_pass:
                continue
            
            stage2_pass = self._check_hsv_range(roi)
            if not stage2_pass:
                continue
            
            stage3_pass = self._check_saturation(roi)
            if not stage3_pass:
                continue
            
            # âœ… ëª¨ë“  ê²€ì¦ í†µê³¼
            pie_charts.append({
                'type': 'pie_chart',
                'bbox': [int(x1), int(y1), int(x2 - x1), int(y2 - y1)],
                'confidence': 0.85,
                'metadata': {
                    'radius': int(r),
                    'center': [int(x), int(y)],
                    'area': int(area)
                }
            })
        
        return pie_charts
    
    def _check_sectors(self, roi: np.ndarray) -> bool:
        """Stage 1: ì„¹í„° ê°œìˆ˜ ì²´í¬"""
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        unique_hues = len(np.unique(hsv[:, :, 0]))
        return unique_hues >= self.color_params['min_sectors']
    
    def _check_hsv_range(self, roi: np.ndarray) -> bool:
        """Stage 2: HSV ë²”ìœ„ ì²´í¬ (ì™„í™”)"""
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        h_range = np.ptp(hsv[:, :, 0])
        return h_range >= self.color_params['min_hsv_range']
    
    def _check_saturation(self, roi: np.ndarray) -> bool:
        """Stage 3: ì±„ë„ ì²´í¬ (ì™„í™”)"""
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        avg_saturation = np.mean(hsv[:, :, 1])
        return avg_saturation >= self.color_params['min_saturation']
    
    def _detect_bar_charts(self, image: np.ndarray) -> List[Dict]:
        """ë§‰ëŒ€ê·¸ë˜í”„ ê°ì§€"""
        bar_charts = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
        
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ë§‰ëŒ€ í›„ë³´ ì°¾ê¸°
        bars = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = w * h
            
            if area < self.bar_chart_params['min_bar_area']:
                continue
            
            # ì„¸ë¡œë¡œ ê¸´ í˜•íƒœ (ë§‰ëŒ€)
            aspect_ratio = h / w if w > 0 else 0
            if aspect_ratio > 1.5:
                bars.append({'x': x, 'y': y, 'w': w, 'h': h})
        
        # ë§‰ëŒ€ë“¤ì„ ê·¸ë£¹í™”
        if len(bars) >= self.bar_chart_params['min_bars']:
            bars.sort(key=lambda b: b['y'])
            
            # Y ì¢Œí‘œ ë¹„ìŠ·í•œ ë§‰ëŒ€ë“¤ ê·¸ë£¹í™”
            groups = []
            current_group = [bars[0]]
            
            for bar in bars[1:]:
                if abs(bar['y'] - current_group[-1]['y']) <= self.bar_chart_params['max_y_diff']:
                    current_group.append(bar)
                else:
                    if len(current_group) >= self.bar_chart_params['min_bars']:
                        groups.append(current_group)
                    current_group = [bar]
            
            if len(current_group) >= self.bar_chart_params['min_bars']:
                groups.append(current_group)
            
            # ê·¸ë£¹ì„ ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ë³€í™˜
            for group in groups:
                min_x = min(b['x'] for b in group)
                min_y = min(b['y'] for b in group)
                max_x = max(b['x'] + b['w'] for b in group)
                max_y = max(b['y'] + b['h'] for b in group)
                
                area = (max_x - min_x) * (max_y - min_y)
                if area >= self.min_region_size:
                    bar_charts.append({
                        'type': 'bar_chart',
                        'bbox': [int(min_x), int(min_y), int(max_x - min_x), int(max_y - min_y)],
                        'confidence': 0.75,
                        'metadata': {'bar_count': len(group)}
                    })
        
        return bar_charts
    
    def _detect_tables_v33(self, image: np.ndarray) -> List[Dict]:
        """
        í‘œ ê°ì§€ v3.3 (í° í‘œ í—ˆìš©)
        
        ê°œì„ ì‚¬í•­:
        - max_width: 5000px (í° í‘œ í—ˆìš©)
        - max_height: 10000px (í° í‘œ í—ˆìš©)
        - min_lines: 2 (ì™„í™”)
        """
        tables = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        
        # Hough Line ê°ì§€
        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)
        
        if lines is None:
            return tables
        
        # ìˆ˜í‰/ìˆ˜ì§ì„  ë¶„ë¥˜
        h_lines = []
        v_lines = []
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            
            # ìˆ˜í‰ì„ 
            if abs(y2 - y1) < 10:
                h_lines.append((x1, y1, x2, y2))
            
            # ìˆ˜ì§ì„ 
            if abs(x2 - x1) < 10:
                v_lines.append((x1, y1, x2, y2))
        
        # í‘œ ì˜ì—­ ì°¾ê¸°
        if len(h_lines) >= self.table_params['min_h_lines'] and len(v_lines) >= self.table_params['min_v_lines']:
            # Bounding box ê³„ì‚°
            all_x = [x for line in h_lines + v_lines for x in [line[0], line[2]]]
            all_y = [y for line in h_lines + v_lines for y in [line[1], line[3]]]
            
            x1, y1 = min(all_x), min(all_y)
            x2, y2 = max(all_x), max(all_y)
            w, h = x2 - x1, y2 - y1
            
            # â­ í¬ê¸° ì²´í¬ (í° í‘œ í—ˆìš©)
            if (self.table_params['min_width'] <= w <= self.table_params['max_width'] and
                self.table_params['min_height'] <= h <= self.table_params['max_height']):
                
                area = w * h
                if area >= self.min_region_size:
                    tables.append({
                        'type': 'table',
                        'bbox': [int(x1), int(y1), int(w), int(h)],
                        'confidence': 0.80,
                        'metadata': {
                            'h_lines': len(h_lines),
                            'v_lines': len(v_lines),
                            'size': f'{w}x{h}'
                        }
                    })
                    logger.info(f"   âœ… í‘œ ê°ì§€ ì„±ê³µ: {w}x{h}px (í° í‘œ í—ˆìš©)")
        
        return tables
    
    def _detect_maps(self, image: np.ndarray) -> List[Dict]:
        """Map ê°ì§€ (ì ì ˆí•œ í•„í„°ë§)"""
        maps = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
        
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # 1. ìµœì†Œ ë©´ì  ì²´í¬
            if area < self.map_params['min_area']:
                continue
            
            x, y, w, h = cv2.boundingRect(contour)
            
            # 2. ì •ì‚¬ê°í˜• ì œì™¸
            aspect_ratio = w / h if h > 0 else 0
            if not (self.map_params['aspect_ratio_min'] <= aspect_ratio <= self.map_params['aspect_ratio_max']):
                continue
            
            # 3. ì›í˜•ë„ ì²´í¬
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
            
            circularity = (4 * np.pi * area) / (perimeter ** 2)
            if circularity > self.map_params['max_circularity']:
                continue
            
            # 4. ë³µì¡ë„ ì²´í¬
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            if hull_area == 0:
                continue
            
            complexity = (1 - area / hull_area) * 100
            if complexity < self.map_params['min_complexity']:
                continue
            
            # âœ… í†µê³¼
            maps.append({
                'type': 'map',
                'bbox': [int(x), int(y), int(w), int(h)],
                'confidence': 0.75,
                'metadata': {
                    'area': int(area),
                    'complexity': float(complexity),
                    'circularity': float(circularity)
                }
            })
        
        return maps
    
    def _detect_text_regions(self, image: np.ndarray) -> List[Dict]:
        """
        ì¼ë°˜ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ (ì‹ ê·œ)
        
        ì°¨íŠ¸/í‘œê°€ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ê°ì§€í•©ë‹ˆë‹¤.
        """
        text_regions = []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        h, w = gray.shape[:2]
        
        # í—¤ë” ì œì™¸ ì˜ì—­
        content_region = gray[int(h * 0.1):, :]
        
        # í…ìŠ¤íŠ¸ ë°€ë„ ë§µ ìƒì„± (100x100 í”½ì…€ ë¸”ë¡ ë‹¨ìœ„)
        block_size = 100
        rows = content_region.shape[0] // block_size
        cols = content_region.shape[1] // block_size
        
        for i in range(rows):
            for j in range(cols):
                y1 = i * block_size
                y2 = (i + 1) * block_size
                x1 = j * block_size
                x2 = (j + 1) * block_size
                
                block = content_region[y1:y2, x1:x2]
                
                # í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚°
                _, binary = cv2.threshold(block, 200, 255, cv2.THRESH_BINARY_INV)
                text_density = np.sum(binary) / (block_size * block_size)
                
                # ì ì ˆí•œ í…ìŠ¤íŠ¸ ë°€ë„ ì²´í¬
                if (self.text_region_params['min_text_density'] <= text_density <= 
                    self.text_region_params['max_text_density']):
                    
                    # ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                    abs_y1 = y1 + int(h * 0.1)
                    area = block_size * block_size
                    
                    if area >= self.text_region_params['min_area']:
                        text_regions.append({
                            'type': 'text',
                            'bbox': [int(x1), int(abs_y1), block_size, block_size],
                            'confidence': 0.70,
                            'metadata': {'text_density': float(text_density)}
                        })
        
        return text_regions
    
    def _merge_overlapping_regions(self, regions: List[Dict]) -> List[Dict]:
        """
        ì¤‘ë³µë˜ëŠ” ì˜ì—­ ë³‘í•©
        
        IoU > 0.5ì¸ ì˜ì—­ë“¤ì„ ë³‘í•©í•©ë‹ˆë‹¤.
        """
        if len(regions) <= 1:
            return regions
        
        merged = []
        used = set()
        
        for i, region1 in enumerate(regions):
            if i in used:
                continue
            
            bbox1 = region1['bbox']
            group = [region1]
            
            for j, region2 in enumerate(regions[i+1:], start=i+1):
                if j in used:
                    continue
                
                bbox2 = region2['bbox']
                iou = self._calculate_iou(bbox1, bbox2)
                
                if iou > 0.5:
                    group.append(region2)
                    used.add(j)
            
            # ê·¸ë£¹ì„ í•˜ë‚˜ë¡œ ë³‘í•©
            if len(group) == 1:
                merged.append(region1)
            else:
                merged_bbox = self._merge_bboxes([r['bbox'] for r in group])
                merged_type = max(set(r['type'] for r in group), 
                                key=lambda t: sum(1 for r in group if r['type'] == t))
                
                merged.append({
                    'type': merged_type,
                    'bbox': merged_bbox,
                    'confidence': max(r['confidence'] for r in group),
                    'metadata': {'merged_count': len(group)}
                })
        
        return merged
    
    def _calculate_iou(self, bbox1: List[int], bbox2: List[int]) -> float:
        """IoU ê³„ì‚°"""
        x1_1, y1_1, w1, h1 = bbox1
        x2_1, y2_1 = x1_1 + w1, y1_1 + h1
        
        x1_2, y1_2, w2, h2 = bbox2
        x2_2, y2_2 = x1_2 + w2, y1_2 + h2
        
        # êµì§‘í•©
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i < x1_i or y2_i < y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        
        # í•©ì§‘í•©
        area1 = w1 * h1
        area2 = w2 * h2
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _merge_bboxes(self, bboxes: List[List[int]]) -> List[int]:
        """ì—¬ëŸ¬ bboxë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©"""
        x1 = min(bbox[0] for bbox in bboxes)
        y1 = min(bbox[1] for bbox in bboxes)
        x2 = max(bbox[0] + bbox[2] for bbox in bboxes)
        y2 = max(bbox[1] + bbox[3] for bbox in bboxes)
        
        return [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == '__main__':
    import sys
    from PIL import Image
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python core_layout_detector_v33_BALANCED.py <image_path>")
        sys.exit(1)
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    img_path = sys.argv[1]
    pil_img = Image.open(img_path)
    img_array = np.array(pil_img)
    
    # BGR ë³€í™˜
    if len(img_array.shape) == 3 and img_array.shape[2] == 3:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    
    # ê°ì§€
    detector = LayoutDetectorV33()
    regions = detector.detect_regions(img_array, page_num=0)
    
    print(f"\nâœ… ì´ {len(regions)}ê°œ ì˜ì—­ ê°ì§€:")
    for i, region in enumerate(regions):
        print(f"{i+1}. {region['type']}: bbox={region['bbox']}, conf={region['confidence']:.2f}")