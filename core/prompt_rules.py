"""
core/prompt_rules.py
PRISM Phase 5.3.0 - Prompt DSL Rules

ëª©ì : íŒíŠ¸â†’í”„ë¡¬í”„íŠ¸ ë§¤í•‘ì„ ëª…ì‹œì  DSLë¡œ ê´€ë¦¬
GPT ì œì•ˆ ë°˜ì˜: í”„ë¡¬í”„íŠ¸ íŠœë‹ì„ ì½”ë“œ ë³€ê²½ ì—†ì´ ë£°ë§Œ êµì²´
"""

import os
from typing import Dict, List, Any


class PromptRules:
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± ê·œì¹™ DSL
    
    GPT í”¼ë“œë°±:
    - ë¬¸ìì—´ ì¡°ë¦½ì´ ì•„ë‹Œ dict ê¸°ë°˜ í…Œì´ë¸”í™”
    - ëª¨ë¸ì´ ë°”ë€Œì–´ë„ ì•ˆì •ì 
    - ë£°ë§Œ êµì²´ë¡œ í”„ë¡¬í”„íŠ¸ íŠœë‹ ê°€ëŠ¥
    """
    
    # í™˜ê²½ ë³€ìˆ˜ë¡œ íŒŒë¼ë¯¸í„°í™” (GPT ì œì•ˆ #3)
    MAP_MIN_LENGTH = int(os.getenv('PRISM_MAP_MIN_LENGTH', '40'))  # 50 â†’ 40
    TABLE_MIN_ROWS = int(os.getenv('PRISM_TABLE_MIN_ROWS', '3'))
    DIAGRAM_MIN_SCORE = int(os.getenv('PRISM_DIAGRAM_MIN_SCORE', '60'))
    
    # ì„¹ì…˜ ê·œì¹™ í…Œì´ë¸”
    SECTION_RULES = {
        "numbers": {
            "title": "## ìˆ«ì ì •ë³´",
            "priority": 3,  # ë†’ì„ìˆ˜ë¡ ìš°ì„ 
            "lines": [
                "í˜ì´ì§€ì˜ ìˆ«ì ë°ì´í„°(ì‹œê°„, ê¸ˆì•¡, í†µê³„ ë“±)ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.",
                "- ì›ë³¸ í¬ë§· ìœ ì§€ (ì˜ˆ: 05:30, 27ë¶„, 35,000ëª…)",
                "- ëª¨ë“  ìˆ«ì ì£¼ë³€ì˜ ë‹¨ìœ„Â·ì„¤ëª…ì„ í•¨ê»˜ ì¶”ì¶œ",
                "- Key-Value í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”:",
                "  * ë°°ì°¨ê°„ê²©: XXë¶„",
                "  * ì²«ì°¨: XX:XX",
                "  * ë§‰ì°¨: XX:XX"
            ],
            "format": "kvs"  # key-value-structured
        },
        
        "text": {
            "title": "## í…ìŠ¤íŠ¸ ë‚´ìš©",
            "priority": 1,
            "lines": [
                "ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.",
                "- ì œëª©ì€ ## ë˜ëŠ” ### í—¤ë”ë¡œ",
                "- ë¬¸ë‹¨ì€ ìì—°ìŠ¤ëŸ½ê²Œ",
                "- ì›ë³¸ ìˆœì„œ ìœ ì§€"
            ],
            "format": "markdown"
        },
        
        "table": {
            "title": "## í‘œ ë°ì´í„°",
            "priority": 2,
            "lines": [
                "í‘œë¥¼ Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.",
                "",
                "| ì—´1 | ì—´2 | ì—´3 |",
                "|-----|-----|-----|",
                "| ê°’1 | ê°’2 | ê°’3 |",
                "",
                "**ê·œì¹™:**",
                "- í—¤ë” í–‰ ì •í™•íˆ ì¶”ì¶œ",
                "- ëª¨ë“  ì…€ ë°ì´í„° í¬í•¨ (ë¹ˆ ì¹¸ë„ '-'ë¡œ í‘œì‹œ)",
                "- ìˆ«ìëŠ” ì²œë‹¨ìœ„ êµ¬ë¶„ì ìœ ì§€"
            ],
            "format": "markdown_table_strict"
        },
        
        "map": {
            "title": "## ì§€ë„ ì •ë³´",
            "priority": 2,
            "lines": [
                "ì§€ë„ì˜ ë‚´ìš©ì„ ì„¤ëª…í•˜ì„¸ìš”.",
                "- ì§€ì—­/ìœ„ì¹˜ëª…",
                "- ì£¼ìš” ëœë“œë§ˆí¬ (ìœ„ì¹˜ì™€ í•¨ê»˜)",
                "- ê²½ë¡œ ë˜ëŠ” ì—°ê²° ê´€ê³„",
                "",
                "**í¬ë§·:**",
                "### ì£¼ìš” ìœ„ì¹˜",
                "- ë¶ìª½: XXX, YYY",
                "- ì¤‘ì•™: ZZZ",
                "",
                "### ê²½ë¡œ",
                "AAA â†’ BBB â†’ CCC"
            ],
            "format": "structured_description",
            "keywords": ["ì§€ì—­ëª…", "ëœë“œë§ˆí¬", "ê²½ë¡œ ì—°ê²°"]
        },
        
        "diagram": {
            "title": "## ë‹¤ì´ì–´ê·¸ë¨ êµ¬ì¡°",
            "priority": 2,
            "lines": [
                "{count}ê°œì˜ ë‹¤ì´ì–´ê·¸ë¨ì´ ìˆìŠµë‹ˆë‹¤. ê°ê° ì„¤ëª…í•˜ì„¸ìš”.",
                "",
                "### ë‹¤ì´ì–´ê·¸ë¨ 1",
                "- ì‹œì‘ì :",
                "- íë¦„/ì—°ê²°: A â†’ B â†’ C",
                "- ì¢…ì :",
                "",
                "(ê° ë‹¤ì´ì–´ê·¸ë¨ë§ˆë‹¤ ë°˜ë³µ)",
                "",
                "**ì¤‘ìš”**: ì •ë¥˜ì¥/ë…¸ë“œ ì´ë¦„ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”."
            ],
            "format": "structured_flow",
            "repeat_count_from_hint": "diagram_count"
        }
    }
    
    # ê²€ì¦ ê·œì¹™ (GPT ì œì•ˆ #2: ì•½í•œ ì‹ í˜¸ ëŒ€ì²´)
    VALIDATION_KEYWORDS = {
        "numbers": {
            "patterns": [
                r'\d{1,2}:\d{2}',  # ì‹œê°„ (05:30)
                r'\d+ë¶„',           # ë¶„ ë‹¨ìœ„
                r'\d+ì›',           # ê¸ˆì•¡
                r'\d+ëª…',           # ì¸ì›
                r'\d+%',            # í¼ì„¼íŠ¸
                r'\d+ëŒ€'            # ëŒ€ìˆ˜
            ],
            "units": ["ë¶„", "ì›", "%", "ëª…", "ëŒ€", "ì´ˆ", "ì‹œê°„"]
        },
        
        "map": {
            "keywords": [
                "ì§€ë„", "ë…¸ì„ ë„", "route", "map",
                "ê²½ë¡œ", "ìœ„ì¹˜", "ì§€ì ", "ì¥ì†Œ",
                "ì •ë¥˜ì¥", "station", "stop",
                "ì§€ì—­", "êµ¬ì—­", "area"
            ],
            "min_length": None  # ëŸ°íƒ€ì„ì— MAP_MIN_LENGTH ì‚¬ìš©
        },
        
        "table": {
            "patterns": [
                r'\|.*\|.*\|',  # Markdown í‘œ
                r'\n\|[-:]+\|'  # êµ¬ë¶„ì„ 
            ],
            "min_rows": None  # ëŸ°íƒ€ì„ì— TABLE_MIN_ROWS ì‚¬ìš©
        },
        
        "diagram": {
            "keywords": [
                "ë‹¤ì´ì–´ê·¸ë¨", "diagram",
                "ë…¸ì„ ", "route", "flow",
                "íë¦„", "ì—°ê²°", "êµ¬ì¡°"
            ],
            "arrow_patterns": ["â†’", "->", "â–¶", "â–º"]
        }
    }
    
    # ì˜¤íƒˆì êµì • ì‚¬ì „ (GPT ì œì•ˆ)
    TYPO_CORRECTIONS = {
        "ì¼ì‚°": ["ì„ì‚°", "ì¼ì‹¼"],
        "í™”ì•”": ["í™”ì•…", "í•˜ì•”"],
        "ê½ƒë°”ìœ„": ["ê½ƒë¹„ìœ„", "ê¼¿ë°”ìœ„"],
        "ë°°ì°¨ê°„ê²©": ["ë°°ì°¨ ê°„ê²©", "ë°°ì°¨ê°„ê²½"],
        # ì¶”ê°€ ê°€ëŠ¥...
    }
    
    @classmethod
    def build_prompt(cls, hints: Dict[str, Any]) -> str:
        """
        íŒíŠ¸ ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            hints: QuickLayoutAnalyzerì˜ CV íŒíŠ¸
            
        Returns:
            ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        sections = []
        
        # í—¤ë”
        sections.append("# í˜ì´ì§€ ë‚´ìš© ì™„ì „ ì¶”ì¶œ\n")
        
        # ë³µì¡ë„ ê²½ê³ 
        if hints.get('layout_complexity') == 'complex':
            sections.append("""
**âš ï¸ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ í˜ì´ì§€**
ëª¨ë“  ì˜ì—­ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”. ëˆ„ë½ ì‹œ í’ˆì§ˆì´ í¬ê²Œ ì €í•˜ë©ë‹ˆë‹¤.
""")
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì„¹ì…˜ ì¶”ê°€
        enabled_sections = cls._get_enabled_sections(hints)
        enabled_sections.sort(key=lambda x: x['priority'], reverse=True)
        
        for section in enabled_sections:
            sections.append(cls._format_section(section, hints))
        
        # ê³µí†µ ê·œì¹™
        sections.append(cls._get_common_rules())
        
        return "\n".join(sections)
    
    @classmethod
    def _get_enabled_sections(cls, hints: Dict) -> List[Dict]:
        """íŒíŠ¸ì—ì„œ í™œì„±í™”ëœ ì„¹ì…˜ ì¶”ì¶œ"""
        enabled = []
        
        if hints.get('has_numbers'):
            enabled.append({
                **cls.SECTION_RULES['numbers'],
                'type': 'numbers'
            })
        
        if hints.get('has_text'):
            enabled.append({
                **cls.SECTION_RULES['text'],
                'type': 'text'
            })
        
        if hints.get('has_table'):
            enabled.append({
                **cls.SECTION_RULES['table'],
                'type': 'table'
            })
        
        if hints.get('has_map'):
            enabled.append({
                **cls.SECTION_RULES['map'],
                'type': 'map'
            })
        
        if hints.get('diagram_count', 0) > 0:
            enabled.append({
                **cls.SECTION_RULES['diagram'],
                'type': 'diagram'
            })
        
        return enabled
    
    @classmethod
    def _format_section(cls, section: Dict, hints: Dict) -> str:
        """ì„¹ì…˜ì„ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = [section['title'], ""]
        
        for line in section['lines']:
            # ë™ì  ê°’ ì¹˜í™˜ (ì˜ˆ: {count})
            if '{count}' in line:
                count = hints.get(section.get('repeat_count_from_hint'), 1)
                line = line.format(count=count)
            
            lines.append(line)
        
        lines.append("")  # ë¹ˆ ì¤„
        return "\n".join(lines)
    
    @classmethod
    def _get_common_rules(cls) -> str:
        """ê³µí†µ ê·œì¹™"""
        return """
---

**ğŸš« ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª… ("ì´ í˜ì´ì§€ëŠ”...", "ì•„ë˜ì™€ ê°™ì´...", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤")
- ì¶”ì¸¡/í•´ì„ (ì›ë³¸ì— ì—†ëŠ” ë‚´ìš©)
- ìš”ì•½ (ëª¨ë“  ë‚´ìš©ì„ ì™„ì „íˆ ì¶”ì¶œ)

**âœ… í•„ìˆ˜:**
- ì›ë³¸ ë‚´ìš©ë§Œ ì¶œë ¥
- Markdown í˜•ì‹ ì‚¬ìš©
- ëˆ„ë½ ì—†ì´ ì™„ì „íˆ ì¶”ì¶œ
- Key-ValueëŠ” ëª…í™•íˆ êµ¬ë¶„
"""
    
    @classmethod
    def build_retry_prompt(cls, hints: Dict, missing: List[str], 
                          prev_content: str) -> str:
        """
        ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (GPT ì œì•ˆ: ëˆ„ë½ ì„¹ì…˜ë§Œ ê°•ì œ)
        
        Args:
            hints: CV íŒíŠ¸
            missing: ëˆ„ë½ëœ ì„¹ì…˜ íƒ€ì… ë¦¬ìŠ¤íŠ¸
            prev_content: ì´ì „ ì¶”ì¶œ ë‚´ìš©
            
        Returns:
            ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        """
        sections = [
            "# â™»ï¸ ëˆ„ë½ ìš”ì†Œ ì¬ì¶”ì¶œ\n",
            "**âš ï¸ ì´ì „ ì¶”ì¶œì—ì„œ ë‹¤ìŒ ìš”ì†Œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤:**\n"
        ]
        
        # ëˆ„ë½ í•­ëª© ë‚˜ì—´
        for miss_type in missing:
            if miss_type in cls.SECTION_RULES:
                rule = cls.SECTION_RULES[miss_type]
                sections.append(f"- {rule['title']}")
        
        sections.append("\n---\n")
        
        # ëˆ„ë½ ì„¹ì…˜ë§Œ ì¶”ì¶œ ì§€ì‹œ
        for miss_type in missing:
            if miss_type in cls.SECTION_RULES:
                rule = cls.SECTION_RULES[miss_type]
                sections.append(f"\n### [RETRY] {rule['title']}\n")
                sections.append(cls._format_section(rule, hints))
        
        # ê¸°ì¡´ ë‚´ìš© ì°¸ê³  (ì¶•ì•½)
        sections.append("\n---\n")
        sections.append("**ê¸°ì¡´ ì¶”ì¶œ ë‚´ìš© (ì°¸ê³ ìš©, ì¤‘ë³µ ê¸ˆì§€):**\n")
        sections.append(f"```\n{prev_content[:500]}...\n```\n")
        
        # ê°•ì¡°
        sections.append("""
**ğŸ”´ ì¤‘ìš”:**
- ìœ„ ëˆ„ë½ í•­ëª©ë§Œ ì¶”ì¶œ
- ê¸°ì¡´ ë‚´ìš© ì¤‘ë³µ ê¸ˆì§€
- ì„¹ì…˜ í—¤ë” `[RETRY]` ìœ ì§€
""")
        
        return "\n".join(sections)
    
    @classmethod
    def correct_typos(cls, text: str) -> str:
        """ì˜¤íƒˆì êµì •"""
        for correct, typos in cls.TYPO_CORRECTIONS.items():
            for typo in typos:
                text = text.replace(typo, correct)
        return text
    
    @classmethod
    def validate_extraction(cls, content: str, hints: Dict) -> Dict:
        """
        ì¶”ì¶œ ê²°ê³¼ ê²€ì¦ (GPT ì œì•ˆ: ê°•í™”ëœ ê²€ì¦)
        
        Returns:
            {
                'passed': bool,
                'missing': List[str],
                'scores': Dict[str, float],
                'warnings': List[str]
            }
        """
        import re
        
        missing = []
        scores = {}
        warnings = []
        
        # 1. ìˆ«ì ì •ë³´ ê²€ì¦
        if hints.get('has_numbers'):
            val_rule = cls.VALIDATION_KEYWORDS['numbers']
            
            found_patterns = sum(
                1 for pattern in val_rule['patterns']
                if re.search(pattern, content)
            )
            
            # íŒ¨í„´ ë˜ëŠ” ë‹¨ìœ„ ì¡´ì¬ ì—¬ë¶€
            has_units = any(unit in content for unit in val_rule['units'])
            
            if found_patterns == 0 and not has_units:
                missing.append('numbers')
                scores['numbers'] = 0
            else:
                scores['numbers'] = min(100, found_patterns * 30 + (30 if has_units else 0))
        
        # 2. ì§€ë„ ê²€ì¦ (GPT ì œì•ˆ: íŒŒë¼ë¯¸í„°í™”)
        if hints.get('has_map'):
            val_rule = cls.VALIDATION_KEYWORDS['map']
            min_length = cls.MAP_MIN_LENGTH  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            
            keyword_count = sum(
                1 for kw in val_rule['keywords']
                if kw in content.lower()
            )
            
            map_section_length = 0
            for line in content.split('\n'):
                if any(kw in line.lower() for kw in ['ì§€ë„', 'map', 'ìœ„ì¹˜']):
                    map_section_length += len(line)
            
            if keyword_count == 0:
                missing.append('map')
                scores['map'] = 0
                warnings.append("ì§€ë„ í‚¤ì›Œë“œ ë¯¸ë°œê²¬")
            elif map_section_length < min_length:
                missing.append('map')
                scores['map'] = 50
                warnings.append(f"ì§€ë„ ì„¤ëª… ë¶€ì¡± ({map_section_length}ì < {min_length}ì)")
            else:
                scores['map'] = min(100, keyword_count * 25)
        
        # 3. í‘œ ê²€ì¦ (GPT ì œì•ˆ: íŒŒë¼ë¯¸í„°í™”)
        if hints.get('has_table'):
            val_rule = cls.VALIDATION_KEYWORDS['table']
            min_rows = cls.TABLE_MIN_ROWS  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            
            table_lines = [
                line for line in content.split('\n')
                if re.match(val_rule['patterns'][0], line)
            ]
            
            if len(table_lines) < min_rows:
                missing.append('table')
                scores['table'] = (len(table_lines) / min_rows) * 100
                warnings.append(f"í‘œ ë°ì´í„° ë¶€ì¡± ({len(table_lines)}í–‰ < {min_rows}í–‰)")
            else:
                scores['table'] = 100
        
        # 4. ë‹¤ì´ì–´ê·¸ë¨ ê²€ì¦ (GPT ì œì•ˆ: íƒ„ë ¥ì )
        if hints.get('diagram_count', 0) > 0:
            val_rule = cls.VALIDATION_KEYWORDS['diagram']
            expected_count = hints['diagram_count']
            min_score = cls.DIAGRAM_MIN_SCORE  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            
            # 1ì°¨: 'ë‹¤ì´ì–´ê·¸ë¨' ë¬¸ìì—´
            diagram_mentions = content.lower().count('ë‹¤ì´ì–´ê·¸ë¨')
            
            # 2ì°¨: ëŒ€ì²´ ì‹ í˜¸ (GPT ì œì•ˆ)
            flow_keywords = ['ë…¸ì„ ', 'flow', 'ì—°ê²°', 'íë¦„', 'ê²½ë¡œ']
            flow_score = sum(content.lower().count(kw) for kw in flow_keywords)
            
            # 3ì°¨: í™”ì‚´í‘œ íŒ¨í„´
            arrow_count = sum(
                content.count(arrow) for arrow in val_rule['arrow_patterns']
            )
            
            # 4ì°¨: ì •ë¥˜ì¥ëª… ì‹œí€€ìŠ¤ (A â†’ B â†’ C)
            station_pattern = r'[ê°€-í£]{2,5}\s*â†’\s*[ê°€-í£]{2,5}'
            station_chains = len(re.findall(station_pattern, content))
            
            # ì¢…í•© ì ìˆ˜ (GPT ì œì•ˆ)
            total_score = (
                diagram_mentions * 30 +
                min(flow_score * 10, 30) +
                min(arrow_count * 5, 20) +
                min(station_chains * 20, 20)
            )
            
            if total_score < min_score and diagram_mentions < expected_count:
                missing.append('diagram')
                scores['diagram'] = total_score
                warnings.append(
                    f"ë‹¤ì´ì–´ê·¸ë¨ ëˆ„ë½/ë¶€ì¡± (ì ìˆ˜: {total_score}/{min_score}, "
                    f"ë©˜ì…˜: {diagram_mentions}/{expected_count})"
                )
            else:
                scores['diagram'] = min(100, total_score)
                if diagram_mentions < expected_count:
                    warnings.append(
                        f"ë‹¤ì´ì–´ê·¸ë¨ ëŒ€ì²´ í‘œí˜„ ì‚¬ìš© (ì ìˆ˜: {total_score}, "
                        f"í™”ì‚´í‘œ: {arrow_count}, ì—°ê²°: {station_chains})"
                    )
        
        # 5. ìµœì†Œ ê¸¸ì´ ê²€ì¦
        if len(content) < 100:
            missing.append('content_length')
            scores['length'] = len(content)
            warnings.append(f"ë‚´ìš© ë„ˆë¬´ ì§§ìŒ ({len(content)}ì)")
        else:
            scores['length'] = 100
        
        passed = len(missing) == 0
        
        return {
            'passed': passed,
            'missing': missing,
            'scores': scores,
            'warnings': warnings
        }
