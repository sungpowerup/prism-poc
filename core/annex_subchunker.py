"""
core/annex_subchunker.py - Phase 0.9.8.3 TableParser Interface

Phase 0.9.8.3 (TableParser ì¸í„°í˜ì´ìŠ¤ ê°œì„ ):
ğŸ¯ ëª©í‘œ: 6ê°œ ì¡°ê° â†’ 2ê°œ ë…¼ë¦¬ ê·¸ë£¹ â†’ TableParser 150í–‰ êµ¬ì¡°í™”

í•µì‹¬ ì „ëµ (GPT ë¯¸ì†¡ë‹˜):
A. ì²­í¬ ë¼ë²¨ë§: "3ê¸‰ìŠ¹ì§„ì œì™¸" / "3ê¸‰ìŠ¹ì§„" ìë™ ê°ì§€
B. ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•©: label ê¸°ë°˜ ê·¸ë£¹í™”
C. TableParser í”¼ë”©: ê° ê·¸ë£¹ì„ í†µí•© í…Œì´ë¸”ë¡œ ì „ë‹¬

ì„±ê³µ ê¸°ì¤€:
- Loss < 3% âœ…
- table_rows = 2ê°œ (ë…¼ë¦¬ ê·¸ë£¹) âœ…
- TableParser = 150í–‰ âœ…
- Annex ì •êµ êµ¬ì¡° + êµ¬ì¡°í™” ë™ì‹œ ë‹¬ì„±

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ + GPT ë¯¸ì†¡ë‹˜
Date: 2025-11-27
Version: Phase 0.9.8.3 TableParser Interface
"""

import re
import logging
import statistics
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# í—¤ë” í‚¤ì›Œë“œ
HEADER_KEYWORDS = re.compile(
    r"(ì„ìš©í•˜ê³ ì|ì„œì—´ëª…ë¶€|ì§ê¸‰|ì‘ì‹œìê²©|ìŠ¹ì§„|ì œì™¸|êµ¬ë¶„|ë¹„ê³ |ì¸ì›ìˆ˜|ì ìˆ˜|í‰ì •|í‰ê°€|ë‹´ë‹¹ì|ìê²©ì·¨ë“|ê²½ë ¥)",
    re.IGNORECASE
)

SEPARATOR_LINE = re.compile(r"^[-â”€â€”]{3,}$")
DIGITISH_LINE = re.compile(r"^\s*(\d+[\.\)]?|\([0-9]+\)|[ê°€-í£]\)|[A-Za-z]\))\s+")


@dataclass
class SubChunk:
    """ì„œë¸Œì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    section_id: str
    section_type: str
    content: str
    metadata: Dict[str, Any]
    char_count: int
    order: int


class AnnexSubChunker:
    """
    Annex ì„œë¸Œì²­í‚¹ (Phase 0.9.8.3 TableParser Interface)
    
    GPT ë¯¸ì†¡ë‹˜ ì„¤ê³„:
    - Phase 0.9.8.2 êµ¬ì¡° ìœ ì§€ (Loss 0%, ì •êµí•œ ë¶„í• )
    - ì¶”ê°€: ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•© ë ˆì´ì–´
    - ëª©í‘œ: TableParser 150í–‰ êµ¬ì¡°í™” ë³µì›
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.patterns = {
            'annex_header': r'\[ë³„í‘œ\s*(\d+)\]\s*([^\n<]+)',
            'related_article': r'<(ì œ\d+ì¡°[^>]*)ê´€ë ¨>',
            'amendment': r'\[(.*?(\d{4}\.\d{1,2}\.\d{1,2}).*?)\]',
            'note_marker': r'^\*\s*(.+)$',
            'digit_line': r'^\d+(\s*\S+)?$',
            'header_keywords': r'(ì§ê¸‰|ì‘ì‹œìê²©|ë¹„ê³ |ì¸ì›ìˆ˜|ì„œì—´ëª…ë¶€|ìˆœìœ„|ë‹´ë‹¹ì|ìê²©ì·¨ë“)',
        }
        
        logger.info("âœ… AnnexSubChunker v0.9.8.3 ì´ˆê¸°í™” (TableParser Interface)")
    
    def chunk(self, annex_text: str, annex_no: str = "1") -> List[SubChunk]:
        """
        âœ… Phase 0.9.8.3: Annex í…ìŠ¤íŠ¸ â†’ ì„œë¸Œì²­í‚¹ â†’ ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•©
        """
        logger.info(f"ğŸ”§ Phase 0.9.8.3: Annex ì„œë¸Œì²­í‚¹ ì‹œì‘: {len(annex_text)}ì")
        
        # Step 1: Annex ì™„ì „ ë¶„ë¦¬
        annex_sections = self._split_by_annex(annex_text)
        
        if not annex_sections:
            logger.warning("âš ï¸ ë³„í‘œ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - fallback ì²˜ë¦¬")
            return self._fallback_chunk(annex_text, annex_no)
        
        logger.info(f"âœ… Step 1: ë³„í‘œ ë¶„ë¦¬ ì™„ë£Œ: {len(annex_sections)}ê°œ")
        
        # Canonical text
        canonical_text = self._clean_annex_text(annex_text)
        
        # Step 2-5: ê° ë³„í‘œë§ˆë‹¤ ì²˜ë¦¬
        all_chunks = []
        global_order = 0
        
        for annex_sec in annex_sections:
            annex_num = annex_sec['annex_no']
            raw_content = annex_sec['content']
            header_end_pos = annex_sec['header_end_pos']
            
            logger.info(f"   ğŸ”¹ ë³„í‘œ{annex_num} ì²˜ë¦¬ ì¤‘... ({len(raw_content)}ì)")
            
            # ê°œí–‰ ë³´ì¡´ ë…¸ì´ì¦ˆ ì œê±°
            cleaned_content = self._clean_annex_text(raw_content)
            
            # âœ¨ Phase 0.9.8.2: ì •êµí•œ ë¶„í• 
            section_chunks = self._process_single_annex_v0982(
                cleaned_content,
                annex_num,
                global_order,
                header_end_pos
            )
            
            # âœ¨ Phase 0.9.8.3: ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•©
            section_chunks = self._regroup_logical_tables_v0983(
                section_chunks,
                annex_num
            )
            
            all_chunks.extend(section_chunks)
            global_order += len(section_chunks)
            
            logger.info(f"   âœ… ë³„í‘œ{annex_num}: {len(section_chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        # Step 5: Loss Check
        self._check_annex_loss(canonical_text, all_chunks)
        
        logger.info(f"âœ… Phase 0.9.8.3: Annex ì„œë¸Œì²­í‚¹ ì™„ë£Œ: ì´ {len(all_chunks)}ê°œ")
        
        # íƒ€ì…ë³„ í†µê³„
        type_counts = {}
        for chunk in all_chunks:
            ctype = chunk.section_type
            type_counts[ctype] = type_counts.get(ctype, 0) + 1
        
        for ctype, count in sorted(type_counts.items()):
            logger.info(f"   - {ctype}: {count}ê°œ")
        
        return all_chunks
    
    # ============================================
    # âœ¨ Phase 0.9.8.3: ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•©
    # ============================================
    
    def _regroup_logical_tables_v0983(
        self,
        chunks: List[SubChunk],
        annex_num: str
    ) -> List[SubChunk]:
        """
        âœ¨ Phase 0.9.8.3: ë…¼ë¦¬ ê·¸ë£¹ ì¬ì¡°í•©
        
        GPT ë¯¸ì†¡ë‹˜ ì „ëµ:
        A. ì²­í¬ ë¼ë²¨ë§: "3ê¸‰ìŠ¹ì§„ì œì™¸" / "3ê¸‰ìŠ¹ì§„" ìë™ ê°ì§€
        B. ê·¸ë£¹í™”: label ê¸°ë°˜ ì¬ì¡°í•©
        C. í†µí•©: ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ table_rowsë¡œ ë³‘í•©
        
        Before (Phase 0.9.8.2):
        [header, table1, note1, header, table2, note2] (6ê°œ)
        
        After (Phase 0.9.8.3):
        [header, logical_table1, logical_table2] (3ê°œ)
        - logical_table1 = table1 + note1 í†µí•©
        - logical_table2 = table2 + note2 í†µí•©
        """
        # Step A: ì²­í¬ ë¼ë²¨ë§
        labeled_chunks = self._label_chunks_v0983(chunks)
        
        # table_rowsë§Œ ì¶”ì¶œ
        table_chunks = [c for c in labeled_chunks if c.section_type == 'table_rows']
        non_table_chunks = [c for c in labeled_chunks if c.section_type != 'table_rows']
        
        if not table_chunks:
            logger.info(f"      â„¹ï¸ table_rows ì—†ìŒ - ì¬ì¡°í•© ìŠ¤í‚µ")
            return chunks
        
        # Step B: ê·¸ë£¹í™”
        groups = self._group_by_label_v0983(table_chunks)
        
        if not groups:
            logger.info(f"      â„¹ï¸ ê·¸ë£¹í™” ì‹¤íŒ¨ - ì›ë³¸ ìœ ì§€")
            return chunks
        
        # Step C: ê° ê·¸ë£¹ì„ í†µí•© table_rowsë¡œ ë³‘í•©
        merged_chunks = []
        
        for label, group_chunks in groups.items():
            if len(group_chunks) == 0:
                continue
            
            # ê·¸ë£¹ ë‚´ ëª¨ë“  ì²­í¬ í†µí•©
            merged_content = '\n'.join(c.content for c in group_chunks)
            merged_char_count = sum(c.char_count for c in group_chunks)
            
            # ì²« ë²ˆì§¸ ì²­í¬ì˜ ë©”íƒ€ ê¸°ë°˜
            first_chunk = group_chunks[0]
            
            merged_chunk = SubChunk(
                section_id=f"ë³„í‘œ{annex_num}",
                section_type="table_rows",
                content=merged_content.strip(),
                metadata={
                    **first_chunk.metadata,
                    'table_label': label,
                    'merged_count': len(group_chunks),
                    'logical_group': True
                },
                char_count=merged_char_count,
                order=first_chunk.order
            )
            
            merged_chunks.append(merged_chunk)
            
            logger.info(
                f"      âœ… ë…¼ë¦¬ ê·¸ë£¹ '{label}': {len(group_chunks)}ê°œ ì²­í¬ â†’ "
                f"1ê°œ table_rows ({merged_char_count}ì)"
            )
        
        # non-table ì²­í¬ì™€ ë³‘í•©
        result = non_table_chunks + merged_chunks
        
        # order ì¬ì •ë ¬
        result = sorted(result, key=lambda x: x.order)
        
        logger.info(
            f"      ğŸ”„ ì¬ì¡°í•© ì™„ë£Œ: {len(table_chunks)}ê°œ table_rows â†’ "
            f"{len(merged_chunks)}ê°œ ë…¼ë¦¬ ê·¸ë£¹"
        )
        
        return result
    
    def _label_chunks_v0983(self, chunks: List[SubChunk]) -> List[SubChunk]:
        """
        Step A: ì²­í¬ ë¼ë²¨ë§
        
        ë¼ë²¨ ê°ì§€ ë¡œì§:
        - "3ê¸‰ìŠ¹ì§„ì œì™¸" í‚¤ì›Œë“œ â†’ label = "3ê¸‰ìŠ¹ì§„ì œì™¸"
        - "3ê¸‰ìŠ¹ì§„" í‚¤ì›Œë“œ (ë‹¨, "ì œì™¸" ì—†ìŒ) â†’ label = "3ê¸‰ìŠ¹ì§„"
        - ê¸°íƒ€ â†’ label = None
        """
        labeled = []
        
        for chunk in chunks:
            content_norm = chunk.content.replace(" ", "").replace("\n", "")
            
            # "3ê¸‰ìŠ¹ì§„ì œì™¸" ê°ì§€
            if "3ê¸‰ìŠ¹ì§„ì œì™¸" in content_norm or "3ê¸‰ìŠ¹ì§„ì œì™¸" in chunk.content:
                chunk.metadata['table_label'] = "3ê¸‰ìŠ¹ì§„ì œì™¸"
                logger.info(f"         ğŸ·ï¸ ë¼ë²¨: '3ê¸‰ìŠ¹ì§„ì œì™¸' (order={chunk.order})")
            
            # "3ê¸‰ìŠ¹ì§„" ê°ì§€ (ë‹¨, "ì œì™¸" ì—†ìŒ)
            elif "3ê¸‰ìŠ¹ì§„" in content_norm and "ì œì™¸" not in content_norm:
                chunk.metadata['table_label'] = "3ê¸‰ìŠ¹ì§„"
                logger.info(f"         ğŸ·ï¸ ë¼ë²¨: '3ê¸‰ìŠ¹ì§„' (order={chunk.order})")
            
            # í—¤ë”/ë¹„ê³  ë“± - ì´ì „/ë‹¤ìŒ ì²­í¬ ê¸°ë°˜ ì¶”ë¡ 
            elif chunk.section_type == 'table_rows':
                # ì§§ì€ ì²­í¬ëŠ” í—¤ë”/ë¹„ê³  ê°€ëŠ¥ì„± ë†’ìŒ
                if chunk.char_count < 50:
                    chunk.metadata['table_label'] = "unknown_fragment"
                    logger.info(f"         ğŸ·ï¸ ë¼ë²¨: 'unknown_fragment' (ì§§ì€ ì¡°ê°, {chunk.char_count}ì)")
                else:
                    chunk.metadata['table_label'] = None
            
            labeled.append(chunk)
        
        # ë¼ë²¨ ì „íŒŒ: unknown_fragmentë¥¼ ì´ì „/ë‹¤ìŒ ë¼ë²¨ë¡œ ì „íŒŒ
        labeled = self._propagate_labels_v0983(labeled)
        
        return labeled
    
    def _propagate_labels_v0983(self, chunks: List[SubChunk]) -> List[SubChunk]:
        """
        ë¼ë²¨ ì „íŒŒ: unknown_fragmentë¥¼ ì¸ì ‘ ì²­í¬ ë¼ë²¨ë¡œ ì „íŒŒ
        
        ì˜ˆ:
        [3ê¸‰ìŠ¹ì§„ì œì™¸, unknown_fragment, 3ê¸‰ìŠ¹ì§„]
        â†’ [3ê¸‰ìŠ¹ì§„ì œì™¸, 3ê¸‰ìŠ¹ì§„ì œì™¸, 3ê¸‰ìŠ¹ì§„]
        """
        for i, chunk in enumerate(chunks):
            if chunk.section_type != 'table_rows':
                continue
            
            current_label = chunk.metadata.get('table_label')
            
            if current_label == "unknown_fragment":
                # ì´ì „ ì²­í¬ í™•ì¸
                prev_label = None
                for j in range(i - 1, -1, -1):
                    if chunks[j].section_type == 'table_rows':
                        prev_label = chunks[j].metadata.get('table_label')
                        if prev_label and prev_label != "unknown_fragment":
                            break
                
                # ë‹¤ìŒ ì²­í¬ í™•ì¸
                next_label = None
                for j in range(i + 1, len(chunks)):
                    if chunks[j].section_type == 'table_rows':
                        next_label = chunks[j].metadata.get('table_label')
                        if next_label and next_label != "unknown_fragment":
                            break
                
                # ì „íŒŒ ìš°ì„ ìˆœìœ„: ì´ì „ > ë‹¤ìŒ
                if prev_label:
                    chunk.metadata['table_label'] = prev_label
                    logger.info(f"         ğŸ”€ ë¼ë²¨ ì „íŒŒ: 'unknown_fragment' â†’ '{prev_label}' (ì´ì „ ê¸°ì¤€)")
                elif next_label:
                    chunk.metadata['table_label'] = next_label
                    logger.info(f"         ğŸ”€ ë¼ë²¨ ì „íŒŒ: 'unknown_fragment' â†’ '{next_label}' (ë‹¤ìŒ ê¸°ì¤€)")
        
        return chunks
    
    def _group_by_label_v0983(
        self,
        table_chunks: List[SubChunk]
    ) -> Dict[str, List[SubChunk]]:
        """
        Step B: label ê¸°ë°˜ ê·¸ë£¹í™”
        
        Returns:
            {"3ê¸‰ìŠ¹ì§„ì œì™¸": [chunk1, chunk2, ...],
             "3ê¸‰ìŠ¹ì§„": [chunk3, chunk4, ...]}
        """
        groups = {}
        
        for chunk in table_chunks:
            label = chunk.metadata.get('table_label')
            
            if not label or label == "unknown_fragment":
                # ë¼ë²¨ ì—†ëŠ” ì²­í¬ëŠ” ë…ë¦½ ê·¸ë£¹
                continue
            
            if label not in groups:
                groups[label] = []
            
            groups[label].append(chunk)
        
        logger.info(f"      ğŸ“Š ê·¸ë£¹í™” ê²°ê³¼:")
        for label, group in groups.items():
            logger.info(f"         '{label}': {len(group)}ê°œ ì²­í¬")
        
        return groups
    
    # ============================================
    # Phase 0.9.8.2: ê¸°ì¡´ ë©”ì„œë“œ (ìœ ì§€)
    # ============================================
    
    def _process_single_annex_v0982(
        self,
        content: str,
        annex_no: str,
        start_order: int,
        header_end_pos: int
    ) -> List[SubChunk]:
        """
        âœ… Phase 0.9.8.2: ë‹¨ì¼ Annex ì²˜ë¦¬ (ë²„ê·¸ ìˆ˜ì • ì ìš©)
        
        GPT ë¯¸ì†¡ë‹˜ ì„¤ê³„:
        1) ë¸”ë¡ ê°ì§€ (start/end ë©”íƒ€ í¬í•¨) â† Fix A
        2) ë³‘í•© (ë©”íƒ€ ì§ì ‘ ì‚¬ìš©) â† Fix A
        3) âœ¨ ê²½ê³„ ê°ì§€ + ì•ˆì „ ë¶„í•  â† Fix B
        4) Chunk ë³€í™˜
        """
        chunks = []
        order = start_order
        
        # Header/Body ë¶„ë¦¬
        header_text, body_text = self._split_header_body_v0976(content)
        
        # Step 1: Header ì²­í¬
        if header_text:
            header_chunk = self._extract_header_chunk(header_text, annex_no, order)
            if header_chunk:
                chunks.append(header_chunk)
                order += 1
        
        # ë¼ì¸ ìœ ì§€
        lines = body_text.split('\n')
        lines = [l for l in lines if l.strip()]
        
        logger.info(f"      ë¼ì¸ ìœ ì§€: {len(lines)}ê°œ")
        
        # Step 2: âœ¨ Table Block Segmentation (start/end ë©”íƒ€ í¬í•¨)
        blocks = self._segment_blocks_v0982(lines)
        
        # Step 3: âœ¨ Table Candidate Merge (ë©”íƒ€ ìœ ì§€)
        blocks = self._merge_table_candidates_v0982(blocks)
        
        # Step 4: âœ¨ Boundary Detection + Safe Split
        refined_blocks = []
        for block in blocks:
            if block['type'] == 'table_rows':
                # í‘œ ë¸”ë¡ë§Œ ê²½ê³„ ê°ì§€ + ì•ˆì „ ë¶„í• 
                sub_blocks = self._split_block_by_boundaries_v0982(lines, block)
                refined_blocks.extend(sub_blocks)
            else:
                # ë¹„í‘œ ë¸”ë¡ì€ ê·¸ëŒ€ë¡œ
                refined_blocks.append(block)
        
        # Step 5: Block â†’ Chunk ë³€í™˜
        for i, block in enumerate(refined_blocks):
            block_lines = block['lines']
            block_type = block['type']
            block_metadata = block['metadata']
            
            is_last_block = (i == len(refined_blocks) - 1)
            
            if is_last_block:
                note_chunk, remaining_lines = self._extract_note_from_lines(
                    block_lines, annex_no, order
                )
                
                if remaining_lines:
                    block_chunk = self._create_block_chunk(
                        remaining_lines, annex_no, order, i, block_type, block_metadata
                    )
                    if block_chunk:
                        chunks.append(block_chunk)
                        order += 1
                
                if note_chunk:
                    chunks.append(note_chunk)
                    order += 1
            else:
                block_chunk = self._create_block_chunk(
                    block_lines, annex_no, order, i, block_type, block_metadata
                )
                if block_chunk:
                    chunks.append(block_chunk)
                    order += 1
        
        return chunks
    
    def _split_block_by_boundaries_v0982(
        self,
        lines: List[str],
        block: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        âœ¨ Phase 0.9.8.2 Fix B: ì•ˆì „í•œ ë¸”ë¡ ë¶„í•  (GPT ë¯¸ì†¡ë‹˜ ì„¤ê³„)
        
        í•µì‹¬ ìˆ˜ì •:
        - cuts ë°°ì—´ ê¸°ë°˜ ì™„ì „ ë¶„í• 
        - í•œ ì¤„ë„ ë²„ë¦¬ì§€ ì•ŠìŒ
        - tail ë²„ë¦¬ê¸° ì¡°ê±´ ì œê±°
        """
        boundaries = self._detect_table_boundaries(lines, block)
        
        if not boundaries:
            logger.info(f"      â„¹ï¸ ê²½ê³„ ì—†ìŒ: ë‹¨ì¼ í‘œë¡œ ìœ ì§€")
            return [block]
        
        # âœ¨ GPT ë¯¸ì†¡ë‹˜ ì„¤ê³„: cuts ë°°ì—´ ê¸°ë°˜
        start = block.get('start', 0)
        end = block.get('end', len(block['lines']) - 1)
        
        # block ë‚´ë¶€ ê²½ê³„ë§Œ í•„í„°
        internal_boundaries = [b for b in boundaries if start < b <= end]
        
        if not internal_boundaries:
            return [block]
        
        # cuts ë°°ì—´ ìƒì„±: [start, boundary1, boundary2, ..., end+1]
        cuts = [start] + internal_boundaries + [end + 1]
        
        logger.info(f"      âœ¨ cuts ë°°ì—´: {cuts}")
        
        # ì™„ì „ ë¶„í•  (í•œ ì¤„ë„ ë²„ë¦¬ì§€ ì•ŠìŒ)
        sub_blocks = []
        
        for i in range(len(cuts) - 1):
            seg_start = cuts[i]
            seg_end = cuts[i + 1] - 1
            
            if seg_end < seg_start:
                continue
            
            # linesì—ì„œ ì‹¤ì œ ë¼ì¸ ì¶”ì¶œ
            segment_lines = lines[seg_start:seg_end + 1]
            
            # ë¹ˆ ë¼ì¸ë§Œ ì²´í¬ (ìµœì†Œ ê¸¸ì´ ì¡°ê±´ ì œê±°)
            non_empty = [l for l in segment_lines if l.strip()]
            if len(non_empty) == 0:
                logger.info(f"         âš ï¸ ë¹ˆ segment ì œì™¸: {seg_start}~{seg_end}")
                continue
            
            sub_blocks.append({
                **block,
                'lines': segment_lines,
                'start': seg_start,
                'end': seg_end
            })
            
            logger.info(f"         âœ… Segment {i+1}: {seg_start}~{seg_end} ({len(segment_lines)}ì¤„)")
        
        logger.info(f"      âœ‚ï¸ í‘œ ë¸”ë¡ ë¶„í• : 1 â†’ {len(sub_blocks)}ê°œ (boundaries={internal_boundaries})")
        
        return sub_blocks if sub_blocks else [block]
    
    def _detect_table_boundaries(
        self,
        lines: List[str],
        block: Dict[str, Any]
    ) -> List[int]:
        """
        âœ¨ Phase 0.9.8.2: í‘œ ê²½ê³„ ê°ì§€ (Phase 0.9.8.1 ìœ ì§€)
        
        GPT ë¯¸ì†¡ë‹˜ íœ´ë¦¬ìŠ¤í‹± 3ê°œ:
        - H1: í—¤ë” ë°˜ë³µ
        - H2: Note/ë¹„ê³  ë¼ì¸
        - H3: í° ê³µë°±
        """
        block_lines = block['lines']
        
        if not block_lines:
            return []
        
        # âœ¨ Fix A: start/end ë©”íƒ€ ì§ì ‘ ì‚¬ìš©
        start = block.get('start', 0)
        end = block.get('end', len(block_lines) - 1)
        
        # í›„ë³´ ìˆ˜ì§‘
        header_candidates = []
        note_lines = []
        empty_runs = []
        
        # H1: í—¤ë” í›„ë³´ íƒìƒ‰
        header_keywords = ["ì„ìš©í•˜ê³ ì", "ì„œì—´ëª…ë¶€", "ì§ê¸‰", "ì‘ì‹œìê²©"]
        for i in range(start, end + 1):
            if i >= len(lines):
                break
            line = lines[i]
            norm = line.replace(" ", "")
            if any(k in norm for k in header_keywords):
                header_candidates.append(i)
        
        # H2: Note/ë¹„ê³  í›„ë³´ íƒìƒ‰
        note_pattern = re.compile(r"^\*?\s*(ë¹„ê³ |ì£¼|è¨»|note|ì„ìš©í•˜ê³ ì)")
        for i in range(start, end + 1):
            if i >= len(lines):
                break
            line = lines[i]
            if note_pattern.search(line):
                note_lines.append(i)
        
        # H3: í° ê³µë°± íƒìƒ‰ (ì—°ì† 2ì¤„ ì´ìƒ)
        empty_count = 0
        for i in range(start, end + 1):
            if i >= len(lines):
                break
            if not lines[i].strip():
                empty_count += 1
            else:
                if empty_count >= 2:
                    empty_runs.append(i)
                empty_count = 0
        
        # ê²½ê³„ í›„ë³´ ì§‘í•©
        boundary_candidates = set()
        
        # H1: í—¤ë”ê°€ 2ë²ˆ ì´ìƒ ë‚˜ì˜¤ë©´ ë‘ ë²ˆì§¸ë¶€í„° ê²½ê³„
        if len(header_candidates) >= 2:
            for idx in header_candidates[1:]:
                boundary_candidates.add(idx)
                logger.info(f"         ğŸ¯ H1 í—¤ë” ë°˜ë³µ ê²½ê³„: {idx}ë²ˆ ë¼ì¸")
        
        # H2: Note ë¼ì¸ ë‹¤ìŒì¤„
        for idx in note_lines:
            next_idx = idx + 1
            if start < next_idx <= end:
                boundary_candidates.add(next_idx)
                logger.info(f"         ğŸ¯ H2 ë¹„ê³  ë¼ì¸ ê²½ê³„: {next_idx}ë²ˆ ë¼ì¸ (note={idx})")
        
        # H3: ê³µë°± ë
        for idx in empty_runs:
            if start < idx <= end:
                boundary_candidates.add(idx)
                logger.info(f"         ğŸ¯ H3 ê³µë°± ê²½ê³„: {idx}ë²ˆ ë¼ì¸")
        
        # block ë‚´ë¶€ì— ìˆëŠ” ê²ƒë§Œ ì •ë ¬
        boundaries = sorted(
            i for i in boundary_candidates
            if start < i <= end
        )
        
        return boundaries
    
    # ============================================
    # Phase 0.9.8.2: Merge/Segment ë¡œì§ (ìœ ì§€)
    # ============================================
    
    def _segment_blocks_v0982(self, lines: List[str]) -> List[Dict[str, Any]]:
        """
        âœ¨ Phase 0.9.8.2 Fix A: Table Block Segmentation (start/end ë©”íƒ€ í¬í•¨)
        """
        blocks = []
        
        if not lines:
            return blocks
        
        window_size = min(8, max(5, len(lines) // 3))
        
        sample_windows = []
        
        i = 0
        while i < len(lines):
            window_end = min(i + window_size, len(lines))
            window_lines = lines[i:window_end]
            
            features = self._calculate_block_features(window_lines)
            table_score = self._calculate_table_score_v0976(features)
            
            if len(sample_windows) < 10:
                sample_windows.append({
                    'range': f"{i}~{window_end}",
                    'score': table_score,
                    'features': features
                })
            
            if table_score >= 0.55:
                block_type = "table_rows"
                
                extended_end = self._extend_table_block(lines, i, window_end, features)
                
                refined_start, refined_end, expand_meta = self._refine_table_block_boundaries_v0976(
                    lines, i, extended_end
                )
                
                block_lines = lines[refined_start:refined_end]
                
                logger.info(
                    f"         í‘œ ë¸”ë¡ ê°ì§€: {refined_start}~{refined_end} ë¼ì¸ "
                    f"(ì ìˆ˜: {table_score:.2f}, í™•ì¥: â†‘{expand_meta['expanded_up']} â†“{expand_meta['expanded_down']})"
                )
                
                i = refined_end
                
                # âœ¨ Fix A: start/end ë©”íƒ€ í¬í•¨
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'start': refined_start,
                    'end': refined_end - 1,
                    'metadata': {
                        **features,
                        'table_score': round(table_score, 3),
                        **expand_meta
                    }
                })
            
            elif 0.50 <= table_score < 0.55 and (
                features['digit_density'] >= 0.25 or
                features['short_line_ratio'] > 0.8 or
                features['header_hint']
            ):
                block_type = "table_candidate"
                
                extended_end = self._extend_table_block(lines, i, window_end, features)
                block_lines = lines[i:extended_end]
                
                logger.info(
                    f"         í‘œ í›„ë³´ ê°ì§€: {i}~{extended_end} ë¼ì¸ "
                    f"(ì ìˆ˜: {table_score:.2f}, digit={features['digit_density']:.2f}, "
                    f"short={features['short_line_ratio']:.2f}, header={features['header_hint']})"
                )
                
                i = extended_end
                
                # âœ¨ Fix A: start/end ë©”íƒ€ í¬í•¨
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'start': i - len(block_lines),
                    'end': i - 1,
                    'metadata': {
                        **features,
                        'table_score': round(table_score, 3)
                    }
                })
            
            else:
                block_type = "paragraph"
                
                para_end = i + 1
                while para_end < len(lines):
                    next_features = self._calculate_block_features(lines[para_end:para_end+5])
                    next_score = self._calculate_table_score_v0976(next_features)
                    
                    if next_score >= 0.50:
                        break
                    
                    para_end += 1
                
                block_lines = lines[i:para_end]
                
                # âœ¨ Fix A: start/end ë©”íƒ€ í¬í•¨
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'start': i,
                    'end': para_end - 1,
                    'metadata': {}
                })
                
                i = para_end
        
        if sample_windows:
            logger.info(f"      ğŸ“Š Window ìƒ˜í”Œ (top {len(sample_windows)}):")
            for sw in sample_windows[:5]:
                logger.info(
                    f"         {sw['range']}: score={sw['score']:.2f}, "
                    f"digit={sw['features']['digit_density']:.2f}, "
                    f"short={sw['features']['short_line_ratio']:.2f}, "
                    f"header={sw['features']['header_hint']}"
                )
        
        # âœ¨ Phase 0.9.8.2: Merge (ë©”íƒ€ ì§ì ‘ ì‚¬ìš©)
        blocks = self._merge_overlapping_blocks_v0982(blocks)
        
        logger.info(f"      ë¸”ë¡ ë¶„ë¦¬: {len(blocks)}ê°œ")
        
        return blocks
    
    def _merge_overlapping_blocks_v0982(self, blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        âœ¨ Phase 0.9.8.2 Fix A: ê²¹ì¹˜ëŠ” í‘œ ë¸”ë¡ ë³‘í•© (index() ì œê±°)
        """
        if not blocks:
            return []
        
        table_blocks = []
        other_blocks = []
        
        for b in blocks:
            if b.get('type') == 'table_rows':
                table_blocks.append(b)
            else:
                other_blocks.append(b)
        
        if not table_blocks:
            return blocks
        
        # start ê¸°ì¤€ ì •ë ¬
        table_blocks = sorted(table_blocks, key=lambda x: x.get('start', 0))
        
        # ì˜¤ë²„ë© ë³‘í•©
        merged = [table_blocks[0]]
        
        for current in table_blocks[1:]:
            last = merged[-1]
            
            # âœ¨ Fix A: ë©”íƒ€ ì§ì ‘ ì‚¬ìš©
            last_start = last.get('start', 0)
            last_end = last.get('end', 0)
            curr_start = current.get('start', 0)
            curr_end = current.get('end', 0)
            
            # ì˜¤ë²„ë© ë˜ëŠ” ì¸ì ‘ ì²´í¬
            if curr_start <= last_end + 1:
                overlap_size = last_end - curr_start + 1 if curr_start <= last_end else 0
                
                if overlap_size > 0:
                    logger.info(f"      ğŸ”— í‘œ ë¸”ë¡ ë³‘í•©: {last_start}~{last_end} + {curr_start}~{curr_end} â†’ {overlap_size}ì¤„ ê²¹ì¹¨")
                
                # ë²”ìœ„ í™•ì¥
                last['end'] = max(last_end, curr_end)
                
                # lines ë³‘í•©
                if curr_start <= last_end:
                    overlap_lines = last_end - curr_start + 1
                    last['lines'] = last['lines'] + current['lines'][overlap_lines:]
                else:
                    last['lines'] = last['lines'] + current['lines']
                
                # scoreëŠ” max
                if 'metadata' in last and 'metadata' in current:
                    last['metadata']['table_score'] = max(
                        last['metadata'].get('table_score', 0),
                        current['metadata'].get('table_score', 0)
                    )
            else:
                merged.append(current)
        
        return merged + other_blocks
    
    def _merge_table_candidates_v0982(self, blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        âœ¨ Phase 0.9.8.2: Table Candidate Merge (ë©”íƒ€ ìœ ì§€)
        """
        if len(blocks) <= 1:
            return blocks
        
        merged = []
        i = 0
        
        while i < len(blocks):
            current = blocks[i]
            current_type = current['type']
            
            if current_type == "paragraph":
                meta = current.get('metadata', {})
                if not meta:
                    meta = self._calculate_block_features(current['lines'])
                    current['metadata'] = meta
                
                if meta.get('digit_density', 0) > 0.35 and meta.get('short_line_ratio', 0) > 0.6:
                    current['type'] = "table_candidate"
                    current_type = "table_candidate"
                    logger.info(
                        f"         âœ… Paragraph â†’ table_candidate ìŠ¹ê²© "
                        f"(digit: {meta.get('digit_density'):.2f}, short: {meta.get('short_line_ratio'):.2f})"
                    )
            
            if current_type == "table_candidate" and i + 1 < len(blocks):
                next_block = blocks[i + 1]
                next_type = next_block['type']
                
                if next_type == "table_candidate":
                    merged_lines = current['lines'] + next_block['lines']
                    merged_meta = self._calculate_block_features(merged_lines)
                    merged_score = self._calculate_table_score_v0976(merged_meta)
                    
                    logger.info(
                        f"         âœ… table_candidate ë³‘í•©: "
                        f"{len(current['lines'])}ì¤„ + {len(next_block['lines'])}ì¤„ "
                        f"â†’ table_rows ìŠ¹ê²© (ì ìˆ˜: {merged_score:.2f})"
                    )
                    
                    merged.append({
                        'type': 'table_rows',
                        'lines': merged_lines,
                        'start': current.get('start', 0),
                        'end': next_block.get('end', 0),
                        'metadata': {
                            **merged_meta,
                            'table_score': round(merged_score, 3),
                            'merged_from_candidates': True
                        }
                    })
                    
                    i += 2
                    continue
            
            if current_type == "table_candidate" and i + 1 < len(blocks):
                next_block = blocks[i + 1]
                next_type = next_block['type']
                
                if next_type == "table_rows":
                    merged_lines = current['lines'] + next_block['lines']
                    merged_meta = next_block['metadata']
                    
                    logger.info(
                        f"         âœ… table_candidate + table_rows ë³‘í•©: "
                        f"{len(current['lines'])}ì¤„ + {len(next_block['lines'])}ì¤„"
                    )
                    
                    merged.append({
                        'type': 'table_rows',
                        'lines': merged_lines,
                        'start': current.get('start', 0),
                        'end': next_block.get('end', 0),
                        'metadata': merged_meta
                    })
                    
                    i += 2
                    continue
            
            if current_type == "table_candidate":
                logger.info(
                    f"         í‘œ í›„ë³´ ê°•ë“±: paragraphë¡œ ì²˜ë¦¬ "
                    f"(ì ìˆ˜: {current['metadata'].get('table_score', 0):.2f}, "
                    f"digit: {current['metadata'].get('digit_density', 0):.2f})"
                )
                current['type'] = "paragraph"
            
            merged.append(current)
            i += 1
        
        return merged
    
    # ============================================
    # Phase 0.9.8.0: ê¸°ì¡´ Helper ë©”ì„œë“œ (ìœ ì§€)
    # ============================================
    
    def _split_by_annex(self, annex_text: str) -> List[Dict[str, Any]]:
        """Step 1: ë³„í‘œ ë‹¨ìœ„ë¡œ ì™„ì „ ë¶„ë¦¬"""
        pattern = r'\[ë³„í‘œ\s*(\d+)\]\s*([^\n<]+)'
        matches = list(re.finditer(pattern, annex_text))
        
        if not matches:
            return []
        
        sections = []
        for i, match in enumerate(matches):
            annex_no = match.group(1)
            title = match.group(2).strip()
            start_pos = match.start()
            
            if i < len(matches) - 1:
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(annex_text)
            
            content = annex_text[start_pos:end_pos]
            header_end_pos = match.end() - start_pos
            
            sections.append({
                'annex_no': annex_no,
                'title': title,
                'content': content,
                'header_end_pos': header_end_pos
            })
        
        return sections
    
    def _split_header_body_v0976(self, content: str) -> Tuple[str, str]:
        """Header/Body ë¶„ë¦¬"""
        lines = content.split('\n')
        
        header_end_idx = 0
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            if i == 0 and '[ë³„í‘œ' in stripped:
                header_end_idx = i + 1
                continue
            
            if i <= 2 and ('<ì œ' in stripped or 'ê´€ë ¨>' in stripped):
                header_end_idx = i + 1
                continue
            
            if i <= 3 and re.match(r'\[.*?\d{4}\.\d{1,2}\.\d{1,2}.*?\]', stripped):
                header_end_idx = i + 1
                continue
            
            if HEADER_KEYWORDS.search(stripped) or re.match(self.patterns['digit_line'], stripped):
                break
        
        header_lines = lines[:header_end_idx]
        body_lines = lines[header_end_idx:]
        
        return '\n'.join(header_lines), '\n'.join(body_lines)
    
    def _calculate_table_score_v0976(self, features: Dict[str, Any]) -> float:
        """Table Score ê³„ì‚°"""
        score = 0.0
        
        score += features['digit_density'] * 0.4
        score += features['short_line_ratio'] * 0.3
        score += features['column_gap_consistency'] * 0.2
        
        if features['header_hint']:
            score += 0.1
        
        if features['short_line_ratio'] < 0.3:
            score -= 0.05
        
        return score
    
    def _calculate_block_features(self, lines: List[str]) -> Dict[str, Any]:
        """5ê°œ íŠ¹ì§• ê³„ì‚°"""
        if not lines:
            return {
                'digit_density': 0.0,
                'short_line_ratio': 0.0,
                'column_gap_consistency': 0.0,
                'header_hint': False,
                'avg_line_length': 0.0
            }
        
        digit_count = sum(len(re.findall(r'\d', line)) for line in lines)
        total_chars = sum(len(line) for line in lines)
        digit_density = digit_count / total_chars if total_chars > 0 else 0
        
        short_lines = sum(1 for line in lines if len(line.strip()) < 50)
        short_line_ratio = short_lines / len(lines)
        
        gap_positions = []
        for line in lines:
            gaps = [m.start() for m in re.finditer(r'\s{2,}', line)]
            gap_positions.extend(gaps)
        
        if len(gap_positions) >= 2:
            gap_variance = statistics.stdev(gap_positions) if len(set(gap_positions)) > 1 else 0
            column_gap_consistency = max(0, 1 - (gap_variance / 60))
        else:
            column_gap_consistency = 0.0
        
        first_line = lines[0] if lines else ""
        header_hint = bool(HEADER_KEYWORDS.search(first_line))
        
        avg_line_length = sum(len(line) for line in lines) / len(lines)
        
        return {
            'digit_density': digit_density,
            'short_line_ratio': short_line_ratio,
            'column_gap_consistency': column_gap_consistency,
            'header_hint': header_hint,
            'avg_line_length': avg_line_length
        }
    
    def _extend_table_block(self, lines: List[str], start: int, end: int, features: Dict[str, Any]) -> int:
        """í‘œ ë¸”ë¡ í™•ì¥"""
        extended_end = end
        
        while extended_end < len(lines):
            next_line = lines[extended_end].strip()
            
            if not next_line:
                break
            
            if DIGITISH_LINE.match(next_line):
                extended_end += 1
            elif len(next_line) < 50:
                extended_end += 1
            else:
                break
        
        return extended_end
    
    def _refine_table_block_boundaries_v0976(
        self,
        lines: List[str],
        start: int,
        end: int
    ) -> Tuple[int, int, Dict[str, int]]:
        """í‘œ ë¸”ë¡ ê²½ê³„ ì •ì œ"""
        refined_start = start
        refined_end = end
        
        MAX_EXPAND_UP = 10
        i = start - 1
        expanded_up = 0
        
        while i >= 0 and expanded_up < MAX_EXPAND_UP:
            prev_line = lines[i].strip()
            
            if not prev_line:
                break
            
            if DIGITISH_LINE.match(prev_line):
                refined_start = i
                expanded_up += 1
                i -= 1
                continue
            
            if SEPARATOR_LINE.match(prev_line):
                refined_start = i
                expanded_up += 1
                i -= 1
            else:
                break
        
        MAX_EXPAND_DOWN = 10
        i = end
        expanded_down = 0
        
        while i < len(lines) and expanded_down < MAX_EXPAND_DOWN:
            next_line = lines[i].strip()
            
            if not next_line:
                break
            
            if DIGITISH_LINE.match(next_line):
                refined_end = i + 1
                expanded_down += 1
                i += 1
                continue
            
            if SEPARATOR_LINE.match(next_line):
                refined_end = i + 1
                expanded_down += 1
                i += 1
                continue
            
            if len(next_line) < 50:
                refined_end = i + 1
                expanded_down += 1
                i += 1
            else:
                break
        
        return refined_start, refined_end, {
            'expanded_up': expanded_up,
            'expanded_down': expanded_down
        }
    
    def _extract_header_chunk(self, header_text: str, annex_no: str, order: int) -> Optional[SubChunk]:
        """í—¤ë” ì²­í¬ ìƒì„±"""
        if not header_text.strip():
            return None
        
        match = re.search(self.patterns['annex_header'], header_text)
        title = match.group(2) if match else "ë³„í‘œ"
        
        related_match = re.search(self.patterns['related_article'], header_text)
        related_article = related_match.group(1) if related_match else None
        
        amendment_match = re.search(self.patterns['amendment'], header_text)
        amendment_date = amendment_match.group(2) if amendment_match else None
        
        metadata = {
            'title': title,
            'related_article': related_article,
            'amendment_date': amendment_date
        }
        
        return SubChunk(
            section_id=f"ë³„í‘œ{annex_no}",
            section_type="header",
            content=header_text.strip(),
            metadata=metadata,
            char_count=len(header_text.strip()),
            order=order
        )
    
    def _extract_note_from_lines(
        self,
        lines: List[str],
        annex_no: str,
        order: int
    ) -> Tuple[Optional[SubChunk], List[str]]:
        """Note ì¶”ì¶œ"""
        note_lines = []
        remaining_lines = []
        
        note_started = False
        for line in lines:
            if re.match(self.patterns['note_marker'], line.strip()):
                note_started = True
                note_lines.append(line)
            elif note_started:
                note_lines.append(line)
            else:
                remaining_lines.append(line)
        
        note_chunk = None
        if note_lines:
            note_text = '\n'.join(note_lines)
            note_chunk = SubChunk(
                section_id=f"ë³„í‘œ{annex_no}",
                section_type="note",
                content=note_text.strip(),
                metadata={},
                char_count=len(note_text.strip()),
                order=order
            )
        
        return note_chunk, remaining_lines
    
    def _create_block_chunk(
        self,
        lines: List[str],
        annex_no: str,
        order: int,
        block_idx: int,
        block_type: str,
        block_metadata: Dict[str, Any]
    ) -> Optional[SubChunk]:
        """Block â†’ Chunk ë³€í™˜"""
        if not lines:
            return None
        
        content = '\n'.join(lines)
        
        return SubChunk(
            section_id=f"ë³„í‘œ{annex_no}",
            section_type=block_type,
            content=content.strip(),
            metadata=block_metadata,
            char_count=len(content.strip()),
            order=order
        )
    
    def _clean_annex_text(self, text: str) -> str:
        """ê°œí–‰ ë³´ì¡´ ë…¸ì´ì¦ˆ ì œê±°"""
        text = re.sub(r'[â–¡â– â—†â—‡â—‹â—â–ªâ–«â—â—‰â˜…â˜†]', '', text)
        text = re.sub(r'[â”â”ƒâ”‚â”€â”œâ”¤â”¬â”´â”¼â”Œâ”â””â”˜]', '', text)
        
        lines = text.splitlines()
        cleaned_lines = []
        for line in lines:
            cleaned_line = re.sub(r'[ \t]+', ' ', line).rstrip()
            cleaned_lines.append(cleaned_line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def _check_annex_loss(self, canonical_text: str, chunks: List[SubChunk]) -> float:
        """Phase 0.9.8.0: Loss ê³„ì‚° (ëˆ„ë½ë§Œ)"""
        original_len = len(canonical_text)
        chunk_total_len = sum(chunk.char_count for chunk in chunks)
        
        loss = max(0, original_len - chunk_total_len)
        loss_rate = loss / original_len if original_len > 0 else 0
        
        logger.info(f"   ğŸ“Š Loss Check:")
        logger.info(f"      ì›ë³¸: {original_len}ì")
        logger.info(f"      ì²­í¬ í•©ê³„: {chunk_total_len}ì")
        logger.info(f"      ì†ì‹¤ë¥ : {loss_rate*100:.1f}%")
        
        MAX_LOSS_RATE = 0.03
        
        if loss_rate <= MAX_LOSS_RATE:
            logger.info(f"   âœ… ì†ì‹¤ë¥  {loss_rate*100:.1f}% â‰¤ {MAX_LOSS_RATE*100:.0f}% (í†µê³¼)")
        else:
            logger.warning(f"   âš ï¸ ì†ì‹¤ë¥  {loss_rate*100:.1f}% > {MAX_LOSS_RATE*100:.0f}% (ê¸°ì¤€ ì´ˆê³¼)")
        
        return loss_rate
    
    def _fallback_chunk(self, annex_text: str, annex_no: str) -> List[SubChunk]:
        """Fallback: ë‹¨ì¼ paragraph ì²­í¬"""
        cleaned_text = self._clean_annex_text(annex_text)
        
        return [
            SubChunk(
                section_id=f"ë³„í‘œ{annex_no}",
                section_type="paragraph",
                content=cleaned_text,
                metadata={},
                char_count=len(cleaned_text),
                order=0
            )
        ]


# ============================================
# Phase 0.9.8.3: validate_subchunks (ìœ ì§€)
# ============================================

def validate_subchunks(chunks: List[SubChunk], original_text_len: int) -> Dict[str, Any]:
    """
    âœ… Phase 0.9.8.0: SubChunk ê²€ì¦ (ìœ ì§€)
    """
    if not chunks:
        return {
            'is_valid': False,
            'reason': 'ì²­í¬ ì—†ìŒ',
            'chunk_count': 0,
            'type_counts': {},
            'loss_rate': 1.0,
            'has_header': False,
            'has_content': False
        }
    
    type_counts = {}
    for chunk in chunks:
        ctype = chunk.section_type
        type_counts[ctype] = type_counts.get(ctype, 0) + 1
    
    has_header = 'header' in type_counts
    has_content = any(t in type_counts for t in ['table_rows', 'paragraph'])
    
    chunk_total_len = sum(chunk.char_count for chunk in chunks)
    
    loss = max(0, original_text_len - chunk_total_len)
    loss_rate = loss / original_text_len if original_text_len > 0 else 0
    
    MAX_LOSS_RATE = 0.03
    is_valid = loss_rate <= MAX_LOSS_RATE
    reason = "ì •ìƒ" if is_valid else f"ì†ì‹¤ë¥  {loss_rate*100:.1f}% ì´ˆê³¼"
    
    return {
        'is_valid': is_valid,
        'reason': reason,
        'chunk_count': len(chunks),
        'type_counts': type_counts,
        'loss_rate': loss_rate,
        'has_header': has_header,
        'has_content': has_content
    }