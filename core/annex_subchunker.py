"""
core/annex_subchunker.py - Phase 0.9.8.0 Validation Fix

Phase 0.9.8.0 (GPT ë¯¸ì†¡ë‹˜ P1 í•´ê²°):
1. âœ… Fix 1: ê²¹ì¹˜ëŠ” í‘œ ë¸”ë¡ ë³‘í•© (_merge_overlapping_blocks)
   - ë¬¸ì œ: 0~156, 149~310 â†’ 149~156 ì¤‘ë³µ
   - í•´ê²°: ì˜¤ë²„ë© ê°ì§€ â†’ 0~310 ë‹¨ì¼ ë¸”ë¡ ë³‘í•©
   - íš¨ê³¼: ì¤‘ë³µ ë¼ì¸ ì œê±° â†’ loss_pct ê¸‰ë½

2. âœ… Fix 2: Loss ê³„ì‚°ì„ "ëˆ„ë½ë§Œ" ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
   - ë¬¸ì œ: abs(ì›ë³¸ - ì²­í¬)ë¡œ "ì¦ê°€"ë„ ì†ì‹¤ë¡œ ê³„ì‚°
   - í•´ê²°: max(0, ì›ë³¸ - ì²­í¬)ë¡œ "ëˆ„ë½ë§Œ" ì†ì‹¤
   - íš¨ê³¼: 2777ì â†’ 3087ì = 11.2% â†’ 0%

3. âœ… Fix 3: validate_subchunks LawParser ê³„ì•½ í†µì¼
   - has_header, has_content, type_counts ì¶”ê°€
   - loss_rate ê³„ì‚° ë°©ì‹ í†µì¼ (ëˆ„ë½ë§Œ)
   - LawParser ë¡œê·¸ í‚¤ ì˜¤ë¥˜ ì œê±°

Phase 0.9.7.8:
- âœ… validate_subchunks í•¨ìˆ˜ ì¶”ê°€ (P0 í•´ê²°!)

Phase 0.9.7.6:
- âœ… ê°œí–‰ ì‚­ì œ ì •ê·œì‹ ì™„ì „ ì œê±°
- âœ… _clean_annex_text ë¼ì¸ ë‹¨ìœ„ ê³µë°±ë§Œ ì •ê·œí™”

í•µì‹¬: í‘œ ë¸”ë¡ ì˜¤ë²„ë© ë³‘í•© + Loss ì •ì˜ ìˆ˜ì • â†’ validation í†µê³¼ â†’ table_rows 3ê°œ ë³µê·€!

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ + GPT ë¯¸ì†¡ë‹˜
Date: 2025-11-25
Version: Phase 0.9.8.0 Validation Fix
"""

import re
import logging
import statistics
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# í—¤ë” í‚¤ì›Œë“œ
HEADER_KEYWORDS = re.compile(
    r"(ì„ìš©í•˜ê³ ì|ì„œì—´ëª…ë¶€|ì§ê¸‰|ì‘ì‹œìê²©|ìŠ¹ì§„|ì œì™¸|êµ¬ë¶„|ë¹„ê³ |ì¸ì›ìˆ˜|ì ìˆ˜|í‰ì •|í‰ê°€|ë‹´ë‹¹ì|ìê²©ì·¨ë“|ê²½ë ¥)",
    re.IGNORECASE
)

SEPARATOR_LINE = re.compile(r"^[-â”€â€”]{3,}$")
DIGITISH_LINE = re.compile(r"^\s*(\d+[\.\)]?|\([0-9]+\)|[ê°€-í£]\)|[A-Za-z]\))\s+")


@dataclass
class SubChunk:
    """ì„œë¸Œì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    section_id: str
    section_type: str
    content: str
    metadata: Dict[str, Any]
    char_count: int
    order: int


class AnnexSubChunker:
    """
    Annex ì„œë¸Œì²­í‚¹ (Phase 0.9.7.6 Emergency Fix)
    
    GPT ë¯¸ì†¡ë‹˜ ì„¤ê³„:
    - R-1: ê°œí–‰ ì‚­ì œ íšŒê·€ ì½”ë“œ ì™„ì „ ì œê±°
    - R-2: ë¼ì¸ ë‹¨ìœ„ ê³µë°±ë§Œ ì •ê·œí™”
    - R-3: SyntaxWarning ì œê±°
    """
    
    def __init__(self):
        """âœ… P0 Fix: ì•ˆì •ì  ì´ˆê¸°í™”"""
        self.patterns = {
            'annex_header': r'\[ë³„í‘œ\s*(\d+)\]\s*([^\n<]+)',
            'related_article': r'<(ì œ\d+ì¡°[^>]*)ê´€ë ¨>',
            'amendment': r'\[(.*?(\d{4}\.\d{1,2}\.\d{1,2}).*?)\]',
            'note_marker': r'^\*\s*(.+)$',
            'digit_line': r'^\d+(\s*\S+)?$',
            'header_keywords': r'(ì§ê¸‰|ì‘ì‹œìê²©|ë¹„ê³ |ì¸ì›ìˆ˜|ì„œì—´ëª…ë¶€|ìˆœìœ„|ë‹´ë‹¹ì|ìê²©ì·¨ë“)',
        }
        
        logger.info("âœ… AnnexSubChunker v0.9.8.0 ì´ˆê¸°í™” (Validation Fix - ë¸”ë¡ ë³‘í•© + Loss ìˆ˜ì •)")
    
    def chunk(self, annex_text: str, annex_no: str = "1") -> List[SubChunk]:
        """
        âœ… Phase 0.9.8.0: Annex í…ìŠ¤íŠ¸ â†’ ì„œë¸Œì²­í‚¹ (ë¸”ë¡ ë³‘í•© + Loss ìˆ˜ì •)
        """
        logger.info(f"ğŸ”§ Phase 0.9.8.0: Annex ì„œë¸Œì²­í‚¹ ì‹œì‘: {len(annex_text)}ì")
        
        # Step 1: Annex ì™„ì „ ë¶„ë¦¬
        annex_sections = self._split_by_annex(annex_text)
        
        if not annex_sections:
            logger.warning("âš ï¸ ë³„í‘œ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - fallback ì²˜ë¦¬")
            return self._fallback_chunk(annex_text, annex_no)
        
        logger.info(f"âœ… Step 1: ë³„í‘œ ë¶„ë¦¬ ì™„ë£Œ: {len(annex_sections)}ê°œ")
        
        # Canonical text
        canonical_text = self._clean_annex_text(annex_text)
        
        # Step 2-4: ê° ë³„í‘œë§ˆë‹¤ ì²˜ë¦¬
        all_chunks = []
        global_order = 0
        
        for annex_sec in annex_sections:
            annex_num = annex_sec['annex_no']
            raw_content = annex_sec['content']
            header_end_pos = annex_sec['header_end_pos']
            
            logger.info(f"   ğŸ”¹ ë³„í‘œ{annex_num} ì²˜ë¦¬ ì¤‘... ({len(raw_content)}ì)")
            
            # âœ… R-2: ê°œí–‰ ë³´ì¡´ ë…¸ì´ì¦ˆ ì œê±°
            cleaned_content = self._clean_annex_text(raw_content)
            
            # Table Block Segmentation
            section_chunks = self._process_single_annex_v0976(
                cleaned_content,
                annex_num,
                global_order,
                header_end_pos
            )
            
            all_chunks.extend(section_chunks)
            global_order += len(section_chunks)
            
            logger.info(f"   âœ… ë³„í‘œ{annex_num}: {len(section_chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        # Step 5: Loss Check
        self._check_annex_loss(canonical_text, all_chunks)
        
        logger.info(f"âœ… Phase 0.9.8.0: Annex ì„œë¸Œì²­í‚¹ ì™„ë£Œ: ì´ {len(all_chunks)}ê°œ")
        
        # íƒ€ì…ë³„ í†µê³„
        type_counts = {}
        for chunk in all_chunks:
            ctype = chunk.section_type
            type_counts[ctype] = type_counts.get(ctype, 0) + 1
        
        for ctype, count in sorted(type_counts.items()):
            logger.info(f"   - {ctype}: {count}ê°œ")
        
        return all_chunks
    
    def _split_by_annex(self, annex_text: str) -> List[Dict[str, Any]]:
        """Step 1: ë³„í‘œ ë‹¨ìœ„ë¡œ ì™„ì „ ë¶„ë¦¬"""
        pattern = r'\[ë³„í‘œ\s*(\d+)\]\s*([^\n<]+)'
        matches = list(re.finditer(pattern, annex_text))
        
        if not matches:
            return []
        
        sections = []
        for i, match in enumerate(matches):
            annex_no = match.group(1)
            title = match.group(2).strip()
            start_pos = match.start()
            
            if i < len(matches) - 1:
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(annex_text)
            
            content = annex_text[start_pos:end_pos]
            header_end_pos = match.end() - start_pos
            
            sections.append({
                'annex_no': annex_no,
                'title': title,
                'content': content,
                'header_end_pos': header_end_pos
            })
        
        return sections
    
    def _process_single_annex_v0976(
        self,
        content: str,
        annex_no: str,
        start_order: int,
        header_end_pos: int
    ) -> List[SubChunk]:
        """
        âœ… Phase 0.9.7.6: ë‹¨ì¼ Annex ì²˜ë¦¬ (Emergency Fix)
        """
        chunks = []
        order = start_order
        
        # Header/Body ë¶„ë¦¬
        header_text, body_text = self._split_header_body_v0976(content)
        
        # Step 1: Header ì²­í¬
        if header_text:
            header_chunk = self._extract_header_chunk(header_text, annex_no, order)
            if header_chunk:
                chunks.append(header_chunk)
                order += 1
        
        # âœ… R-2: ë¼ì¸ ìœ ì§€ (ê°œí–‰ ë³´ì¡´ í™•ì¸)
        lines = body_text.split('\n')
        lines = [l for l in lines if l.strip()]
        
        logger.info(f"      ë¼ì¸ ìœ ì§€: {len(lines)}ê°œ")
        
        # Step 2: Table Block Segmentation
        blocks = self._segment_blocks_v0976(lines)
        
        # Step 3: Table Candidate Merge
        blocks = self._merge_table_candidates_v0976(blocks)
        
        # Step 4: Block â†’ Chunk ë³€í™˜
        for i, block in enumerate(blocks):
            block_lines = block['lines']
            block_type = block['type']
            block_metadata = block['metadata']
            
            is_last_block = (i == len(blocks) - 1)
            
            if is_last_block:
                note_chunk, remaining_lines = self._extract_note_from_lines(
                    block_lines, annex_no, order
                )
                
                if remaining_lines:
                    block_chunk = self._create_block_chunk(
                        remaining_lines, annex_no, order, i, block_type, block_metadata
                    )
                    if block_chunk:
                        chunks.append(block_chunk)
                        order += 1
                
                if note_chunk:
                    chunks.append(note_chunk)
                    order += 1
            else:
                block_chunk = self._create_block_chunk(
                    block_lines, annex_no, order, i, block_type, block_metadata
                )
                if block_chunk:
                    chunks.append(block_chunk)
                    order += 1
        
        return chunks
    
    def _merge_overlapping_blocks(self, blocks: List[Dict[str, Any]], original_lines: List[str]) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.9.8.0: ê²¹ì¹˜ëŠ” í‘œ ë¸”ë¡ ë³‘í•© (GPT ë¯¸ì†¡ë‹˜ Fix 1)
        
        ë¬¸ì œ: í‘œ ë¸”ë¡ 0~156, 149~310 â†’ 149~156 ì¤‘ë³µ
        í•´ê²°: ì˜¤ë²„ë© ê°ì§€ â†’ 0~310 ë‹¨ì¼ ë¸”ë¡ìœ¼ë¡œ ë³‘í•©
        íš¨ê³¼: ì¤‘ë³µ ë¼ì¸ ì œê±° â†’ loss_pct ê¸‰ë½ â†’ validation í†µê³¼
        """
        if not blocks:
            return []
        
        # table_rows ë¸”ë¡ë§Œ ì¶”ì¶œ (start/endë¡œ ì •ë ¬ í•„ìš”)
        table_blocks = []
        other_blocks = []
        
        for b in blocks:
            if b.get('type') == 'table_rows':
                # linesì—ì„œ ì›ë³¸ ì¸ë±ìŠ¤ ë³µì› (ì²« ë¼ì¸ìœ¼ë¡œ ì°¾ê¸°)
                first_line = b['lines'][0] if b['lines'] else ""
                try:
                    start_idx = original_lines.index(first_line)
                    end_idx = start_idx + len(b['lines'])
                    table_blocks.append({
                        **b,
                        '_start': start_idx,
                        '_end': end_idx
                    })
                except ValueError:
                    # ëª» ì°¾ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
                    other_blocks.append(b)
            else:
                other_blocks.append(b)
        
        if not table_blocks:
            return blocks
        
        # start ê¸°ì¤€ ì •ë ¬
        table_blocks = sorted(table_blocks, key=lambda x: x['_start'])
        
        # ì˜¤ë²„ë© ë³‘í•©
        merged = [table_blocks[0]]
        
        for current in table_blocks[1:]:
            last = merged[-1]
            
            # ì˜¤ë²„ë© ë˜ëŠ” ì¸ì ‘ ì²´í¬
            if current['_start'] <= last['_end'] + 1:
                # ë³‘í•©
                overlap_size = last['_end'] - current['_start'] + 1 if current['_start'] <= last['_end'] else 0
                
                if overlap_size > 0:
                    logger.info(f"      ğŸ”— í‘œ ë¸”ë¡ ë³‘í•©: {last['_start']}~{last['_end']} + {current['_start']}~{current['_end']} â†’ {overlap_size}ì¤„ ê²¹ì¹¨")
                
                # ë²”ìœ„ í™•ì¥
                last['_end'] = max(last['_end'], current['_end'])
                
                # lines ì¬êµ¬ì„± (ì›ë³¸ì—ì„œ ì¶”ì¶œ)
                last['lines'] = original_lines[last['_start']:last['_end']]
                
                # scoreëŠ” max
                if 'metadata' in last and 'metadata' in current:
                    last['metadata']['table_score'] = max(
                        last['metadata'].get('table_score', 0),
                        current['metadata'].get('table_score', 0)
                    )
            else:
                # ê²¹ì¹¨ ì—†ìŒ â†’ ë³„ë„ ë¸”ë¡
                merged.append(current)
        
        # _start/_end ë©”íƒ€ë°ì´í„° ì œê±°
        for b in merged:
            b.pop('_start', None)
            b.pop('_end', None)
        
        return merged + other_blocks
    
    def _split_header_body_v0976(self, content: str) -> Tuple[str, str]:
        """Header/Body ë¶„ë¦¬"""
        lines = content.split('\n')
        
        header_end_idx = 0
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            if i == 0 and '[ë³„í‘œ' in stripped:
                header_end_idx = i + 1
                continue
            
            if i <= 2 and ('<ì œ' in stripped or 'ê´€ë ¨>' in stripped):
                header_end_idx = i + 1
                continue
            
            if i <= 3 and re.match(r'\[.*?\d{4}\.\d{1,2}\.\d{1,2}.*?\]', stripped):
                header_end_idx = i + 1
                continue
            
            if HEADER_KEYWORDS.search(stripped) or re.match(self.patterns['digit_line'], stripped):
                break
        
        header_lines = lines[:header_end_idx]
        body_lines = lines[header_end_idx:]
        
        return '\n'.join(header_lines), '\n'.join(body_lines)
    
    def _segment_blocks_v0976(self, lines: List[str]) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.9.7.6: Table Block Segmentation (Emergency Fix)
        
        GPT ë¯¸ì†¡ë‹˜ í•µì‹¬ ìˆ˜ì •:
        - candidate ê²Œì´íŠ¸ ì™„í™” (OR ê¸°ë°˜)
        - ê°€ì‹œí™” ë¡œê·¸ ì¶”ê°€
        """
        blocks = []
        
        if not lines:
            return blocks
        
        window_size = min(8, max(5, len(lines) // 3))
        
        # âœ… ê°€ì‹œí™”ë¥¼ ìœ„í•œ ìƒ˜í”Œ ìˆ˜ì§‘
        sample_windows = []
        
        i = 0
        while i < len(lines):
            window_end = min(i + window_size, len(lines))
            window_lines = lines[i:window_end]
            
            # 5ê°œ íŠ¹ì§• ê³„ì‚°
            features = self._calculate_block_features(window_lines)
            
            # Table Score ê³„ì‚°
            table_score = self._calculate_table_score_v0976(features)
            
            # âœ… ìƒ˜í”Œ ìˆ˜ì§‘ (top 10 window)
            if len(sample_windows) < 10:
                sample_windows.append({
                    'range': f"{i}~{window_end}",
                    'score': table_score,
                    'features': features
                })
            
            # table_rows ê¸°ì¤€: 0.55
            if table_score >= 0.55:
                block_type = "table_rows"
                
                extended_end = self._extend_table_block(lines, i, window_end, features)
                
                refined_start, refined_end, expand_meta = self._refine_table_block_boundaries_v0976(
                    lines, i, extended_end
                )
                
                block_lines = lines[refined_start:refined_end]
                
                logger.info(
                    f"         í‘œ ë¸”ë¡ ê°ì§€: {refined_start}~{refined_end} ë¼ì¸ "
                    f"(ì ìˆ˜: {table_score:.2f}, í™•ì¥: â†‘{expand_meta['expanded_up']} â†“{expand_meta['expanded_down']})"
                )
                
                i = refined_end
                
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'metadata': {
                        **features,
                        'table_score': round(table_score, 3),
                        **expand_meta
                    }
                })
            
            # âœ… candidate ê²Œì´íŠ¸ ì™„í™” (OR ê¸°ë°˜)
            elif 0.50 <= table_score < 0.55 and (
                features['digit_density'] >= 0.25 or
                features['short_line_ratio'] > 0.8 or
                features['header_hint']
            ):
                block_type = "table_candidate"
                
                extended_end = self._extend_table_block(lines, i, window_end, features)
                block_lines = lines[i:extended_end]
                
                logger.info(
                    f"         í‘œ í›„ë³´ ê°ì§€: {i}~{extended_end} ë¼ì¸ "
                    f"(ì ìˆ˜: {table_score:.2f}, digit={features['digit_density']:.2f}, "
                    f"short={features['short_line_ratio']:.2f}, header={features['header_hint']})"
                )
                
                i = extended_end
                
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'metadata': {
                        **features,
                        'table_score': round(table_score, 3)
                    }
                })
            
            else:
                # Paragraph
                block_type = "paragraph"
                
                para_end = i + 1
                while para_end < len(lines):
                    next_features = self._calculate_block_features(lines[para_end:para_end+5])
                    next_score = self._calculate_table_score_v0976(next_features)
                    
                    if next_score >= 0.50:
                        break
                    
                    para_end += 1
                
                block_lines = lines[i:para_end]
                i = para_end
                
                blocks.append({
                    'type': block_type,
                    'lines': block_lines,
                    'metadata': {}
                })
        
        # âœ… ìƒ˜í”Œ ë¡œê·¸ ì¶œë ¥
        if sample_windows:
            logger.info(f"      ğŸ“Š Window ìƒ˜í”Œ (top {len(sample_windows)}):")
            for sw in sample_windows[:5]:  # ìƒìœ„ 5ê°œë§Œ
                logger.info(
                    f"         {sw['range']}: score={sw['score']:.2f}, "
                    f"digit={sw['features']['digit_density']:.2f}, "
                    f"short={sw['features']['short_line_ratio']:.2f}, "
                    f"header={sw['features']['header_hint']}"
                )
        
        # âœ… Phase 0.9.8.0: ì˜¤ë²„ë© ë¸”ë¡ ë³‘í•© (GPT ë¯¸ì†¡ë‹˜ Fix 1)
        blocks = self._merge_overlapping_blocks(blocks, lines)
        
        logger.info(f"      ë¸”ë¡ ë¶„ë¦¬: {len(blocks)}ê°œ")
        
        return blocks
    
    def _calculate_table_score_v0976(self, features: Dict[str, Any]) -> float:
        """Table Score ê³„ì‚°"""
        score = 0.0
        
        score += features['digit_density'] * 0.4
        score += features['short_line_ratio'] * 0.3
        score += features['column_gap_consistency'] * 0.2
        
        if features['header_hint']:
            score += 0.1
        
        if features['short_line_ratio'] < 0.3:
            score -= 0.05
        
        return score
    
    def _calculate_block_features(self, lines: List[str]) -> Dict[str, Any]:
        """5ê°œ íŠ¹ì§• ê³„ì‚°"""
        if not lines:
            return {
                'digit_density': 0.0,
                'short_line_ratio': 0.0,
                'column_gap_consistency': 0.0,
                'header_hint': False,
                'avg_line_length': 0.0
            }
        
        # 1. Digit Density
        digit_count = sum(len(re.findall(r'\d', line)) for line in lines)
        total_chars = sum(len(line) for line in lines)
        digit_density = digit_count / total_chars if total_chars > 0 else 0
        
        # 2. Short Line Ratio
        short_lines = sum(1 for line in lines if len(line.strip()) < 50)
        short_line_ratio = short_lines / len(lines)
        
        # 3. Column Gap Consistency
        gap_positions = []
        for line in lines:
            gaps = [m.start() for m in re.finditer(r'\s{2,}', line)]
            gap_positions.extend(gaps)
        
        if len(gap_positions) >= 2:
            gap_variance = statistics.stdev(gap_positions) if len(set(gap_positions)) > 1 else 0
            column_gap_consistency = max(0, 1 - (gap_variance / 60))
        else:
            column_gap_consistency = 0.0
        
        # 4. Header Hint
        first_line = lines[0] if lines else ""
        header_hint = bool(HEADER_KEYWORDS.search(first_line))
        
        # 5. Avg Line Length
        avg_line_length = sum(len(line) for line in lines) / len(lines)
        
        return {
            'digit_density': round(digit_density, 3),
            'short_line_ratio': round(short_line_ratio, 3),
            'column_gap_consistency': round(column_gap_consistency, 3),
            'header_hint': header_hint,
            'avg_line_length': round(avg_line_length, 1)
        }
    
    def _extend_table_block(
        self,
        lines: List[str],
        start: int,
        end: int,
        features: Dict[str, Any]
    ) -> int:
        """í‘œ ë¸”ë¡ í™•ì¥"""
        extended_end = end
        
        while extended_end < len(lines):
            next_line = lines[extended_end]
            
            if re.match(self.patterns['digit_line'], next_line):
                extended_end += 1
            elif len(next_line) < 50:
                extended_end += 1
            else:
                break
        
        return extended_end
    
    def _refine_table_block_boundaries_v0976(
        self,
        lines: List[str],
        start: int,
        end: int
    ) -> Tuple[int, int, Dict[str, Any]]:
        """ê²½ê³„ ë³´ì • (10/10ì¤„)"""
        refined_start = start
        refined_end = end
        
        # ìƒí–¥ í™•ì¥ MAX 10ì¤„
        MAX_EXPAND_UP = 10
        i = start - 1
        expanded_up = 0
        
        while i >= 0 and expanded_up < MAX_EXPAND_UP:
            prev_line = lines[i].strip()
            
            if not prev_line:
                break
            
            if HEADER_KEYWORDS.search(prev_line):
                refined_start = i
                expanded_up += 1
                i -= 1
                continue
            
            if any(kw in prev_line for kw in ["ë‹´ë‹¹ì", "ì œì™¸", "í‰ì •", "ìŠ¹ì§„", "ì‘ì‹œìê²©", "ì„ìš©", "ìê²©ì·¨ë“"]):
                refined_start = i
                expanded_up += 1
                i -= 1
                continue
            
            if len(prev_line) <= 80:
                refined_start = i
                expanded_up += 1
                i -= 1
            else:
                break
        
        # í•˜í–¥ í™•ì¥ MAX 10ì¤„
        MAX_EXPAND_DOWN = 10
        i = end
        expanded_down = 0
        
        while i < len(lines) and expanded_down < MAX_EXPAND_DOWN:
            next_line = lines[i].strip()
            
            if not next_line:
                break
            
            if DIGITISH_LINE.match(next_line):
                refined_end = i + 1
                expanded_down += 1
                i += 1
                continue
            
            if SEPARATOR_LINE.match(next_line):
                refined_end = i + 1
                expanded_down += 1
                i += 1
                continue
            
            if len(next_line) < 50:
                refined_end = i + 1
                expanded_down += 1
                i += 1
            else:
                break
        
        return refined_start, refined_end, {
            'expanded_up': expanded_up,
            'expanded_down': expanded_down
        }
    
    def _merge_table_candidates_v0976(self, blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        âœ… Phase 0.9.7.6: Table Candidate Merge
        """
        if len(blocks) <= 1:
            return blocks
        
        merged = []
        i = 0
        
        while i < len(blocks):
            current = blocks[i]
            current_type = current['type']
            
            # Paragraph ìŠ¹ê²© ì¡°ê±´ ì™„í™” (digit > 0.35)
            if current_type == "paragraph":
                meta = current.get('metadata', {})
                if not meta:
                    meta = self._calculate_block_features(current['lines'])
                    current['metadata'] = meta
                
                # digit_density > 0.35 AND short_line_ratio > 0.6 â†’ table_candidate ìŠ¹ê²©
                if meta.get('digit_density', 0) > 0.35 and meta.get('short_line_ratio', 0) > 0.6:
                    current['type'] = "table_candidate"
                    current_type = "table_candidate"
                    logger.info(
                        f"         âœ… Paragraph â†’ table_candidate ìŠ¹ê²© "
                        f"(digit: {meta.get('digit_density'):.2f}, short: {meta.get('short_line_ratio'):.2f})"
                    )
            
            # table_candidate 2ê°œ ì—°ì† â†’ ë³‘í•© í›„ table_rows ìŠ¹ê²©
            if current_type == "table_candidate" and i + 1 < len(blocks):
                next_block = blocks[i + 1]
                next_type = next_block['type']
                
                if next_type == "table_candidate":
                    merged_lines = current['lines'] + next_block['lines']
                    merged_meta = self._calculate_block_features(merged_lines)
                    merged_score = self._calculate_table_score_v0976(merged_meta)
                    
                    logger.info(
                        f"         âœ… table_candidate ë³‘í•©: "
                        f"{len(current['lines'])}ì¤„ + {len(next_block['lines'])}ì¤„ "
                        f"â†’ table_rows ìŠ¹ê²© (ì ìˆ˜: {merged_score:.2f})"
                    )
                    
                    merged.append({
                        'type': 'table_rows',
                        'lines': merged_lines,
                        'metadata': {
                            **merged_meta,
                            'table_score': round(merged_score, 3),
                            'merged_from_candidates': True
                        }
                    })
                    
                    i += 2
                    continue
            
            # table_candidate + table_rows ì—°ì† â†’ ê°•ì œ ë³‘í•©
            if current_type == "table_candidate" and i + 1 < len(blocks):
                next_block = blocks[i + 1]
                next_type = next_block['type']
                
                if next_type == "table_rows":
                    merged_lines = current['lines'] + next_block['lines']
                    merged_meta = next_block['metadata']
                    
                    logger.info(
                        f"         âœ… table_candidate + table_rows ë³‘í•©: "
                        f"{len(current['lines'])}ì¤„ + {len(next_block['lines'])}ì¤„"
                    )
                    
                    merged.append({
                        'type': 'table_rows',
                        'lines': merged_lines,
                        'metadata': merged_meta
                    })
                    
                    i += 2
                    continue
            
            # ë³‘í•© ì•ˆ ë¨ â†’ ê·¸ëŒ€ë¡œ ì¶”ê°€
            if current_type == "table_candidate":
                # ê°•ë“± ì´ìœ  ë¡œê·¸
                logger.info(
                    f"         í‘œ í›„ë³´ ê°•ë“±: paragraphë¡œ ì²˜ë¦¬ "
                    f"(ì ìˆ˜: {current['metadata'].get('table_score', 0):.2f}, "
                    f"digit: {current['metadata'].get('digit_density', 0):.2f})"
                )
                current['type'] = "paragraph"
            
            merged.append(current)
            i += 1
        
        return merged
    
    # ===== ê¸°ì¡´ ë©”ì„œë“œ =====
    
    def _extract_header_chunk(self, header_text: str, annex_no: str, order: int) -> Optional[SubChunk]:
        """í—¤ë” ì²­í¬ ìƒì„±"""
        if not header_text.strip():
            return None
        
        match = re.search(self.patterns['annex_header'], header_text)
        title = match.group(2) if match else "ë³„í‘œ"
        
        related_match = re.search(self.patterns['related_article'], header_text)
        related_article = related_match.group(1) if related_match else None
        
        amendment_match = re.search(self.patterns['amendment'], header_text)
        amendment_date = amendment_match.group(2) if amendment_match else None
        
        metadata = {
            'title': title,
            'related_article': related_article,
            'amendment_date': amendment_date
        }
        
        return SubChunk(
            section_id=f"ë³„í‘œ{annex_no}",
            section_type="header",
            content=header_text.strip(),
            metadata=metadata,
            char_count=len(header_text.strip()),
            order=order
        )
    
    def _extract_note_from_lines(
        self,
        lines: List[str],
        annex_no: str,
        order: int
    ) -> Tuple[Optional[SubChunk], List[str]]:
        """Note ì¶”ì¶œ"""
        note_lines = []
        remaining_lines = []
        
        note_started = False
        for line in lines:
            if re.match(self.patterns['note_marker'], line.strip()):
                note_started = True
                note_lines.append(line)
            elif note_started:
                note_lines.append(line)
            else:
                remaining_lines.append(line)
        
        note_chunk = None
        if note_lines:
            note_text = '\n'.join(note_lines)
            note_chunk = SubChunk(
                section_id=f"ë³„í‘œ{annex_no}",
                section_type="note",
                content=note_text.strip(),
                metadata={},
                char_count=len(note_text.strip()),
                order=order
            )
        
        return note_chunk, remaining_lines
    
    def _create_block_chunk(
        self,
        lines: List[str],
        annex_no: str,
        order: int,
        block_idx: int,
        block_type: str,
        block_metadata: Dict[str, Any]
    ) -> Optional[SubChunk]:
        """Block â†’ Chunk ë³€í™˜"""
        if not lines:
            return None
        
        content = '\n'.join(lines)
        
        return SubChunk(
            section_id=f"ë³„í‘œ{annex_no}",
            section_type=block_type,
            content=content.strip(),
            metadata=block_metadata,
            char_count=len(content.strip()),
            order=order
        )
    
    def _clean_annex_text(self, text: str) -> str:
        """
        âœ… R-1, R-2, R-3: ê°œí–‰ ë³´ì¡´ ë…¸ì´ì¦ˆ ì œê±° (GPT ë¯¸ì†¡ë‹˜ í•µì‹¬ ìˆ˜ì •)
        
        ë³€ê²½ ì „ (ì¹˜ëª…ì  íšŒê·€ - ì™„ì „ ì œê±°!):
        - ê°œí–‰ ì‚­ì œ ì •ê·œì‹ ì‚¬ìš© (SyntaxWarning)
        
        ë³€ê²½ í›„ (ê°œí–‰ ë³´ì¡´):
        - ì¤„ ë‹¨ìœ„ë¡œ ê³µë°±ë§Œ ì •ê·œí™”
        - 310ì¤„ì§œë¦¬ í‘œ í…ìŠ¤íŠ¸ ë³´ì¡´
        - SyntaxWarning ì œê±°
        """
        # ë…¸ì´ì¦ˆ ë¬¸ì ì œê±°
        text = re.sub(r'[â–¡â– â—†â—‡â—‹â—â–ªâ–«â—â—‰â˜…â˜†]', '', text)
        text = re.sub(r'[â”â”ƒâ”‚â”€â”œâ”¤â”¬â”´â”¼â”Œâ”â””â”˜]', '', text)
        
        # âœ… GPT ë¯¸ì†¡ë‹˜ ìˆ˜ì •: ì¤„ ë‹¨ìœ„ë¡œ ê³µë°±ë§Œ ì •ê·œí™” (splitlines ì‚¬ìš©)
        lines = text.splitlines()
        cleaned_lines = []
        for line in lines:
            # ê° ì¤„ì˜ ì—°ì† ê³µë°±/íƒ­ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
            cleaned_line = re.sub(r'[ \t]+', ' ', line).rstrip()
            cleaned_lines.append(cleaned_line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def _check_annex_loss(self, canonical_text: str, chunks: List[SubChunk]) -> float:
        """
        âœ… Phase 0.9.8.0: Loss ê³„ì‚° ìˆ˜ì • (GPT ë¯¸ì†¡ë‹˜ Fix 2)
        
        ë¬¸ì œ: abs(ì›ë³¸ - ì²­í¬)ë¡œ "ì¦ê°€"ë„ ì†ì‹¤ë¡œ ê³„ì‚°
              2777ì â†’ 3087ì = 11.2% ì†ì‹¤(?)
        í•´ê²°: max(0, ì›ë³¸ - ì²­í¬)ë¡œ "ëˆ„ë½ë§Œ" ì†ì‹¤ë¡œ ê³„ì‚°
              2777ì â†’ 3087ì = 0% ì†ì‹¤
        """
        original_len = len(canonical_text)
        total_chars = sum(c.char_count for c in chunks)
        
        # âœ… ëˆ„ë½ë§Œ ì†ì‹¤ë¡œ ê³„ì‚° (ì¦ê°€ëŠ” ì†ì‹¤ ì•„ë‹˜!)
        loss_rate = max(0, original_len - total_chars) / original_len if original_len > 0 else 0
        loss_pct = loss_rate * 100
        
        logger.info(f"   ğŸ“Š Loss Check:")
        logger.info(f"      ì›ë³¸: {original_len}ì")
        logger.info(f"      ì²­í¬ í•©ê³„: {total_chars}ì")
        logger.info(f"      ì†ì‹¤ë¥ : {loss_pct:.1f}%")
        
        if loss_rate > 0.03:
            logger.warning(f"   âš ï¸ ì†ì‹¤ë¥  {loss_pct:.1f}% > 3% (ì‹¤íŒ¨)")
        else:
            logger.info(f"   âœ… ì†ì‹¤ë¥  {loss_pct:.1f}% â‰¤ 3% (í†µê³¼)")
        
        return loss_rate
    
    def _fallback_chunk(self, annex_text: str, annex_no: str) -> List[SubChunk]:
        """Fallback ì²˜ë¦¬"""
        cleaned = self._clean_annex_text(annex_text)
        
        return [SubChunk(
            section_id=f"ë³„í‘œ{annex_no}",
            section_type="paragraph",
            content=cleaned,
            metadata={'fallback': True},
            char_count=len(cleaned),
            order=0
        )]



# ============================================================
# Phase 0.9.7.8 Final Fix - validate_subchunks ì¶”ê°€
# ============================================================

def validate_subchunks(chunks: List[SubChunk], original_length: int) -> Dict[str, Any]:
    """
    âœ… Phase 0.9.8.0: LawParser ê³„ì•½ ì™„ë²½ ì¤€ìˆ˜ (GPT ë¯¸ì†¡ë‹˜ Fix 3)
    
    LawParserê°€ ê¸°ëŒ€í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤:
    - is_valid: bool
    - reason: str
    - chunk_count: int
    - type_counts: Dict[str, int]
    - loss_rate: float (ëˆ„ë½ë§Œ ê³„ì‚°!)
    - has_header: bool
    - has_content: bool
    
    Args:
        chunks: ê²€ì¦í•  ì„œë¸Œì²­í¬ ë¦¬ìŠ¤íŠ¸
        original_length: ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´
    
    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not chunks:
        return {
            "is_valid": False,
            "reason": "ì²­í¬ ì—†ìŒ",
            "chunk_count": 0,
            "type_counts": {},
            "loss_rate": 1.0,
        }
    
    # type_counts ê³„ì‚°
    type_counts = {}
    for c in chunks:
        type_counts[c.section_type] = type_counts.get(c.section_type, 0) + 1
    
    # âœ… char_count í•©ìœ¼ë¡œ loss ê³„ì‚° (ëˆ„ë½ë§Œ!)
    total_chars = sum(c.char_count for c in chunks)
    loss_rate = max(0, original_length - total_chars) / original_length if original_length > 0 else 0
    
    # ê²€ì¦ ê¸°ì¤€
    has_header = "header" in type_counts
    has_content = ("table_rows" in type_counts) or ("paragraph" in type_counts)
    
    is_valid = has_header and has_content and (loss_rate <= 0.03)
    
    return {
        "is_valid": is_valid,
        "reason": "OK" if is_valid else "ê²€ì¦ ì‹¤íŒ¨",
        "chunk_count": len(chunks),
        "type_counts": type_counts,
        "total_chars": total_chars,
        "loss_rate": loss_rate,
        "has_header": has_header,
        "has_content": has_content,
    }


# âœ… Phase 0.9.8.0: validate_subchunks ê³„ì•½ í†µì¼
__all__ = ['AnnexSubChunker', 'SubChunk', 'validate_subchunks']