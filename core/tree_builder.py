"""
core/tree_builder.py
PRISM Phase 5.7.2 Hotfix - TreeBuilder v1.2.1 (ê¸´ê¸‰ íŒ¨ì¹˜)

ëª©í‘œ: Markdown â†’ ë²•ë ¹ íŠ¸ë¦¬ (JSON) ë³€í™˜

í”Œë¡œìš°:
1. Markdown ì „ì²˜ë¦¬ (ë¹ˆ í˜ì´ì§€ í•„í„°ë§)
2. ì¡°ë¬¸ ê²½ê³„ ê°ì§€
3. í•­Â·í˜¸ ì¤‘ì²© êµ¬ì¡° íŒŒì‹±
4. Tree êµ¬ì¡° ìƒì„±
5. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

âœ¨ Phase 5.7.2.1 ê¸´ê¸‰ ìˆ˜ì • (GPT ì˜ê²¬ 100% ë°˜ì˜):
1. SyntaxWarning ì œê±° (docstring raw string ë³€í™˜)
2. í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ ê°•í™” (# Page N, ----, ===)
3. OCR ì˜¤íƒˆì ì²˜ë¦¬ ("ì„ìš©í›ˆ" â†’ "ì„ìš©ê¶Œ", "ê³µê¸ˆê´€ë¦¬" â†’ "ìƒê¸‰ì¸ì‚¬")
4. ë¹ˆ í˜ì´ì§€ íŒì • ê°•í™” (ê°€ì‹œë¬¸ì < 10ì)

Author: ë°•ì¤€í˜¸ (AI/ML Lead) + GPT(ë¯¸ì†¡) ì˜ê²¬ ë°˜ì˜
Date: 2025-10-30
Version: 5.7.2.1 Hotfix
"""

import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)


class TreeBuilder:
    r"""
    Phase 5.7.2 TreeBuilder (ê¸´ê¸‰ íŒ¨ì¹˜)
    
    ì—­í• :
    - Markdownì„ ë²•ë ¹ íŠ¸ë¦¬ë¡œ ë³€í™˜
    - ì¡°ë¬¸Â·í•­Â·í˜¸ 3ë‹¨ ê³„ì¸µ êµ¬ì¡° ìƒì„±
    - ê°œì • ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    
    âœ… Phase 5.6.3 Final+ ì§€í‘œ ëŒ€ì‘:
    - hierarchy_preservation_rate ê²€ì¦
    - boundary_cross_bleed_rate ê²€ì¦
    - empty_article_rate ê²€ì¦
    
    âœ¨ Phase 5.7.2.1 ìµœì¢… ê°œì„ :
    - ë¹ˆ í˜ì´ì§€ ìë™ í•„í„°ë§ (# Page \d+, ---)
    - í˜ì´ì§€ ë²ˆí˜¸ ì •í™• ì¶”ì 
    - Chapter(ì¥) êµ¬ì¡° ì§€ì›
    - OCR ì˜¤íƒˆì ìë™ êµì •
    """
    
    # âœ… Phase 5.7.3.1: íŒ¨í„´ ì •ì˜ (Markdown í—¤ë” + í•­/í˜¸ í™•ì¥)
    # Markdown í—¤ë”(#)ë¥¼ í¬í•¨í•œ ì¡°ë¬¸ ì¸ì‹
    ARTICLE_PATTERN = re.compile(r'^\s{0,3}#{0,6}\s*(ì œ\s?\d+ì¡°(?:ì˜\s?\d+)?)(?:\s*\(([^)]+)\))?', re.MULTILINE)
    
    # âœ¨ Phase 5.7.3.1: CLAUSE_PATTERN í™•ì¥ (â‘ , (1), ì œ1í•­, 1. ëª¨ë‘ ì§€ì›)
    CLAUSE_PATTERN = re.compile(
        r'^\s{0,3}#{0,6}\s*(?:'
        r'\(?([â‘ -â‘³]|ì œ\s?\d+í•­)\)?|'  # â‘ , (â‘ ), ì œ1í•­
        r'(\d+)\.\s+'                  # 1., 2., 3.
        r')',
        re.MULTILINE
    )
    
    # âœ¨ Phase 5.7.3.1: ITEM_PATTERN í™•ì¥ (í˜¸, ëª¨ë“  í˜•ì‹ ì§€ì›)
    ITEM_PATTERN = re.compile(r'^\s{0,3}[-*]?\s*(\d{1,2}[.)]|[ê°€-í£][.)])', re.MULTILINE)
    
    SUBITEM_PATTERN = re.compile(r'^\s{0,3}([ê°€-í£]\)|[\d]+\))', re.MULTILINE)
    
    # âœ¨ Phase 5.7.3: Chapter íŒ¨í„´ (í—¤ë” ì§€ì›)
    CHAPTER_PATTERN = re.compile(r'^\s{0,3}#{0,6}\s*(ì œ\s?\d+ì¥)(?:\s+(.+))?', re.MULTILINE)
    
    # ì‚­ì œ ì¡°ë¬¸ íŒ¨í„´
    DELETED_PATTERN = re.compile(r'<ì‚­ì œ\s*(\d{4}\.\d{2}\.\d{2})>')
    
    # ê°œì •ì¼ íŒ¨í„´
    AMENDED_PATTERN = re.compile(r'\[.*?(\d{4}\.\d{2}\.\d{2}).*?\]')
    
    # âœ¨ Phase 5.7.2.1: í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ ê°•í™”
    PAGE_DIVIDER_PATTERNS = [
        re.compile(r'^#{1,3}\s*Page\s+\d+\s*$', re.IGNORECASE),  # # Page 1
        re.compile(r'^Page\s+\d+\s*$', re.IGNORECASE),           # Page 1
        re.compile(r'^[-â€”â€“_]{3,}\s*$'),                          # ---
        re.compile(r'^[*]{3,}\s*$'),                             # ***
        re.compile(r'^[=]{3,}\s*$'),                             # ===
    ]
    
    # âœ¨ Phase 5.7.2.1: OCR ì˜¤íƒˆì ì‚¬ì „
    OCR_TYPO_DICT = {
        'ì„ìš©í›ˆ': 'ì„ìš©ê¶Œ',
        'ê³µê¸ˆê´€ë¦¬ìœ„ì›íšŒ': 'ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ',
        'ê³µê¸ˆì¸ì‚¬ìœ„ì›íšŒ': 'ìƒê¸‰ì¸ì‚¬ìœ„ì›íšŒ',
        'ì„±ê³¼ê³„ì¬ë‹¨ìƒì': 'ì„±ê³¼ê°œì„ ëŒ€ìƒì',
        'ì„±ê³¼ê³„ì¬ì„ ë°œì': 'ì„±ê³¼ê°œì„ ëŒ€ìƒì',
        'ì±„ìš©ì†Œì¬ì‹œí—˜ì§€': 'ì±„ìš©ì‹ ì²´ê²€ì‚¬',
        'ì„ìš©Â·ìš©í›ˆ': 'ì„ìš©ê¶Œí•œ',
        'ì§ì›ì— ì„ìš©': 'ì§ì›ì˜ ì„ìš©',
    }
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        logger.info("âœ… TreeBuilder v5.7.2.1 ì´ˆê¸°í™” ì™„ë£Œ (Hotfix)")
    
    def build(
        self,
        markdown: str,
        document_title: str = "",
        enacted_date: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Markdownì„ Treeë¡œ ë³€í™˜
        
        Args:
            markdown: Markdown í…ìŠ¤íŠ¸
            document_title: ë¬¸ì„œ ì œëª©
            enacted_date: ì œì •ì¼ (YYYY.MM.DD)
        
        Returns:
            Document ìŠ¤í‚¤ë§ˆ (Phase 5.7.2)
        """
        logger.info(f"ğŸŒ² TreeBuilder ì‹œì‘: {document_title}")
        
        # âœ¨ Phase 5.7.2.1: OCR ì˜¤íƒˆì êµì •
        markdown = self._fix_ocr_typos(markdown)
        
        # âœ¨ Phase 5.7.2.1: ë¹ˆ í˜ì´ì§€ í•„í„°ë§ ê°•í™”
        markdown, removed_count = self._clean_page_dividers(markdown)
        logger.info(f"   ğŸ—‘ï¸ í˜ì´ì§€ êµ¬ë¶„ì ì œê±°: {removed_count}ê°œ ë¼ì¸")
        
        # ì¡°ë¬¸ íŒŒì‹±
        articles = self._parse_articles(markdown)
        logger.info(f"   ğŸ“„ ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ: {len(articles)}ê°œ")
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'title': document_title,
            'enacted_date': enacted_date or '',
            'extracted_at': datetime.now().isoformat(),
            'version': '5.7.2.1'
        }
        
        # Document ìŠ¤í‚¤ë§ˆ
        document = {
            'document': {
                'metadata': metadata,
                'tree': articles
            }
        }
        
        logger.info(f"âœ… TreeBuilder ì™„ë£Œ")
        return document
    
    def _fix_ocr_typos(self, markdown: str) -> str:
        """
        âœ¨ Phase 5.7.2.1: OCR ì˜¤íƒˆì êµì •
        
        Args:
            markdown: ì›ë³¸ Markdown
        
        Returns:
            êµì •ëœ Markdown
        """
        corrected = markdown
        corrections = 0
        
        for wrong, correct in self.OCR_TYPO_DICT.items():
            if wrong in corrected:
                count = corrected.count(wrong)
                corrected = corrected.replace(wrong, correct)
                corrections += count
                logger.debug(f"      OCR êµì •: '{wrong}' â†’ '{correct}' ({count}íšŒ)")
        
        if corrections > 0:
            logger.info(f"   âœï¸ OCR ì˜¤íƒˆì êµì •: {corrections}ê°œ")
        
        return corrected
    
    def _clean_page_dividers(self, markdown: str) -> Tuple[str, int]:
        """
        âœ¨ Phase 5.7.2.1: í˜ì´ì§€ êµ¬ë¶„ì ì œê±° (ê°•í™”)
        
        ëª©ì :
        - "# Page 1", "Page 2", "---" ë“± ì œê±°
        - ë¹ˆ ë¼ì¸ ì •ë¦¬
        
        Args:
            markdown: ì›ë³¸ Markdown
        
        Returns:
            (ì •ë¦¬ëœ Markdown, ì œê±°ëœ ë¼ì¸ ìˆ˜)
        """
        lines = markdown.split('\n')
        cleaned_lines = []
        removed_count = 0
        
        for line in lines:
            line_stripped = line.strip()
            
            # ë¹ˆ ë¼ì¸ì€ ìœ ì§€ (ì¤‘ìš”í•œ êµ¬ë¶„ì)
            if not line_stripped:
                cleaned_lines.append(line)
                continue
            
            # í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ ë§¤ì¹­
            is_divider = False
            for pattern in self.PAGE_DIVIDER_PATTERNS:
                if pattern.match(line_stripped):
                    is_divider = True
                    removed_count += 1
                    logger.debug(f"      ì œê±°: '{line_stripped[:50]}'")
                    break
            
            if not is_divider:
                cleaned_lines.append(line)
        
        cleaned = '\n'.join(cleaned_lines)
        
        return cleaned, removed_count
    
    def _parse_articles(self, markdown: str) -> List[Dict[str, Any]]:
        """
        ì¡°ë¬¸ íŒŒì‹± (ê²½ê³„ ëˆ„ìˆ˜ 0% ë³´ì¥)
        
        ì „ëµ:
        1. ì¡°ë¬¸ í—¤ë” ê°ì§€ ì¦‰ì‹œ ì´ì „ ì¡°ë¬¸ flush
        2. í•­Â·í˜¸ ì¤‘ì²© êµ¬ì¡° íŒŒì‹±
        3. ë¹ˆ ì¡°ë¬¸ ìë™ ì œê±°
        
        Args:
            markdown: ì „ì²˜ë¦¬ëœ Markdown
        
        Returns:
            Article ë¦¬ìŠ¤íŠ¸
        """
        articles = []
        current_article = None
        current_chapter = None
        page_num = 1
        sequence = 0
        
        lines = markdown.split('\n')
        
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            
            if not line_stripped:
                if current_article:
                    current_article['content'] += '\n'
                continue
            
            # âœ¨ Phase 5.7.2: Chapter ê°ì§€
            chapter_match = self.CHAPTER_PATTERN.match(line_stripped)
            if chapter_match:
                current_chapter = chapter_match.group(1)
                if chapter_match.group(2):
                    current_chapter += ' ' + chapter_match.group(2).strip()
                logger.debug(f"      ì¥ ê°ì§€: {current_chapter}")
                continue
            
            # ğŸš¨ ì¡°ë¬¸ í—¤ë” ê°ì§€ â†’ ì¦‰ì‹œ flush
            article_match = self.ARTICLE_PATTERN.match(line_stripped)
            if article_match:
                # ì´ì „ ì¡°ë¬¸ ì €ì¥ (ë¹ˆ ì¡°ë¬¸ í•„í„°ë§)
                if current_article:
                    if self._is_valid_article(current_article):
                        articles.append(current_article)
                    else:
                        logger.debug(f"      ë¹ˆ ì¡°ë¬¸ ì œê±°: {current_article['article_no']}")
                
                # ìƒˆ ì¡°ë¬¸ ì‹œì‘
                sequence += 1
                article_no = article_match.group(1)
                article_title = article_match.group(2)
                
                current_article = {
                    'level': 'article',
                    'article_no': article_no,
                    'article_title': article_title or '',
                    'content': '',
                    'children': [],
                    'metadata': {
                        'amended_dates': [],
                        'is_deleted': False,
                        'is_newly_established': False,
                        'change_log': [],
                        'has_empty_content': False,
                        'has_cross_bleed': False
                    },
                    'position': {
                        'page_number': page_num,
                        'sequence': sequence
                    }
                }
                
                if current_chapter:
                    current_article['chapter'] = current_chapter
                
                logger.debug(f"      ì¡°ë¬¸ ê°ì§€: {article_no} {article_title or ''}")
                continue
            
            # ì¡°ë¬¸ ë‚´ìš© ì¶”ê°€
            if current_article:
                # ì‚­ì œ ì¡°ë¬¸ ê°ì§€
                deleted_match = self.DELETED_PATTERN.search(line_stripped)
                if deleted_match:
                    current_article['metadata']['is_deleted'] = True
                    current_article['metadata']['change_log'].append({
                        'type': 'deleted',
                        'date': deleted_match.group(1)
                    })
                    logger.debug(f"      ì‚­ì œ ì¡°ë¬¸: {current_article['article_no']}")
                    continue
                
                # ê°œì •ì¼ ì¶”ì¶œ
                amended_matches = self.AMENDED_PATTERN.findall(line_stripped)
                for date in amended_matches:
                    if date not in current_article['metadata']['amended_dates']:
                        current_article['metadata']['amended_dates'].append(date)
                        current_article['metadata']['change_log'].append({
                            'type': 'amended',
                            'date': date
                        })
                
                # âœ¨ Phase 5.7.1: í•­Â·í˜¸ íŒŒì‹±
                clause_match = self.CLAUSE_PATTERN.match(line_stripped)
                item_match = self.ITEM_PATTERN.match(line_stripped)
                
                if clause_match:
                    # í•­ ì¶”ê°€
                    clause_no = clause_match.group(1)
                    content = line_stripped[clause_match.end():].strip()
                    
                    current_article['children'].append({
                        'level': 'clause',
                        'clause_no': clause_no,
                        'content': content,
                        'parent_article_no': current_article['article_no'],
                        'children': [],
                        'metadata': {
                            'amended_dates': current_article['metadata']['amended_dates'].copy(),
                            'is_deleted': False
                        },
                        'position': {
                            'page_number': page_num,
                            'sequence': sequence
                        }
                    })
                    logger.debug(f"        í•­ ê°ì§€: {clause_no}")
                
                elif item_match:
                    # í˜¸ ì¶”ê°€ (ë§ˆì§€ë§‰ í•­ì˜ ìì‹ìœ¼ë¡œ)
                    item_no = item_match.group(1)
                    content = line_stripped[item_match.end():].strip()
                    
                    if current_article['children'] and current_article['children'][-1]['level'] == 'clause':
                        last_clause = current_article['children'][-1]
                        last_clause['children'].append({
                            'level': 'item',
                            'item_no': item_no,
                            'content': content,
                            'parent_article_no': current_article['article_no'],
                            'parent_clause_no': last_clause['clause_no'],
                            'metadata': {
                                'amended_dates': current_article['metadata']['amended_dates'].copy(),
                                'is_deleted': False
                            },
                            'position': {
                                'page_number': page_num,
                                'sequence': sequence
                            }
                        })
                        logger.debug(f"          í˜¸ ê°ì§€: {item_no}")
                    else:
                        # í•­ ì—†ì´ í˜¸ë§Œ ìˆëŠ” ê²½ìš° â†’ ì¡°ë¬¸ ì§ì†
                        current_article['children'].append({
                            'level': 'item',
                            'item_no': item_no,
                            'content': content,
                            'parent_article_no': current_article['article_no'],
                            'metadata': {
                                'amended_dates': current_article['metadata']['amended_dates'].copy(),
                                'is_deleted': False
                            },
                            'position': {
                                'page_number': page_num,
                                'sequence': sequence
                            }
                        })
                
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸
                    current_article['content'] += line_stripped + ' '
        
        # ë§ˆì§€ë§‰ ì¡°ë¬¸ ì €ì¥
        if current_article and self._is_valid_article(current_article):
            articles.append(current_article)
        
        return articles
    
    def _is_valid_article(self, article: Dict[str, Any]) -> bool:
        """
        âœ¨ Phase 5.7.2.1: ë¹ˆ ì¡°ë¬¸ íŒì • ê°•í™”
        
        ì¡°ê±´:
        1. ê°€ì‹œë¬¸ì 10ì ì´ìƒ OR
        2. ìì‹(í•­Â·í˜¸) 1ê°œ ì´ìƒ
        
        Args:
            article: Article ë…¸ë“œ
        
        Returns:
            ìœ íš¨ ì—¬ë¶€
        """
        # ì‚­ì œ ì¡°ë¬¸ì€ í—ˆìš©
        if article['metadata']['is_deleted']:
            return True
        
        # ê°€ì‹œë¬¸ì ì¹´ìš´íŠ¸
        visible_chars = len(article['content'].replace(' ', '').replace('\n', ''))
        
        # ìì‹ ì¹´ìš´íŠ¸
        has_children = len(article['children']) > 0
        
        # íŒì •
        is_valid = visible_chars >= 10 or has_children
        
        if not is_valid:
            article['metadata']['has_empty_content'] = True
            logger.debug(f"      ë¹ˆ ì¡°ë¬¸ íŒì •: {article['article_no']} (ê¸€ì: {visible_chars}, ìì‹: {len(article['children'])})")
        
        return is_valid