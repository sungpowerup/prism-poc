"""
core/phase29_pipeline.py
PRISM Phase 2.9 íŒŒì´í”„ë¼ì¸ (ê°„ì†Œí™” ë²„ì „)

Phase 2.8 íŒŒì´í”„ë¼ì¸ì„ ì¬ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
"""

import os
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import json

# Phase 2.8 íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©
from core.phase28_pipeline import Phase28Pipeline
from core.smart_encoding_fixer import SmartEncodingFixer
from core.rag_optimized_chunker import RAGOptimizedChunker

logger = logging.getLogger(__name__)


class Phase29Pipeline:
    """
    PRISM Phase 2.9 ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Phase 2.8 ê¸°ë°˜ + ì¶”ê°€ ê¸°ëŠ¥:
    1. ìŠ¤ë§ˆíŠ¸ ì¸ì½”ë”© ìˆ˜ì •
    2. RAG ìµœì í™” ì²­í‚¹
    """
    
    def __init__(self, vlm_provider: str = 'azure_openai'):
        """
        Args:
            vlm_provider: VLM í”„ë¡œë°”ì´ë”
        """
        logger.info("="*60)
        logger.info("PRISM Phase 2.9 Pipeline ì´ˆê¸°í™”")
        logger.info("="*60)
        
        # Phase 2.8 íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
        self.phase28 = Phase28Pipeline(vlm_provider=vlm_provider)
        logger.info("âœ… Phase 2.8 íŒŒì´í”„ë¼ì¸ ë¡œë“œ")
        
        # Phase 2.9 ì¶”ê°€ ê¸°ëŠ¥
        self.encoding_fixer = SmartEncodingFixer()
        logger.info("âœ… ìŠ¤ë§ˆíŠ¸ ì¸ì½”ë”© ìˆ˜ì •ê¸°")
        
        self.chunker = RAGOptimizedChunker(
            min_chunk_size=100,
            max_chunk_size=800,
            overlap=50,
            preserve_structure=True
        )
        logger.info("âœ… RAG ìµœì í™” ì²­í‚¹ ì—”ì§„")
        
        self.vlm_provider = vlm_provider
        
        logger.info("="*60)
    
    def process_pdf(
        self,
        pdf_path: str,
        output_dir: str = 'output',
        max_pages: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        PDF ë¬¸ì„œ ì²˜ë¦¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        logger.info("\n" + "="*60)
        logger.info(f"ğŸ“„ Phase 2.9 ë¬¸ì„œ ì²˜ë¦¬: {Path(pdf_path).name}")
        logger.info("="*60)
        
        # Phase 2.8ë¡œ ê¸°ë³¸ ì²˜ë¦¬
        phase28_result = self.phase28.process_pdf(
            pdf_path=pdf_path,
            output_dir=output_dir,
            max_pages=max_pages
        )
        
        # Phase 2.9 ì¶”ê°€ ì²˜ë¦¬
        
        # 1. ì¸ì½”ë”© ìˆ˜ì •
        logger.info("\n--- Phase 2.9: ì¸ì½”ë”© ìˆ˜ì • ---")
        fixed_chunks = self._fix_encoding(phase28_result['stage2_chunks'])
        
        # 2. RAG ìµœì í™” ì²­í‚¹
        logger.info("\n--- Phase 2.9: RAG ì²­í‚¹ ---")
        rag_chunks = self._optimize_for_rag(fixed_chunks)
        
        # ê²°ê³¼ í†µí•©
        result = {
            'metadata': {
                'filename': Path(pdf_path).name,
                'phase': '2.9',
                'vlm_provider': self.vlm_provider,
                'processed_at': datetime.now().isoformat(),
                'total_pages': phase28_result['metadata']['total_pages'],
                'total_chunks': len(rag_chunks),
                'processing_time_sec': phase28_result['metadata']['processing_time_sec'],
                'encoding_fixes': self.encoding_fixer.base_fixer.get_stats()
            },
            'chunks': [chunk.to_dict() for chunk in rag_chunks]
        }
        
        # ì €ì¥
        self._save_results(result, output_dir)
        
        logger.info("\n" + "="*60)
        logger.info("âœ… Phase 2.9 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   ì²­í¬: {len(rag_chunks)}ê°œ")
        logger.info(f"   ì¸ì½”ë”© ìˆ˜ì •: {result['metadata']['encoding_fixes']['fixed']}ê±´")
        logger.info("="*60)
        
        return result
    
    def _fix_encoding(self, chunks: List[Dict]) -> List[Dict]:
        """ì¸ì½”ë”© ìˆ˜ì •"""
        fixed_chunks = []
        fix_count = 0
        
        for chunk in chunks:
            content = chunk.get('content', '')
            
            # ì¸ì½”ë”© ìˆ˜ì •
            fixed_content, confidence = self.encoding_fixer.fix_with_confidence(content)
            
            if fixed_content != content:
                fix_count += 1
                logger.info(f"ì²­í¬ ìˆ˜ì •: ì‹ ë¢°ë„ {confidence:.2%}")
            
            # ì—…ë°ì´íŠ¸
            fixed_chunk = chunk.copy()
            fixed_chunk['content'] = fixed_content
            fixed_chunks.append(fixed_chunk)
        
        logger.info(f"ì¸ì½”ë”© ìˆ˜ì • ì™„ë£Œ: {fix_count}ê±´")
        
        return fixed_chunks
    
    def _optimize_for_rag(self, chunks: List[Dict]) -> List:
        """RAG ìµœì í™” ì²­í‚¹"""
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n\n".join([
            f"[í˜ì´ì§€ {c.get('page_number', 1)}]\n{c.get('content', '')}"
            for c in chunks
        ])
        
        # RAG ì²­í‚¹
        rag_chunks = self.chunker.chunk_with_structure(
            text=full_text,
            metadata={'source_chunks': len(chunks)}
        )
        
        logger.info(f"RAG ì²­í‚¹ ì™„ë£Œ: {len(chunks)} â†’ {len(rag_chunks)}ê°œ")
        
        return rag_chunks
    
    def _save_results(self, result: Dict, output_dir: str):
        """ê²°ê³¼ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        filename = result['metadata']['filename']
        base_name = Path(filename).stem
        
        # JSON ì €ì¥
        json_path = Path(output_dir) / f"{base_name}_phase29.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {json_path}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == '__main__':
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    pipeline = Phase29Pipeline(vlm_provider='azure_openai')
    
    result = pipeline.process_pdf(
        pdf_path='input/test.pdf',
        output_dir='output',
        max_pages=3
    )
    
    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ: {result['metadata']['total_chunks']}ê°œ ì²­í¬")