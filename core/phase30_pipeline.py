"""
core/phase30_pipeline.py
PRISM Phase 3.0 íŒŒì´í”„ë¼ì¸

Stage 1: PDF â†’ Page Images
Stage 2: Layout Detection (í˜ì´ì§€ë‹¹ ì—¬ëŸ¬ ì˜ì—­)
Stage 3: Region-based VLM Analysis
Stage 4: Section-aware Chunking
"""

import time
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import logging
import cv2
import numpy as np
from dotenv import load_dotenv
from PIL import Image

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from .pdf_processor import PDFProcessor
from .layout_detector import LayoutDetector, Region
from .vlm_service import VLMService
from .section_chunker import SectionAwareChunker

logger = logging.getLogger(__name__)


class Phase30Pipeline:
    """
    PRISM Phase 3.0 íŒŒì´í”„ë¼ì¸
    
    ì£¼ìš” ê°œì„ ì‚¬í•­:
    - Layout Detectionìœ¼ë¡œ ê°œë³„ ì˜ì—­ ë¶„ë¦¬
    - Region-based VLM Analysis
    - Section-aware Chunking
    """
    
    def __init__(self, vlm_provider='azure_openai'):
        """
        Args:
            vlm_provider: 'azure_openai', 'claude', 'ollama'
        """
        logger.info("="*60)
        logger.info("PRISM Phase 3.0 Pipeline ì´ˆê¸°í™”")
        logger.info("="*60)
        
        self.vlm_provider = vlm_provider
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.pdf_processor = PDFProcessor()
        logger.info("âœ… PDF Processor")
        
        self.vlm_service = VLMService(provider=vlm_provider)
        logger.info(f"âœ… VLM Service ({vlm_provider})")
        
        self.layout_detector = LayoutDetector(
            vlm_service=self.vlm_service,
            use_vlm_validation=True
        )
        logger.info("âœ… Layout Detector")
        
        self.chunker = SectionAwareChunker(
            min_size=100,
            max_size=500,
            preserve_structure=True
        )
        logger.info("âœ… Section-aware Chunker")
        
        logger.info("="*60 + "\n")
    
    def process_pdf(
        self,
        pdf_path: str,
        output_dir='output',
        max_pages: int = None
    ) -> Dict[str, Any]:
        """
        PDF ì²˜ë¦¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            
        Returns:
            {
                'metadata': {...},
                'regions': [...],
                'chunks': [...]
            }
        """
        start_time = time.time()
        
        logger.info("\n" + "="*60)
        logger.info(f"ğŸ“„ PRISM Phase 3.0 ë¬¸ì„œ ì²˜ë¦¬")
        logger.info(f"   íŒŒì¼: {Path(pdf_path).name}")
        logger.info("="*60)
        
        # Stage 1: PDF â†’ Images
        logger.info("\n--- Stage 1: PDF â†’ Page Images ---")
        page_images_raw = self.pdf_processor.pdf_to_images(pdf_path)
        
        if max_pages:
            page_images_raw = page_images_raw[:max_pages]
        
        # PIL Image â†’ numpy array ë³€í™˜
        page_images = []
        for i, img in enumerate(page_images_raw, 1):
            if isinstance(img, str):
                # Base64 ë¬¸ìì—´ì¸ ê²½ìš°
                import base64
                from io import BytesIO
                
                # data URL ì œê±°
                if img.startswith('data:image'):
                    img = img.split(',')[1]
                
                img_bytes = base64.b64decode(img)
                pil_img = Image.open(BytesIO(img_bytes))
                np_img = np.array(pil_img)
            elif hasattr(img, 'convert'):
                # PIL Imageì¸ ê²½ìš°
                np_img = np.array(img.convert('RGB'))
            else:
                # ì´ë¯¸ numpy arrayì¸ ê²½ìš°
                np_img = img
            
            # BGR â†’ RGB ë³€í™˜ í™•ì¸ (OpenCVëŠ” BGR ì‚¬ìš©)
            if len(np_img.shape) == 3 and np_img.shape[2] == 3:
                # RGB ê·¸ëŒ€ë¡œ ì‚¬ìš© (PILì€ RGB)
                page_images.append(np_img)
            else:
                page_images.append(np_img)
        
        logger.info(f"âœ… {len(page_images)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ (numpy array)\n")
        
        all_regions = []
        all_extractions = []
        
        # Stage 2 & 3: í˜ì´ì§€ë³„ ì²˜ë¦¬
        for page_num, page_img in enumerate(page_images, 1):
            logger.info("\n" + "="*60)
            logger.info(f"í˜ì´ì§€ {page_num}/{len(page_images)} ì²˜ë¦¬")
            logger.info("="*60)
            
            # Stage 2: Layout Detection
            logger.info("\n--- Stage 2: Layout Detection ---")
            regions = self.layout_detector.detect_regions(page_img, page_num)
            
            # Stage 3: Region-based Extraction
            logger.info("\n--- Stage 3: Region-based Extraction ---")
            for region_num, region in enumerate(regions, 1):
                logger.info(f"\n[Region {region_num}/{len(regions)}] {region.type}")
                
                # ì˜ì—­ í¬ë¡­
                x, y, w, h = region.bbox
                crop = page_img[y:y+h, x:x+w]
                
                # íƒ€ì…ë³„ ì¶”ì¶œ
                content = self._extract_content(crop, region)
                
                extraction = {
                    'page_number': page_num,
                    'region_number': region_num,
                    'region_type': region.type,
                    'bbox': region.bbox,
                    'content': content,
                    'metadata': region.metadata
                }
                
                all_regions.append(region)
                all_extractions.append(extraction)
                
                logger.info(f"   ì¶”ì¶œ ì™„ë£Œ: {len(content)}ì")
        
        # Stage 4: Section-aware Chunking
        logger.info("\n" + "="*60)
        logger.info("--- Stage 4: Section-aware Chunking ---")
        logger.info("="*60)
        
        chunks = self.chunker.chunk_extractions(all_extractions)
        
        logger.info(f"\nâœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        
        # ê²°ê³¼ í†µí•©
        result = {
            'metadata': {
                'filename': Path(pdf_path).name,
                'phase': '3.0',
                'vlm_provider': self.vlm_provider,
                'processed_at': datetime.now().isoformat(),
                'total_pages': len(page_images),
                'total_regions': len(all_regions),
                'total_chunks': len(chunks),
                'processing_time_sec': round(time.time() - start_time, 2)
            },
            'regions': [r.to_dict() for r in all_regions],
            'extractions': all_extractions,
            'chunks': [c.to_dict() for c in chunks]
        }
        
        # ì €ì¥
        self._save_results(result, output_dir)
        
        logger.info("\n" + "="*60)
        logger.info("âœ… Phase 3.0 ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {result['metadata']['processing_time_sec']}ì´ˆ")
        logger.info(f"   ê°ì§€ëœ ì˜ì—­: {len(all_regions)}ê°œ")
        logger.info(f"   ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")
        logger.info("="*60 + "\n")
        
        return result
    
    def _extract_content(self, crop_image: np.ndarray, region: Region) -> str:
        """
        ì˜ì—­ íƒ€ì…ë³„ ì½˜í…ì¸  ì¶”ì¶œ
        
        Args:
            crop_image: í¬ë¡­ëœ ì˜ì—­ ì´ë¯¸ì§€
            region: ì˜ì—­ ì •ë³´
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        region_type = region.type
        
        if region_type == 'header':
            return self._extract_header(crop_image, region)
        elif region_type == 'chart':
            return self._extract_chart(crop_image, region)
        elif region_type == 'table':
            return self._extract_table(crop_image, region)
        elif region_type == 'map':
            return self._extract_map(crop_image, region)
        else:
            return self._extract_text(crop_image, region)
    
    def _extract_header(self, crop_image: np.ndarray, region: Region) -> str:
        """í—¤ë” ì¶”ì¶œ (VLM)"""
        from prompts.layout_prompt import HEADER_EXTRACTION_PROMPT
        
        try:
            result = self.vlm_service.analyze_image(crop_image, HEADER_EXTRACTION_PROMPT)
            
            # JSON íŒŒì‹±
            if isinstance(result, str):
                result = json.loads(result)
            
            header_text = result.get('text', '')
            
            logger.info(f"   í—¤ë”: {header_text}")
            
            return header_text
            
        except Exception as e:
            logger.error(f"   í—¤ë” ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "[í—¤ë” ì¶”ì¶œ ì‹¤íŒ¨]"
    
    def _extract_chart(self, crop_image: np.ndarray, region: Region) -> str:
        """ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ (VLM)"""
        from prompts.chart_prompt import CHART_EXTRACTION_PROMPT
        
        # ì°¨íŠ¸ íƒ€ì… íŒíŠ¸
        chart_type = region.metadata.get('chart_type', 'unknown')
        
        prompt = CHART_EXTRACTION_PROMPT
        
        if chart_type == 'pie':
            prompt += "\n\n**íŒíŠ¸**: ì´ ì°¨íŠ¸ëŠ” ì›ê·¸ë˜í”„(íŒŒì´ ì°¨íŠ¸)ì…ë‹ˆë‹¤."
        elif chart_type == 'bar':
            prompt += "\n\n**íŒíŠ¸**: ì´ ì°¨íŠ¸ëŠ” ë§‰ëŒ€ê·¸ë˜í”„ì…ë‹ˆë‹¤."
        
        try:
            caption = self.vlm_service.analyze_image(crop_image, prompt)
            
            logger.info(f"   ì°¨íŠ¸ ë¶„ì„ ì™„ë£Œ: {len(caption)}ì")
            
            return caption
            
        except Exception as e:
            logger.error(f"   ì°¨íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "[ì°¨íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨]"
    
    def _extract_table(self, crop_image: np.ndarray, region: Region) -> str:
        """í‘œ êµ¬ì¡°í™” (VLM)"""
        from prompts.table_prompt import TABLE_EXTRACTION_PROMPT
        
        try:
            table_data = self.vlm_service.analyze_image(crop_image, TABLE_EXTRACTION_PROMPT)
            
            logger.info(f"   í‘œ ì¶”ì¶œ ì™„ë£Œ: {len(table_data)}ì")
            
            return table_data
            
        except Exception as e:
            logger.error(f"   í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "[í‘œ ì¶”ì¶œ ì‹¤íŒ¨]"
    
    def _extract_map(self, crop_image: np.ndarray, region: Region) -> str:
        """ì§€ë„ ë°ì´í„° ì¶”ì¶œ (VLM + ê²€ì¦)"""
        from prompts.layout_prompt import MAP_REGION_PROMPT
        
        try:
            result = self.vlm_service.analyze_image(crop_image, MAP_REGION_PROMPT)
            
            # JSON íŒŒì‹± ë° ê²€ì¦
            if isinstance(result, str):
                result = json.loads(result)
            
            regions_data = result.get('regions', [])
            
            # ê²€ì¦: ì§€ì—­ ê°œìˆ˜
            expected_regions = 6  # í•œêµ­ ì§€ë„ ê¸°ì¤€
            if len(regions_data) < expected_regions:
                logger.warning(f"   âš ï¸ ì§€ì—­ ê°œìˆ˜ ë¶€ì¡±: {len(regions_data)}/{expected_regions}")
            
            # í…ìŠ¤íŠ¸ í¬ë§·
            lines = ["[ì§€ì—­ë³„ ë¶„í¬]"]
            for r in regions_data:
                lines.append(f"- {r['name']}: {r['value']}%")
            
            map_text = "\n".join(lines)
            
            logger.info(f"   ì§€ë„ ì¶”ì¶œ ì™„ë£Œ: {len(regions_data)}ê°œ ì§€ì—­")
            
            return map_text
            
        except Exception as e:
            logger.error(f"   ì§€ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "[ì§€ë„ ì¶”ì¶œ ì‹¤íŒ¨]"
    
    def _extract_text(self, crop_image: np.ndarray, region: Region) -> str:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR ë˜ëŠ” VLM)"""
        # TODO: PaddleOCR í†µí•©
        
        from prompts.image_prompt import IMAGE_CAPTION_PROMPT
        
        try:
            text = self.vlm_service.analyze_image(crop_image, IMAGE_CAPTION_PROMPT)
            
            logger.info(f"   í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text)}ì")
            
            return text
            
        except Exception as e:
            logger.error(f"   í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "[í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨]"
    
    def _save_results(self, result: Dict, output_dir: str):
        """ê²°ê³¼ ì €ì¥ (JSON + MD)"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = Path(result['metadata']['filename']).stem
        
        # JSON ì €ì¥
        json_path = output_path / f"prism_phase30_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {json_path}")
        
        # Markdown ì €ì¥
        md_path = output_path / f"prism_phase30_{timestamp}.md"
        self._write_markdown(result, md_path)
        
        logger.info(f"ğŸ’¾ ë§ˆí¬ë‹¤ìš´: {md_path}")
    
    def _write_markdown(self, result: Dict, md_path: Path):
        """Markdown íŒŒì¼ ìƒì„±"""
        lines = []
        
        lines.append(f"# PRISM Phase 3.0 - êµ¬ì¡°í™”ëœ ë¬¸ì„œ ì¶”ì¶œ\n")
        lines.append(f"**ìƒì„±ì¼ì‹œ**: {result['metadata']['processed_at']}\n")
        lines.append("---\n")
        
        lines.append("## ğŸ“„ ë¬¸ì„œ ì •ë³´\n")
        lines.append(f"- **íŒŒì¼ëª…**: {result['metadata']['filename']}")
        lines.append(f"- **ì´ í˜ì´ì§€**: {result['metadata']['total_pages']}ê°œ")
        lines.append(f"- **ì´ ì˜ì—­**: {result['metadata']['total_regions']}ê°œ")
        lines.append(f"- **ì´ ì²­í¬**: {result['metadata']['total_chunks']}ê°œ")
        lines.append(f"- **ì²˜ë¦¬ ì‹œê°„**: {result['metadata']['processing_time_sec']}ì´ˆ")
        lines.append(f"- **Phase**: 3.0\n")
        
        lines.append("## ğŸ§© ì²­í¬\n")
        
        for i, chunk in enumerate(result['chunks'], 1):
            lines.append(f"### ì²­í¬ #{i}\n")
            lines.append(f"- **ID**: {chunk['chunk_id']}")
            lines.append(f"- **íƒ€ì…**: {chunk['metadata']['chunk_type']}")
            lines.append(f"- **ì„¹ì…˜**: {chunk['metadata'].get('section_path', 'N/A')}")
            lines.append(f"- **í˜ì´ì§€**: {chunk['metadata']['page_number']}\n")
            lines.append("```")
            lines.append(chunk['content'])
            lines.append("```\n")
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))


# CLI ì‹¤í–‰
if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python -m core.phase30_pipeline <pdf_path> [output_dir] [vlm_provider]")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else 'output'
    vlm_provider = sys.argv[3] if len(sys.argv) > 3 else 'azure_openai'
    
    pipeline = Phase30Pipeline(vlm_provider=vlm_provider)
    result = pipeline.process_pdf(pdf_path, output_dir)
    
    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   ì²­í¬: {result['metadata']['total_chunks']}ê°œ")
    print(f"   ì‹œê°„: {result['metadata']['processing_time_sec']}ì´ˆ")