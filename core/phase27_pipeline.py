"""
PRISM Phase 2.7 - Main Processing Pipeline
2-Stage Pipeline + Intelligent Chunking

Stage 1: Layout Detection
Stage 2: Hybrid Extraction
Stage 3: Intelligent Chunking

Author: ì´ì„œì˜ (Backend Lead)
Date: 2025-10-20
Fixed: bbox tuple access issue + Anthropic initialization
"""

import time
from pathlib import Path
from typing import List, Dict, Optional
from PIL import Image
import fitz  # PyMuPDF

from core.layout_detector import LayoutDetector, Region
from core.hybrid_extractor import HybridExtractor, ExtractedContent
from core.intelligent_chunker import IntelligentChunker, Chunk


class Phase27Pipeline:
    """
    PRISM Phase 2.7 ë©”ì¸ íŒŒì´í”„ë¼ì¸
    
    íŠ¹ì§•:
    - 2-Stage ì²˜ë¦¬ (Layout â†’ Extraction)
    - í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ (OCR + VLM)
    - ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹
    - RAG ìµœì í™”
    """
    
    def __init__(
        self,
        vlm_provider: str = 'claude',
        min_chunk_size: int = 100,
        max_chunk_size: int = 500,
        overlap_size: int = 50
    ):
        """
        Args:
            vlm_provider: VLM í”„ë¡œë°”ì´ë” ('claude', 'azure_openai', 'ollama')
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸° (í† í°)
            max_chunk_size: ìµœëŒ€ ì²­í¬ í¬ê¸° (í† í°)
            overlap_size: ì²­í¬ ê°„ ì˜¤ë²„ë© (í† í°)
        """
        print("\n" + "="*60)
        print("PRISM Phase 2.7 Pipeline Initialization")
        print("="*60 + "\n")
        
        self.vlm_provider = vlm_provider
        print(f"ğŸ¤– VLM Provider: {vlm_provider.upper()}")
        
        # Stage 1: Layout Detection
        self.layout_detector = LayoutDetector(vlm_provider=vlm_provider)
        
        # Stage 2: Hybrid Extraction
        self.extractor = HybridExtractor(vlm_provider=vlm_provider)
        
        # Stage 3: Intelligent Chunking
        self.chunker = IntelligentChunker(
            min_chunk_size=min_chunk_size,
            max_chunk_size=max_chunk_size,
            overlap_size=overlap_size
        )
        
        print("\nâœ… Pipeline ready!\n")
    
    def process(
        self,
        pdf_path: str,
        max_pages: Optional[int] = None
    ) -> Dict:
        """
        PDF ë¬¸ì„œ ì „ì²´ ì²˜ë¦¬ (ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return self.process_pdf(pdf_path, max_pages)
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: Optional[int] = None
    ) -> Dict:
        """
        PDF ë¬¸ì„œ ì „ì²´ ì²˜ë¦¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        print(f"ğŸ“„ Processing PDF: {pdf_path}")
        print(f"â±ï¸  Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # PDF ì—´ê¸°
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        
        if max_pages:
            total_pages = min(total_pages, max_pages)
        
        print(f"ğŸ“– Total pages: {total_pages}\n")
        
        # ê° í˜ì´ì§€ ì²˜ë¦¬
        all_chunks = []
        
        for page_num in range(total_pages):
            print("="*60)
            print(f"ğŸ“„ Processing Page {page_num + 1}/{total_pages}")
            print("="*60 + "\n")
            
            # í˜ì´ì§€ë³„ ì²­í¬ ìƒì„±
            page_chunks = self._process_page(doc, page_num)
            all_chunks.extend(page_chunks)
            
            print(f"\nâœ… Page {page_num + 1} completed: {len(page_chunks)} chunks generated\n")
        
        # ë¬¸ì„œ ë‹«ê¸°
        doc.close()
        
        # ì²˜ë¦¬ ì™„ë£Œ
        end_time = time.time()
        processing_time = end_time - start_time
        
        # ë©”íƒ€ë°ì´í„°
        metadata = {
            'processed_at': time.strftime('%Y-%m-%dT%H:%M:%S'),
            'total_pages': total_pages,
            'total_chunks': len(all_chunks),
            'processing_time_seconds': round(processing_time, 2),
            'chunk_types': self._count_chunk_types(all_chunks),
            'vlm_provider': self.vlm_provider
        }
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        result = {
            'metadata': metadata,
            'chunks': [chunk.to_dict() for chunk in all_chunks]
        }
        
        print("="*60)
        print("ğŸ‰ Processing Complete!")
        print("="*60)
        print(f"â±ï¸  Total time: {processing_time:.1f}s")
        print(f"ğŸ“Š Total chunks: {len(all_chunks)}")
        print(f"ğŸ“ˆ Chunk types: {metadata['chunk_types']}\n")
        
        return result
    
    def _process_page(self, doc: fitz.Document, page_num: int) -> List[Chunk]:
        """
        ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬
        
        Args:
            doc: PyMuPDF ë¬¸ì„œ ê°ì²´
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (0-based)
            
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        page = doc[page_num]
        
        # Stage 1: Page â†’ Image
        print("ğŸ–¼ï¸  Step 1: Converting page to image...")
        pix = page.get_pixmap(dpi=150)
        img_data = pix.tobytes("png")
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        print(f"   Image size: {img.width}x{img.height}")
        
        # Stage 2: Layout Detection
        print("ğŸ” Step 2: Detecting layout regions...")
        regions = self.layout_detector.detect_regions(img)
        print(f"   Found {len(regions)} regions")
        
        # Stage 3: Hybrid Extraction
        print("ğŸ“ Step 3: Extracting content from regions...")
        extracted_contents = []
        
        for i, region in enumerate(regions, 1):
            print(f"   Region {i}/{len(regions)}: {region.type} - {region.description}")
            
            # âœ… ìˆ˜ì •: bboxëŠ” íŠœí”Œ (x, y, width, height)
            # íŠœí”Œ ì–¸íŒ©ìœ¼ë¡œ ê° ê°’ ì¶”ì¶œ
            x, y, width, height = region.bbox
            
            # ì˜ì—­ ì´ë¯¸ì§€ ì¶”ì¶œ
            region_img = img.crop((
                x,
                y,
                x + width,
                y + height
            ))
            
            # ì»¨í…ì¸  ì¶”ì¶œ
            content = self.extractor.extract_content(
                image=region_img,
                region_type=region.type,
                page_text=page.get_text()
            )
            
            extracted_contents.append(content)
            
            # ì¶”ì¶œ ê²°ê³¼ ì¶œë ¥
            char_count = len(content.content)
            confidence = content.confidence
            print(f"      âœ“ Extracted {char_count} characters (confidence: {confidence:.2f})")
        
        # Stage 4: Intelligent Chunking
        print("âœ‚ï¸  Step 4: Creating intelligent chunks...")
        all_chunks = []
        
        for i, content in enumerate(extracted_contents, 1):
            region_desc = regions[i-1].description if i <= len(regions) else "Region"
            
            chunks = self.chunker.chunk_content(
                content=content.content,
                content_type=content.type,
                page_num=page_num + 1,  # 1-based page number
                base_section=region_desc,
                metadata=content.metadata
            )
            
            all_chunks.extend(chunks)
            print(f"   Region {i}: {len(chunks)} chunk(s) created")
        
        return all_chunks
    
    def _count_chunk_types(self, chunks: List[Chunk]) -> Dict[str, int]:
        """ì²­í¬ íƒ€ì…ë³„ ê°œìˆ˜ ì„¸ê¸°"""
        counts = {}
        for chunk in chunks:
            counts[chunk.type] = counts.get(chunk.type, 0) + 1
        return counts


# ============================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("PRISM Phase 2.7 - Pipeline Test")
    print("="*60 + "\n")
    
    # VLM Provider ì„ íƒ
    import sys
    vlm_provider = sys.argv[1] if len(sys.argv) > 1 else 'claude'
    
    pipeline = Phase27Pipeline(vlm_provider=vlm_provider)
    
    # í…ŒìŠ¤íŠ¸ PDF ê²½ë¡œ í™•ì¸
    test_pdf = Path("input/test_document.pdf")
    
    if test_pdf.exists():
        print(f"âœ… Test PDF found: {test_pdf}\n")
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = pipeline.process_pdf(str(test_pdf), max_pages=3)
        
        print("\nğŸ“Š Result Summary:")
        print(f"   Chunks: {result['metadata']['total_chunks']}")
        print(f"   Types: {result['metadata']['chunk_types']}")
        print(f"   Time: {result['metadata']['processing_time_seconds']}s")
        print(f"   Provider: {result['metadata']['vlm_provider']}")
    else:
        print(f"âš ï¸  Test PDF not found: {test_pdf}")
        print(f"   Please place a PDF file at: {test_pdf.absolute()}")