"""
core/quick_layout_analyzer.py
PRISM Phase 5.3.0 - Quick Layout Analyzer

ëª©ì : OpenCVë¡œ 0.5ì´ˆ ì´ë‚´ì— ë¬¸ì„œ êµ¬ì¡° íŒíŠ¸ ì œê³µ
GPT ì œì•ˆ ë°˜ì˜: MVP ë²„ì „ - has_numbersì™€ diagram_count ìš°ì„  êµ¬í˜„
"""

import cv2
import numpy as np
from PIL import Image
import base64
import io
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)


class QuickLayoutAnalyzer:
    """
    ê²½ëŸ‰ CV ê¸°ë°˜ ë ˆì´ì•„ì›ƒ íŒíŠ¸ ìƒì„±ê¸°
    
    Phase 5.3.0 MVP ì „ëµ:
    - has_numbersì™€ diagram_count ìš°ì„  ì •í™•ë„ (GPT ì œì•ˆ)
    - ë‚˜ë¨¸ì§€ëŠ” ë³´ìˆ˜ì  ì¶”ì • (False Positive ìµœì†Œí™”)
    - 0.5ì´ˆ ì´ë‚´ ì²˜ë¦¬ ëª©í‘œ
    """
    
    def __init__(self):
        self.min_text_area = 1000
        self.min_diagram_area = 5000
        self.max_diagram_area = 100000
        
        # Tesseract ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
        self.tesseract_available = self._check_tesseract()
        
        logger.info(f"âœ… QuickLayoutAnalyzer ì´ˆê¸°í™” (Tesseract: {'ì‚¬ìš© ê°€ëŠ¥' if self.tesseract_available else 'ë¯¸ì„¤ì¹˜'})")
    
    def _check_tesseract(self) -> bool:
        """Tesseract ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            import pytesseract
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            pytesseract.get_tesseract_version()
            return True
        except:
            logger.warning("âš ï¸ Tesseract ë¯¸ì„¤ì¹˜ - ìˆ«ì ê²€ì¶œ ê¸°ëŠ¥ ì œí•œ")
            return False
    
    def analyze(self, image_data: str) -> Dict:
        """
        ë¹ ë¥¸ ë ˆì´ì•„ì›ƒ ë¶„ì„
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            
        Returns:
            hints: {
                'has_text': bool,
                'has_table': bool,
                'has_map': bool,
                'diagram_count': int,  # MVP ìš°ì„ 
                'has_numbers': bool,   # MVP ìš°ì„ 
                'layout_complexity': str
            }
        """
        logger.info("ğŸ” Quick CV ë¶„ì„ ì‹œì‘ (Phase 5.3.0 MVP)")
        
        try:
            # Base64 â†’ numpy array
            image = self._decode_image(image_data)
            
            # MVP ìš°ì„ : has_numbersì™€ diagram_count
            hints = {
                'has_numbers': self._detect_numbers(image),
                'diagram_count': self._count_diagrams(image),
                'has_text': self._detect_text_regions(image),
                'has_table': self._detect_tables(image),
                'has_map': self._detect_map(image),
                'layout_complexity': self._assess_complexity(image)
            }
            
            logger.info(f"âœ… CV ë¶„ì„ ì™„ë£Œ: numbers={hints['has_numbers']}, diagrams={hints['diagram_count']}")
            return hints
            
        except Exception as e:
            logger.error(f"âŒ CV ë¶„ì„ ì‹¤íŒ¨: {e}")
            # Fallback: ì•ˆì „í•œ ê¸°ë³¸ê°’
            return {
                'has_text': True,
                'has_table': False,
                'has_map': False,
                'diagram_count': 0,
                'has_numbers': True,  # ë³´ìˆ˜ì ìœ¼ë¡œ True
                'layout_complexity': 'medium'
            }
    
    def _decode_image(self, image_data: str) -> np.ndarray:
        """Base64 â†’ OpenCV ì´ë¯¸ì§€"""
        try:
            # Base64 ë””ì½”ë”©
            img_bytes = base64.b64decode(image_data)
            img = Image.open(io.BytesIO(img_bytes))
            
            # PIL â†’ OpenCV (RGB â†’ BGR)
            return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            raise
    
    def _detect_numbers(self, image: np.ndarray) -> bool:
        """
        ìˆ«ì ë°€ì§‘ ì˜ì—­ ê²€ì¶œ (MVP ìš°ì„  - GPT ì œì•ˆ)
        
        ì›ë¦¬:
        1. Tesseractë¡œ ìˆ«ì ìŠ¤ìº” (ê°€ëŠ¥ ì‹œ)
        2. íŒ¨í„´ ë§¤ì¹­ (ì‹œê°„, ê¸ˆì•¡ ë“±)
        """
        if not self.tesseract_available:
            # Tesseract ì—†ìœ¼ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ True (VLMì´ íŒë‹¨)
            logger.debug("   Tesseract ì—†ìŒ â†’ ìˆ«ì ê²€ì¶œ True (ê¸°ë³¸ê°’)")
            return True
        
        try:
            import pytesseract
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ìˆ«ì ì¸ì‹ í–¥ìƒ)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
            
            # ìˆ«ì + ì½œë¡  + ë‹¨ìœ„ë§Œ ì¸ì‹ (GPT ì œì•ˆ: kor+eng)
            try:
                text = pytesseract.image_to_string(
                    binary,
                    lang='kor+eng',  # í•œê¸€ + ì˜ë¬¸
                    config='--psm 6 -c tessedit_char_whitelist=0123456789:ë¶„ì›%ëª…ëŒ€ì´ˆì‹œê°„'
                )
            except Exception as e:
                # kor+eng ì‹¤íŒ¨ ì‹œ engë¡œ Fallback
                logger.warning(f"   Tesseract kor+eng ì‹¤íŒ¨, engë¡œ Fallback: {e}")
                text = pytesseract.image_to_string(
                    binary,
                    lang='eng',
                    config='--psm 6 -c tessedit_char_whitelist=0123456789:ë¶„ì›%ëª…ëŒ€ì´ˆì‹œê°„'
                )
            
            # ì‹œê°„ íŒ¨í„´ (XX:XX)
            colon_count = text.count(':')
            
            # ë‹¨ìœ„ íŒ¨í„´
            units = ['ë¶„', 'ì›', '%', 'ëª…', 'ëŒ€', 'ì´ˆ']
            unit_count = sum(text.count(u) for u in units)
            
            has_numbers = colon_count >= 2 or unit_count >= 3
            
            logger.debug(f"   ìˆ«ì ê²€ì¶œ: {has_numbers} (ì½œë¡ : {colon_count}, ë‹¨ìœ„: {unit_count})")
            return has_numbers
            
        except Exception as e:
            logger.warning(f"   Tesseract ì‹¤íŒ¨: {e}")
            return True  # ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ True
    
    def _count_diagrams(self, image: np.ndarray) -> int:
        """
        ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì¶”ì • (MVP ìš°ì„  - GPT ì œì•ˆ)
        
        ì›ë¦¬: ë‹«íŒ ì¤‘ê°„ í¬ê¸° ì˜ì—­ ì¹´ìš´íŠ¸
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Edge ê²€ì¶œ
        edges = cv2.Canny(gray, 50, 150)
        
        # ë‹«íŒ ì˜ì—­ ê°•ì¡°
        kernel = np.ones((5, 5), np.uint8)
        closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)
        
        # Contour ì°¾ê¸°
        contours, _ = cv2.findContours(
            closed,
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        # ì ì ˆí•œ í¬ê¸° ì˜ì—­ ì¹´ìš´íŠ¸
        diagram_count = 0
        for contour in contours:
            area = cv2.contourArea(contour)
            
            if self.min_diagram_area < area < self.max_diagram_area:
                # ì¢…íš¡ë¹„ ì²´í¬ (ë„ˆë¬´ ê¸¸ì­‰í•˜ë©´ ì œì™¸)
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h if h > 0 else 0
                
                if 0.3 < aspect_ratio < 3.0:
                    diagram_count += 1
        
        # ìµœëŒ€ 5ê°œë¡œ ì œí•œ (ê³¼ë‹¤ ê²€ì¶œ ë°©ì§€ - GPT ì œì•ˆ)
        diagram_count = min(diagram_count, 5)
        
        logger.debug(f"   ë‹¤ì´ì–´ê·¸ë¨ ê²€ì¶œ: {diagram_count}ê°œ")
        return diagram_count
    
    def _detect_text_regions(self, image: np.ndarray) -> bool:
        """
        í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ
        
        ì›ë¦¬: í…ìŠ¤íŠ¸ëŠ” ìˆ˜í‰ì„ ì´ ë§ìŒ
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ìˆ˜í‰ì„  ê²€ì¶œ
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        detect_horizontal = cv2.morphologyEx(
            gray,
            cv2.MORPH_OPEN,
            horizontal_kernel,
            iterations=2
        )
        
        # í°ìƒ‰ í”½ì…€ ë¹„ìœ¨
        white_ratio = np.sum(detect_horizontal > 200) / detect_horizontal.size
        
        has_text = white_ratio > 0.01
        logger.debug(f"   í…ìŠ¤íŠ¸ ê²€ì¶œ: {has_text} (ë¹„ìœ¨: {white_ratio:.3f})")
        return has_text
    
    def _detect_tables(self, image: np.ndarray) -> bool:
        """
        í‘œ ê²€ì¶œ (ê²©ì íŒ¨í„´)
        
        ì›ë¦¬: í‘œëŠ” ìˆ˜í‰ì„  + ìˆ˜ì§ì„  êµì°¨
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        
        # ìˆ˜í‰ì„  ê²€ì¶œ
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        h_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        # ìˆ˜ì§ì„  ê²€ì¶œ
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        v_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
        
        # êµì°¨ì  = í‘œ
        intersections = cv2.bitwise_and(h_lines, v_lines)
        intersection_count = np.sum(intersections > 0)
        
        has_table = intersection_count > 50
        logger.debug(f"   í‘œ ê²€ì¶œ: {has_table} (êµì°¨ì : {intersection_count})")
        return has_table
    
    def _detect_map(self, image: np.ndarray) -> bool:
        """
        ì§€ë„ ê²€ì¶œ
        
        ì›ë¦¬: ë³µì¡í•œ ê³¡ì„  + ìƒ‰ìƒ ë‹¤ì–‘ì„±
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Contour ê²€ì¶œ
        edges = cv2.Canny(gray, 30, 100)
        contours, _ = cv2.findContours(
            edges,
            cv2.RETR_TREE,
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        # ë³µì¡í•œ ê³¡ì„  contour ê°œìˆ˜
        curved_contours = 0
        for contour in contours:
            area = cv2.contourArea(contour)
            
            if area > 1000:  # ì¶©ë¶„íˆ í° ì˜ì—­
                arc_length = cv2.arcLength(contour, True)
                epsilon = 0.01 * arc_length
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # ë³µì¡í•œ í˜•ìƒ (10ê°œ ì´ìƒ ê¼­ì§€ì )
                if len(approx) > 10:
                    curved_contours += 1
        
        # ìƒ‰ìƒ ë‹¤ì–‘ì„± ì²´í¬
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        unique_hues = len(np.unique(hsv[:, :, 0]))
        
        # GPT ì œì•ˆ: ë³´ìˆ˜ì  ê¸°ì¤€ (False Positive ìµœì†Œí™”)
        has_map = curved_contours > 5 and unique_hues > 30
        
        logger.debug(f"   ì§€ë„ ê²€ì¶œ: {has_map} (ê³¡ì„ : {curved_contours}, ìƒ‰ìƒ: {unique_hues})")
        return has_map
    
    def _assess_complexity(self, image: np.ndarray) -> str:
        """
        ë ˆì´ì•„ì›ƒ ë³µì¡ë„ í‰ê°€
        
        Returns:
            'simple': í…ìŠ¤íŠ¸ë§Œ ë˜ëŠ” ë‹¨ìˆœ í‘œ
            'medium': í…ìŠ¤íŠ¸ + í‘œ/ì°¨íŠ¸
            'complex': ì§€ë„ + ë‹¤ì´ì–´ê·¸ë¨ + í…ìŠ¤íŠ¸
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # Edge ë°€ë„
        edge_density = np.sum(edges > 0) / edges.size
        
        # Contour ë³µì¡ë„
        contours, _ = cv2.findContours(
            edges,
            cv2.RETR_TREE,
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        if edge_density < 0.05 and len(contours) < 100:
            complexity = 'simple'
        elif edge_density < 0.15 and len(contours) < 500:
            complexity = 'medium'
        else:
            complexity = 'complex'
        
        logger.debug(f"   ë³µì¡ë„: {complexity} (edge: {edge_density:.3f}, contours: {len(contours)})")
        return complexity
