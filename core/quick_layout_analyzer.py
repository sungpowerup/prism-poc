"""
core/quick_layout_analyzer.py
PRISM Phase 5.3.1 - Quick Layout Analyzer (ê¸´ê¸‰ íŒ¨ì¹˜)

âœ… Phase 5.3.1 ìˆ˜ì •:
1. Canny threshold ì™„í™” (50/150 â†’ 30/100)
2. Tesseract í‘œ í‚¤ì›Œë“œ ê²€ì¶œ ì¶”ê°€ (2ë‹¨ ê²€ì¦)
3. í‘œ ê²€ì¶œ ë¯¼ê°ë„ í–¥ìƒ

Author: ë°•ì¤€í˜¸ (AI/ML Lead) + GPT ì œì•ˆ ë°˜ì˜
Date: 2025-10-27
Version: 5.3.1
"""

import cv2
import numpy as np
import logging
import base64
from typing import Dict, Any

logger = logging.getLogger(__name__)

# Tesseract ì„ íƒì  import
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    logger.warning("âš ï¸ pytesseract ì—†ìŒ - í‘œ í‚¤ì›Œë“œ ê²€ì¶œ ë¹„í™œì„±í™”")


class QuickLayoutAnalyzer:
    """
    Phase 5.3.1 OpenCV ê¸°ë°˜ ë¹ ë¥¸ ë ˆì´ì•„ì›ƒ ë¶„ì„ê¸°
    
    GPT ì œì•ˆ ë°˜ì˜:
    - Canny threshold ì™„í™”ë¡œ íë¦¿í•œ ì„  ê²€ì¶œ
    - Tesseractë¡œ í‘œ í‚¤ì›Œë“œ ë³´ì¡° ê²€ì¶œ (2ë‹¨ ê²€ì¦)
    
    ëª©ì :
    - VLM í˜¸ì¶œ ì „ 0.5ì´ˆ ì´ë‚´ êµ¬ì¡° íŒíŠ¸ ìƒì„±
    - í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ê²€ì¦ ê¸°ì¤€ ì œê³µ
    
    íŒíŠ¸:
    - has_text: í…ìŠ¤íŠ¸ ì˜ì—­ ì¡´ì¬
    - has_map: ì§€ë„/ë…¸ì„ ë„ ì¡´ì¬
    - has_table: í‘œ ì¡´ì¬
    - has_numbers: ìˆ«ì ë°ì´í„° ì¡´ì¬
    - diagram_count: ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.tesseract_available = TESSERACT_AVAILABLE
        logger.info("âœ… QuickLayoutAnalyzer v5.3.1 ì´ˆê¸°í™” ì™„ë£Œ")
        if self.tesseract_available:
            logger.info("   ğŸ“Š Tesseract í‘œ í‚¤ì›Œë“œ ê²€ì¶œ í™œì„±í™”")
    
    def analyze(self, image_data: str) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ êµ¬ì¡° ë¶„ì„ (0.5ì´ˆ ì´ë‚´)
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
        
        Returns:
            {
                'has_text': bool,
                'has_map': bool,
                'has_table': bool,
                'has_numbers': bool,
                'diagram_count': int
            }
        """
        logger.info("   ğŸ” QuickLayoutAnalyzer ì‹œì‘")
        
        # Base64 â†’ OpenCV ì´ë¯¸ì§€
        image = self._base64_to_cv2(image_data)
        
        # êµ¬ì¡° ê°ì§€
        hints = {
            'has_text': self._detect_text(image),
            'has_map': self._detect_map(image),
            'has_table': self._detect_tables(image, image_data),  # âœ… image_data ì¶”ê°€
            'has_numbers': self._detect_numbers(image),
            'diagram_count': self._count_diagrams(image)
        }
        
        logger.info(f"   âœ… íŒíŠ¸: {hints}")
        return hints
    
    def _base64_to_cv2(self, image_data: str) -> np.ndarray:
        """Base64 â†’ OpenCV ì´ë¯¸ì§€ ë³€í™˜"""
        img_bytes = base64.b64decode(image_data)
        np_arr = np.frombuffer(img_bytes, np.uint8)
        image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        return image
    
    def _detect_text(self, image: np.ndarray) -> bool:
        """
        í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ
        
        ì „ëµ: ê°€ë¡œ ì„ ì´ ë§ìœ¼ë©´ í…ìŠ¤íŠ¸
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # ê°€ë¡œ ì„  ê²€ì¶œ
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        # ê°€ë¡œ ì„  í”½ì…€ ë¹„ìœ¨
        h_ratio = np.sum(horizontal_lines > 0) / horizontal_lines.size
        
        has_text = h_ratio > 0.01
        logger.debug(f"      í…ìŠ¤íŠ¸ ì˜ì—­: {has_text} (ê°€ë¡œì„  ë¹„ìœ¨: {h_ratio:.4f})")
        return has_text
    
    def _detect_map(self, image: np.ndarray) -> bool:
        """
        ì§€ë„/ë…¸ì„ ë„ ê²€ì¶œ
        
        ì „ëµ: ìƒ‰ìƒ ë‹¤ì–‘ì„± + ê³¡ì„ 
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ìƒ‰ìƒ ë‹¤ì–‘ì„± (í‘œì¤€í¸ì°¨)
        std_dev = np.std(gray)
        
        # ê³¡ì„  ê²€ì¶œ (Canny + Contour)
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # í° ì»¨íˆ¬ì–´ ê°œìˆ˜
        large_contours = sum(1 for c in contours if cv2.contourArea(c) > 1000)
        
        has_map = std_dev > 40 and large_contours > 5
        logger.debug(f"      ì§€ë„/ë…¸ì„ ë„: {has_map} (í¸ì°¨: {std_dev:.1f}, ì»¨íˆ¬ì–´: {large_contours})")
        return has_map
    
    def _detect_tables(self, image: np.ndarray, image_data: str = None) -> bool:
        """
        âœ… Phase 5.3.1: í‘œ ê²€ì¶œ ê°•í™” (GPT ì œì•ˆ)
        
        ì „ëµ:
        1. OpenCV Canny threshold ì™„í™” (30/100)
        2. Tesseract í‘œ í‚¤ì›Œë“œ ë³´ì¡° ê²€ì¶œ (2ë‹¨ ê²€ì¦)
        
        Args:
            image: OpenCV ì´ë¯¸ì§€
            image_data: Base64 ì´ë¯¸ì§€ (Tesseractìš©, ì„ íƒ)
        
        Returns:
            í‘œ ì¡´ì¬ ì—¬ë¶€
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # âœ… 1. Canny threshold ì™„í™” (íë¦¿í•œ ì„  ê²€ì¶œ)
        edges = cv2.Canny(gray, 30, 100)  # ê¸°ì¡´: 50, 150
        
        # ê°€ë¡œì„  ê²€ì¶œ
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        # ì„¸ë¡œì„  ê²€ì¶œ
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
        
        # êµì°¨ì  ê²€ì¶œ
        intersections = cv2.bitwise_and(horizontal_lines, vertical_lines)
        intersections_sum = np.sum(intersections > 0)
        
        # OpenCV ê¸°ë°˜ í‘œ ê²€ì¶œ
        has_table_cv = intersections_sum > 50
        
        # âœ… 2. Tesseract í‘œ í‚¤ì›Œë“œ ê²€ì¶œ (ë³´ì¡°)
        has_table_text = False
        if self.tesseract_available and image_data:
            try:
                # OCR ì‹¤í–‰
                text = pytesseract.image_to_string(gray, lang='kor+eng')
                
                # í‘œ í‚¤ì›Œë“œ ê²€ì‚¬
                table_keywords = ['ë‹¨ìœ„', 'ì‚¬ë¡€ìˆ˜', 'ë¹„ìœ¨', 'í•©ê³„', '%', 'ëª…', 'ì›', 'ê°œ']
                for keyword in table_keywords:
                    if keyword in text:
                        has_table_text = True
                        logger.debug(f"      Tesseract í‘œ í‚¤ì›Œë“œ ê°ì§€: '{keyword}'")
                        break
            
            except Exception as e:
                logger.debug(f"      Tesseract OCR ì‹¤íŒ¨: {e}")
        
        # 2ë‹¨ ê²€ì¦: OpenCV ë˜ëŠ” Tesseract ì¤‘ í•˜ë‚˜ë¼ë„ í†µê³¼
        has_table = has_table_cv or has_table_text
        
        logger.debug(
            f"      í‘œ ê²€ì¶œ: {has_table} "
            f"(CV êµì°¨ì : {intersections_sum}, "
            f"Tesseract í‚¤ì›Œë“œ: {has_table_text})"
        )
        return has_table
    
    def _detect_numbers(self, image: np.ndarray) -> bool:
        """
        ìˆ«ì ë°ì´í„° ê²€ì¶œ
        
        ì „ëµ: ì‘ì€ í…ìŠ¤íŠ¸ ë°•ìŠ¤ê°€ ë§ìœ¼ë©´ ìˆ«ì
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # ì»¨íˆ¬ì–´ ê²€ì¶œ
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ì‘ì€ ë°•ìŠ¤ (ìˆ«ì) ê°œìˆ˜
        small_boxes = sum(1 for c in contours if 10 < cv2.contourArea(c) < 500)
        
        has_numbers = small_boxes > 20
        logger.debug(f"      ìˆ«ì ë°ì´í„°: {has_numbers} (ì‘ì€ ë°•ìŠ¤: {small_boxes})")
        return has_numbers
    
    def _count_diagrams(self, image: np.ndarray) -> int:
        """
        ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì¶”ì •
        
        ì „ëµ: í° ì—°ê²° ì˜ì—­ ê°œìˆ˜
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # ì»¨íˆ¬ì–´ ê²€ì¶œ
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # í° ì˜ì—­ë§Œ ì¹´ìš´íŠ¸ (ë©´ì  > 5000)
        large_regions = sum(1 for c in contours if cv2.contourArea(c) > 5000)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì¶”ì • (ìµœëŒ€ 5ê°œ)
        diagram_count = min(5, large_regions)
        
        logger.debug(f"      ë‹¤ì´ì–´ê·¸ë¨: {diagram_count}ê°œ (í° ì˜ì—­: {large_regions})")
        return diagram_count


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python quick_layout_analyzer.py <base64_image>")
        sys.exit(1)
    
    analyzer = QuickLayoutAnalyzer()
    image_data = sys.argv[1]
    
    hints = analyzer.analyze(image_data)
    
    print("=== QuickLayoutAnalyzer ê²°ê³¼ ===")
    for key, value in hints.items():
        print(f"{key}: {value}")