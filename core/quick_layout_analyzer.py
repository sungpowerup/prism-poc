"""
core/quick_layout_analyzer.py
PRISM Phase 5.5.1 - Quick Layout Analyzer (Hotfix)

âœ… Phase 5.5.1 í•«í”½ìŠ¤ (GPT ë³´ê°• ë°˜ì˜):
- êµì°¨ì  ê³„ì‚° ë³´ìˆ˜í™” (ì ì‘ ì´ì§„í™” + ê°€ëŠ” ì„  ì œê±°)
- ìµœì†Œ ì„  ê¸¸ì´ í•„í„°ë§ (40px)
- í‘œ ì‹ ë¢°ë„ ì •í™•ë„ í–¥ìƒ

(Phase 5.5.0 ê¸°ëŠ¥ ìœ ì§€)
- OCR í…ìŠ¤íŠ¸ ë°˜í™˜
- ì¡°í•­ í† í° ë¹„ìœ¨ ê³„ì‚°
- ë²ˆí˜¸ ëª©ë¡ ë°€ë„ ê³„ì‚°
- ë²„ìŠ¤ í‚¤ì›Œë“œ ê²€ì¶œ

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-27
Version: 5.5.1
"""

import cv2
import numpy as np
import logging
import base64
import re
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

# Tesseract ì„ íƒì  import
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    logger.warning("âš ï¸ pytesseract ì—†ìŒ - OCR ê¸°ëŠ¥ ë¹„í™œì„±í™”")


class QuickLayoutAnalyzer:
    """
    Phase 5.5.1 OpenCV + OCR ê¸°ë°˜ ë¹ ë¥¸ ë ˆì´ì•„ì›ƒ ë¶„ì„ê¸° (Hotfix)
    
    ê°œì„ :
    - êµì°¨ì  ê³„ì‚° ë³´ìˆ˜í™” (ì ì‘ ì´ì§„í™” + morphology)
    - ê°€ëŠ” ì„  ì œê±° (ì¡°í•­ ë²ˆí˜¸/êµ¬ë¶„ì„  í•„í„°ë§)
    - ìµœì†Œ ì„  ê¸¸ì´ í•„í„°ë§
    
    ëª©ì :
    - VLM í˜¸ì¶œ ì „ 0.5ì´ˆ ì´ë‚´ êµ¬ì¡° íŒíŠ¸ ìƒì„±
    - í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ê²€ì¦ ê¸°ì¤€ ì œê³µ
    - í‘œ ê³¼ê²€ì¶œ ë°©ì§€ (ë³´ìˆ˜ì  ê³„ì‚°)
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.tesseract_available = TESSERACT_AVAILABLE
        logger.info("âœ… QuickLayoutAnalyzer v5.5.1 ì´ˆê¸°í™” ì™„ë£Œ (Hotfix)")
        if self.tesseract_available:
            logger.info("   ğŸ“Š Tesseract OCR í™œì„±í™” (í‘œ + ë²„ìŠ¤ + ê·œì • í‚¤ì›Œë“œ)")
        else:
            logger.warning("   âš ï¸ Tesseract OCR ë¹„í™œì„±í™” (ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ)")
    
    def analyze(self, image_data: str) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ êµ¬ì¡° ë¶„ì„ (0.5ì´ˆ ì´ë‚´)
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
        
        Returns:
            {
                'has_text': bool,
                'has_map': bool,
                'has_table': bool,
                'has_numbers': bool,
                'diagram_count': int,
                'grid_intersections': int,
                'h_v_line_density': float,
                'ocr_text': str,
                'article_token_ratio': float,
                'numbered_list_density': float,
                'bus_keywords': List[str]
            }
        """
        logger.info("   ğŸ” QuickLayoutAnalyzer v5.5.1 ì‹œì‘ (Hotfix)")
        
        # Base64 â†’ OpenCV ì´ë¯¸ì§€
        image = self._base64_to_cv2(image_data)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•µì‹¬!)
        ocr_text = self._extract_ocr_text(gray) if self.tesseract_available else ""
        
        # êµ¬ì¡° ê°ì§€
        hints = {
            'has_text': self._detect_text(image),
            'has_map': self._detect_map(image),
            'has_table': self._detect_tables(image, image_data),
            'has_numbers': self._detect_numbers(image),
            'diagram_count': self._count_diagrams(image),
            
            # âœ… Phase 5.5.1: ë³´ìˆ˜ì  í‘œ ì‹ ë¢°ë„ ê³„ì‚°ìš© í•„ë“œ
            'grid_intersections': self._count_grid_intersections_conservative(gray),
            'h_v_line_density': self._calculate_line_density_conservative(gray),
            
            # Phase 5.5.0: OCR ê¸°ë°˜ í•„ë“œ
            'ocr_text': ocr_text[:500],  # ì§§ê²Œ (500ì)
            'article_token_ratio': self._calculate_article_ratio(ocr_text),
            'numbered_list_density': self._calculate_numbered_density(ocr_text),
            
            # Phase 5.4.0: ë²„ìŠ¤ í‚¤ì›Œë“œ
            'bus_keywords': self._detect_bus_keywords(ocr_text)
        }
        
        logger.info(f"   âœ… íŒíŠ¸ ìƒì„± ì™„ë£Œ:")
        logger.info(f"      - í…ìŠ¤íŠ¸: {hints['has_text']}, ì§€ë„: {hints['has_map']}, í‘œ: {hints['has_table']}")
        logger.info(f"      - êµì°¨ì : {hints['grid_intersections']}, ì„ ë°€ë„: {hints['h_v_line_density']:.6f}")
        logger.info(f"      - ì¡°í•­ë¹„ìœ¨: {hints['article_token_ratio']:.2f}, ë²ˆí˜¸ë°€ë„: {hints['numbered_list_density']:.2f}")
        if hints['bus_keywords']:
            logger.info(f"      - ë²„ìŠ¤ í‚¤ì›Œë“œ: {hints['bus_keywords']}")
        
        return hints
    
    def _base64_to_cv2(self, image_data: str) -> np.ndarray:
        """Base64 â†’ OpenCV ì´ë¯¸ì§€ ë³€í™˜"""
        img_bytes = base64.b64decode(image_data)
        np_arr = np.frombuffer(img_bytes, np.uint8)
        image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        return image
    
    def _extract_ocr_text(self, gray: np.ndarray) -> str:
        """
        OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            gray: Grayscale ì´ë¯¸ì§€
        
        Returns:
            OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ (ìµœëŒ€ 1000ì)
        """
        if not self.tesseract_available:
            return ""
        
        try:
            # Tesseract ì‹¤í–‰ (í•œê¸€ + ì˜ì–´)
            text = pytesseract.image_to_string(gray, lang='kor+eng')
            
            # ê³µë°± ì •ë¦¬
            text = re.sub(r'\s+', ' ', text).strip()
            
            logger.debug(f"      OCR í…ìŠ¤íŠ¸: {len(text)}ì ì¶”ì¶œ")
            return text[:1000]  # ìµœëŒ€ 1000ì
        
        except Exception as e:
            logger.debug(f"      OCR ì‹¤íŒ¨: {e}")
            return ""
    
    def _calculate_article_ratio(self, ocr_text: str) -> float:
        """
        ì¡°í•­ í† í° ë¹„ìœ¨ ê³„ì‚°
        
        ëª©ì : ê·œì •/ë²•ë ¹ ë¬¸ì„œ ê°ì§€ + í‘œ ê³¼ê²€ì¶œ ë°©ì§€
        
        Args:
            ocr_text: OCR í…ìŠ¤íŠ¸
        
        Returns:
            ì¡°í•­ í† í° ë¹„ìœ¨ (0.0 ~ 1.0)
        """
        if not ocr_text:
            return 0.0
        
        # ì¡°í•­ íŒ¨í„´ ê²€ìƒ‰
        patterns = [
            r'ì œ\s?\d+ì¡°',
            r'ì œ\s?\d+í•­',
            r'ì œ\s?\d+í˜¸',
            r'\(\d+\)',
            r'â‘ |â‘¡|â‘¢|â‘£|â‘¤|â‘¥|â‘¦|â‘§|â‘¨|â‘©',
            r'^\d+\.',
        ]
        
        # ë§¤ì¹­ëœ í† í° ê°œìˆ˜
        matches = sum(len(re.findall(p, ocr_text, re.MULTILINE)) for p in patterns)
        
        # ì „ì²´ í† í° ê°œìˆ˜ (ê³µë°± ê¸°ì¤€)
        total_tokens = len(ocr_text.split())
        
        if total_tokens == 0:
            return 0.0
        
        # ë¹„ìœ¨ ê³„ì‚° (0.0 ~ 1.0)
        ratio = min(1.0, matches / max(1, total_tokens))
        
        logger.debug(f"      ì¡°í•­ í† í°: {matches}/{total_tokens} = {ratio:.2f}")
        return ratio
    
    def _calculate_numbered_density(self, ocr_text: str) -> float:
        """
        ë²ˆí˜¸ ëª©ë¡ ë°€ë„ ê³„ì‚°
        
        ëª©ì : ê·œì •/ë²•ë ¹ ë¬¸ì„œ ê°ì§€ + í‘œ ê³¼ê²€ì¶œ ë°©ì§€
        
        Args:
            ocr_text: OCR í…ìŠ¤íŠ¸
        
        Returns:
            ë²ˆí˜¸ ëª©ë¡ ë°€ë„ (0.0 ~ 1.0)
        """
        if not ocr_text:
            return 0.0
        
        lines = ocr_text.split('\n')
        if len(lines) == 0:
            return 0.0
        
        # ë²ˆí˜¸ ëª©ë¡ íŒ¨í„´ (ì¤„ ì‹œì‘)
        patterns = [
            r'^\s*\d+\.',
            r'^\s*\d+\)',
            r'^\s*[â‘ -â‘³]',
            r'^\s*\(\d+\)',
        ]
        
        # ë§¤ì¹­ëœ ì¤„ ê°œìˆ˜
        numbered_lines = sum(
            1 for line in lines
            if any(re.match(p, line) for p in patterns)
        )
        
        # ë°€ë„ ê³„ì‚°
        density = numbered_lines / max(1, len(lines))
        
        logger.debug(f"      ë²ˆí˜¸ ëª©ë¡: {numbered_lines}/{len(lines)} ì¤„ = {density:.2f}")
        return density
    
    def _count_grid_intersections_conservative(self, gray: np.ndarray) -> int:
        """
        âœ… Phase 5.5.1: ë³´ìˆ˜ì  ê²©ì êµì°¨ì  ê³„ì‚°
        
        ê°œì„ :
        - ì ì‘ ì´ì§„í™” (Adaptive Threshold)
        - morphology openìœ¼ë¡œ ê°€ëŠ” ì„  ì œê±°
        - ìµœì†Œ ì„  ê¸¸ì´ í•„í„°ë§ (40px)
        
        Args:
            gray: Grayscale ì´ë¯¸ì§€
        
        Returns:
            êµì°¨ì  ê°œìˆ˜ (ë³´ìˆ˜ì )
        """
        # âœ… 1ë‹¨ê³„: ì ì‘ ì´ì§„í™”
        # - ì¡°ëª… ë³€í™”ì— ê°•í•¨
        # - ê°€ëŠ” ì„  (ì¡°í•­ ë²ˆí˜¸) ì œê±° íš¨ê³¼
        binary = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV,
            11, 2
        )
        
        # âœ… 2ë‹¨ê³„: Canny ì—£ì§€ ê²€ì¶œ
        edges = cv2.Canny(binary, 30, 100)
        
        # âœ… 3ë‹¨ê³„: ê°€ë¡œì„  ê²€ì¶œ (ìµœì†Œ ê¸¸ì´ 40px)
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        # morphology openìœ¼ë¡œ ê°€ëŠ” ì„  ì œê±°
        horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_OPEN, np.ones((1, 3), np.uint8))
        
        # âœ… 4ë‹¨ê³„: ì„¸ë¡œì„  ê²€ì¶œ (ìµœì†Œ ê¸¸ì´ 40px)
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
        
        # morphology openìœ¼ë¡œ ê°€ëŠ” ì„  ì œê±°
        vertical_lines = cv2.morphologyEx(vertical_lines, cv2.MORPH_OPEN, np.ones((3, 1), np.uint8))
        
        # âœ… 5ë‹¨ê³„: êµì°¨ì  ê²€ì¶œ (ë³´ìˆ˜ì )
        intersections = cv2.bitwise_and(horizontal_lines, vertical_lines)
        
        # âœ… 6ë‹¨ê³„: ì‘ì€ ë…¸ì´ì¦ˆ ì œê±° (5x5 ì»¤ë„)
        kernel_denoise = np.ones((5, 5), np.uint8)
        intersections = cv2.morphologyEx(intersections, cv2.MORPH_OPEN, kernel_denoise)
        
        intersections_count = np.sum(intersections > 0)
        
        logger.debug(f"      ê²©ì êµì°¨ì (ë³´ìˆ˜ì ): {intersections_count}ê°œ")
        return int(intersections_count)
    
    def _calculate_line_density_conservative(self, gray: np.ndarray) -> float:
        """
        âœ… Phase 5.5.1: ë³´ìˆ˜ì  ê°€ë¡œ/ì„¸ë¡œì„  ë°€ë„ ê³„ì‚°
        
        ê°œì„ :
        - ì ì‘ ì´ì§„í™”
        - morphology openìœ¼ë¡œ ê°€ëŠ” ì„  ì œê±°
        - ìµœì†Œ ì„  ê¸¸ì´ í•„í„°ë§
        
        Args:
            gray: Grayscale ì´ë¯¸ì§€
        
        Returns:
            ì„  ë°€ë„ (0.0 ~ 1.0, ë³´ìˆ˜ì )
        """
        # âœ… 1ë‹¨ê³„: ì ì‘ ì´ì§„í™”
        binary = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV,
            11, 2
        )
        
        # âœ… 2ë‹¨ê³„: Canny ì—£ì§€ ê²€ì¶œ
        edges = cv2.Canny(binary, 30, 100)
        
        # âœ… 3ë‹¨ê³„: ê°€ë¡œì„  ê²€ì¶œ (ìµœì†Œ 40px)
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_OPEN, np.ones((1, 3), np.uint8))
        
        # âœ… 4ë‹¨ê³„: ì„¸ë¡œì„  ê²€ì¶œ (ìµœì†Œ 40px)
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
        vertical_lines = cv2.morphologyEx(vertical_lines, cv2.MORPH_OPEN, np.ones((3, 1), np.uint8))
        
        # âœ… 5ë‹¨ê³„: ì„  í”½ì…€ í•©ê³„
        h_pixels = np.sum(horizontal_lines > 0)
        v_pixels = np.sum(vertical_lines > 0)
        
        # ì „ì²´ í”½ì…€
        total_pixels = gray.shape[0] * gray.shape[1]
        
        # ë°€ë„ ê³„ì‚° (ë³´ìˆ˜ì )
        density = (h_pixels + v_pixels) / max(1, total_pixels)
        
        logger.debug(f"      ì„  ë°€ë„(ë³´ìˆ˜ì ): {density:.6f}")
        return float(density)
    
    def _detect_text(self, image: np.ndarray) -> bool:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        h_ratio = np.sum(horizontal_lines > 0) / horizontal_lines.size
        has_text = h_ratio > 0.01
        logger.debug(f"      í…ìŠ¤íŠ¸ ì˜ì—­: {has_text} (ê°€ë¡œì„  ë¹„ìœ¨: {h_ratio:.4f})")
        return has_text
    
    def _detect_map(self, image: np.ndarray) -> bool:
        """ì§€ë„/ë…¸ì„ ë„ ê²€ì¶œ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        std_dev = np.std(gray)
        
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        large_contours = sum(1 for c in contours if cv2.contourArea(c) > 1000)
        
        total_area = image.shape[0] * image.shape[1]
        contour_area = sum(cv2.contourArea(c) for c in contours if cv2.contourArea(c) > 1000)
        area_ratio = contour_area / total_area if total_area > 0 else 0
        
        has_map = std_dev > 60 and large_contours > 10 and area_ratio > 0.3
        
        logger.debug(
            f"      ì§€ë„/ë…¸ì„ ë„: {has_map} "
            f"(í¸ì°¨: {std_dev:.1f}, ì»¨íˆ¬ì–´: {large_contours}, ë©´ì ë¹„: {area_ratio:.2%})"
        )
        return has_map
    
    def _detect_tables(self, image: np.ndarray, image_data: str = None) -> bool:
        """í‘œ ê²€ì¶œ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 30, 100)
        
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
        
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
        
        intersections = cv2.bitwise_and(horizontal_lines, vertical_lines)
        intersections_sum = np.sum(intersections > 0)
        
        has_table_cv = intersections_sum > 50
        
        has_table_text = False
        if self.tesseract_available and image_data:
            try:
                text = pytesseract.image_to_string(gray, lang='kor+eng')
                table_keywords = ['ë‹¨ìœ„', 'ì‚¬ë¡€ìˆ˜', 'ë¹„ìœ¨', 'í•©ê³„', '%', 'ëª…', 'ì›', 'ê°œ']
                for keyword in table_keywords:
                    if keyword in text:
                        has_table_text = True
                        logger.debug(f"      Tesseract í‘œ í‚¤ì›Œë“œ ê°ì§€: '{keyword}'")
                        break
            except Exception as e:
                logger.debug(f"      Tesseract OCR ì‹¤íŒ¨: {e}")
        
        has_table = has_table_cv or has_table_text
        
        logger.debug(
            f"      í‘œ ê²€ì¶œ: {has_table} "
            f"(CV êµì°¨ì : {intersections_sum}, Tesseract í‚¤ì›Œë“œ: {has_table_text})"
        )
        return has_table
    
    def _detect_numbers(self, image: np.ndarray) -> bool:
        """ìˆ«ì ë°ì´í„° ê²€ì¶œ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        small_boxes = sum(1 for c in contours if 10 < cv2.contourArea(c) < 500)
        has_numbers = small_boxes > 20
        logger.debug(f"      ìˆ«ì ë°ì´í„°: {has_numbers} (ì‘ì€ ë°•ìŠ¤: {small_boxes})")
        return has_numbers
    
    def _count_diagrams(self, image: np.ndarray) -> int:
        """ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì¶”ì •"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        large_regions = sum(1 for c in contours if cv2.contourArea(c) > 5000)
        diagram_count = min(5, large_regions)
        logger.debug(f"      ë‹¤ì´ì–´ê·¸ë¨: {diagram_count}ê°œ (í° ì˜ì—­: {large_regions})")
        return diagram_count
    
    def _detect_bus_keywords(self, ocr_text: str) -> List[str]:
        """ë²„ìŠ¤ í‚¤ì›Œë“œ ê²€ì¶œ"""
        if not ocr_text:
            return []
        BUS_KEYWORDS = ['ë…¸ì„ ', 'ë°°ì°¨', 'ì •ë¥˜ì¥', 'ì²«ì°¨', 'ë§‰ì°¨', 'ì°¨ê³ ì§€', 'ë²„ìŠ¤']
        detected = [kw for kw in BUS_KEYWORDS if kw in ocr_text]
        return detected