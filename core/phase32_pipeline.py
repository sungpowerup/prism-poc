"""
PRISM Phase 3.2 - Integrated Pipeline

âœ… í†µí•© ê°œì„ :
1. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ í†µí•©
2. ê°„ê²°í•œ VLM í”„ë¡¬í”„íŠ¸ (368ì â†’ 30ì)
3. CV + OCR í•˜ì´ë¸Œë¦¬ë“œ
4. RAG ìµœì í™” ì²­í‚¹

Author: ì´ì„œì˜ (Backend Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-22
Version: 3.2
"""

import logging
from typing import List, Dict, Optional
from pathlib import Path
import time

# Core ëª¨ë“ˆ
from core.pdf_processor import PDFProcessor
from core.vlm_service import VLMService
from core.layout_detector import LayoutDetector

# Phase 3.2 ì‹ ê·œ ëª¨ë“ˆ
try:
    from core.ocr_text_extractor import OCRTextExtractor
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("âš ï¸  OCR ëª¨ë“ˆ ì—†ìŒ. OCR ê¸°ëŠ¥ ì œí•œë¨.")

try:
    from phase32_concise_prompts import Phase32PromptBuilder
    CONCISE_PROMPTS_AVAILABLE = True
except ImportError:
    CONCISE_PROMPTS_AVAILABLE = False
    print("âš ï¸  ê°„ê²° í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì—†ìŒ. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©.")

logger = logging.getLogger(__name__)


class Phase32Pipeline:
    """
    Phase 3.2 í†µí•© íŒŒì´í”„ë¼ì¸
    
    í†µí•© êµ¬ì„±:
    1. Layout Detection (CV) - ì°¨íŠ¸, í‘œ ê°ì§€
    2. OCR Text Extraction - ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    3. VLM Analysis - ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ì„
    4. RAG-optimized Chunking - ê²€ìƒ‰ ìµœì í™” ì²­í‚¹
    """
    
    def __init__(
        self,
        vlm_provider: str = "azure_openai",
        use_ocr: bool = True,
        use_concise_prompts: bool = True
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            vlm_provider: VLM ì œê³µì ('azure_openai', 'anthropic')
            use_ocr: OCR ì‚¬ìš© ì—¬ë¶€
            use_concise_prompts: ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ì—¬ë¶€
        """
        logger.info("="*60)
        logger.info("PRISM Phase 3.2 Pipeline ì´ˆê¸°í™”")
        logger.info("="*60)
        
        # 1. PDF Processor
        self.pdf_processor = PDFProcessor()
        logger.info("âœ… PDF Processor")
        
        # 2. VLM Service
        self.vlm_service = VLMService(provider=vlm_provider)
        logger.info(f"âœ… VLM Service ({vlm_provider})")
        
        # 3. Layout Detector (CV)
        self.layout_detector = LayoutDetector()
        logger.info("âœ… Layout Detector (CV)")
        
        # 4. OCR Text Extractor (ì‹ ê·œ)
        if use_ocr and OCR_AVAILABLE:
            self.ocr_extractor = OCRTextExtractor()
            self.use_ocr = True
            logger.info("âœ… OCR Text Extractor")
        else:
            self.ocr_extractor = None
            self.use_ocr = False
            logger.warning("âš ï¸  OCR ë¹„í™œì„±í™”")
        
        # 5. ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ ë¹Œë” (ì‹ ê·œ)
        if use_concise_prompts and CONCISE_PROMPTS_AVAILABLE:
            self.prompt_builder = Phase32PromptBuilder()
            self.use_concise = True
            logger.info("âœ… Concise Prompt Builder (Phase 3.2)")
        else:
            self.prompt_builder = None
            self.use_concise = False
            logger.warning("âš ï¸  ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
        
        logger.info("="*60)
    
    def process_pdf(
        self,
        pdf_path: str,
        max_pages: Optional[int] = None
    ) -> Dict:
        """
        PDF ì²˜ë¦¬ (Phase 3.2 í†µí•©)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ“„ PRISM Phase 3.2 ë¬¸ì„œ ì²˜ë¦¬")
        logger.info(f"   íŒŒì¼: {Path(pdf_path).name}")
        logger.info("="*60 + "\n")
        
        # Stage 1: PDF â†’ Images
        logger.info("--- Stage 1: PDF â†’ Base64 Images ---")
        pages = self.pdf_processor.extract_pages_as_base64(pdf_path, max_pages)
        logger.info(f"âœ… {len(pages)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        
        # Stage 2: numpy ë³€í™˜
        import numpy as np
        from PIL import Image
        import io
        import base64
        
        page_images = []
        for i, page in enumerate(pages, 1):
            img_data = base64.b64decode(page['image'].split(',')[1])
            img = Image.open(io.BytesIO(img_data))
            arr = np.array(img)
            page_images.append(arr)
            logger.info(f"  í˜ì´ì§€ {i}: Base64 â†’ numpy array ë³€í™˜ ì™„ë£Œ {arr.shape}")
        
        logger.info(f"âœ… {len(page_images)}ê°œ í˜ì´ì§€ numpy ë³€í™˜ ì™„ë£Œ")
        
        # Stage 3: í˜ì´ì§€ë³„ ì²˜ë¦¬
        all_regions = []
        all_chunks = []
        current_section = "ì‹œì‘"
        
        for page_num, image in enumerate(page_images):
            logger.info("\n" + "="*60)
            logger.info(f"í˜ì´ì§€ {page_num + 1}/{len(page_images)} ì²˜ë¦¬")
            logger.info("="*60 + "\n")
            
            # â­ Stage 3.1: Layout Detection (CV)
            logger.info("--- Stage 3.1: Layout Detection (CV) ---")
            cv_regions = self.layout_detector.detect_regions(image, page_num)
            logger.info(f"âœ… {len(cv_regions)}ê°œ CV ì˜ì—­ ê°ì§€\n")
            
            # â­ Stage 3.2: OCR Text Extraction (ì‹ ê·œ!)
            ocr_regions = []
            section_titles = []
            full_text = ""
            
            if self.use_ocr:
                logger.info("--- Stage 3.2: OCR Text Extraction ---")
                
                # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                ocr_result = self.ocr_extractor.extract_full_text(image)
                full_text = ocr_result['full_text']
                logger.info(f"   â†’ {len(ocr_result['lines'])}ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
                logger.info(f"   â†’ ì‹ ë¢°ë„: {ocr_result['confidence']:.1f}%")
                
                # ì„¹ì…˜ í—¤ë” ê°ì§€
                section_titles = self.ocr_extractor.extract_section_titles(image)
                logger.info(f"   â†’ {len(section_titles)}ê°œ ì„¹ì…˜ í—¤ë” ê°ì§€")
                
                # í…ìŠ¤íŠ¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ
                ocr_regions = self.ocr_extractor.extract_text_regions(image)
                logger.info(f"   â†’ {len(ocr_regions)}ê°œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€\n")
            
            # â­ Stage 3.3: ì˜ì—­ í†µí•©
            logger.info("--- Stage 3.3: Region Integration ---")
            
            # ìš°ì„ ìˆœìœ„: section_titles > cv_regions > ocr_regions
            page_regions = section_titles + cv_regions + ocr_regions
            logger.info(f"âœ… ì´ {len(page_regions)}ê°œ ì˜ì—­ í†µí•©\n")
            
            # â­ Stage 3.4: VLM Analysis (ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸!)
            logger.info("--- Stage 3.4: VLM Analysis (Concise) ---\n")
            
            for i, region in enumerate(page_regions, 1):
                region_type = region['type']
                
                logger.info(f"[Region {i}/{len(page_regions)}] {region_type}")
                
                # ì„¹ì…˜ í—¤ë” ê°ì§€
                if region_type == 'section_header':
                    # OCRì—ì„œ ì´ë¯¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    caption = region.get('title', '')
                    current_section = caption
                    logger.info(f"   â†’ ì„¹ì…˜ ë³€ê²½: {current_section}\n")
                
                # í…ìŠ¤íŠ¸ ì˜ì—­ (OCR ê²°ê³¼ ì‚¬ìš©)
                elif region_type == 'text_region':
                    caption = region.get('text', '')
                    logger.info(f"   â†’ OCR í…ìŠ¤íŠ¸ ì‚¬ìš©: {len(caption)}ì\n")
                
                # ì°¨íŠ¸/í‘œ (VLM ë¶„ì„ í•„ìš”)
                elif region_type in ['pie_chart', 'bar_chart', 'table', 'map']:
                    # ì˜ì—­ crop
                    x, y, w, h = region['bbox']
                    cropped = image[y:y+h, x:x+w]
                    
                    # â­ ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    if self.use_concise:
                        prompt = self.prompt_builder.build_prompt(
                            element_type=region_type,
                            context=current_section
                        )
                    else:
                        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (fallback)
                        prompt = f"ì´ {region_type}ë¥¼ ë¶„ì„í•˜ì„¸ìš”."
                    
                    # VLM í˜¸ì¶œ
                    vlm_start = time.time()
                    caption = self.vlm_service.analyze_image(cropped, prompt)
                    vlm_time = time.time() - vlm_start
                    
                    logger.info(f"   âœ… VLM ë¶„ì„ ì™„ë£Œ: {vlm_time:.2f}ì´ˆ")
                    logger.info(f"   â†’ {len(caption)}ì\n")
                    
                    # â­ ì¶œë ¥ ê²€ì¦
                    if self.use_concise:
                        validation = self.prompt_builder.validate_output(
                            caption, region_type
                        )
                        
                        if not validation['valid']:
                            logger.warning(f"   âš ï¸  ê²€ì¦ ì‹¤íŒ¨: {validation['reason']}")
                
                # í—¤ë” (VLM ê°„ë‹¨ ë¶„ì„)
                elif region_type == 'header':
                    # OCRì´ ìˆìœ¼ë©´ OCR ì‚¬ìš©
                    if self.use_ocr:
                        caption = full_text[:100]  # ìƒë‹¨ 100ì
                    else:
                        # VLM ê°„ë‹¨ ë¶„ì„
                        x, y, w, h = region['bbox']
                        cropped = image[y:y+h, x:x+w]
                        caption = self.vlm_service.analyze_image(
                            cropped,
                            "í˜ì´ì§€ í—¤ë” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. 20ì ì´ë‚´."
                        )
                    
                    current_section = caption.strip()
                    logger.info(f"   â†’ í—¤ë”: {caption}\n")
                
                else:
                    caption = ""
                
                # ì˜ì—­ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                region['caption'] = caption
                region['section'] = current_section
                region['page_number'] = page_num + 1
                
                all_regions.append(region)
            
            # â­ Stage 3.5: RAG-optimized Chunking
            logger.info("--- Stage 3.5: RAG-optimized Chunking ---")
            
            for region in page_regions:
                chunk = {
                    'id': f"chunk_{len(all_chunks):03d}",
                    'type': region['type'],
                    'section': region.get('section', ''),
                    'page': region.get('page_number', page_num + 1),
                    'content': region.get('caption', ''),
                    'bbox': region.get('bbox', [0, 0, 0, 0]),
                    'confidence': region.get('confidence', 0.0)
                }
                all_chunks.append(chunk)
            
            logger.info(f"âœ… {len(page_regions)}ê°œ ì²­í¬ ìƒì„±\n")
        
        # ìµœì¢… ê²°ê³¼
        processing_time = time.time() - start_time
        
        logger.info("="*60)
        logger.info("âœ… Phase 3.2 ì²˜ë¦¬ ì™„ë£Œ!")
        logger.info(f"   ì´ í˜ì´ì§€: {len(page_images)}ê°œ")
        logger.info(f"   ê°ì§€ëœ ì˜ì—­: {len(all_regions)}ê°œ")
        logger.info(f"   ìƒì„±ëœ ì²­í¬: {len(all_chunks)}ê°œ")
        logger.info(f"   ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        logger.info("="*60 + "\n")
        
        return {
            'metadata': {
                'filename': Path(pdf_path).name,
                'total_pages': len(page_images),
                'total_regions': len(all_regions),
                'total_chunks': len(all_chunks),
                'processing_time_sec': round(processing_time, 2),
                'vlm_provider': self.vlm_service.provider,
                'ocr_enabled': self.use_ocr,
                'concise_prompts': self.use_concise
            },
            'regions': all_regions,
            'chunks': all_chunks,
            'pages': page_images
        }


# ===========================
# ê²°ê³¼ í¬ë§·í„° (Phase 3.2)
# ===========================

class Phase32ResultFormatter:
    """
    Phase 3.2 ê²°ê³¼ í¬ë§·í„°
    
    ê°œì„ :
    - ê°„ê²°í•œ ì²­í¬ ì¶œë ¥
    - RAG ìµœì í™” í˜•ì‹
    """
    
    @staticmethod
    def format_to_markdown(result: Dict) -> str:
        """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        metadata = result['metadata']
        chunks = result['chunks']
        
        md = f"""# PRISM Phase 3.2 - ê°„ê²°í•œ ë¬¸ì„œ ì¶”ì¶œ

**ìƒì„±ì¼ì‹œ**: {time.strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“„ ë¬¸ì„œ ì •ë³´

- **íŒŒì¼ëª…**: {metadata['filename']}
- **ì´ í˜ì´ì§€**: {metadata['total_pages']}ê°œ
- **ì´ ì˜ì—­**: {metadata['total_regions']}ê°œ
- **ì´ ì²­í¬**: {metadata['total_chunks']}ê°œ
- **ì²˜ë¦¬ ì‹œê°„**: {metadata['processing_time_sec']}ì´ˆ
- **OCR ì‚¬ìš©**: {'âœ…' if metadata['ocr_enabled'] else 'âŒ'}
- **ê°„ê²° í”„ë¡¬í”„íŠ¸**: {'âœ…' if metadata['concise_prompts'] else 'âŒ'}
- **Phase**: 3.2

"""
        
        # ì²­í¬ë³„ ì¶œë ¥
        md += "## ğŸ§© ì²­í¬\n\n"
        
        current_section = ""
        for i, chunk in enumerate(chunks, 1):
            # ì„¹ì…˜ ë³€ê²½ ì‹œ í—¤ë”
            if chunk['section'] != current_section:
                current_section = chunk['section']
                md += f"\n### {current_section}\n\n"
            
            md += f"**[{i}] {chunk['type']}** (í˜ì´ì§€ {chunk['page']})\n\n"
            md += f"{chunk['content']}\n\n"
            md += "---\n\n"
        
        return md
    
    @staticmethod
    def format_to_json(result: Dict) -> Dict:
        """JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return {
            'metadata': result['metadata'],
            'chunks': result['chunks']
        }


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    print("="*60)
    print("Phase 3.2 Pipeline í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    pipeline = Phase32Pipeline(
        vlm_provider='azure_openai',
        use_ocr=True,
        use_concise_prompts=True
    )
    
    print("\nâœ… Pipeline ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"   OCR: {pipeline.use_ocr}")
    print(f"   ê°„ê²° í”„ë¡¬í”„íŠ¸: {pipeline.use_concise}")
