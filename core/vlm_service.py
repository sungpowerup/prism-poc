"""
core/vlm_service.py
PRISM Phase 5.0 - VLM Service (ë²”ìš© ì „ëžµ íŒ¨í„´)
"""

import os
import logging
import json
import re
from typing import Dict, Any
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv

# âœ… ìƒëŒ€ ìž„í¬íŠ¸ ì‚¬ìš©
from .document_classifier import DocumentClassifierV50

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV50:
    """ë²”ìš© VLM ì„œë¹„ìŠ¤ v5.0"""
    
    def __init__(self, provider: str = "azure_openai"):
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
        
        self.classifier = DocumentClassifierV50(provider)
        logger.info(f"âœ… VLM Service v5.0 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def analyze_page_v50(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """Phase 5.0: ë²”ìš© ë¬¸ì„œ ë¶„ì„"""
        logger.info(f"ðŸŽ¯ Page {page_num}: Phase 5.0 ë²”ìš© ë¶„ì„ ì‹œìž‘")
        
        # Step 1: ë¬¸ì„œ íƒ€ìž… íŒë³„
        doc_type_result = self.classifier.classify(image_data, page_num)
        doc_type = doc_type_result.get('type', 'mixed')
        subtype = doc_type_result.get('subtype', 'unknown')
        confidence = doc_type_result.get('confidence', 0.5)
        
        logger.info(f"âœ… íƒ€ìž…: {doc_type} ({subtype}), ì‹ ë¢°ë„: {confidence:.2f}")
        
        # Step 2-4: íƒ€ìž…ë³„ ì „ëžµ ì‹¤í–‰
        if doc_type == 'text_document':
            content = self._extract_text_document(image_data, subtype)
        elif doc_type == 'diagram':
            content = self._extract_diagram(image_data, subtype)
        elif doc_type == 'technical_drawing':
            content = self._extract_technical_drawing(image_data, subtype)
        elif doc_type == 'image_content':
            content = self._extract_image_content(image_data, subtype)
        elif doc_type == 'chart_statistics':
            content = self._extract_chart_statistics(image_data, subtype)
        else:
            content = self._extract_mixed(image_data)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)} ê¸€ìž")
        
        # Step 5: í’ˆì§ˆ í‰ê°€
        quality_score = self._calculate_quality(content, doc_type)
        
        return {
            'content': content,
            'confidence': confidence,
            'strategy': f'{doc_type}_v50',
            'doc_type': doc_type,
            'subtype': subtype,
            'quality_score': quality_score,
            'structure': doc_type_result
        }
    
    def _extract_text_document(self, image_data: str, subtype: str) -> str:
        prompt = f"""ì´ {subtype} ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™:**
1. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•ížˆ ì¶”ì¶œí•˜ì„¸ìš”
2. ì¡°í•­/í•­ ë²ˆí˜¸ë¥¼ ì •í™•ížˆ ë³´ì¡´í•˜ì„¸ìš”
3. í‘œê°€ ìžˆìœ¼ë©´ Markdown í‘œë¡œ ë³€í™˜í•˜ì„¸ìš”
4. ë©”íƒ€ ì •ë³´ëŠ” ìµœì†Œí™”í•˜ì„¸ìš”
5. ê°„ê²°í•˜ê²Œ ìž‘ì„±í•˜ì„¸ìš”"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_diagram(self, image_data: str, subtype: str) -> str:
        if subtype == 'transport_route':
            prompt = """ì´ êµí†µ ë…¸ì„ ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë…¸ì„  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë…¸ì„  ì •ë³´
**ë…¸ì„ ëª…**: [ë…¸ì„ ë²ˆí˜¸/ì´ë¦„]

### ê²½ë¡œ
1. [ì¶œë°œì§€]
2. [ê²½ìœ ì§€ 1]
...

**ì£¼ì˜:** ì •ë¥˜ìž¥/ì—­ ì´ë¦„ì„ ì •í™•ížˆ ì¶”ì¶œí•˜ê³  ìˆœì„œë¥¼ ì§€í‚¤ì„¸ìš”."""
        else:
            prompt = """ì´ ë‹¤ì´ì–´ê·¸ëž¨ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."""
        return self._call_vlm(image_data, prompt)
    
    def _extract_technical_drawing(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ë„ë©´ì„ ë¶„ì„í•˜ì—¬ ê³µê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## í‰ë©´ë„

### ê³µê°„ êµ¬ì„±
1. **[ê³µê°„ ì´ë¦„]** ([ë©´ì ])
   - ìœ„ì¹˜: [ë°©í–¥/ìœ„ì¹˜]
   - ì¹˜ìˆ˜: [ê°€ë¡œ Ã— ì„¸ë¡œ]"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_image_content(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

**í˜•ì‹:**
## ì´ë¯¸ì§€ ì„¤ëª…

### ì£¼ìš” ìš”ì†Œ
- [ìš”ì†Œ]: [ì„¤ëª…]

### ì‹œê°ì  íŠ¹ì§•
- ìƒ‰ìƒ: [ì£¼ìš” ìƒ‰ìƒ]
- ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼]"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_chart_statistics(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì°¨íŠ¸/í‘œë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë°ì´í„°

**ì°¨íŠ¸ ì œëª©**: [ì œëª©]

### ë°ì´í„° í…Œì´ë¸”
| í•­ëª© | ê°’ 1 | ê°’ 2 |
|------|------|------|
| í–‰ 1 | [ê°’] | [ê°’] |"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_mixed(self, image_data: str) -> str:
        prompt = """ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."""
        return self._call_vlm(image_data, prompt)
    
    def _call_vlm(self, image_data: str, prompt: str) -> str:
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/png;base64,{image_data}"}
                                }
                            ]
                        }
                    ],
                    max_tokens=2000,
                    temperature=0.2
                )
                return response.choices[0].message.content.strip()
            else:
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.2,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_data
                                    }
                                },
                                {"type": "text", "text": prompt}
                            ]
                        }
                    ]
                )
                return response.content[0].text.strip()
        except Exception as e:
            logger.error(f"âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"## ì¶”ì¶œ ì‹¤íŒ¨\nì˜¤ë¥˜: {str(e)}"
    
    def _calculate_quality(self, content: str, doc_type: str) -> float:
        score = 100.0
        if len(content) < 50:
            score -= 30
        headers = re.findall(r'^#+\s+', content, re.MULTILINE)
        if len(headers) == 0:
            score -= 20
        elif len(headers) >= 3:
            score += 10
        return max(0.0, min(100.0, score))