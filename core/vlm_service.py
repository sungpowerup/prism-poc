"""
core/vlm_service_v50.py
PRISM Phase 5.0 - VLM Service (ë²”ìš© ì „ëµ íŒ¨í„´)

âœ… Phase 5.0 í•µì‹¬:
1. ë¬¸ì„œ íƒ€ì… ìš°ì„  íŒë³„
2. íƒ€ì…ë³„ ì „ëµ ìë™ ì„ íƒ
3. ë²”ìš© í”„ë¡¬í”„íŠ¸ (í•˜ë“œì½”ë”© ì œë¡œ)
4. ì›ë³¸ ì¶©ì‹¤ë„ 95% ëª©í‘œ

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-24
Version: 5.0
"""

import os
import logging
import json
import re
from typing import Dict, Any
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv
from document_classifier import DocumentClassifierV50

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV50:
    """
    ë²”ìš© VLM ì„œë¹„ìŠ¤ v5.0
    
    íŠ¹ì§•:
    - ë¬¸ì„œ íƒ€ì… ìë™ ì¸ì‹
    - ì „ëµ íŒ¨í„´ ìë™ ì ìš©
    - ì™„ì „ ë²”ìš© ì„¤ê³„
    """
    
    def __init__(self, provider: str = "azure_openai"):
        """VLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
        
        # ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ê¸°
        self.classifier = DocumentClassifierV50(provider)
        
        logger.info(f"âœ… VLM Service v5.0 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def analyze_page_v50(
        self,
        image_data: str,
        page_num: int
    ) -> Dict[str, Any]:
        """
        Phase 5.0: ë²”ìš© ë¬¸ì„œ ë¶„ì„
        
        1ë‹¨ê³„: ë¬¸ì„œ íƒ€ì… íŒë³„
        2ë‹¨ê³„: íƒ€ì…ë³„ ì „ëµ ì„ íƒ
        3ë‹¨ê³„: êµ¬ì¡° ë¶„ì„
        4ë‹¨ê³„: ë‚´ìš© ì¶”ì¶œ
        5ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¯ Page {page_num}: Phase 5.0 ë²”ìš© ë¶„ì„ ì‹œì‘")
        logger.info(f"{'='*60}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 1: ë¬¸ì„œ íƒ€ì… íŒë³„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"\n[Step 1] ë¬¸ì„œ íƒ€ì… íŒë³„...")
        
        doc_type_result = self.classifier.classify(image_data, page_num)
        
        doc_type = doc_type_result.get('type', 'mixed')
        subtype = doc_type_result.get('subtype', 'unknown')
        confidence = doc_type_result.get('confidence', 0.5)
        
        logger.info(f"âœ… íƒ€ì…: {doc_type} ({subtype}), ì‹ ë¢°ë„: {confidence:.2f}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 2-4: íƒ€ì…ë³„ ì „ëµ ì‹¤í–‰
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"\n[Step 2-4] íƒ€ì…ë³„ ë‚´ìš© ì¶”ì¶œ...")
        
        if doc_type == 'text_document':
            content = self._extract_text_document(image_data, subtype)
        elif doc_type == 'diagram':
            content = self._extract_diagram(image_data, subtype)
        elif doc_type == 'technical_drawing':
            content = self._extract_technical_drawing(image_data, subtype)
        elif doc_type == 'image_content':
            content = self._extract_image_content(image_data, subtype)
        elif doc_type == 'chart_statistics':
            content = self._extract_chart_statistics(image_data, subtype)
        else:  # mixed
            content = self._extract_mixed(image_data)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)} ê¸€ì")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 5: í’ˆì§ˆ í‰ê°€
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        quality_score = self._calculate_quality(content, doc_type)
        
        logger.info(f"âœ… í’ˆì§ˆ: {quality_score:.1f}/100")
        logger.info(f"{'='*60}\n")
        
        return {
            'content': content,
            'confidence': confidence,
            'strategy': f'{doc_type}_v50',
            'doc_type': doc_type,
            'subtype': subtype,
            'quality_score': quality_score,
            'structure': doc_type_result
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # íƒ€ì…ë³„ ì¶”ì¶œ ë©”ì„œë“œ
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _extract_text_document(self, image_data: str, subtype: str) -> str:
        """í…ìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ì¶œ (ì‚¬ê·œ, ê³„ì•½ì„œ, ë³´ê³ ì„œ)"""
        
        prompt = f"""ì´ {subtype} ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
# [ë¬¸ì„œ ì œëª©]

**ë¬¸ì„œ ì •ë³´**
- ë¬¸ì„œë²ˆí˜¸: [ë²ˆí˜¸]
- ì œì •ì¼: [ë‚ ì§œ]
- ê°œì •ì¼: [ë‚ ì§œ]

## [ì²« ë²ˆì§¸ ì„¹ì…˜]

### [í•˜ìœ„ ì„¹ì…˜]
ë‚´ìš©...

**ì¤‘ìš” ê·œì¹™:**
1. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
2. ì¡°í•­/í•­ ë²ˆí˜¸ë¥¼ ì •í™•íˆ ë³´ì¡´í•˜ì„¸ìš”
3. í‘œê°€ ìˆìœ¼ë©´ Markdown í‘œë¡œ ë³€í™˜í•˜ì„¸ìš”
4. ë©”íƒ€ ì •ë³´ëŠ” ìµœì†Œí™”í•˜ì„¸ìš” (RAG ìµœì í™”)
5. ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”"""
        
        return self._call_vlm(image_data, prompt)
    
    def _extract_diagram(self, image_data: str, subtype: str) -> str:
        """ë‹¤ì´ì–´ê·¸ë¨ ì¶”ì¶œ (ë…¸ì„ ë„, í”Œë¡œìš°ì°¨íŠ¸, ì¡°ì§ë„)"""
        
        if subtype == 'transport_route':
            prompt = """ì´ êµí†µ ë…¸ì„ ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë…¸ì„  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë…¸ì„  ì •ë³´

**ë…¸ì„ ëª…**: [ë…¸ì„ ë²ˆí˜¸/ì´ë¦„]
**ìš´í–‰ ì •ë³´**: [ë°°ì°¨ê°„ê²©, ìš´í–‰ì‹œê°„ ë“±]

### ê²½ë¡œ
1. [ì¶œë°œì§€]
2. [ê²½ìœ ì§€ 1]
3. [ê²½ìœ ì§€ 2]
...
n. [ì¢…ì ]

**ì£¼ì˜:**
- ì •ë¥˜ì¥/ì—­ ì´ë¦„ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
- ìˆœì„œë¥¼ ì •í™•íˆ ì§€í‚¤ì„¸ìš”
- ì¤‘ë³µ ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”"""
        
        elif subtype == 'flowchart':
            prompt = """ì´ í”Œë¡œìš°ì°¨íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## í”„ë¡œì„¸ìŠ¤ í”Œë¡œìš°

### ë‹¨ê³„
1. **[ë‹¨ê³„ ì´ë¦„]**
   - ë‚´ìš©: [ì„¤ëª…]
   - ì¡°ê±´: [ìˆë‹¤ë©´]
   - ë‹¤ìŒ: [ë‹¤ìŒ ë‹¨ê³„]

2. **[ë‹¨ê³„ ì´ë¦„]**
   ...

### ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸
- [ì¡°ê±´ A] â†’ [ê²°ê³¼ 1]
- [ì¡°ê±´ B] â†’ [ê²°ê³¼ 2]"""
        
        else:  # organization, network ë“±
            prompt = """ì´ ë‹¤ì´ì–´ê·¸ë¨ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## êµ¬ì¡°

### ì£¼ìš” ìš”ì†Œ
- [ìš”ì†Œ 1]: [ì„¤ëª…]
- [ìš”ì†Œ 2]: [ì„¤ëª…]

### ê´€ê³„
- [ìš”ì†Œ 1] â†’ [ìš”ì†Œ 2]: [ê´€ê³„ ì„¤ëª…]"""
        
        return self._call_vlm(image_data, prompt)
    
    def _extract_technical_drawing(self, image_data: str, subtype: str) -> str:
        """ê¸°ìˆ  ë„ë©´ ì¶”ì¶œ (ì¸í…Œë¦¬ì–´, ê±´ì¶•)"""
        
        prompt = """ì´ ë„ë©´ì„ ë¶„ì„í•˜ì—¬ ê³µê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## í‰ë©´ë„

**ì „ì²´ ì •ë³´**
- ì´ ë©´ì : [ë©´ì ]
- ì¶•ì²™: [ì¶•ì²™]

### ê³µê°„ êµ¬ì„±
1. **[ê³µê°„ ì´ë¦„]** ([ë©´ì ])
   - ìœ„ì¹˜: [ë°©í–¥/ìœ„ì¹˜]
   - ì¹˜ìˆ˜: [ê°€ë¡œ Ã— ì„¸ë¡œ]
   - íŠ¹ì§•: [ì£¼ìš” íŠ¹ì§•]

2. **[ê³µê°„ ì´ë¦„]**
   ...

**ì£¼ì˜:**
- ê³µê°„ ì´ë¦„ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
- ì¹˜ìˆ˜ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”"""
        
        return self._call_vlm(image_data, prompt)
    
    def _extract_image_content(self, image_data: str, subtype: str) -> str:
        """ì´ë¯¸ì§€ ì½˜í…ì¸  ì¶”ì¶œ (íŒ¨ì…˜, ì œí’ˆ)"""
        
        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‚´ìš©ì„ ì„¤ëª…í•˜ì„¸ìš”.

**í˜•ì‹:**
## ì´ë¯¸ì§€ ì„¤ëª…

### ì£¼ìš” ìš”ì†Œ
- [ìš”ì†Œ 1]: [ì„¤ëª…]
- [ìš”ì†Œ 2]: [ì„¤ëª…]

### ì‹œê°ì  íŠ¹ì§•
- ìƒ‰ìƒ: [ì£¼ìš” ìƒ‰ìƒ]
- ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼ ì„¤ëª…]
- ë¶„ìœ„ê¸°: [ë¶„ìœ„ê¸°]

### ì„¸ë¶€ ì‚¬í•­
[ìƒì„¸ ì„¤ëª…]

**ì£¼ì˜:**
- ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
- ë¶ˆí•„ìš”í•œ ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”"""
        
        return self._call_vlm(image_data, prompt)
    
    def _extract_chart_statistics(self, image_data: str, subtype: str) -> str:
        """ì°¨íŠ¸/í†µê³„ ì¶”ì¶œ"""
        
        prompt = """ì´ ì°¨íŠ¸/í‘œë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë°ì´í„°

**ì°¨íŠ¸ ì œëª©**: [ì œëª©]
**ì°¨íŠ¸ íƒ€ì…**: [ë§‰ëŒ€/ì›í˜•/ì„  ë“±]

### ë°ì´í„° í…Œì´ë¸”

| [í•­ëª©] | [ê°’ 1] | [ê°’ 2] | [ê°’ 3] |
|--------|--------|--------|--------|
| [í–‰ 1] | [ê°’]   | [ê°’]   | [ê°’]   |
| [í–‰ 2] | [ê°’]   | [ê°’]   | [ê°’]   |

### ì£¼ìš” ë°œê²¬
- [í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1]
- [í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2]

**ì£¼ì˜:**
- ë°ì´í„°ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
- í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”
- ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”"""
        
        return self._call_vlm(image_data, prompt)
    
    def _extract_mixed(self, image_data: str) -> str:
        """ë³µí•© ë¬¸ì„œ ì¶”ì¶œ"""
        
        prompt = """ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## [ë¬¸ì„œ ì œëª©]

### [ì„¹ì…˜ 1]
ë‚´ìš©...

### [ì„¹ì…˜ 2]
ë‚´ìš©...

**ì£¼ì˜:**
- ë¬¸ì„œ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ì ì ˆíˆ ì¶”ì¶œí•˜ì„¸ìš”
- í…ìŠ¤íŠ¸, í‘œ, ì´ë¯¸ì§€ ë“±ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”
- ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”"""
        
        return self._call_vlm(image_data, prompt)
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # VLM í˜¸ì¶œ
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _call_vlm(self, image_data: str, prompt: str) -> str:
        """VLM í˜¸ì¶œ"""
        
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/png;base64,{image_data}"}
                                }
                            ]
                        }
                    ],
                    max_tokens=2000,
                    temperature=0.2
                )
                
                return response.choices[0].message.content.strip()
                
            else:  # claude
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.2,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_data
                                    }
                                },
                                {"type": "text", "text": prompt}
                            ]
                        }
                    ]
                )
                
                return response.content[0].text.strip()
        
        except Exception as e:
            logger.error(f"âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"## ì¶”ì¶œ ì‹¤íŒ¨\nì˜¤ë¥˜: {str(e)}"
    
    def _calculate_quality(self, content: str, doc_type: str) -> float:
        """í’ˆì§ˆ í‰ê°€ (ë²”ìš©)"""
        score = 100.0
        
        # ìµœì†Œ ê¸¸ì´ ì²´í¬
        if len(content) < 50:
            score -= 30
        
        # êµ¬ì¡° ì²´í¬ (í—¤ë” ì¡´ì¬)
        headers = re.findall(r'^#+\s+', content, re.MULTILINE)
        if len(headers) == 0:
            score -= 20
        elif len(headers) >= 3:
            score += 10
        
        # RAG ë¶ˆí•„ìš” ë‚´ìš© ì²´í¬
        meta_keywords = [
            'ì´ ë¬¸ì„œëŠ”', 'ë‹¤ìŒê³¼ ê°™ì´', 'ì•„ë˜ì™€ ê°™ì´',
            'ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤', 'í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
        ]
        for keyword in meta_keywords:
            if keyword in content:
                score -= 5
        
        return max(0.0, min(100.0, score))