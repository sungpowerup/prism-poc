"""
core/vlm_service.py

VLM (Vision Language Model) API í†µí•© ì„œë¹„ìŠ¤
âœ… custom_prompt ì§€ì› ì¶”ê°€ (2-Pass Hybrid ì™„ë²½ ì§€ì›)
"""

import os
import base64
import time
from typing import Optional, Dict, Any
from anthropic import Anthropic
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VLMService:
    """VLM API ì„œë¹„ìŠ¤ í´ëž˜ìŠ¤ (custom_prompt ì§€ì›)"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.api_key = api_key or os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = Anthropic(api_key=self.api_key)
        self.model = "claude-sonnet-4-20250514"
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        try:
            from prompts import chart_prompt, table_prompt, image_prompt, diagram_prompt
            
            self.prompts = {
                'chart': chart_prompt.PROMPT,
                'table': table_prompt.PROMPT,
                'image': image_prompt.PROMPT,
                'diagram': diagram_prompt.PROMPT,
                'text': "ì´ ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”."
            }
        except ImportError:
            logger.warning("í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©.")
            self.prompts = {
                'text': "ì´ ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”.",
                'chart': "ì´ ì°¨íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.",
                'table': "ì´ í‘œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.",
                'image': "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.",
                'diagram': "ì´ ë‹¤ì´ì–´ê·¸ëž¨ì„ ì„¤ëª…í•˜ì„¸ìš”."
            }
    
    def generate_caption(
        self, 
        image_data: bytes, 
        element_type: str,
        max_retries: int = 3,
        custom_prompt: Optional[str] = None  # âœ… ì¶”ê°€!
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ë¥¼ ìžì—°ì–´ ìº¡ì…˜ìœ¼ë¡œ ë³€í™˜
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            element_type: Element íƒ€ìž… (chart/table/image/diagram/text)
            max_retries: ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì˜µì…˜) âœ… ì¶”ê°€!
            
        Returns:
            {
                'caption': str,
                'confidence': float,
                'processing_time_ms': int,
                'tokens_used': int,
                'cost_usd': float
            }
        """
        start_time = time.time()
        
        # âœ… í”„ë¡¬í”„íŠ¸ ì„ íƒ: custom_prompt ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        if custom_prompt:
            prompt = custom_prompt
            logger.info("âœ… Custom prompt ì‚¬ìš©")
        else:
            prompt = self.prompts.get(element_type, self.prompts.get('text', 'ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.'))
            logger.info(f"ðŸ“‹ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (type: {element_type})")
        
        # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        image_b64 = base64.b64encode(image_data).decode('utf-8')
        
        # API í˜¸ì¶œ (ìž¬ì‹œë„ ë¡œì§)
        for attempt in range(max_retries):
            try:
                logger.info(f"VLM API í˜¸ì¶œ (attempt {attempt + 1}/{max_retries})")
                
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=2048,  # âœ… ì¦ê°€ (êµ¬ì¡°í™”ë¥¼ ìœ„í•´)
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_b64
                                    }
                                },
                                {
                                    "type": "text",
                                    "text": prompt
                                }
                            ]
                        }
                    ]
                )
                
                # ì‘ë‹µ íŒŒì‹±
                caption = response.content[0].text
                
                # í† í° ì‚¬ìš©ëŸ‰
                input_tokens = response.usage.input_tokens
                output_tokens = response.usage.output_tokens
                total_tokens = input_tokens + output_tokens
                
                # ë¹„ìš© ê³„ì‚° (Claude Sonnet 4 ê¸°ì¤€)
                input_cost = (input_tokens / 1_000_000) * 3.0  # $3/M tokens
                output_cost = (output_tokens / 1_000_000) * 15.0  # $15/M tokens
                cost_usd = input_cost + output_cost
                
                # ì²˜ë¦¬ ì‹œê°„
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                # ì‹ ë¢°ë„ ì¶”ì •
                confidence = self._estimate_confidence(caption, element_type)
                
                logger.info(f"âœ… VLM ì„±ê³µ: {len(caption)}ìž, {processing_time_ms}ms, ${cost_usd:.6f}")
                
                return {
                    'caption': caption,
                    'confidence': confidence,
                    'processing_time_ms': processing_time_ms,
                    'tokens_used': total_tokens,
                    'cost_usd': cost_usd
                }
                
            except Exception as e:
                logger.error(f"VLM API ì—ëŸ¬ (attempt {attempt + 1}): {str(e)}")
                
                if attempt == max_retries - 1:
                    # ìµœì¢… ì‹¤íŒ¨
                    raise
                
                # Exponential backoff
                wait_time = 2 ** attempt
                logger.info(f"{wait_time}ì´ˆ ëŒ€ê¸° í›„ ìž¬ì‹œë„...")
                time.sleep(wait_time)
    
    def _estimate_confidence(self, caption: str, element_type: str) -> float:
        """
        ìº¡ì…˜ ì‹ ë¢°ë„ ì¶”ì •
        
        Args:
            caption: ìƒì„±ëœ ìº¡ì…˜
            element_type: Element íƒ€ìž…
            
        Returns:
            ì‹ ë¢°ë„ (0.0 ~ 1.0)
        """
        confidence = 0.7  # ê¸°ë³¸ê°’
        
        # ê¸¸ì´ ì²´í¬
        if len(caption) > 50:
            confidence += 0.1
        if len(caption) > 100:
            confidence += 0.1
        
        # íƒ€ìž…ë³„ í‚¤ì›Œë“œ ì²´í¬
        keywords = {
            'chart': ['ê·¸ëž˜í”„', 'ì°¨íŠ¸', 'ì¶”ì´', 'ë°ì´í„°', 'ìˆ˜ì¹˜', 'ì¦ê°€', 'ê°ì†Œ'],
            'table': ['í‘œ', 'í–‰', 'ì—´', 'ë°ì´í„°', 'í•­ëª©', 'ê°’'],
            'image': ['ì´ë¯¸ì§€', 'ì‚¬ì§„', 'ê·¸ë¦¼', 'ë³´ì—¬ì£¼'],
            'diagram': ['ë‹¤ì´ì–´ê·¸ëž¨', 'ë„ì‹', 'êµ¬ì¡°', 'íë¦„', 'í”„ë¡œì„¸ìŠ¤'],
            'text': ['í…ìŠ¤íŠ¸', 'ë¬¸ì„œ', 'ë‚´ìš©', 'ì •ë³´']
        }
        
        element_keywords = keywords.get(element_type, [])
        keyword_count = sum(1 for kw in element_keywords if kw in caption)
        
        if keyword_count > 0:
            confidence += min(0.1 * keyword_count, 0.2)
        
        return min(confidence, 1.0)
    
    def batch_generate_captions(
        self, 
        elements: list[Dict[str, Any]]
    ) -> list[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ Elementë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        
        Args:
            elements: Element ë¦¬ìŠ¤íŠ¸
                [{'image_data': bytes, 'type': str, 'id': str}, ...]
        
        Returns:
            ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, elem in enumerate(elements):
            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {i+1}/{len(elements)}")
            
            try:
                result = self.generate_caption(
                    elem['image_data'],
                    elem['type']
                )
                result['element_id'] = elem['id']
                result['status'] = 'success'
                results.append(result)
                
            except Exception as e:
                logger.error(f"Element {elem['id']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                results.append({
                    'element_id': elem['id'],
                    'status': 'failed',
                    'error': str(e)
                })
        
        return results