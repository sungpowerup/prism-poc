"""
core/vlm_service.py
PRISM Phase 4.5 - VLM Service (OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ)

âœ… Phase 4.5 ê°œì„ ì‚¬í•­:
1. OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ VLMìœ¼ë¡œ êµ¬ì¡° ì´í•´
2. ë‹¤ì´ì–´ê·¸ë¨ ì •í™• ê°ì§€ (ë¹„ì „ ë¶„ì„ ê°•í™”)
3. í™˜ê° ë°©ì§€ (OCR í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦)
4. RAG ìµœì í™” (ë¶ˆí•„ìš” ë‚´ìš© ì œê±°)

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-23
Version: 4.5
"""

import os
import logging
import re
from typing import Dict, Any, Optional, List
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv
import base64
from io import BytesIO
from PIL import Image

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    logging.warning("pytesseract not available - OCR disabled")

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV45:
    """
    Vision Language Model ì„œë¹„ìŠ¤ v4.5
    
    Phase 4.5 íŠ¹ì§•:
    - OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ
    - ë‹¤ì´ì–´ê·¸ë¨ ì •í™• ê°ì§€
    - í™˜ê° ë°©ì§€
    - RAG ìµœì í™”
    """
    
    def __init__(self, provider: str = "azure_openai"):
        """VLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            logger.info(f"âœ… Azure OpenAI ì´ˆê¸°í™”: {deployment}")
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
            logger.info(f"âœ… Claude ì´ˆê¸°í™”: {self.model}")
        
        else:
            raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: {provider}")
        
        logger.info(f"âœ… VLM Service v4.5 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def analyze_page_intelligent(
        self,
        image_data: str,
        page_num: int
    ) -> Dict[str, Any]:
        """
        OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ í˜ì´ì§€ ë¶„ì„ (Phase 4.5)
        
        Step 1: OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        Step 2: VLMìœ¼ë¡œ êµ¬ì¡° ë¶„ì„
        Step 3: OCR + VLM í†µí•© ì¶”ì¶œ
        Step 4: ê²€ì¦
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            {
                'content': str,
                'structure': dict,
                'confidence': float,
                'strategy': str
            }
        """
        logger.info(f"ğŸ¯ Page {page_num}: OCR + VLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 1: OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Step 1] OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ...")
        ocr_text = self._extract_text_ocr(image_data)
        
        if ocr_text:
            logger.info(f"  [Step 1] OCR ì¶”ì¶œ: {len(ocr_text)} ê¸€ì")
        else:
            logger.warning(f"  [Step 1] OCR ì‹¤íŒ¨ - VLM ë‹¨ë… ì‚¬ìš©")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 2: VLM êµ¬ì¡° ë¶„ì„
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Step 2] VLM êµ¬ì¡° ë¶„ì„...")
        structure = self._analyze_structure_enhanced(image_data)
        
        diagram_count = structure.get('diagram_count', 0)
        logger.info(f"  [Step 2] ë‹¤ì´ì–´ê·¸ë¨: {diagram_count}ê°œ")
        logger.info(f"  [Step 2] ìš”ì†Œ: {structure.get('elements', [])}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 3: OCR + VLM í†µí•© ì¶”ì¶œ
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Step 3] OCR + VLM í†µí•© ì¶”ì¶œ...")
        
        if diagram_count >= 2 or structure.get('complexity') == 'high':
            # Complex: OCR í…ìŠ¤íŠ¸ í™œìš©
            content = self._extract_with_ocr(image_data, structure, ocr_text)
            strategy = 'complex_ocr'
        else:
            # Simple: VLM ë‹¨ë…
            content = self._extract_simple(image_data, structure)
            strategy = 'simple'
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Step 4: ê²€ì¦
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Step 4] ê²€ì¦ ì¤‘...")
        is_valid, issues = self._validate_output(content, structure, ocr_text)
        
        if not is_valid:
            logger.warning(f"  [Step 4] ê²€ì¦ ì‹¤íŒ¨: {issues}")
        
        confidence = self._calculate_confidence(content, structure, ocr_text)
        
        logger.info(f"  [ì™„ë£Œ] {len(content)} ê¸€ì, ì‹ ë¢°ë„: {confidence:.2f}, ì „ëµ: {strategy}")
        
        return {
            'content': content,
            'structure': structure,
            'confidence': confidence,
            'strategy': strategy
        }
    
    def _extract_text_ocr(self, image_data: str) -> str:
        """Step 1: OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not TESSERACT_AVAILABLE:
            return ""
        
        try:
            # Base64 â†’ PIL Image
            img_bytes = base64.b64decode(image_data)
            img = Image.open(BytesIO(img_bytes))
            
            # OCR ì‹¤í–‰ (í•œê¸€ + ì˜ì–´)
            text = pytesseract.image_to_string(img, lang='kor+eng')
            return text.strip()
            
        except Exception as e:
            logger.warning(f"OCR ì‹¤íŒ¨: {e}")
            return ""
    
    def _analyze_structure_enhanced(self, image_data: str) -> Dict:
        """Step 2: VLM êµ¬ì¡° ë¶„ì„ (ê°•í™”)"""
        
        prompt = """ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ğŸ¯ **ì„ë¬´: ì´ í˜ì´ì§€ì˜ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”**

### ğŸ” ì¤‘ìš”: ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì •í™•íˆ ì„¸ê¸°!

ì´ í˜ì´ì§€ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ **ë…¸ì„ ë„ ë‹¤ì´ì–´ê·¸ë¨**ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ê° ë‹¤ì´ì–´ê·¸ë¨ì€:
- ì¶œë°œì ì—ì„œ ì‹œì‘
- ì—¬ëŸ¬ ì •ë¥˜ì¥ì„ ê±°ì³
- ì¢…ì ê¹Œì§€ ì—°ê²°ë˜ëŠ” ì„ í˜• êµ¬ì¡°

**ë°˜ë“œì‹œ ëª¨ë“  ë‹¤ì´ì–´ê·¸ë¨ì„ ì„¸ê³  ê°œìˆ˜ë¥¼ ì •í™•íˆ ë³´ê³ í•˜ì„¸ìš”!**

### ğŸ“‹ ë¶„ì„ í•­ëª©

1. **í˜ì´ì§€ ì œëª©/ì£¼ì œ**
2. **ì£¼ìš” ìš”ì†Œ** (text, map, diagram ë“±)
3. **ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜** (ì •í™•íˆ!)
4. **ë³µì¡ë„ íŒë‹¨**:
   - `simple`: ë‹¤ì´ì–´ê·¸ë¨ 0~1ê°œ
   - `medium`: ë‹¤ì´ì–´ê·¸ë¨ 2~3ê°œ
   - `high`: ë‹¤ì´ì–´ê·¸ë¨ 4ê°œ ì´ìƒ

5. **ì˜ˆìƒ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜**

JSONìœ¼ë¡œ ì‘ë‹µ:
```json
{
  "title": "í˜ì´ì§€ ì œëª©",
  "elements": ["text", "map", "diagram"],
  "diagram_count": 3,
  "complexity": "medium",
  "has_map": true,
  "estimated_data_points": 50
}
```

**ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ë¥¼ ì •í™•íˆ ì„¸ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤!**"""
        
        result = self._call_vlm(image_data, prompt, temperature=0.3)
        structure = self._parse_json_response(result)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ì¬ê²€ì¦
        diagram_count = structure.get('diagram_count', 0)
        if diagram_count >= 2:
            structure['complexity'] = 'high'
        
        return structure
    
    def _extract_with_ocr(self, image_data: str, structure: Dict, ocr_text: str) -> str:
        """Step 3: OCR + VLM í†µí•© ì¶”ì¶œ (Complex)"""
        
        diagram_count = structure.get('diagram_count', 1)
        
        # OCR í…ìŠ¤íŠ¸ì—ì„œ ì •ë¥˜ì¥ ì´ë¦„ ì¶”ì¶œ
        stop_names = self._extract_stop_names(ocr_text)
        
        prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ¯ ì„ë¬´: ë²„ìŠ¤ ë…¸ì„ ë„ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”

### âš ï¸ ì¤‘ìš” ì •ë³´

**ì´ í˜ì´ì§€ì—ëŠ” {diagram_count}ê°œì˜ ë‹¤ì´ì–´ê·¸ë¨ì´ ìˆìŠµë‹ˆë‹¤.**

**OCRë¡œ ì¶”ì¶œëœ ì •ë¥˜ì¥ ì´ë¦„:**
```
{chr(10).join(stop_names[:50])}
```

### ğŸ“‹ ì¶œë ¥ í˜•ì‹

#### ìƒë‹¨ ì •ë³´
(ë…¸ì„ ëª…, ë°°ì°¨ê°„ê²©, ìš´í–‰êµ¬ê°„ ë“±)

---

#### ì§€ë„ (ìˆëŠ” ê²½ìš°)
(ì§€ë„ì— í‘œì‹œëœ ì£¼ìš” ë¼ë²¨)

---

#### ë‹¤ì´ì–´ê·¸ë¨ {diagram_count}ê°œ

ê° ë‹¤ì´ì–´ê·¸ë¨ì„ ìˆœì„œëŒ€ë¡œ:

**ë‹¤ì´ì–´ê·¸ë¨ 1**
- ì¶œë°œ: [ì‹œì‘ì ]
- ê²½ìœ :
  - [ì •ë¥˜ì¥1]
  - [ì •ë¥˜ì¥2]
  - ...
- ì¢…ì : [ì¢…ì ]

**ë‹¤ì´ì–´ê·¸ë¨ 2**
...

**ë‹¤ì´ì–´ê·¸ë¨ {diagram_count}**
...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âœ… í•„ìˆ˜ ê·œì¹™

1. **OCR í…ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš©**
   - ìœ„ì˜ OCR ì •ë¥˜ì¥ ì´ë¦„ì„ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”
   - ì¶”ì¸¡í•˜ì§€ ë§ê³  OCR ê²°ê³¼ë¥¼ ì‹ ë¢°í•˜ì„¸ìš”

2. **{diagram_count}ê°œ ë‹¤ì´ì–´ê·¸ë¨ ëª¨ë‘ ì¶”ì¶œ**
   - ë¹ ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”!

3. **ì •ë¥˜ì¥ ìˆœì„œ ì •í™•íˆ**
   - ë…¸ì„ ë„ì˜ íë¦„ëŒ€ë¡œ ìˆœì„œë¥¼ ì§€í‚¤ì„¸ìš”

4. **ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°**
   - ì²´í¬ë¦¬ìŠ¤íŠ¸ âŒ
   - í’ˆì§ˆ ì´ìŠˆ âŒ
   - ì£¼ì„ ìµœì†Œí™” âœ…

5. **RAG ìµœì í™”**
   - ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ
   - ì¤‘ë³µ ì œê±°

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ì œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!"""
        
        return self._call_vlm(image_data, prompt, temperature=0.1, max_tokens=6000)
    
    def _extract_stop_names(self, ocr_text: str) -> List[str]:
        """OCR í…ìŠ¤íŠ¸ì—ì„œ ì •ë¥˜ì¥ ì´ë¦„ ì¶”ì¶œ"""
        if not ocr_text:
            return []
        
        # í•œê¸€ì´ í¬í•¨ëœ ë¼ì¸ë§Œ ì¶”ì¶œ
        lines = ocr_text.split('\n')
        stop_names = []
        
        for line in lines:
            clean = line.strip()
            # í•œê¸€ì´ ìˆê³ , 3ê¸€ì ì´ìƒ, 50ê¸€ì ì´í•˜
            if re.search(r'[ê°€-í£]', clean) and 3 <= len(clean) <= 50:
                # ìˆ«ìë§Œ ìˆëŠ” ì¤„ ì œì™¸
                if not clean.replace(' ', '').isdigit():
                    stop_names.append(clean)
        
        return stop_names
    
    def _extract_simple(self, image_data: str, structure: Dict) -> str:
        """Step 3: VLM ë‹¨ë… ì¶”ì¶œ (Simple)"""
        
        prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ¯ ì„ë¬´: ì´ í˜ì´ì§€ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”

### ğŸ“‹ ì¶œë ¥ í˜•ì‹

ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

#### ì„¹ì…˜ êµ¬ë¶„
- `---`ë¡œ ì£¼ìš” ì„¹ì…˜ êµ¬ë¶„
- RAG ì¹œí™”ì  ì²­í‚¹

#### ì˜ˆì‹œ:
```markdown
#### [ì„¹ì…˜ ì œëª©]

[ìì—°ì–´ ì„¤ëª…]

**ë°ì´í„°:**
- í•­ëª©1: ê°’1
- í•­ëª©2: ê°’2

---

#### [ë‹¤ìŒ ì„¹ì…˜]
...
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## âœ… í•„ìˆ˜ ê·œì¹™

1. **ì •í™•ì„± ìµœìš°ì„ **
2. **ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°** (ì²´í¬ë¦¬ìŠ¤íŠ¸, í’ˆì§ˆ ì´ìŠˆ ë“±)
3. **RAG ìµœì í™”** (ê°„ê²°, ëª…í™•)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ì œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!"""
        
        return self._call_vlm(image_data, prompt, temperature=0.1)
    
    def _validate_output(self, content: str, structure: Dict, ocr_text: str) -> tuple[bool, List[str]]:
        """Step 4: ì¶œë ¥ ê²€ì¦ (ê°•í™”)"""
        issues = []
        
        # 1. ìµœì†Œ ê¸¸ì´
        if len(content) < 100:
            issues.append("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ")
        
        # 2. ë°˜ë³µ íŒ¨í„´ ê°ì§€ (í™˜ê°)
        lines = content.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            if len(clean) > 5 and clean.startswith('- '):
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        for line, count in line_counts.items():
            if count >= 10:
                issues.append(f"ë°˜ë³µ íŒ¨í„´ ê°ì§€: '{line}' x{count}")
        
        # 3. ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ í™•ì¸
        expected_diagrams = structure.get('diagram_count', 0)
        actual_diagrams = content.count('**ë‹¤ì´ì–´ê·¸ë¨')
        
        if expected_diagrams > 0 and actual_diagrams < expected_diagrams:
            issues.append(f"ë‹¤ì´ì–´ê·¸ë¨ ëˆ„ë½: {actual_diagrams}/{expected_diagrams}")
        
        # 4. OCR í…ìŠ¤íŠ¸ ë§¤ì¹­ (ìˆëŠ” ê²½ìš°)
        if ocr_text and len(ocr_text) > 100:
            stop_names = self._extract_stop_names(ocr_text)
            if stop_names:
                # OCRì—ì„œ ì¶”ì¶œí•œ ì •ë¥˜ì¥ ì¤‘ contentì— ì—†ëŠ” ê²ƒ
                missing = [name for name in stop_names[:20] if name not in content]
                if len(missing) > len(stop_names) * 0.5:  # 50% ì´ìƒ ëˆ„ë½
                    issues.append(f"OCR ì •ë¥˜ì¥ ëŒ€ëŸ‰ ëˆ„ë½: {len(missing)}/{len(stop_names[:20])}")
        
        # 5. ë¶ˆí•„ìš”í•œ ë‚´ìš© ì²´í¬
        if 'âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸' in content:
            issues.append("ë¶ˆí•„ìš”í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ í¬í•¨")
        if 'âš ï¸ **í’ˆì§ˆ ì´ìŠˆ:**' in content:
            issues.append("ë¶ˆí•„ìš”í•œ í’ˆì§ˆ ì´ìŠˆ ì„¹ì…˜ í¬í•¨")
        
        is_valid = len(issues) == 0
        return is_valid, issues
    
    def _call_vlm(
        self,
        image_data: str,
        prompt: str,
        temperature: float = 0.1,
        max_tokens: int = 4000
    ) -> str:
        """VLM API í˜¸ì¶œ"""
        
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[{
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}"
                                }
                            }
                        ]
                    }],
                    max_tokens=max_tokens,
                    temperature=temperature
                )
                result = response.choices[0].message.content
                
            elif self.provider == "claude":
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[{
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": image_data
                                }
                            },
                            {"type": "text", "text": prompt}
                        ]
                    }]
                )
                result = message.content[0].text
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: {self.provider}")
            
            return result.strip() if result else ""
            
        except Exception as e:
            logger.error(f"âŒ VLM API ì˜¤ë¥˜: {e}")
            return ""
    
    def _parse_json_response(self, response: str) -> Dict:
        """JSON ì‘ë‹µ íŒŒì‹±"""
        import json
        
        try:
            # JSON ë¸”ë¡ ì°¾ê¸°
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # JSON ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ íŒŒì‹±
            return json.loads(response)
            
        except Exception as e:
            logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’
            return {
                'title': 'Unknown',
                'elements': ['text'],
                'complexity': 'medium',
                'diagram_count': 0,
                'has_map': False,
                'estimated_data_points': 10
            }
    
    def _calculate_confidence(self, content: str, structure: Dict, ocr_text: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚° (ê°•í™”)"""
        confidence = 0.95
        
        # 1. ê¸¸ì´ ì²´í¬
        if len(content) < 200:
            confidence -= 0.15
        
        # 2. ë°˜ë³µ íŒ¨í„´ ê°ì§€
        lines = content.split('\n')
        line_counts = {}
        for line in lines:
            clean = line.strip()
            if len(clean) > 5:
                line_counts[clean] = line_counts.get(clean, 0) + 1
        
        max_repeat = max(line_counts.values()) if line_counts else 1
        if max_repeat >= 10:
            confidence -= 0.2
        elif max_repeat >= 5:
            confidence -= 0.1
        
        # 3. ë‹¤ì´ì–´ê·¸ë¨ ê°œìˆ˜ ë§¤ì¹­
        expected = structure.get('diagram_count', 0)
        actual = content.count('**ë‹¤ì´ì–´ê·¸ë¨')
        if expected > 0 and actual < expected:
            confidence -= 0.15
        
        # 4. OCR ë§¤ì¹­ (ìˆëŠ” ê²½ìš°)
        if ocr_text and len(ocr_text) > 100:
            stop_names = self._extract_stop_names(ocr_text)
            if stop_names:
                matched = sum(1 for name in stop_names[:20] if name in content)
                match_rate = matched / len(stop_names[:20])
                if match_rate < 0.5:
                    confidence -= 0.2
        
        # 5. ë¶ˆí•„ìš”í•œ ë‚´ìš©
        if 'âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸' in content or 'âš ï¸ **í’ˆì§ˆ ì´ìŠˆ:**' in content:
            confidence -= 0.05
        
        return max(0.5, min(1.0, confidence))