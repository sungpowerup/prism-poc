"""
core/vlm_service.py
ë©€í‹° VLM í”„ë¡œë°”ì´ë” ì§€ì› (Claude + Ollama)
"""

import os
import logging
import time
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class VLMProvider(ABC):
    """VLM í”„ë¡œë°”ì´ë” ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        pass
    
    @abstractmethod
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str,
        extracted_text: str
    ) -> Dict[str, Any]:
        """ìº¡ì…˜ ìƒì„±"""
        pass
    
    @abstractmethod
    def get_info(self) -> Dict[str, str]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        pass


class AzureOpenAIProvider(VLMProvider):
    """Azure OpenAI í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        self.deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4-vision")
        self.api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
        self.client = None
        
        if self.api_key and self.endpoint:
            try:
                from openai import AzureOpenAI
                self.client = AzureOpenAI(
                    api_key=self.api_key,
                    api_version=self.api_version,
                    azure_endpoint=self.endpoint
                )
                logger.info("Azure OpenAI ì´ˆê¸°í™” ì™„ë£Œ")
            except ImportError:
                logger.warning("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")
            except Exception as e:
                logger.error(f"Azure OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.client is not None
    
    def get_info(self) -> Dict[str, str]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        return {
            'name': 'GPT-4 Vision (Azure)',
            'provider': 'Azure OpenAI',
            'speed': 'âš¡ ë¹ ë¦„ (3-5ì´ˆ)',
            'quality': 'â­â­â­â­â­ ìµœê³ ',
            'cost': 'ğŸ’° ìœ ë£Œ (~$0.015/í˜ì´ì§€)',
            'description': 'Microsoft Azure ê¸°ë°˜. ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë³´ì•ˆ. í•œê¸€ ë¬¸ì„œ ìš°ìˆ˜'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Azure OpenAI API í˜¸ì¶œ"""
        start_time = time.time()
        
        try:
            prompt = self._build_prompt(element_type, extracted_text)
            
            response = self.client.chat.completions.create(
                model=self.deployment,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1500,
                temperature=0.1
            )
            
            processing_time = time.time() - start_time
            caption = response.choices[0].message.content.strip()
            
            # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.prompt_tokens
            output_tokens = response.usage.completion_tokens
            
            # Azure OpenAI GPT-4 Vision ê°€ê²© (ëŒ€ëµì )
            # Input: $10 / 1M tokens
            # Output: $30 / 1M tokens
            cost_usd = (input_tokens * 10 / 1_000_000) + (output_tokens * 30 / 1_000_000)
            
            logger.info(
                f"âœ… Azure OpenAI ì™„ë£Œ | {processing_time:.1f}ì´ˆ | "
                f"í† í°: {input_tokens + output_tokens:,} | ${cost_usd:.4f}"
            )
            
            return {
                'caption': caption,
                'confidence': 0.93,
                'processing_time': processing_time,
                'model': f'GPT-4 Vision ({self.deployment})',
                'provider': 'Azure OpenAI',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens,
                    'cost_usd': cost_usd,
                    'cost_krw': int(cost_usd * 1300)
                }
            }
            
        except Exception as e:
            logger.error(f"Azure OpenAI API ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base = """ì´ í•œê¸€ ë¬¸ì„œ í˜ì´ì§€ë¥¼ ë§¤ìš° ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.

í¬í•¨ ë‚´ìš©:
1. ì œëª©/í—¤ë”
2. ì£¼ìš” ë‚´ìš© (í‘œ/ì°¨íŠ¸/ë‹¤ì´ì–´ê·¸ë¨/ë³¸ë¬¸)
3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ (ë‚ ì§œ, ìˆ«ì, ë¹„ìœ¨)
4. ì‹œê°ì  íŠ¹ì§•

200-600ì, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±"""
        
        if extracted_text and len(extracted_text) > 50:
            return f"""{base}

**OCR í…ìŠ¤íŠ¸ ì°¸ê³ **:
{extracted_text[:2500]}"""
        
        return base


class ClaudeProvider(VLMProvider):
    """Claude API í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.api_key = os.getenv("ANTHROPIC_API_KEY")
        self.client = None
        self.model = "claude-sonnet-4-20250514"
        
        if self.api_key:
            try:
                from anthropic import Anthropic
                self.client = Anthropic(api_key=self.api_key)
                logger.info("Claude API ì´ˆê¸°í™” ì™„ë£Œ")
            except ImportError:
                logger.warning("anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropic")
            except Exception as e:
                logger.error(f"Claude API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.client is not None
    
    def get_info(self) -> Dict[str, str]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        return {
            'name': 'Claude Sonnet 4',
            'provider': 'Anthropic',
            'speed': 'âš¡ ë¹ ë¦„ (2-3ì´ˆ)',
            'quality': 'â­â­â­â­â­ ìµœê³ ',
            'cost': 'ğŸ’° ìœ ë£Œ (~$0.01/í˜ì´ì§€)',
            'description': 'ìµœê³  í’ˆì§ˆì˜ í•œê¸€ ë¬¸ì„œ ì´í•´. í‘œ, ì°¨íŠ¸, ë‹¤ì´ì–´ê·¸ë¨ ì™„ë²½ ë¶„ì„'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Claude API í˜¸ì¶œ"""
        start_time = time.time()
        
        try:
            prompt = self._build_prompt(element_type, extracted_text)
            
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1536,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": image_base64
                                }
                            },
                            {
                                "type": "text",
                                "text": prompt
                            }
                        ]
                    }
                ]
            )
            
            processing_time = time.time() - start_time
            caption = response.content[0].text.strip()
            
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = (input_tokens * 3 / 1_000_000) + (output_tokens * 15 / 1_000_000)
            
            logger.info(
                f"âœ… Claude ì™„ë£Œ | {processing_time:.1f}ì´ˆ | "
                f"í† í°: {input_tokens + output_tokens:,} | ${cost_usd:.4f}"
            )
            
            return {
                'caption': caption,
                'confidence': 0.95,
                'processing_time': processing_time,
                'model': 'Claude Sonnet 4',
                'provider': 'Anthropic',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens,
                    'cost_usd': cost_usd,
                    'cost_krw': int(cost_usd * 1300)
                }
            }
            
        except Exception as e:
            logger.error(f"Claude API ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base = """ì´ í•œê¸€ ë¬¸ì„œ í˜ì´ì§€ë¥¼ ë§¤ìš° ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.

í¬í•¨ ë‚´ìš©:
1. ì œëª©/í—¤ë”
2. ì£¼ìš” ë‚´ìš© (í‘œ/ì°¨íŠ¸/ë‹¤ì´ì–´ê·¸ë¨/ë³¸ë¬¸)
3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ (ë‚ ì§œ, ìˆ«ì, ë¹„ìœ¨)
4. ì‹œê°ì  íŠ¹ì§•

200-600ì, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±"""
        
        if extracted_text and len(extracted_text) > 50:
            return f"""{base}

**OCR í…ìŠ¤íŠ¸ ì°¸ê³ **:
{extracted_text[:2500]}"""
        
        return base


class OllamaProvider(VLMProvider):
    """Ollama ë¡œì»¬ í”„ë¡œë°”ì´ë”"""
    
    def __init__(self, model_name: str):
        self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model = model_name
        self.available = self._check_availability()
    
    def _check_availability(self) -> bool:
        """Ollama ì—°ê²° í™•ì¸"""
        try:
            import requests
            response = requests.get(f"{self.base_url}/api/tags", timeout=3)
            
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                
                if any(self.model in name for name in model_names):
                    logger.info(f"Ollama {self.model} ì‚¬ìš© ê°€ëŠ¥")
                    return True
                else:
                    logger.warning(f"Ollama ëª¨ë¸ '{self.model}' ë¯¸ì„¤ì¹˜")
                    return False
            
            return False
            
        except Exception as e:
            logger.warning(f"Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def is_available(self) -> bool:
        return self.available
    
    def get_info(self) -> Dict[str, str]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        model_info = {
            'llava:7b': {
                'name': 'LLaVA 7B',
                'speed': 'ğŸ¢ ëŠë¦¼ (60-80ì´ˆ)',
                'quality': 'â­â­ ê¸°ë³¸',
                'description': 'ê¸°ë³¸ ëª¨ë¸. í•œê¸€ ì•½í•¨'
            },
            'llava:13b': {
                'name': 'LLaVA 13B',
                'speed': 'ğŸŒ ë§¤ìš° ëŠë¦¼ (90-120ì´ˆ)',
                'quality': 'â­â­â­ ë³´í†µ',
                'description': 'ë” í° ëª¨ë¸. í•œê¸€ ê°œì„ '
            },
            'llama3.2-vision:11b': {
                'name': 'Llama 3.2 Vision 11B',
                'speed': 'ğŸ¢ ëŠë¦¼ (30-60ì´ˆ)',
                'quality': 'â­â­â­ ë³´í†µ',
                'description': 'Meta ìµœì‹ . í•œê¸€ ì¤€ìˆ˜'
            }
        }
        
        info = model_info.get(self.model, {
            'name': self.model,
            'speed': 'â“ ì•Œ ìˆ˜ ì—†ìŒ',
            'quality': 'â“ ì•Œ ìˆ˜ ì—†ìŒ',
            'description': 'ì‚¬ìš©ì ì •ì˜ ëª¨ë¸'
        })
        
        return {
            'name': info['name'],
            'provider': 'Ollama (ë¡œì»¬)',
            'speed': info['speed'],
            'quality': info['quality'],
            'cost': 'âœ… ë¬´ë£Œ',
            'description': info['description']
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Ollama API í˜¸ì¶œ"""
        import requests
        
        start_time = time.time()
        
        try:
            prompt = self._build_prompt(element_type, extracted_text)
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "images": [image_base64],
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "top_p": 0.8,
                        "num_predict": 600
                    }
                },
                timeout=180
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
            
            processing_time = time.time() - start_time
            result_data = response.json()
            caption = result_data.get('response', '').strip()
            
            confidence = self._calculate_confidence(caption, extracted_text)
            
            logger.info(f"âœ… Ollama ì™„ë£Œ | {processing_time:.1f}ì´ˆ | ì‹ ë¢°ë„: {confidence:.2f}")
            
            return {
                'caption': caption,
                'confidence': confidence,
                'processing_time': processing_time,
                'model': self.model,
                'provider': 'Ollama (ë¡œì»¬)',
                'usage': {
                    'cost_usd': 0.0,
                    'cost_krw': 0
                }
            }
            
        except Exception as e:
            logger.error(f"Ollama ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if extracted_text and len(extracted_text) > 50:
            return f"""ì´ í•œê¸€ ë¬¸ì„œ í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

OCR í…ìŠ¤íŠ¸:
{extracted_text[:2000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë³´ê³  200-500ìë¡œ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”:
- ì œëª©/í—¤ë”
- ì£¼ìš” ë‚´ìš© (í‘œ/ì°¨íŠ¸/ë³¸ë¬¸)
- êµ¬ì²´ì ì¸ ê°’ë“¤
- ë ˆì´ì•„ì›ƒ

í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""
        else:
            return """ì´ í•œê¸€ ë¬¸ì„œ í˜ì´ì§€ë¥¼ 200-500ìë¡œ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”:
- ì œëª©
- ë‚´ìš©
- êµ¬ì¡°
í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""
    
    def _calculate_confidence(self, caption: str, extracted_text: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.70
        
        if len(caption) > 150:
            confidence += 0.10
        
        korean_chars = sum(1 for c in caption if 'ê°€' <= c <= 'í£')
        total_chars = len(caption.replace(' ', ''))
        
        if total_chars > 0 and korean_chars / total_chars > 0.5:
            confidence += 0.10
        
        import re
        if len(re.findall(r'\d+', caption)) >= 3:
            confidence += 0.05
        
        return min(0.90, confidence)


class VLMService:
    """ë©€í‹° í”„ë¡œë°”ì´ë” VLM ì„œë¹„ìŠ¤"""
    
    def __init__(self, provider_name: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            provider_name: í”„ë¡œë°”ì´ë” ì´ë¦„ ('claude', 'llava:7b', 'llama3.2-vision:11b' ë“±)
        """
        self.providers = self._initialize_providers()
        self.current_provider = None
        
        if provider_name:
            self.set_provider(provider_name)
        else:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ í”„ë¡œë°”ì´ë” ì„ íƒ
            self._select_default_provider()
    
    def _initialize_providers(self) -> Dict[str, VLMProvider]:
        """ëª¨ë“  í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”"""
        providers = {
            'claude': ClaudeProvider(),
            'llava:7b': OllamaProvider('llava:7b'),
            'llava:13b': OllamaProvider('llava:13b'),
            'llama3.2-vision:11b': OllamaProvider('llama3.2-vision:11b'),
        }
        
        return providers
    
    def _select_default_provider(self):
        """ê¸°ë³¸ í”„ë¡œë°”ì´ë” ì„ íƒ"""
        # Claude ìš°ì„ , ì—†ìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸
        for name in ['claude', 'llama3.2-vision:11b', 'llava:13b', 'llava:7b']:
            if self.providers[name].is_available():
                self.current_provider = self.providers[name]
                logger.info(f"ê¸°ë³¸ í”„ë¡œë°”ì´ë” ì„ íƒ: {name}")
                return
        
        raise RuntimeError(
            "ì‚¬ìš© ê°€ëŠ¥í•œ VLM í”„ë¡œë°”ì´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            "1. Claude API: .envì— ANTHROPIC_API_KEY ì¶”ê°€\n"
            "2. Ollama: ollama pull llama3.2-vision:11b"
        )
    
    def get_available_providers(self) -> Dict[str, Dict[str, str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë” ëª©ë¡"""
        available = {}
        
        for name, provider in self.providers.items():
            if provider.is_available():
                info = provider.get_info()
                info['id'] = name
                available[name] = info
        
        return available
    
    def set_provider(self, provider_name: str) -> bool:
        """í”„ë¡œë°”ì´ë” ë³€ê²½"""
        if provider_name not in self.providers:
            logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œë°”ì´ë”: {provider_name}")
            return False
        
        if not self.providers[provider_name].is_available():
            logger.error(f"í”„ë¡œë°”ì´ë” ì‚¬ìš© ë¶ˆê°€: {provider_name}")
            return False
        
        self.current_provider = self.providers[provider_name]
        logger.info(f"í”„ë¡œë°”ì´ë” ë³€ê²½: {provider_name}")
        return True
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """í˜„ì¬ í”„ë¡œë°”ì´ë”ë¡œ ìº¡ì…˜ ìƒì„±"""
        if not self.current_provider:
            raise RuntimeError("í”„ë¡œë°”ì´ë”ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return await self.current_provider.generate_caption(
            image_base64, element_type, extracted_text
        )
    
    def get_current_provider_info(self) -> Dict[str, str]:
        """í˜„ì¬ í”„ë¡œë°”ì´ë” ì •ë³´"""
        if not self.current_provider:
            return {'name': 'None', 'provider': 'None'}
        
        return self.current_provider.get_info()