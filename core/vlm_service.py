"""
core/vlm_service.py
PRISM Phase 4.2 - VLM Service (ë©€í‹°ìŠ¤í… ê²€ì¦)

âœ… Phase 4.2 ê°œì„ ì‚¬í•­:
1. 2-Pass Processing (êµ¬ì¡° íŒŒì•… â†’ ì •ë°€ ì¶”ì¶œ)
2. ì§€ë„ ì°¨íŠ¸ ì „ìš© í”„ë¡¬í”„íŠ¸
3. ìˆ«ì ì •í™•ë„ ê²€ì¦ ê°•í™”
4. ë²”ìš© í”„ë¡¬í”„íŠ¸ (í•˜ë“œì½”ë”© ì œê±°)
5. ìë™ ì²­í‚¹ (ì„¹ì…˜ êµ¬ë¶„)

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-23
Version: 4.2
"""

import os
import logging
from typing import Dict, Any, Optional
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV42:
    """
    Vision Language Model ì„œë¹„ìŠ¤ v4.2
    
    Phase 4.2 íŠ¹ì§•:
    - 2-Pass ë©€í‹°ìŠ¤í… ì²˜ë¦¬
    - ê°•í™”ëœ í”„ë¡¬í”„íŒ…
    - ë²”ìš©ì„± í™•ë³´
    """
    
    def __init__(self, provider: str = "azure_openai"):
        """VLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            logger.info(f"âœ… Azure OpenAI ì´ˆê¸°í™”: {deployment}")
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
            logger.info(f"âœ… Claude ì´ˆê¸°í™”: {self.model}")
        
        else:
            raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: {provider}")
        
        logger.info(f"âœ… VLM Service v4.2 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def analyze_page_multipass(
        self,
        image_data: str,
        page_num: int
    ) -> Dict[str, Any]:
        """
        2-Pass ë©€í‹°ìŠ¤í… í˜ì´ì§€ ë¶„ì„ (Phase 4.2)
        
        Pass 1: êµ¬ì¡° íŒŒì•…
        Pass 2: ì •ë°€ ì¶”ì¶œ
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            {
                'content': str,  # ìµœì¢… Markdown
                'pass1_structure': dict,  # Pass 1 êµ¬ì¡° ì •ë³´
                'confidence': float  # ì‹ ë¢°ë„
            }
        """
        logger.info(f"ğŸ¯ Page {page_num}: 2-Pass ë¶„ì„ ì‹œì‘")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Pass 1: êµ¬ì¡° íŒŒì•…
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Pass 1] êµ¬ì¡° íŒŒì•…...")
        pass1_prompt = self._get_pass1_prompt()
        pass1_result = self._call_vlm(image_data, pass1_prompt, temperature=0.2)
        
        # Pass 1 ê²°ê³¼ íŒŒì‹±
        structure = self._parse_structure(pass1_result)
        logger.info(f"  [Pass 1] ê°ì§€: {structure.get('chart_types', [])}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Pass 2: ì •ë°€ ì¶”ì¶œ
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info(f"  [Pass 2] ì •ë°€ ì¶”ì¶œ...")
        pass2_prompt = self._get_pass2_prompt(structure)
        pass2_result = self._call_vlm(image_data, pass2_prompt, temperature=0.1)
        
        # ìµœì¢… ê²°ê³¼
        return {
            'content': pass2_result,
            'pass1_structure': structure,
            'confidence': self._calculate_confidence(pass2_result)
        }
    
    def _get_pass1_prompt(self) -> str:
        """Pass 1: êµ¬ì¡° íŒŒì•… í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ í˜ì´ì§€ì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

ğŸ¯ **ëª©í‘œ: ë ˆì´ì•„ì›ƒ ì´í•´ (ë°ì´í„° ì¶”ì¶œ ì•„ë‹˜)**

ë‹¤ìŒ ì •ë³´ë§Œ ê°„ë‹¨íˆ íŒŒì•…:
1. **í˜ì´ì§€ ì œëª©/ì„¹ì…˜**: í° ì œëª©ì´ ìˆë‚˜ìš”?
2. **ì°¨íŠ¸ ì¢…ë¥˜**: ì›ê·¸ë˜í”„, ë§‰ëŒ€ê·¸ë˜í”„, ì§€ë„, í‘œ ë“± ì–´ë–¤ ì°¨íŠ¸ê°€ ìˆë‚˜ìš”?
3. **ì§€ë„ ì°¨íŠ¸ ì—¬ë¶€**: í•œêµ­ ì§€ë„ê°€ ìˆë‚˜ìš”? (ì§€ì—­ ë¼ë²¨ í™•ì¸)
4. **ì„¹ì…˜ ê°œìˆ˜**: ëª‡ ê°œì˜ ë…ë¦½ì ì¸ ì„¹ì…˜(â˜‰, â— ë“±)ìœ¼ë¡œ ë‚˜ë‰˜ë‚˜ìš”?

JSONìœ¼ë¡œ ì‘ë‹µ:
```json
{
  "title": "í˜ì´ì§€ ì œëª©",
  "has_map_chart": true/false,
  "chart_types": ["pie", "bar", "map", "table"],
  "section_count": 3,
  "complexity": "simple/medium/high"
}
```

ê°„ë‹¨íˆ! ë°ì´í„°ëŠ” Pass 2ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    def _get_pass2_prompt(self, structure: Dict) -> str:
        """Pass 2: ì •ë°€ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (êµ¬ì¡° ì •ë³´ í™œìš©)"""
        
        has_map = structure.get('has_map_chart', False)
        complexity = structure.get('complexity', 'medium')
        
        base_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì´ í˜ì´ì§€ë¥¼ **ì™„ë²½í•œ ì •í™•ë„**ë¡œ ë¶„ì„í•˜ì„¸ìš”.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ¯ Phase 4.2 í•µì‹¬ ì›ì¹™

### âš ï¸ ì ˆëŒ€ ì¤€ìˆ˜ ì‚¬í•­ (CRITICAL)

1. **100% ì›ë³¸ ì¶©ì‹¤ë„**
   - í…ìŠ¤íŠ¸ë¥¼ **í•œ ê¸€ìë„** ë°”ê¾¸ì§€ ë§ ê²ƒ
   - ìˆ«ìë¥¼ **ì ˆëŒ€** ë°˜ì˜¬ë¦¼í•˜ì§€ ë§ ê²ƒ
   - ì§€ì—­ëª…/ë‹¨ìœ„ë¥¼ **ì ˆëŒ€** ë³€ê²½í•˜ì§€ ë§ ê²ƒ

2. **ë°ì´í„° ì •í™•ì„± ê²€ì¦**
   - ë°±ë¶„ìœ¨ í•©ê³„ê°€ 99~101%ì¸ì§€ í™•ì¸
   - ëª¨ë“  ìˆ«ìë¥¼ **ë‘ ë²ˆ** í™•ì¸
   - ì• ë§¤í•˜ë©´ **ë‹¤ì‹œ ë³´ê¸°**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ“‹ ì¶œë ¥ í˜•ì‹

### ì„¹ì…˜ êµ¬ë¶„ ê·œì¹™
- ê° ë…ë¦½ì ì¸ ì£¼ì œëŠ” `---`ë¡œ êµ¬ë¶„
- RAG ì¹œí™”ì  ì²­í‚¹ ì œê³µ

### ì˜ˆì‹œ:
```markdown
### [í˜ì´ì§€ ì œëª©]

---

#### [ì„¹ì…˜ 1 ì œëª©]

[ìì—°ì–´ ì„¤ëª…]

**ë°ì´í„°:**
- í•­ëª©1: ê°’1
- í•­ëª©2: ê°’2

---

#### [ì„¹ì…˜ 2 ì œëª©]

[ìì—°ì–´ ì„¤ëª…]

**ë°ì´í„°:**
- ...

---
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ“Š ì°¨íŠ¸ë³„ ê°€ì´ë“œ

### ì›ê·¸ë˜í”„/ë§‰ëŒ€ê·¸ë˜í”„
- ì •í™•í•œ ë°±ë¶„ìœ¨ ë˜ëŠ” ê°’ ì¶”ì¶œ
- í•©ê³„ ê²€ì¦ (99~101%)

### í‘œ (Table)
- Markdown í‘œ í˜•ì‹
- ëª¨ë“  ì…€ ì •í™•íˆ
"""

        # ì§€ë„ ì°¨íŠ¸ íŠ¹ìˆ˜ ì²˜ë¦¬
        if has_map:
            base_prompt += """
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ—ºï¸ ì§€ë„ ì°¨íŠ¸ íŠ¹ë³„ ì§€ì¹¨ (CRITICAL)

âš ï¸ **ì´ í˜ì´ì§€ì—ëŠ” í•œêµ­ ì§€ë„ ì°¨íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤!**

### ì§€ë„ ì½ê¸° ë°©ë²•:
1. **ì§€ë„ë¥¼ ì²œì²œíˆ ìŠ¤ìº”**
   - ê° ì§€ì—­ ë¼ë²¨ì„ ì°¾ìœ¼ì„¸ìš”
   - ë¼ë²¨ ì˜† ìˆ«ìë¥¼ ì •í™•íˆ ì½ìœ¼ì„¸ìš”

2. **ì§€ì—­ëª… ê·¸ëŒ€ë¡œ ì¶”ì¶œ**
   - ë³´ì´ëŠ” ê·¸ëŒ€ë¡œ ì‘ì„± (ë³€ê²½ ê¸ˆì§€)
   - ì˜ˆ: "ê°•ì›/ì œì£¼" â†’ "ê°•ì›/ì œì£¼" âœ…
   - ì˜ˆ: "ê°•ì›/ì œì£¼" â†’ "ê°•ì›ê¶Œ", "ì œì£¼ê¶Œ" âŒ (ë¶„ë¦¬ ê¸ˆì§€!)

3. **ìˆ«ì ì •í™•íˆ**
   - ì†Œìˆ˜ì  ì´í•˜ê¹Œì§€
   - ë°˜ì˜¬ë¦¼ ê¸ˆì§€

4. **ê²€ì¦**
   - ì§€ì—­ë³„ í•©ê³„ê°€ 99~101%ì¸ì§€ í™•ì¸
   - í‹€ë¦¬ë©´ ë‹¤ì‹œ ì½ê¸°!

### ì¶œë ¥ ì˜ˆì‹œ:
```markdown
**ê¶Œì—­ë³„ ë¶„í¬:**
- ìˆ˜ë„ê¶Œ: XX.X%
- ì¶©ì²­ê¶Œ: XX.X%
- ì „ë¼ê¶Œ: XX.X%
- ê²½ë¶ê¶Œ: XX.X%
- ê²½ë‚¨ê¶Œ: XX.X%
- ê°•ì›/ì œì£¼ê¶Œ: XX.X%

(í•©ê³„: 100.0%)
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

        base_prompt += """
## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì¶œë ¥ ì „ì— í™•ì¸:
- [ ] ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œ
- [ ] ëª¨ë“  ìˆ«ìë¥¼ ì •í™•íˆ ì¶”ì¶œ (ì†Œìˆ˜ì  í¬í•¨)
- [ ] ë°±ë¶„ìœ¨ í•©ê³„ê°€ 99~101% ë²”ìœ„
- [ ] ì§€ì—­ëª…/ìš©ì–´ë¥¼ ë³€ê²½í•˜ì§€ ì•ŠìŒ
- [ ] ì„¹ì…˜ì„ `---`ë¡œ êµ¬ë¶„
- [ ] ìì—°ì–´ ì„¤ëª… í¬í•¨

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ì œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”. **ì •í™•ë„ê°€ ìƒëª…ì…ë‹ˆë‹¤!**
"""
        
        return base_prompt
    
    def _call_vlm(
        self,
        image_data: str,
        prompt: str,
        temperature: float = 0.1
    ) -> str:
        """VLM API í˜¸ì¶œ"""
        
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[{
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_data}"
                                }
                            }
                        ]
                    }],
                    max_tokens=4000,
                    temperature=temperature
                )
                result = response.choices[0].message.content
                
            elif self.provider == "claude":
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=4000,
                    temperature=temperature,
                    messages=[{
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": image_data
                                }
                            },
                            {"type": "text", "text": prompt}
                        ]
                    }]
                )
                result = message.content[0].text
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: {self.provider}")
            
            return result.strip() if result else ""
            
        except Exception as e:
            logger.error(f"âŒ VLM API ì˜¤ë¥˜: {e}")
            return ""
    
    def _parse_structure(self, pass1_result: str) -> Dict:
        """Pass 1 ê²°ê³¼ íŒŒì‹±"""
        import json
        import re
        
        try:
            # JSON ë¸”ë¡ ì°¾ê¸°
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', pass1_result, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # JSON ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ íŒŒì‹± ì‹œë„
            return json.loads(pass1_result)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Pass 1 íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'title': 'Unknown',
                'has_map_chart': False,
                'chart_types': [],
                'section_count': 1,
                'complexity': 'medium'
            }
    
    def _calculate_confidence(self, content: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        import re
        
        # ë°±ë¶„ìœ¨ ê²€ì¦
        percentages = re.findall(r'(\d+\.?\d*)%', content)
        
        if len(percentages) < 3:
            return 0.9  # ë°±ë¶„ìœ¨ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ë°±ë¶„ìœ¨ ê·¸ë£¹ ì°¾ê¸°
        values = [float(p) for p in percentages]
        
        # ì—°ì†ëœ ë°±ë¶„ìœ¨ì´ 99~101% í•©ê³„ë¥¼ ì´ë£¨ëŠ”ì§€ í™•ì¸
        for i in range(len(values)):
            group_sum = values[i]
            for j in range(i+1, min(i+10, len(values))):
                group_sum += values[j]
                
                if 99.0 <= group_sum <= 101.0:
                    return 0.95  # ê²€ì¦ ì„±ê³µ
                
                if group_sum > 105.0:
                    break
        
        return 0.7  # ê²€ì¦ ì‹¤íŒ¨