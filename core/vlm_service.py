"""
core/vlm_service.py
PRISM Phase 5.1.1 - VLM Service (RAG ìµœì í™” ê°•í™”)
"""

import os
import logging
import json
import re
from typing import Dict, Any
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv

from .document_classifier import DocumentClassifierV50

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV50:
    """ë²”ìš© VLM ì„œë¹„ìŠ¤ v5.1.1 - RAG ìµœì í™” ê°•í™”"""
    
    def __init__(self, provider: str = "azure_openai"):
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
        
        self.classifier = DocumentClassifierV50(provider)
        logger.info(f"âœ… VLM Service v5.1.1 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def analyze_page_v50(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """Phase 5.1.1: RAG ìµœì í™” ê°•í™” ë¬¸ì„œ ë¶„ì„"""
        logger.info(f"ðŸŽ¯ Page {page_num}: Phase 5.1.1 ë¶„ì„ ì‹œìž‘")
        
        doc_type_result = self.classifier.classify(image_data, page_num)
        doc_type = doc_type_result.get('type', 'mixed')
        subtype = doc_type_result.get('subtype', 'unknown')
        confidence = doc_type_result.get('confidence', 0.5)
        
        logger.info(f"âœ… íƒ€ìž…: {doc_type} ({subtype}), ì‹ ë¢°ë„: {confidence:.2f}")
        
        if doc_type == 'text_document':
            content = self._extract_text_document(image_data, subtype)
        elif doc_type == 'diagram':
            content = self._extract_diagram(image_data, subtype)
        elif doc_type == 'technical_drawing':
            content = self._extract_technical_drawing(image_data, subtype)
        elif doc_type == 'image_content':
            content = self._extract_image_content(image_data, subtype)
        elif doc_type == 'chart_statistics':
            content = self._extract_chart_statistics(image_data, subtype)
        else:
            content = self._extract_mixed(image_data)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)} ê¸€ìž")
        
        quality_score = self._calculate_quality(content, doc_type)
        
        return {
            'content': content,
            'confidence': confidence,
            'strategy': f'{doc_type}_v511',
            'doc_type': doc_type,
            'subtype': subtype,
            'quality_score': quality_score,
            'structure': doc_type_result
        }
    
    def _extract_text_document(self, image_data: str, subtype: str) -> str:
        prompt = f"""ì´ {subtype} ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**ê·œì¹™:**
1. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•ížˆ ì¶”ì¶œ
2. ì¡°í•­/í•­ ë²ˆí˜¸ ì •í™•ížˆ ë³´ì¡´
3. í‘œëŠ” Markdown í‘œë¡œ ë³€í™˜

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª… ("ì´ ì´ë¯¸ì§€ëŠ”", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤", "ì•„ëž˜ëŠ”")
- ì•ˆë‚´ ë¬¸êµ¬ ("í•„ìš”í•˜ì‹ ", "ë§ì”€í•´ ì£¼ì„¸ìš”", "ìž¬êµ¬ì„± ê°€ëŠ¥")
- ìš”ì•½ ì„¹ì…˜ ("**ìš”ì•½:**", "**êµ¬ì¡° ìš”ì•½:**")

**ì˜¤ì§ ì›ë³¸ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.**"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_diagram(self, image_data: str, subtype: str) -> str:
        if subtype == 'transport_route':
            prompt = """ì´ êµí†µ ë…¸ì„ ë„ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë…¸ì„  ì •ë³´
**ë…¸ì„ ëª…**: [ë…¸ì„ ë²ˆí˜¸/ì´ë¦„]

### ê²½ë¡œ
1. [ì •ë¥˜ìž¥ 1]
2. [ì •ë¥˜ìž¥ 2]

**ì ˆëŒ€ ê¸ˆì§€:**
- "ë‹¤ì´ì–´ê·¸ëž¨ì˜ êµ¬ì¡°ëŠ”", "í•„ìš”í•˜ì‹ ", "ìž¬êµ¬ì„± ê°€ëŠ¥" ë“±
- ì˜¤ì§ ë…¸ì„  ì •ë³´ë§Œ ì¶œë ¥"""
        else:
            prompt = """ì´ ë‹¤ì´ì–´ê·¸ëž¨ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬, ìš”ì•½
- ì˜¤ì§ ë‹¤ì´ì–´ê·¸ëž¨ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_technical_drawing(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ë„ë©´ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

## í‰ë©´ë„

### ê³µê°„ êµ¬ì„±
1. **[ê³µê°„ ì´ë¦„]** ([ë©´ì ])
   - ìœ„ì¹˜: [ë°©í–¥/ìœ„ì¹˜]
   - ì¹˜ìˆ˜: [ê°€ë¡œ Ã— ì„¸ë¡œ]

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬
- ì˜¤ì§ ë„ë©´ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_image_content(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

## ì´ë¯¸ì§€ ì„¤ëª…

### ì£¼ìš” ìš”ì†Œ
- [ìš”ì†Œ]: [ì„¤ëª…]

### ì‹œê°ì  íŠ¹ì§•
- ìƒ‰ìƒ: [ì£¼ìš” ìƒ‰ìƒ]
- ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼]

**ì ˆëŒ€ ê¸ˆì§€:**
- "ì´ ì´ë¯¸ì§€ëŠ”", "ì•„ëž˜ëŠ”" ë“± ë©”íƒ€ ì„¤ëª…
- ì˜¤ì§ ì´ë¯¸ì§€ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_chart_statistics(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì°¨íŠ¸/í‘œì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

## ë°ì´í„°

**ì°¨íŠ¸ ì œëª©**: [ì œëª©]

### ë°ì´í„° í…Œì´ë¸”
| í•­ëª© | ê°’ 1 | ê°’ 2 |
|------|------|------|
| í–‰ 1 | [ê°’] | [ê°’] |

**ì ˆëŒ€ ê¸ˆì§€:**
- "ì•„ëž˜ëŠ” ì´ë¯¸ì§€ì˜ ì°¨íŠ¸/í‘œì—ì„œ ì¶”ì¶œí•œ"
- "í•„ìš”í•œ ë°ì´í„°ê°€ ë” ìžˆìœ¼ë©´"
- ì˜¤ì§ ì°¨íŠ¸/í‘œ ë°ì´í„°ë§Œ ì¶œë ¥"""
        return self._call_vlm(image_data, prompt)
    
    def _extract_mixed(self, image_data: str) -> str:
        prompt = """ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬, ìš”ì•½
- ì˜¤ì§ ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self._call_vlm(image_data, prompt)
    
    def _call_vlm(self, image_data: str, prompt: str) -> str:
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/png;base64,{image_data}"}
                                }
                            ]
                        }
                    ],
                    max_tokens=2000,
                    temperature=0.2
                )
                return response.choices[0].message.content.strip()
            else:
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.2,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_data
                                    }
                                },
                                {"type": "text", "text": prompt}
                            ]
                        }
                    ]
                )
                return response.content[0].text.strip()
        except Exception as e:
            logger.error(f"âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"## ì¶”ì¶œ ì‹¤íŒ¨\nì˜¤ë¥˜: {str(e)}"
    
    def _calculate_quality(self, content: str, doc_type: str) -> float:
        score = 100.0
        if len(content) < 50:
            score -= 30
        headers = re.findall(r'^#+\s+', content, re.MULTILINE)
        if len(headers) == 0:
            score -= 20
        elif len(headers) >= 3:
            score += 10
        return max(0.0, min(100.0, score))