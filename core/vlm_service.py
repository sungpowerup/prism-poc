"""
core/vlm_service.py

VLM (Vision Language Model) API í†µí•© ì„œë¹„ìŠ¤
âœ… í”„ë¡¬í”„íŠ¸ ë¡œë”© ê°œì„  (import ë¬¸ì œ í•´ê²°)
"""

import os
import sys
import base64
import time
from pathlib import Path
from typing import Optional, Dict, Any
from anthropic import Anthropic
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VLMService:
    """VLM API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ (custom_prompt ì§€ì›)"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.api_key = api_key or os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = Anthropic(api_key=self.api_key)
        self.model = "claude-sonnet-4-20250514"
        
        # âœ… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        self.prompts = self._load_prompts()
        
        logger.info(f"âœ… VLMService ì´ˆê¸°í™” ì™„ë£Œ (model: {self.model})")
        logger.info(f"ğŸ“‹ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸: {list(self.prompts.keys())}")
    
    def _load_prompts(self) -> Dict[str, str]:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ (ê°œì„  ë²„ì „)
        
        Returns:
            í”„ë¡¬í”„íŠ¸ ë”•ì…”ë„ˆë¦¬
        """
        prompts = {}
        
        # 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ í™•ì¸
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent  # prism-poc/
        prompts_dir = project_root / 'prompts'
        
        logger.info(f"ğŸ“‚ í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬: {prompts_dir}")
        
        # 2. prompts ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
        if str(prompts_dir.parent) not in sys.path:
            sys.path.insert(0, str(prompts_dir.parent))
            logger.info(f"âœ… sys.pathì— ì¶”ê°€: {prompts_dir.parent}")
        
        # 3. ê° í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
        prompt_files = {
            'chart': 'chart_prompt',
            'table': 'table_prompt',
            'image': 'image_prompt',
            'diagram': 'diagram_prompt'
        }
        
        for element_type, module_name in prompt_files.items():
            try:
                # ë™ì  import
                module = __import__(f'prompts.{module_name}', fromlist=['PROMPT'])
                prompt_text = getattr(module, 'PROMPT', None)
                
                if prompt_text and len(prompt_text) > 100:
                    prompts[element_type] = prompt_text
                    # í”„ë¡¬í”„íŠ¸ ì²« 100ì ë¯¸ë¦¬ë³´ê¸°
                    preview = prompt_text[:100].replace('\n', ' ')
                    logger.info(f"âœ… {element_type}: {preview}...")
                    logger.info(f"   ê¸¸ì´: {len(prompt_text)} ì")
                else:
                    logger.warning(f"âš ï¸  {element_type}: PROMPTê°€ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ")
                    prompts[element_type] = self._get_fallback_prompt(element_type)
                    
            except ImportError as e:
                logger.error(f"âŒ {element_type} í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                prompts[element_type] = self._get_fallback_prompt(element_type)
            except Exception as e:
                logger.error(f"âŒ {element_type} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                prompts[element_type] = self._get_fallback_prompt(element_type)
        
        # 4. ê¸°ë³¸ text í”„ë¡¬í”„íŠ¸
        prompts['text'] = "ì´ ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        
        return prompts
    
    def _get_fallback_prompt(self, element_type: str) -> str:
        """
        í´ë°± í”„ë¡¬í”„íŠ¸ (ì§§ì§€ë§Œ ëª…í™•í•˜ê²Œ)
        
        Args:
            element_type: Element íƒ€ì…
            
        Returns:
            í´ë°± í”„ë¡¬í”„íŠ¸
        """
        fallback_prompts = {
            'chart': """ì´ ì°¨íŠ¸ë¥¼ ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì„¸ìš”.

**ì¤‘ìš”**: ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í¬í•¨í•˜ê³ , êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”. ìš”ì•½í•˜ì§€ ë§ˆì„¸ìš”.

1. ì°¨íŠ¸ ìœ í˜• ë° ì£¼ì œ
2. ì¶• ì •ë³´ (ë³€ìˆ˜ëª…, ë‹¨ìœ„, ë²”ìœ„)
3. ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ ë‚˜ì—´
4. íŠ¸ë Œë“œ ë° íŒ¨í„´
5. ë¹„êµ ë° ì¸ì‚¬ì´íŠ¸""",
            
            'table': """ì´ í‘œë¥¼ ì™„ì „í•œ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì„¸ìš”.

**ì ˆëŒ€ ê·œì¹™**: 
- í‘œì˜ **ëª¨ë“  í–‰**ì„ ë°˜ë“œì‹œ ë³€í™˜
- "ì´ Nê°œ" ê°™ì€ ìš”ì•½ í‘œí˜„ ê¸ˆì§€
- ê° í–‰ë§ˆë‹¤ "ì²« ë²ˆì§¸ í•­ëª©..., ë‘ ë²ˆì§¸ í•­ëª©..." í˜•ì‹

1. í‘œ êµ¬ì¡° ì„¤ëª… (í—¤ë” ë‚˜ì—´)
2. ê° í–‰ì„ ìˆœì„œëŒ€ë¡œ ì™„ì „íˆ ì„œìˆ 
3. íŒ¨í„´ ë° ì¸ì‚¬ì´íŠ¸ (ì„ íƒ)""",
            
            'image': "ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”. ì£¼ìš” ìš”ì†Œ, ë°°ê²½, í…ìŠ¤íŠ¸ ë“±ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.",
            
            'diagram': "ì´ ë‹¤ì´ì–´ê·¸ë¨ì˜ êµ¬ì¡°ì™€ íë¦„ì„ ì„¤ëª…í•˜ì„¸ìš”. ëª¨ë“  êµ¬ì„± ìš”ì†Œì™€ ì—°ê²° ê´€ê³„ë¥¼ í¬í•¨í•˜ì„¸ìš”."
        }
        
        return fallback_prompts.get(element_type, "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.")
    
    def generate_caption(
        self, 
        image_data: bytes, 
        element_type: str,
        max_retries: int = 3,
        custom_prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ë¥¼ ìì—°ì–´ ìº¡ì…˜ìœ¼ë¡œ ë³€í™˜
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            element_type: Element íƒ€ì… (chart/table/image/diagram/text)
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì˜µì…˜)
            
        Returns:
            {
                'caption': str,
                'confidence': float,
                'processing_time_ms': int,
                'tokens_used': int,
                'cost_usd': float
            }
        """
        start_time = time.time()
        
        # âœ… í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if custom_prompt:
            prompt = custom_prompt
            logger.info("âœ… Custom prompt ì‚¬ìš©")
        else:
            prompt = self.prompts.get(element_type, self.prompts.get('text', 'ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.'))
            logger.info(f"ğŸ“‹ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (type: {element_type}, ê¸¸ì´: {len(prompt)} ì)")
        
        # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        image_b64 = base64.b64encode(image_data).decode('utf-8')
        
        # API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§)
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ VLM API í˜¸ì¶œ (attempt {attempt + 1}/{max_retries})")
                
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=4096,  # âœ… ì¦ê°€ (ì™„ì „ ë³€í™˜ ìœ„í•´)
                    temperature=0.3,  # âœ… ë‚®ì¶¤ (ë” ê²°ì •ì )
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_b64
                                    }
                                },
                                {
                                    "type": "text",
                                    "text": prompt
                                }
                            ]
                        }
                    ]
                )
                
                # ì‘ë‹µ íŒŒì‹±
                caption = response.content[0].text
                
                # í† í° ì‚¬ìš©ëŸ‰
                input_tokens = response.usage.input_tokens
                output_tokens = response.usage.output_tokens
                total_tokens = input_tokens + output_tokens
                
                # ë¹„ìš© ê³„ì‚° (Claude Sonnet 4 ê¸°ì¤€)
                # Input: $3 / 1M tokens, Output: $15 / 1M tokens
                input_cost = (input_tokens / 1_000_000) * 3.0
                output_cost = (output_tokens / 1_000_000) * 15.0
                total_cost = input_cost + output_cost
                
                # ì²˜ë¦¬ ì‹œê°„
                processing_time = int((time.time() - start_time) * 1000)
                
                # ì‹ ë¢°ë„ ì¶”ì •
                confidence = self._estimate_confidence(caption, element_type)
                
                logger.info(f"âœ… VLM ì‘ë‹µ ì„±ê³µ (tokens: {total_tokens}, cost: ${total_cost:.6f})")
                
                return {
                    'caption': caption,
                    'confidence': confidence,
                    'processing_time_ms': processing_time,
                    'tokens_used': total_tokens,
                    'cost_usd': total_cost
                }
                
            except Exception as e:
                logger.error(f"âŒ VLM API ì˜¤ë¥˜ (attempt {attempt + 1}): {str(e)}")
                
                if attempt == max_retries - 1:
                    return {
                        'caption': None,
                        'confidence': 0.0,
                        'processing_time_ms': int((time.time() - start_time) * 1000),
                        'tokens_used': 0,
                        'cost_usd': 0.0,
                        'error': str(e)
                    }
                
                # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                time.sleep(2 ** attempt)
    
    def _estimate_confidence(self, caption: str, element_type: str) -> float:
        """
        ì‹ ë¢°ë„ ì¶”ì •
        
        Args:
            caption: ìƒì„±ëœ ìº¡ì…˜
            element_type: Element íƒ€ì…
            
        Returns:
            ì‹ ë¢°ë„ (0.0 ~ 1.0)
        """
        if not caption:
            return 0.0
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ (ê¸¸ì´ ê¸°ë°˜)
        base_confidence = min(0.7 + len(caption) / 5000, 0.9)
        
        # íƒ€ì…ë³„ í‚¤ì›Œë“œ ì²´í¬
        keywords = {
            'chart': ['ì°¨íŠ¸', 'ê·¸ë˜í”„', 'ë°ì´í„°', 'ìˆ˜ì¹˜', 'ì¶”ì´', 'ì¦ê°€', 'ê°ì†Œ', 'ë¹„ìœ¨'],
            'table': ['í‘œ', 'í–‰', 'ì—´', 'í•­ëª©', 'ì²« ë²ˆì§¸', 'ë‘ ë²ˆì§¸', 'ë…¸ì„ ', 'í˜ì´ì§€'],
            'image': ['ì´ë¯¸ì§€', 'ì‚¬ì§„', 'ê·¸ë¦¼', 'ë³´ì—¬ì£¼'],
            'diagram': ['ë‹¤ì´ì–´ê·¸ë¨', 'ë„ì‹', 'êµ¬ì¡°', 'íë¦„', 'í”„ë¡œì„¸ìŠ¤'],
            'text': ['í…ìŠ¤íŠ¸', 'ë¬¸ì„œ', 'ë‚´ìš©', 'ì •ë³´']
        }
        
        element_keywords = keywords.get(element_type, [])
        keyword_matches = sum(1 for kw in element_keywords if kw in caption)
        
        # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
        keyword_bonus = min(keyword_matches * 0.02, 0.1)
        
        # ìµœì¢… ì‹ ë¢°ë„
        confidence = min(base_confidence + keyword_bonus, 1.0)
        
        return confidence
    
    def batch_generate_captions(
        self, 
        elements: list[Dict[str, Any]]
    ) -> list[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ Elementë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        
        Args:
            elements: Element ë¦¬ìŠ¤íŠ¸
                [{'image_data': bytes, 'type': str, 'id': str}, ...]
        
        Returns:
            ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, elem in enumerate(elements):
            logger.info(f"ğŸ“„ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {i+1}/{len(elements)}")
            
            try:
                result = self.generate_caption(
                    elem['image_data'],
                    elem['type']
                )
                result['element_id'] = elem['id']
                result['status'] = 'success'
                results.append(result)
                
            except Exception as e:
                logger.error(f"âŒ Element {elem['id']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                results.append({
                    'element_id': elem['id'],
                    'status': 'failed',
                    'error': str(e)
                })
        
        return results


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    vlm = VLMService()
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ í™•ì¸
    print("\nğŸ“‹ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸:")
    for element_type, prompt in vlm.prompts.items():
        print(f"\n{element_type}:")
        print(f"  ê¸¸ì´: {len(prompt)} ì")
        print(f"  ë¯¸ë¦¬ë³´ê¸°: {prompt[:200]}...")