"""
core/vlm_service.py
PRISM Phase 0 Hotfix - VLM Service with Retry Logic

âœ… Phase 0 ì¶”ê°€:
- call_with_retry(): ë¹ˆ ì‘ë‹µ ìž¬ì‹œë„ ë¡œì§
- íŽ˜ì´ì§€ ì—­í• ë³„ ìž¬ì‹œë„ ì˜ˆì‚° ì°¨ë“± ì ìš©
- 429/5xx ì—ëŸ¬ í•¸ë“¤ë§ (ì§€í„° ë°±ì˜¤í”„)

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-11-06
Version: Phase 0 Hotfix
"""

import os
import logging
import json
import re
import time
from typing import Dict, Any
from openai import AzureOpenAI
from anthropic import Anthropic
from dotenv import load_dotenv

try:
    from .document_classifier import DocumentClassifierV50
except ImportError:
    DocumentClassifierV50 = None

load_dotenv()
logger = logging.getLogger(__name__)


class VLMServiceV50:
    """ë²”ìš© VLM ì„œë¹„ìŠ¤ Phase 0 - ìž¬ì‹œë„ ë¡œì§ ì¶”ê°€"""
    
    def __init__(self, provider: str = "azure_openai"):
        self.provider = provider
        
        if provider == "azure_openai":
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
            
            if not all([api_key, azure_endpoint, deployment]):
                raise ValueError("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            self.deployment = deployment
            
        elif provider == "claude":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("âŒ ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
            
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-5-sonnet-20241022"
        
        # DocumentClassifierëŠ” ì„ íƒì 
        if DocumentClassifierV50:
            self.classifier = DocumentClassifierV50(provider)
        else:
            self.classifier = None
            logger.warning("âš ï¸ DocumentClassifier ì—†ìŒ - call() ë©”ì„œë“œë§Œ ì‚¬ìš©")
        
        logger.info(f"âœ… VLM Service Phase 0 ì´ˆê¸°í™” ì™„ë£Œ: {provider}")
    
    def call(self, image_data: str, prompt: str) -> str:
        """
        VLM í˜¸ì¶œ (ë‹¨ì¼ ì‹œë„)
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            prompt: VLM í”„ë¡¬í”„íŠ¸
        
        Returns:
            VLM ì‘ë‹µ í…ìŠ¤íŠ¸ (Markdown)
        """
        try:
            if self.provider == "azure_openai":
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/png;base64,{image_data}"}
                                }
                            ]
                        }
                    ],
                    max_tokens=3000,  # âœ… Phase 0: ê°œì •ì´ë ¥ í‘œë¥¼ ìœ„í•´ ì¦ê°€
                    temperature=0,     # âœ… Phase 0: ê²°ì •ì  ì¶œë ¥
                    top_p=1
                )
                return response.choices[0].message.content.strip()
            
            else:  # claude
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=3000,
                    temperature=0,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_data
                                    }
                                },
                                {"type": "text", "text": prompt}
                            ]
                        }
                    ]
                )
                return response.content[0].text.strip()
        
        except Exception as e:
            logger.error(f"âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def call_with_retry(
        self,
        image_data: str,
        prompt: str,
        page_role: str = "general",
        max_retries: int = 2
    ) -> Dict[str, Any]:
        """
        âœ… Phase 0 ì‹ ê·œ: ë¹ˆ ì‘ë‹µ ìž¬ì‹œë„ ë¡œì§
        
        ì „ëžµ:
        - íŽ˜ì´ì§€ ì—­í• ë³„ ìž¬ì‹œë„ ì˜ˆì‚° ì°¨ë“± ì ìš©
        - ìž¬ì‹œë„ ì‹œ í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™”
        - 429/5xx ì—ëŸ¬ëŠ” ì§€í„° ë°±ì˜¤í”„
        
        Args:
            image_data: Base64 ì´ë¯¸ì§€
            prompt: VLM í”„ë¡¬í”„íŠ¸
            page_role: íŽ˜ì´ì§€ ì—­í•  ("revision_table", "general")
            max_retries: ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜ (ë¬´ì‹œë¨, page_roleë¡œ ê²°ì •)
        
        Returns:
            {
                'content': str,
                'retry_count': int,
                'fallback': bool,
                'fallback_reason': str
            }
        """
        # íŽ˜ì´ì§€ ì—­í• ë³„ ìž¬ì‹œë„ ì˜ˆì‚°
        if page_role == "revision_table":
            budget = 2  # ê°œì •ì´ë ¥ í‘œëŠ” 2íšŒ
            logger.info("      ðŸŽ¯ ê°œì •ì´ë ¥ íŽ˜ì´ì§€ - ìž¬ì‹œë„ ì˜ˆì‚° 2íšŒ")
        else:
            budget = 1  # ì¼ë°˜ íŽ˜ì´ì§€ëŠ” 1íšŒ
        
        for attempt in range(budget + 1):
            try:
                # ì²« ì‹œë„ëŠ” ì›ë³¸ í”„ë¡¬í”„íŠ¸, ìž¬ì‹œë„ëŠ” ë‹¨ìˆœí™”
                if attempt == 0:
                    current_prompt = prompt
                else:
                    logger.info(f"      ðŸ”„ ìž¬ì‹œë„ {attempt}/{budget} - í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™”")
                    current_prompt = self._simplify_prompt(page_role)
                
                # VLM í˜¸ì¶œ
                response = self.call(image_data, current_prompt)
                
                # ë¹ˆ ì‘ë‹µ ì²´í¬
                if response and len(response.strip()) >= 50:
                    if attempt > 0:
                        logger.info(f"      âœ… ìž¬ì‹œë„ {attempt}íšŒ ë§Œì— ì„±ê³µ!")
                    return {
                        'content': response,
                        'retry_count': attempt,
                        'fallback': False,
                        'fallback_reason': ''
                    }
                else:
                    logger.warning(f"      âš ï¸ ì‹œë„ {attempt+1} ë¹ˆ ì‘ë‹µ ({len(response)} ê¸€ìž)")
                    
            except Exception as e:
                error_str = str(e).lower()
                
                # 429 ë˜ëŠ” 5xx ì—ëŸ¬ëŠ” ì§€í„° ë°±ì˜¤í”„
                if '429' in error_str or '5' in error_str[:1]:
                    wait_time = 0.6 + 0.2 * attempt  # jitter
                    logger.warning(f"      âš ï¸ Rate limit/Server error - {wait_time:.1f}ì´ˆ ëŒ€ê¸°")
                    time.sleep(wait_time)
                else:
                    logger.error(f"      âŒ VLM ì˜¤ë¥˜: {e}")
                    break
        
        # ëª¨ë“  ìž¬ì‹œë„ ì‹¤íŒ¨
        logger.error(f"      âŒ {budget+1}íšŒ ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨ â†’ Fallback")
        return {
            'content': '',
            'retry_count': budget,
            'fallback': True,
            'fallback_reason': 'empty_response_after_retries'
        }
    
    def _simplify_prompt(self, page_role: str) -> str:
        """
        ìž¬ì‹œë„ìš© ë‹¨ìˆœí™” í”„ë¡¬í”„íŠ¸
        
        Args:
            page_role: íŽ˜ì´ì§€ ì—­í• 
        
        Returns:
            ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸
        """
        if page_role == "revision_table":
            return """Extract the revision history table.

Output as a Markdown table with columns: ì°¨ìˆ˜ | ë‚ ì§œ

Example:
| ì°¨ìˆ˜ | ë‚ ì§œ |
| --- | --- |
| ì œ37ì°¨ ê°œì • | 2019.05.27 |

Extract ALL rows. Do NOT add any commentary."""
        
        else:
            return """Extract all text from this page. Preserve formatting. Output as Markdown.

Do NOT add any meta descriptions or commentary."""
    
    def analyze_page_v50(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """
        Phase 5.0-5.1 í˜¸í™˜: ë¬¸ì„œ íƒ€ìž…ë³„ ë¶„ì„
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            page_num: íŽ˜ì´ì§€ ë²ˆí˜¸
        
        Returns:
            {
                'content': str,
                'confidence': float,
                'strategy': str,
                'doc_type': str,
                'subtype': str,
                'quality_score': float,
                'structure': Dict
            }
        """
        if not self.classifier:
            logger.warning("âš ï¸ DocumentClassifier ì—†ìŒ - mixed íƒ€ìž…ìœ¼ë¡œ ì²˜ë¦¬")
            doc_type = 'mixed'
            subtype = 'unknown'
            confidence = 0.5
            doc_type_result = {}
        else:
            logger.info(f"ðŸŽ¯ Page {page_num}: Phase 5.1.1 ë¶„ì„ ì‹œìž‘")
            doc_type_result = self.classifier.classify(image_data, page_num)
            doc_type = doc_type_result.get('type', 'mixed')
            subtype = doc_type_result.get('subtype', 'unknown')
            confidence = doc_type_result.get('confidence', 0.5)
            logger.info(f"âœ… íƒ€ìž…: {doc_type} ({subtype}), ì‹ ë¢°ë„: {confidence:.2f}")
        
        if doc_type == 'text_document':
            content = self._extract_text_document(image_data, subtype)
        elif doc_type == 'diagram':
            content = self._extract_diagram(image_data, subtype)
        elif doc_type == 'technical_drawing':
            content = self._extract_technical_drawing(image_data, subtype)
        elif doc_type == 'image_content':
            content = self._extract_image_content(image_data, subtype)
        elif doc_type == 'chart_statistics':
            content = self._extract_chart_statistics(image_data, subtype)
        else:
            content = self._extract_mixed(image_data)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)} ê¸€ìž")
        
        quality_score = self._calculate_quality(content, doc_type)
        
        return {
            'content': content,
            'confidence': confidence,
            'strategy': f'{doc_type}_v511',
            'doc_type': doc_type,
            'subtype': subtype,
            'quality_score': quality_score,
            'structure': doc_type_result
        }
    
    def _extract_text_document(self, image_data: str, subtype: str) -> str:
        prompt = f"""ì´ {subtype} ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**ê·œì¹™:**
1. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•ížˆ ì¶”ì¶œ
2. ì¡°í•­/í•­ ë²ˆí˜¸ ì •í™•ížˆ ë³´ì¡´
3. í‘œëŠ” Markdown í‘œë¡œ ë³€í™˜

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª… ("ì´ ì´ë¯¸ì§€ëŠ”", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤", "ì•„ëž˜ëŠ”")
- ì•ˆë‚´ ë¬¸êµ¬ ("í•„ìš”í•˜ì‹ ", "ë§ì”€í•´ ì£¼ì„¸ìš”", "ìž¬êµ¬ì„± ê°€ëŠ¥")
- ìš”ì•½ ì„¹ì…˜ ("**ìš”ì•½:**", "**êµ¬ì¡° ìš”ì•½:**")

**ì˜¤ì§ ì›ë³¸ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.**"""
        return self.call(image_data, prompt)
    
    def _extract_diagram(self, image_data: str, subtype: str) -> str:
        if subtype == 'transport_route':
            prompt = """ì´ êµí†µ ë…¸ì„ ë„ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**í˜•ì‹:**
## ë…¸ì„  ì •ë³´
**ë…¸ì„ ëª…**: [ë…¸ì„ ë²ˆí˜¸/ì´ë¦„]

### ê²½ë¡œ
1. [ì •ë¥˜ìž¥ 1]
2. [ì •ë¥˜ìž¥ 2]

**ì ˆëŒ€ ê¸ˆì§€:**
- "ë‹¤ì´ì–´ê·¸ëž¨ì˜ êµ¬ì¡°ëŠ”", "í•„ìš”í•˜ì‹ ", "ìž¬êµ¬ì„± ê°€ëŠ¥" ë“±
- ì˜¤ì§ ë…¸ì„  ì •ë³´ë§Œ ì¶œë ¥"""
        else:
            prompt = """ì´ ë‹¤ì´ì–´ê·¸ëž¨ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬, ìš”ì•½
- ì˜¤ì§ ë‹¤ì´ì–´ê·¸ëž¨ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self.call(image_data, prompt)
    
    def _extract_technical_drawing(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ë„ë©´ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

## í‰ë©´ë„

### ê³µê°„ êµ¬ì„±
1. **[ê³µê°„ ì´ë¦„]** ([ë©´ì ])
   - ìœ„ì¹˜: [ë°©í–¥/ìœ„ì¹˜]
   - ì¹˜ìˆ˜: [ê°€ë¡œ Ã— ì„¸ë¡œ]

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬
- ì˜¤ì§ ë„ë©´ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self.call(image_data, prompt)
    
    def _extract_image_content(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

## ì´ë¯¸ì§€ ì„¤ëª…

### ì£¼ìš” ìš”ì†Œ
- [ìš”ì†Œ]: [ì„¤ëª…]

### ì‹œê°ì  íŠ¹ì§•
- ìƒ‰ìƒ: [ì£¼ìš” ìƒ‰ìƒ]
- ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼]

**ì ˆëŒ€ ê¸ˆì§€:**
- "ì´ ì´ë¯¸ì§€ëŠ”", "ì•„ëž˜ëŠ”" ë“± ë©”íƒ€ ì„¤ëª…
- ì˜¤ì§ ì´ë¯¸ì§€ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self.call(image_data, prompt)
    
    def _extract_chart_statistics(self, image_data: str, subtype: str) -> str:
        prompt = """ì´ ì°¨íŠ¸/í‘œì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

## ë°ì´í„°

**ì°¨íŠ¸ ì œëª©**: [ì œëª©]

### ë°ì´í„° í…Œì´ë¸”
| í•­ëª© | ê°’ 1 | ê°’ 2 |
|------|------|------|
| í–‰ 1 | [ê°’] | [ê°’] |

**ì ˆëŒ€ ê¸ˆì§€:**
- "ì•„ëž˜ëŠ” ì´ë¯¸ì§€ì˜ ì°¨íŠ¸/í‘œì—ì„œ ì¶”ì¶œí•œ"
- "í•„ìš”í•œ ë°ì´í„°ê°€ ë” ìžˆìœ¼ë©´"
- ì˜¤ì§ ì°¨íŠ¸/í‘œ ë°ì´í„°ë§Œ ì¶œë ¥"""
        return self.call(image_data, prompt)
    
    def _extract_mixed(self, image_data: str) -> str:
        prompt = """ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€:**
- ë©”íƒ€ ì„¤ëª…, ì•ˆë‚´ ë¬¸êµ¬, ìš”ì•½
- ì˜¤ì§ ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶œë ¥"""
        return self.call(image_data, prompt)
    
    def _calculate_quality(self, content: str, doc_type: str) -> float:
        score = 100.0
        if len(content) < 50:
            score -= 30
        headers = re.findall(r'^#+\s+', content, re.MULTILINE)
        if len(headers) == 0:
            score -= 20
        elif len(headers) >= 3:
            score += 10
        return max(0.0, min(100.0, score))