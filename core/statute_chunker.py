"""
core/statute_chunker.py
PRISM Phase 5.6.0 - Statute-aware Chunker

Î™©Ï†Å: Í∑úÏ†ï/Î≤ïÎ†π Î¨∏ÏÑúÏùò Ï°∞Î¨∏ Îã®ÏúÑ Ï≤≠ÌÇπ Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±

Í∞úÏÑ†:
- Ï†ú‚óãÏ°∞ Í∏∞Ï§Ä Ï≤≠ÌÇπ
- Ï°∞Î≤àÌò∏/Ïû•/Ï†à Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
- Í∞úÏ†ïÏùº ÌÉúÍπÖ

Author: Ïù¥ÏÑúÏòÅ (Backend Lead)
Date: 2025-10-27
Version: 5.6.0
"""

import re
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)


class StatuteChunker:
    """
    Phase 5.6.0 Ï°∞Î¨∏ Îã®ÏúÑ Ï≤≠ÌÇπ
    
    Î™©Ï†Å:
    - Í∑úÏ†ï/Î≤ïÎ†π Î¨∏ÏÑúÎ•º Ï°∞Î¨∏ Îã®ÏúÑÎ°ú Î∂ÑÌï†
    - Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú (Ï°∞Î≤àÌò∏, Ïû•, Ï†à, Í∞úÏ†ïÏùº)
    - RAG Í≤ÄÏÉâ Ï†ïÎ∞ÄÎèÑ Ìñ•ÏÉÅ
    
    Ï≤≠ÌÇπ Í∏∞Ï§Ä:
    1. Ï†ú‚óãÏ°∞ (Article)
    2. Ï†ú‚óãÏû• (Chapter) - Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
    3. Ï†ú‚óãÏ†à (Section) - Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
    
    Ï∂úÎ†• Íµ¨Ï°∞:
    {
        'chunk_id': 'statute_art_1',
        'article_no': 'Ï†ú1Ï°∞',
        'article_title': 'Î™©Ï†Å',
        'chapter': 'Ï†ú1Ïû• Ï¥ùÏπô',
        'section': None,
        'content': '...',
        'metadata': {
            'last_amended': '2024.1.1',
            'page_range': [1, 1]
        }
    }
    """
    
    def __init__(self):
        """Ï¥àÍ∏∞Ìôî"""
        logger.info("‚úÖ StatuteChunker v5.6.0 Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
    
    def chunk(self, content: str, page_num: int = None) -> List[Dict[str, Any]]:
        """
        Ï°∞Î¨∏ Îã®ÏúÑ Ï≤≠ÌÇπ
        
        Args:
            content: Markdown ÌÖçÏä§Ìä∏
            page_num: ÌéòÏù¥ÏßÄ Î≤àÌò∏ (ÏÑ†ÌÉù)
        
        Returns:
            Ï≤≠ÌÅ¨ Î¶¨Ïä§Ìä∏
        """
        logger.info(f"   üìö StatuteChunker ÏãúÏûë (page: {page_num})")
        
        chunks = []
        current_chunk = []
        current_meta = {}
        
        # ÌòÑÏû¨ Î¨∏Îß• (Ïû•/Ï†à)
        current_chapter = None
        current_section = None
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            # 1) Ï†ú‚óãÏû• Í∞êÏßÄ
            chapter_match = re.match(r'^#{1,3}\s*(Ï†ú\s?\d+Ïû•)\s*(.+)?$', line)
            if chapter_match:
                current_chapter = chapter_match.group(1)
                if chapter_match.group(2):
                    current_chapter += ' ' + chapter_match.group(2).strip()
                logger.debug(f"      Ïû• Í∞êÏßÄ: {current_chapter}")
                current_chunk.append(line)
                continue
            
            # 2) Ï†ú‚óãÏ†à Í∞êÏßÄ
            section_match = re.match(r'^#{1,3}\s*(Ï†ú\s?\d+Ï†à)\s*(.+)?$', line)
            if section_match:
                current_section = section_match.group(1)
                if section_match.group(2):
                    current_section += ' ' + section_match.group(2).strip()
                logger.debug(f"      Ï†à Í∞êÏßÄ: {current_section}")
                current_chunk.append(line)
                continue
            
            # 3) Ï†ú‚óãÏ°∞ Í∞êÏßÄ (Ï≤≠ÌÅ¨ Íµ¨Î∂ÑÏ†ê)
            article_match = re.match(r'^#{1,3}\s*(Ï†ú\s?\d+Ï°∞)\s*(\([^)]+\))?', line)
            if article_match:
                # Ïù¥Ï†Ñ Ï≤≠ÌÅ¨ Ï†ÄÏû•
                if current_chunk and current_meta:
                    chunk_content = '\n'.join(current_chunk).strip()
                    if chunk_content:
                        chunks.append(self._build_chunk(
                            content=chunk_content,
                            meta=current_meta,
                            chapter=current_chapter,
                            section=current_section,
                            page_num=page_num
                        ))
                
                # ÏÉà Ï≤≠ÌÅ¨ ÏãúÏûë
                article_no = article_match.group(1)
                article_title = article_match.group(2).strip('()') if article_match.group(2) else None
                
                current_meta = {
                    'article_no': article_no,
                    'article_title': article_title
                }
                
                current_chunk = [line]
                logger.debug(f"      Ï°∞Î¨∏ Í∞êÏßÄ: {article_no} ({article_title})")
                continue
            
            # 4) ÏùºÎ∞ò ÎÇ¥Ïö© ÎùºÏù∏
            current_chunk.append(line)
        
        # ÎßàÏßÄÎßâ Ï≤≠ÌÅ¨ Ï†ÄÏû•
        if current_chunk and current_meta:
            chunk_content = '\n'.join(current_chunk).strip()
            if chunk_content:
                chunks.append(self._build_chunk(
                    content=chunk_content,
                    meta=current_meta,
                    chapter=current_chapter,
                    section=current_section,
                    page_num=page_num
                ))
        
        logger.info(f"   ‚úÖ Ï≤≠ÌÇπ ÏôÑÎ£å: {len(chunks)}Í∞ú Ï°∞Î¨∏")
        return chunks
    
    def _build_chunk(
        self,
        content: str,
        meta: Dict[str, str],
        chapter: str,
        section: str,
        page_num: int
    ) -> Dict[str, Any]:
        """
        Ï≤≠ÌÅ¨ Í∞ùÏ≤¥ ÏÉùÏÑ±
        
        Args:
            content: Ï≤≠ÌÅ¨ ÎÇ¥Ïö©
            meta: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ (article_no, article_title)
            chapter: ÌòÑÏû¨ Ïû•
            section: ÌòÑÏû¨ Ï†à
            page_num: ÌéòÏù¥ÏßÄ Î≤àÌò∏
        
        Returns:
            Ï≤≠ÌÅ¨ Í∞ùÏ≤¥
        """
        article_no = meta.get('article_no', 'unknown')
        article_title = meta.get('article_title', '')
        
        # chunk_id ÏÉùÏÑ±
        chunk_id = f"statute_{article_no.replace(' ', '_')}"
        
        # Í∞úÏ†ïÏùº Ï∂îÏ∂ú (Í∞ÑÎã® Ìå®ÌÑ¥)
        amended_dates = re.findall(r'Í∞úÏ†ï\s*(\d{4}\.\d{1,2}\.\d{1,2})', content)
        last_amended = amended_dates[-1] if amended_dates else None
        
        chunk = {
            'chunk_id': chunk_id,
            'article_no': article_no,
            'article_title': article_title,
            'chapter': chapter,
            'section': section,
            'content': content,
            'metadata': {
                'last_amended': last_amended,
                'page_num': page_num,
                'amended_dates': amended_dates
            }
        }
        
        return chunk
    
    def get_stats(self, chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Ï≤≠ÌÇπ ÌÜµÍ≥Ñ
        
        Args:
            chunks: Ï≤≠ÌÅ¨ Î¶¨Ïä§Ìä∏
        
        Returns:
            ÌÜµÍ≥Ñ Ï†ïÎ≥¥
        """
        total_chunks = len(chunks)
        total_chars = sum(len(c['content']) for c in chunks)
        avg_chunk_size = total_chars / max(1, total_chunks)
        
        chapters = set(c['chapter'] for c in chunks if c['chapter'])
        sections = set(c['section'] for c in chunks if c['section'])
        
        return {
            'total_chunks': total_chunks,
            'total_chars': total_chars,
            'avg_chunk_size': avg_chunk_size,
            'chapters': len(chapters),
            'sections': len(sections)
        }
