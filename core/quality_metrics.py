"""
core/quality_metrics.py
PRISM Phase 5.6.3 - Complete Automatic Quality Metrics

ğŸ¯ GPT(ë¯¸ì†¡) ì œì•ˆ 100% ë°˜ì˜:
- 5ê°€ì§€ í•„ìˆ˜ ìë™ ì§€í‘œ
- ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ìë™í™”
- íšŒê·€ ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ
- DoD(Definition of Done) ìë™ ê²€ì¦

Author: ì •ìˆ˜ì•„ (QA Lead)
Date: 2025-10-27
Version: 5.6.3 Final
"""

import json
import re
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


class QualityMetrics:
    """
    Phase 5.6.3 ì™„ì „í•œ ìë™ ì§„ë‹¨ ì‹œìŠ¤í…œ
    
    ëª©í‘œ:
    - "ê³ ì³ë†“ì€ ê²Œ ë‹¤ì‹œ ë¬´ë„ˆì§€ì§€ ì•Šê²Œ"
    - ìë™ ì§€í‘œë¡œ ì¡°ê¸° ê²½ë³´
    - 5ê°€ì§€ í•„ìˆ˜ ì§€í‘œ 100% êµ¬í˜„
    """
    
    # ğŸ¯ DoD(Definition of Done) ê¸°ì¤€ (GPT ì œì•ˆ)
    DOD_CRITERIA = {
        'article_boundary_f1': 0.97,      # ì¡°ë¬¸ ê²½ê³„ F1 â‰¥ 0.97
        'list_binding_fix_rate': 0.98,    # ëª©ë¡ ê²°ì† â‰¥ 0.98
        'table_false_positive': 0.0,      # í‘œ ê³¼ê²€ì¶œ = 0
        'amendment_capture_rate': 1.0,    # ê°œì • ë©”íƒ€ = 1.0
        'empty_article_rate': 0.0         # ë¹ˆ ì¡°ë¬¸ = 0
    }
    
    def __init__(self, output_dir: str = "metrics"):
        """ì´ˆê¸°í™”"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.metrics = {
            'timestamp': None,
            'doc_id': None,
            'doc_type': None,
            'stage_metrics': {},
            'quality_scores': {},
            'regression_flags': [],
            'dod_status': {}
        }
        
        logger.info("âœ… QualityMetrics v5.6.3 Final ì´ˆê¸°í™” ì™„ë£Œ (GPT ì œì•ˆ ë°˜ì˜)")
        logger.info(f"   ğŸ¯ DoD ê¸°ì¤€: {self.DOD_CRITERIA}")
    
    def start_collection(self, doc_id: str, doc_type: str = 'general'):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        self.metrics['timestamp'] = datetime.now().isoformat()
        self.metrics['doc_id'] = doc_id
        self.metrics['doc_type'] = doc_type
        logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘: {doc_id} (íƒ€ì…: {doc_type})")
    
    # 1ï¸âƒ£ Article Boundary Precision/Recall
    def record_article_boundaries(
        self,
        detected_articles: List[str],
        ground_truth: Optional[List[str]] = None
    ):
        """
        ì¡°ë¬¸ ê²½ê³„ ì •í™•ë„ (GPT ì§€í‘œ 1)
        
        Args:
            detected_articles: ê°ì§€ëœ ì¡°ë¬¸ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ['ì œ1ì¡°', 'ì œ2ì¡°', ...]
            ground_truth: ì •ë‹µ ì¡°ë¬¸ ë²ˆí˜¸ (ì„ íƒ)
        """
        metrics = {
            'detected_count': len(detected_articles),
            'detected_articles': detected_articles
        }
        
        if ground_truth:
            # Precision & Recall
            detected_set = set(detected_articles)
            truth_set = set(ground_truth)
            
            true_positive = len(detected_set & truth_set)
            false_positive = len(detected_set - truth_set)
            false_negative = len(truth_set - detected_set)
            
            precision = true_positive / max(1, true_positive + false_positive)
            recall = true_positive / max(1, true_positive + false_negative)
            f1 = 2 * precision * recall / max(0.0001, precision + recall)
            
            metrics.update({
                'ground_truth_count': len(ground_truth),
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'true_positive': true_positive,
                'false_positive': false_positive,
                'false_negative': false_negative
            })
            
            logger.info(f"   ğŸ“ ì¡°ë¬¸ ê²½ê³„: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}")
            
            # DoD ì²´í¬
            if f1 < self.DOD_CRITERIA['article_boundary_f1']:
                self.metrics['regression_flags'].append(
                    f"ARTICLE_BOUNDARY: F1={f1:.3f} < {self.DOD_CRITERIA['article_boundary_f1']}"
                )
        
        self.record_stage('article_boundaries', metrics)
    
    # 2ï¸âƒ£ List Binding Fix Rate
    def record_list_binding(self, original: str, normalized: str):
        """
        ë²ˆí˜¸ëª©ë¡ ê²°ì† ë³µêµ¬ìœ¨ (GPT ì§€í‘œ 2)
        
        Args:
            original: ì›ë³¸ í…ìŠ¤íŠ¸
            normalized: ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        # ì›ë³¸ì—ì„œ ëŠê¸´ ëª©ë¡ íŒ¨í„´ ì°¾ê¸°
        broken_patterns = [
            r'^\d+\.\s*$',      # 1.
            r'^[ê°€-í£]\.\s*$',  # ê°€.
            r'^\(\d+\)\s*$',    # (1)
            r'^[â‘ -â‘³]\s*$'       # â‘ 
        ]
        
        original_broken = 0
        normalized_broken = 0
        
        for pattern in broken_patterns:
            original_broken += len(re.findall(pattern, original, re.MULTILINE))
            normalized_broken += len(re.findall(pattern, normalized, re.MULTILINE))
        
        # ë³µêµ¬ìœ¨
        fixed_count = original_broken - normalized_broken
        fix_rate = fixed_count / max(1, original_broken) if original_broken > 0 else 1.0
        
        metrics = {
            'original_broken_count': original_broken,
            'normalized_broken_count': normalized_broken,
            'fixed_count': fixed_count,
            'fix_rate': fix_rate
        }
        
        logger.info(f"   ğŸ”— ëª©ë¡ ê²°ì†: {original_broken}ê°œ â†’ {normalized_broken}ê°œ (ë³µêµ¬ìœ¨: {fix_rate:.1%})")
        
        self.record_stage('list_binding', metrics)
        
        # DoD ì²´í¬
        if fix_rate < self.DOD_CRITERIA['list_binding_fix_rate']:
            self.metrics['regression_flags'].append(
                f"LIST_BINDING: Fix Rate={fix_rate:.3f} < {self.DOD_CRITERIA['list_binding_fix_rate']}"
            )
        
        # ë‚¨ì€ ëŠê¹€ì— ëŒ€í•œ íšŒê·€ í”Œë˜ê·¸
        if normalized_broken > 5:
            self.metrics['regression_flags'].append(
                f"LIST_BINDING: {normalized_broken}ê°œ ëŠê¹€ ì”ì¡´ (ëª©í‘œ: â‰¤5)"
            )
    
    # 3ï¸âƒ£ Table Confidence Precision
    def record_table_detection(
        self,
        page_has_table: bool,
        detected_tables: int,
        confidence: float
    ):
        """
        í‘œ í™˜ê° ì–µì œ ê²€ì¦ (GPT ì§€í‘œ 3)
        
        Args:
            page_has_table: í˜ì´ì§€ì— ì‹¤ì œ í‘œê°€ ìˆëŠ”ì§€ (Falseë©´ ê²€ì¶œ 0ì´ì–´ì•¼ í•¨)
            detected_tables: ê°ì§€ëœ í‘œ ê°œìˆ˜
            confidence: í‘œ ì‹ ë¢°ë„
        """
        metrics = {
            'page_has_table': page_has_table,
            'detected_tables': detected_tables,
            'confidence': confidence
        }
        
        # False Positive (í‘œ ì—†ëŠ”ë° ê²€ì¶œ)
        false_positive = 0
        if not page_has_table and detected_tables > 0:
            false_positive = 1
            logger.warning(f"   âš ï¸ í‘œ ê³¼ê²€ì¶œ: í‘œ ì—†ëŠ” í˜ì´ì§€ì—ì„œ {detected_tables}ê°œ ê²€ì¶œ")
        
        metrics['false_positive'] = false_positive
        
        self.record_stage('table_detection', metrics)
        
        # DoD ì²´í¬ (ê·œì • ëª¨ë“œì—ì„œ has_table=Falseë©´ ê²€ì¶œ 0ì´ì–´ì•¼ í•¨)
        if self.metrics['doc_type'] == 'statute' and not page_has_table and detected_tables > 0:
            self.metrics['regression_flags'].append(
                f"TABLE_DETECTION: False Positive (í‘œ ì—†ëŠ”ë° {detected_tables}ê°œ ê²€ì¶œ)"
            )
    
    # 4ï¸âƒ£ Amendment Capture Rate
    def record_amendment_sync(self, chunks: List[Dict[str, Any]]):
        """
        ê°œì •/ì‚­ì œ ë©”íƒ€ ë™ê¸°í™” ê²€ì¦ (GPT ì§€í‘œ 4)
        
        Args:
            chunks: ì¡°ë¬¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        total_chunks = len(chunks)
        sync_success = 0
        sync_fail = 0
        
        for chunk in chunks:
            content = chunk.get('content', '')
            meta = chunk.get('metadata', {})
            change_log = meta.get('change_log', [])
            
            # ë³¸ë¬¸ì— ê°œì •/ì‚­ì œ í‘œì‹ì´ ìˆëŠ”ì§€
            has_content_marker = bool(re.search(r'(ê°œì •|ì‚­ì œ)\s*\d{4}\.\d{1,2}\.\d{1,2}', content))
            
            # ë©”íƒ€ì— change_logê°€ ìˆëŠ”ì§€
            has_meta_log = len(change_log) > 0
            
            # ë™ê¸°í™” ê²€ì¦
            if has_content_marker and has_meta_log:
                sync_success += 1
            elif has_content_marker or has_meta_log:
                sync_fail += 1
                logger.debug(f"      ë™ê¸°í™” ë¶ˆì¼ì¹˜: {chunk.get('article_no', 'unknown')}")
            else:
                sync_success += 1  # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ OK
        
        capture_rate = sync_success / max(1, total_chunks)
        
        metrics = {
            'total_chunks': total_chunks,
            'sync_success': sync_success,
            'sync_fail': sync_fail,
            'capture_rate': capture_rate
        }
        
        logger.info(f"   ğŸ“ ê°œì •/ì‚­ì œ ë©”íƒ€: {sync_success}/{total_chunks} ë™ê¸°í™” (ì„±ê³µë¥ : {capture_rate:.1%})")
        
        self.record_stage('amendment_sync', metrics)
        
        # DoD ì²´í¬
        if capture_rate < self.DOD_CRITERIA['amendment_capture_rate']:
            self.metrics['regression_flags'].append(
                f"AMENDMENT_SYNC: Capture Rate={capture_rate:.3f} < {self.DOD_CRITERIA['amendment_capture_rate']}"
            )
    
    # 5ï¸âƒ£ Empty Article Rate
    def record_empty_articles(self, chunks: List[Dict[str, Any]]):
        """
        ë¹ˆ ì¡°ë¬¸ ìƒì„± ë°©ì§€ ê²€ì¦ (GPT ì§€í‘œ 5)
        
        Args:
            chunks: ì¡°ë¬¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        total_chunks = len(chunks)
        empty_count = 0
        
        for chunk in chunks:
            content = chunk.get('content', '').strip()
            deleted = chunk.get('metadata', {}).get('deleted', False)
            
            # ì‚­ì œëœ ì¡°ë¬¸ì€ ë¹ˆ ë‚´ìš© í—ˆìš©
            if not deleted and len(content) < 10:
                empty_count += 1
                logger.debug(f"      ë¹ˆ ì¡°ë¬¸: {chunk.get('article_no', 'unknown')}")
        
        empty_rate = empty_count / max(1, total_chunks)
        
        metrics = {
            'total_chunks': total_chunks,
            'empty_count': empty_count,
            'empty_rate': empty_rate
        }
        
        logger.info(f"   ğŸ“„ ë¹ˆ ì¡°ë¬¸: {empty_count}/{total_chunks} (ë¹„ìœ¨: {empty_rate:.1%})")
        
        self.record_stage('empty_articles', metrics)
        
        # DoD ì²´í¬
        if empty_rate > self.DOD_CRITERIA['empty_article_rate']:
            self.metrics['regression_flags'].append(
                f"EMPTY_ARTICLE: Rate={empty_rate:.3f} > {self.DOD_CRITERIA['empty_article_rate']}"
            )
    
    def record_stage(self, stage: str, metrics: Dict[str, Any]):
        """ë‹¨ê³„ë³„ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.metrics['stage_metrics'][stage] = metrics
        logger.debug(f"   ğŸ“ˆ {stage}: {metrics}")
    
    def calculate_quality_scores(self):
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        stage_metrics = self.metrics['stage_metrics']
        
        # 1. ì¡°ë¬¸ ê²½ê³„ ì ìˆ˜
        boundaries = stage_metrics.get('article_boundaries', {})
        boundary_score = boundaries.get('f1_score', 0) * 100
        
        # 2. ëª©ë¡ ê²°ì† ì ìˆ˜
        list_binding = stage_metrics.get('list_binding', {})
        binding_score = list_binding.get('fix_rate', 0) * 100
        
        # 3. í‘œ ê²€ì¶œ ì ìˆ˜ (False Positive ì—†ìœ¼ë©´ 100)
        table_detection = stage_metrics.get('table_detection', {})
        table_score = 100 if table_detection.get('false_positive', 0) == 0 else 0
        
        # 4. ê°œì • ë©”íƒ€ ì ìˆ˜
        amendment = stage_metrics.get('amendment_sync', {})
        amendment_score = amendment.get('capture_rate', 0) * 100
        
        # 5. ë¹ˆ ì¡°ë¬¸ ì ìˆ˜ (ì—†ìœ¼ë©´ 100)
        empty_articles = stage_metrics.get('empty_articles', {})
        empty_score = 100 if empty_articles.get('empty_rate', 0) == 0 else 0
        
        # ì „ì²´ ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
        overall_score = (
            boundary_score * 0.3 +
            binding_score * 0.25 +
            table_score * 0.2 +
            amendment_score * 0.15 +
            empty_score * 0.1
        )
        
        self.metrics['quality_scores'] = {
            'article_boundary': boundary_score,
            'list_binding': binding_score,
            'table_detection': table_score,
            'amendment_sync': amendment_score,
            'empty_articles': empty_score,
            'overall': overall_score
        }
        
        logger.info(f"   ğŸ“Š ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {overall_score:.1f}/100")
    
    def check_dod(self) -> bool:
        """
        DoD(Definition of Done) ìë™ ê²€ì¦ (GPT ì œì•ˆ)
        
        Returns:
            DoD í†µê³¼ ì—¬ë¶€
        """
        stage_metrics = self.metrics['stage_metrics']
        
        dod_results = {}
        
        # 1. ì¡°ë¬¸ ê²½ê³„ F1
        boundaries = stage_metrics.get('article_boundaries', {})
        f1 = boundaries.get('f1_score', 0)
        dod_results['article_boundary_f1'] = {
            'value': f1,
            'target': self.DOD_CRITERIA['article_boundary_f1'],
            'pass': f1 >= self.DOD_CRITERIA['article_boundary_f1']
        }
        
        # 2. ëª©ë¡ ê²°ì†
        list_binding = stage_metrics.get('list_binding', {})
        fix_rate = list_binding.get('fix_rate', 0)
        dod_results['list_binding_fix_rate'] = {
            'value': fix_rate,
            'target': self.DOD_CRITERIA['list_binding_fix_rate'],
            'pass': fix_rate >= self.DOD_CRITERIA['list_binding_fix_rate']
        }
        
        # 3. í‘œ ê³¼ê²€ì¶œ
        table_detection = stage_metrics.get('table_detection', {})
        false_positive = table_detection.get('false_positive', 0)
        dod_results['table_false_positive'] = {
            'value': false_positive,
            'target': self.DOD_CRITERIA['table_false_positive'],
            'pass': false_positive == self.DOD_CRITERIA['table_false_positive']
        }
        
        # 4. ê°œì • ë©”íƒ€
        amendment = stage_metrics.get('amendment_sync', {})
        capture_rate = amendment.get('capture_rate', 0)
        dod_results['amendment_capture_rate'] = {
            'value': capture_rate,
            'target': self.DOD_CRITERIA['amendment_capture_rate'],
            'pass': capture_rate >= self.DOD_CRITERIA['amendment_capture_rate']
        }
        
        # 5. ë¹ˆ ì¡°ë¬¸
        empty_articles = stage_metrics.get('empty_articles', {})
        empty_rate = empty_articles.get('empty_rate', 0)
        dod_results['empty_article_rate'] = {
            'value': empty_rate,
            'target': self.DOD_CRITERIA['empty_article_rate'],
            'pass': empty_rate <= self.DOD_CRITERIA['empty_article_rate']
        }
        
        self.metrics['dod_status'] = dod_results
        
        # ì „ì²´ í†µê³¼ ì—¬ë¶€
        all_pass = all(v['pass'] for v in dod_results.values())
        
        logger.info(f"   ğŸ¯ DoD ê²€ì¦: {'âœ… PASS' if all_pass else 'âŒ FAIL'}")
        for key, result in dod_results.items():
            status = 'âœ…' if result['pass'] else 'âŒ'
            logger.info(f"      {status} {key}: {result['value']:.3f} (ëª©í‘œ: {result['target']})")
        
        return all_pass
    
    def save(self, filename: str = None):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        self.calculate_quality_scores()
        dod_pass = self.check_dod()
        
        if filename is None:
            filename = f"metrics_{self.metrics['doc_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.metrics, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥: {filepath}")
        
        # íšŒê·€ í”Œë˜ê·¸ ê²½ê³ 
        if self.metrics['regression_flags']:
            logger.warning(f"   âš ï¸ íšŒê·€ í”Œë˜ê·¸: {len(self.metrics['regression_flags'])}ê°œ")
            for flag in self.metrics['regression_flags']:
                logger.warning(f"      - {flag}")
        
        # DoD ê²°ê³¼
        if not dod_pass:
            logger.error("   âŒ DoD í†µê³¼ ì‹¤íŒ¨: ë¦´ë¦¬ìŠ¤ ë¶ˆê°€")
        else:
            logger.info("   âœ… DoD í†µê³¼: ë¦´ë¦¬ìŠ¤ ê°€ëŠ¥")
    
    def get_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½"""
        dod_pass = all(v['pass'] for v in self.metrics.get('dod_status', {}).values())
        
        return {
            'doc_id': self.metrics['doc_id'],
            'doc_type': self.metrics['doc_type'],
            'quality_scores': self.metrics['quality_scores'],
            'regression_count': len(self.metrics['regression_flags']),
            'has_regression': len(self.metrics['regression_flags']) > 0,
            'dod_pass': dod_pass
        }
