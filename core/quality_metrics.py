"""
core/quality_metrics.py
PRISM Phase 5.6.3 Final+ - Complete Automatic Quality Metrics

ğŸš€ Phase 5.6.3 Final+ (GPT ì œì•ˆ 100% ë°˜ì˜):
- âœ… ê¸°ì¡´ 5ê°€ì§€ ì§€í‘œ ìœ ì§€
- âœ… ê³„ì¸µ ë³´ì¡´ìœ¨(hierarchy_preservation) ì¶”ê°€
- âœ… ê²½ê³„ ëˆ„ìˆ˜ ì ìˆ˜(boundary_cross_bleed) ì¶”ê°€
- âœ… ì‹¤íŒ¨ ì‹œê·¸ë„ ì›ì¸ ì§€í–¥ ë¡œê·¸
- âœ… í‘œ FP í˜ì´ì§€ ë‹¨ìœ„ ì§‘ê³„

ì´ 7ê°€ì§€ ì§€í‘œë¡œ ì™„ì „í•œ íšŒê·€ ë°©ì§€

Author: ì •ìˆ˜ì•„ (QA Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-27
Version: 5.6.3 Final+
"""

import json
import re
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pathlib import Path
from collections import defaultdict

logger = logging.getLogger(__name__)


class QualityMetrics:
    """
    Phase 5.6.3 Final+ ì™„ì „í•œ ìë™ ì§„ë‹¨ ì‹œìŠ¤í…œ
    
    ëª©í‘œ:
    - "ê³ ì³ë†“ì€ ê²Œ ë‹¤ì‹œ ë¬´ë„ˆì§€ì§€ ì•Šê²Œ"
    - ìë™ ì§€í‘œë¡œ ì¡°ê¸° ê²½ë³´
    - 7ê°€ì§€ ì§€í‘œë¡œ ì™„ì „í•œ ì•ˆì „ë§
    
    âœ… GPT ì œì•ˆ ë°˜ì˜:
    - ê³„ì¸µ ë³´ì¡´ìœ¨ (ì¡°Â·í•­Â·í˜¸ ì™„ì „ì„±)
    - ê²½ê³„ ëˆ„ìˆ˜ ì ìˆ˜ (ì¡°ë¬¸ í˜¼ì…)
    - ì›ì¸ ì§€í–¥ ë¡œê·¸
    - í˜ì´ì§€ ë‹¨ìœ„ í‘œ FP
    """
    
    # ğŸ¯ DoD(Definition of Done) ê¸°ì¤€ (Final+ í™•ì¥)
    DOD_CRITERIA = {
        # ê¸°ì¡´ 5ê°€ì§€
        'article_boundary_f1': 0.97,         # ì¡°ë¬¸ ê²½ê³„ F1 â‰¥ 0.97
        'list_binding_fix_rate': 0.98,       # ëª©ë¡ ê²°ì† â‰¥ 0.98
        'table_false_positive': 0.0,         # í‘œ ê³¼ê²€ì¶œ = 0
        'amendment_capture_rate': 1.0,       # ê°œì • ë©”íƒ€ = 1.0
        'empty_article_rate': 0.0,           # ë¹ˆ ì¡°ë¬¸ = 0
        
        # âœ… GPT ì œì•ˆ 2ê°€ì§€ ì¶”ê°€
        'hierarchy_preservation_rate': 0.95,  # ê³„ì¸µ ë³´ì¡´ìœ¨ â‰¥ 0.95
        'boundary_cross_bleed_rate': 0.0      # ê²½ê³„ ëˆ„ìˆ˜ = 0
    }
    
    def __init__(self, output_dir: str = "metrics"):
        """ì´ˆê¸°í™”"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.metrics = {
            'timestamp': None,
            'doc_id': None,
            'doc_type': None,
            'stage_metrics': {},
            'quality_scores': {},
            'regression_flags': [],
            'dod_status': {},
            'page_level_details': {}  # âœ… í˜ì´ì§€ ë‹¨ìœ„ ìƒì„¸ ì •ë³´
        }
        
        logger.info("âœ… QualityMetrics v5.6.3 Final+ ì´ˆê¸°í™” ì™„ë£Œ (GPT ì œì•ˆ 100% ë°˜ì˜)")
        logger.info(f"   ğŸ¯ DoD ê¸°ì¤€: 7ê°€ì§€ ì§€í‘œ")
        logger.info(f"   ğŸ“Š ì‹ ê·œ ì§€í‘œ: hierarchy_preservation, boundary_cross_bleed")
    
    def start_collection(self, doc_id: str, doc_type: str = 'general'):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        self.metrics['timestamp'] = datetime.now().isoformat()
        self.metrics['doc_id'] = doc_id
        self.metrics['doc_type'] = doc_type
        logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘: {doc_id} (íƒ€ì…: {doc_type})")
    
    # ==========================================
    # ê¸°ì¡´ 5ê°€ì§€ ì§€í‘œ (ìœ ì§€)
    # ==========================================
    
    def record_article_boundaries(
        self,
        detected_articles: List[str],
        ground_truth: Optional[List[str]] = None
    ):
        """
        1ï¸âƒ£ Article Boundary Precision/Recall
        
        ëª©ì : ì¡°ë¬¸ ê²½ê³„ ì •í™•ë„ (F1 Score)
        DoD: F1 â‰¥ 0.97
        
        Args:
            detected_articles: ê²€ì¶œëœ ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ ['ì œ1ì¡°', 'ì œ2ì¡°', ...]
            ground_truth: ì •ë‹µ ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ detectedë¥¼ ì •ë‹µìœ¼ë¡œ ê°„ì£¼)
        """
        if ground_truth is None:
            ground_truth = detected_articles
        
        # ì§‘í•© ë³€í™˜
        detected_set = set(detected_articles)
        truth_set = set(ground_truth)
        
        # True Positive
        tp = len(detected_set & truth_set)
        
        # False Positive
        fp = len(detected_set - truth_set)
        
        # False Negative
        fn = len(truth_set - detected_set)
        
        # Precision, Recall, F1
        precision = tp / max(1, tp + fp)
        recall = tp / max(1, tp + fn)
        f1 = 2 * precision * recall / max(0.0001, precision + recall)
        
        self.metrics['stage_metrics']['article_boundaries'] = {
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'detected_count': len(detected_articles),
            'truth_count': len(ground_truth),
            'tp': tp,
            'fp': fp,
            'fn': fn
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if f1 < self.DOD_CRITERIA['article_boundary_f1']:
            msg = (f"ARTICLE_BOUNDARY: F1={f1:.3f} < {self.DOD_CRITERIA['article_boundary_f1']:.3f} "
                   f"(TP={tp}, FP={fp}, FN={fn})")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
        else:
            logger.info(f"   âœ… Article Boundary: F1={f1:.3f} (ëª©í‘œ: â‰¥{self.DOD_CRITERIA['article_boundary_f1']:.3f})")
    
    def record_list_binding(
        self,
        original: str,
        normalized: str
    ):
        """
        2ï¸âƒ£ List Binding Fix Rate
        
        ëª©ì : ë²ˆí˜¸ëª©ë¡ ê²°ì† ë³µêµ¬ìœ¨
        DoD: â‰¥ 0.98
        
        íŒ¨í„´: "1.\n\në‚´ìš©" â†’ "1. ë‚´ìš©" ê°™ì€ ëŠê¹€ ë³µêµ¬ìœ¨
        """
        # ëŠê¸´ ëª©ë¡ íŒ¨í„´ (1.\n\n, ê°€.\n\n, (1)\n\n)
        broken_patterns = [
            r'\d+\.\s*\n{2,}',      # 1.\n\n
            r'[ê°€-í£]\.\s*\n{2,}',  # ê°€.\n\n
            r'\(\d+\)\s*\n{2,}',    # (1)\n\n
            r'[â‘ -â‘³]\s*\n{2,}'      # â‘ \n\n
        ]
        
        # ì›ë³¸ ëŠê¹€ ê°œìˆ˜
        original_broken = 0
        for pattern in broken_patterns:
            original_broken += len(re.findall(pattern, original))
        
        # ì •ê·œí™” í›„ ëŠê¹€ ê°œìˆ˜
        normalized_broken = 0
        for pattern in broken_patterns:
            normalized_broken += len(re.findall(pattern, normalized))
        
        # ë³µêµ¬ìœ¨
        if original_broken > 0:
            fix_rate = (original_broken - normalized_broken) / original_broken
        else:
            fix_rate = 1.0
        
        self.metrics['stage_metrics']['list_binding'] = {
            'fix_rate': fix_rate,
            'original_broken_count': original_broken,
            'normalized_broken_count': normalized_broken,
            'fixed_count': original_broken - normalized_broken
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if fix_rate < self.DOD_CRITERIA['list_binding_fix_rate']:
            msg = (f"LIST_BINDING: fix_rate={fix_rate:.3f} < {self.DOD_CRITERIA['list_binding_fix_rate']:.3f} "
                   f"(ëŠê¹€ ì”ì¡´: {normalized_broken}ê°œ, ì›ë³¸: {original_broken}ê°œ)")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
        else:
            logger.info(f"   âœ… List Binding: fix_rate={fix_rate:.3f} (ëŠê¹€: {original_broken}â†’{normalized_broken})")
    
    def record_table_detection(
        self,
        page_has_table: bool,
        detected_tables: int,
        confidence: float,
        page_num: Optional[int] = None
    ):
        """
        3ï¸âƒ£ Table Confidence Precision + âœ… í˜ì´ì§€ ë‹¨ìœ„ ì§‘ê³„
        
        ëª©ì : í‘œ í™˜ê° ì–µì œ (False Positive)
        DoD: FP = 0
        
        âœ… GPT ì œì•ˆ: í˜ì´ì§€ ë‹¨ìœ„ FP rate ì¶”ê°€
        """
        # False Positive íŒì •
        is_false_positive = (not page_has_table) and (detected_tables > 0)
        
        # ë¬¸ì„œ ë ˆë²¨ ì§‘ê³„
        if 'table_detection' not in self.metrics['stage_metrics']:
            self.metrics['stage_metrics']['table_detection'] = {
                'false_positive': 0,
                'total_pages': 0,
                'fp_pages': []
            }
        
        self.metrics['stage_metrics']['table_detection']['total_pages'] += 1
        
        if is_false_positive:
            self.metrics['stage_metrics']['table_detection']['false_positive'] += 1
            if page_num:
                self.metrics['stage_metrics']['table_detection']['fp_pages'].append(page_num)
        
        # âœ… í˜ì´ì§€ ë‹¨ìœ„ ìƒì„¸ ì •ë³´
        if page_num:
            if 'table_fp_by_page' not in self.metrics['page_level_details']:
                self.metrics['page_level_details']['table_fp_by_page'] = {}
            
            self.metrics['page_level_details']['table_fp_by_page'][page_num] = {
                'has_table': page_has_table,
                'detected_tables': detected_tables,
                'confidence': confidence,
                'is_false_positive': is_false_positive
            }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if is_false_positive:
            msg = f"TABLE_FP: page={page_num}, detected={detected_tables}, confidence={confidence:.3f}"
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
    
    def record_amendment_sync(self, chunks: List[Dict[str, Any]]):
        """
        4ï¸âƒ£ Amendment Capture Rate
        
        ëª©ì : ê°œì •/ì‚­ì œ ë©”íƒ€ ë™ê¸°í™”
        DoD: = 1.0
        """
        total = len(chunks)
        synced = 0
        
        for chunk in chunks:
            metadata = chunk.get('metadata', {})
            
            # ê°œì • ë©”íƒ€ ì¡´ì¬ ì—¬ë¶€
            has_amended = bool(metadata.get('amended_dates') or metadata.get('change_log'))
            
            # ë³¸ë¬¸ì— ê°œì •/ì‚­ì œ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€
            content = chunk.get('content', '')
            has_keyword = any(kw in content for kw in ['ê°œì •', 'ì‚­ì œ', 'ì‹ ì„¤'])
            
            # ë™ê¸°í™” íŒì •: í‚¤ì›Œë“œ ìˆìœ¼ë©´ ë©”íƒ€ë„ ìˆì–´ì•¼ í•¨
            if has_keyword:
                if has_amended:
                    synced += 1
            else:
                synced += 1  # í‚¤ì›Œë“œ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
        
        capture_rate = synced / max(1, total)
        
        self.metrics['stage_metrics']['amendment_sync'] = {
            'capture_rate': capture_rate,
            'synced_count': synced,
            'total_chunks': total
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if capture_rate < self.DOD_CRITERIA['amendment_capture_rate']:
            missing = total - synced
            msg = (f"AMENDMENT_SYNC: rate={capture_rate:.3f} < {self.DOD_CRITERIA['amendment_capture_rate']:.3f} "
                   f"(ë¯¸ë™ê¸°: {missing}ê°œ/{total}ê°œ)")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
        else:
            logger.info(f"   âœ… Amendment Sync: rate={capture_rate:.3f} ({synced}/{total})")
    
    def record_empty_articles(self, chunks: List[Dict[str, Any]]):
        """
        5ï¸âƒ£ Empty Article Rate
        
        ëª©ì : ë¹ˆ ì¡°ë¬¸ ìƒì„± ë°©ì§€
        DoD: = 0
        """
        total = len(chunks)
        empty = 0
        
        for chunk in chunks:
            content = chunk.get('content', '').strip()
            
            # ë¹ˆ ì¡°ë¬¸ íŒì • (ì œëª©ë§Œ ìˆê³  ë³¸ë¬¸ ì—†ìŒ)
            if not content or len(content) < 10:
                empty += 1
        
        empty_rate = empty / max(1, total)
        
        self.metrics['stage_metrics']['empty_articles'] = {
            'empty_rate': empty_rate,
            'empty_count': empty,
            'total_articles': total
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if empty_rate > self.DOD_CRITERIA['empty_article_rate']:
            msg = (f"EMPTY_ARTICLES: rate={empty_rate:.3f} > {self.DOD_CRITERIA['empty_article_rate']:.3f} "
                   f"(ë¹ˆ ì¡°ë¬¸: {empty}ê°œ/{total}ê°œ)")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
        else:
            logger.info(f"   âœ… Empty Articles: rate={empty_rate:.3f} (ë¹ˆ ì¡°ë¬¸: {empty}/{total})")
    
    # ==========================================
    # âœ… GPT ì œì•ˆ ì‹ ê·œ 2ê°€ì§€ ì§€í‘œ
    # ==========================================
    
    def record_hierarchy_preservation(
        self,
        chunks: List[Dict[str, Any]],
        expected_layers: Optional[List[str]] = None
    ):
        """
        âœ… 6ï¸âƒ£ Hierarchy Preservation Rate (GPT ì œì•ˆ)
        
        ëª©ì : ì¡°Â·í•­Â·í˜¸ ê³„ì¸µ ë³´ì¡´ìœ¨
        DoD: â‰¥ 0.95
        
        ì¸¡ì •:
        - ì¡°(ì œâ—‹ì¡°) ê²€ì¶œ ì—¬ë¶€
        - í•­(â‘ , â‘¡, ì œâ—‹í•­) ê²€ì¶œ ì—¬ë¶€
        - í˜¸(ê°€., ë‚˜., ì œâ—‹í˜¸) ê²€ì¶œ ì—¬ë¶€
        
        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            expected_layers: ê¸°ëŒ€ë˜ëŠ” ê³„ì¸µ ['article', 'clause', 'item'] (ì—†ìœ¼ë©´ ìë™ ê°ì§€)
        """
        if not expected_layers:
            expected_layers = ['article']  # ê¸°ë³¸: ì¡°ë¬¸ë§Œ ì²´í¬
        
        layer_patterns = {
            'article': r'ì œ\s?\d+ì¡°',
            'clause': r'[â‘ -â‘³]|ì œ\s?\d+í•­',
            'item': r'[ê°€-í£]\.|ì œ\s?\d+í˜¸'
        }
        
        detected_layers = set()
        layer_counts = defaultdict(int)
        
        for chunk in chunks:
            content = chunk.get('content', '')
            
            for layer, pattern in layer_patterns.items():
                if re.search(pattern, content):
                    detected_layers.add(layer)
                    layer_counts[layer] += 1
        
        # ë³´ì¡´ìœ¨ ê³„ì‚°
        expected_set = set(expected_layers)
        preservation_rate = len(detected_layers & expected_set) / max(1, len(expected_set))
        
        self.metrics['stage_metrics']['hierarchy_preservation'] = {
            'preservation_rate': preservation_rate,
            'expected_layers': list(expected_layers),
            'detected_layers': list(detected_layers),
            'layer_counts': dict(layer_counts),
            'missing_layers': list(expected_set - detected_layers)
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if preservation_rate < self.DOD_CRITERIA['hierarchy_preservation_rate']:
            missing = list(expected_set - detected_layers)
            msg = (f"HIERARCHY_PRESERVATION: rate={preservation_rate:.3f} < "
                   f"{self.DOD_CRITERIA['hierarchy_preservation_rate']:.3f} "
                   f"(ëˆ„ë½ ê³„ì¸µ: {missing})")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
        else:
            logger.info(f"   âœ… Hierarchy Preservation: rate={preservation_rate:.3f} (ê³„ì¸µ: {list(detected_layers)})")
    
    def record_boundary_cross_bleed(
        self,
        chunks: List[Dict[str, Any]]
    ):
        """
        âœ… 7ï¸âƒ£ Boundary Cross-Bleed Rate (GPT ì œì•ˆ)
        
        ëª©ì : ì¡°ë¬¸ ê²½ê³„ ëˆ„ìˆ˜ íƒì§€
        DoD: = 0
        
        ì¸¡ì •:
        - ì œâ—‹ì¡° ë¸”ë¡ ë‚´ë¶€ì— ë‹¤ë¥¸ ì¡°ë¬¸ í‘œì‹ì´ ì„ì¸ ë¹„ìœ¨
        - ì˜ˆ: ì œ1ì¡° ë‚´ìš© ì¤‘ì— "ì œ2ì¡°", "ì œ3ì¡°" ê°™ì€ í‘œì‹ì´ ìˆìœ¼ë©´ ëˆ„ìˆ˜
        
        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        total_articles = 0
        cross_bleed_count = 0
        cross_bleed_details = []
        
        for chunk in chunks:
            article_no = chunk.get('article_no', '')
            content = chunk.get('content', '')
            
            # ì¡°ë¬¸ ì²­í¬ë§Œ ì²´í¬
            if not article_no or not re.match(r'ì œ\s?\d+ì¡°', article_no):
                continue
            
            total_articles += 1
            
            # ë³¸ë¬¸ì—ì„œ ë‹¤ë¥¸ ì¡°ë¬¸ í‘œì‹ ê²€ì¶œ
            other_articles = re.findall(r'ì œ\s?\d+ì¡°', content)
            
            # ìê¸° ìì‹  ì œì™¸
            other_articles = [a for a in other_articles if a != article_no]
            
            if other_articles:
                cross_bleed_count += 1
                cross_bleed_details.append({
                    'article_no': article_no,
                    'mixed_with': other_articles
                })
        
        cross_bleed_rate = cross_bleed_count / max(1, total_articles)
        
        self.metrics['stage_metrics']['boundary_cross_bleed'] = {
            'cross_bleed_rate': cross_bleed_rate,
            'cross_bleed_count': cross_bleed_count,
            'total_articles': total_articles,
            'details': cross_bleed_details[:5]  # ìµœëŒ€ 5ê°œë§Œ ê¸°ë¡
        }
        
        # âœ… ì›ì¸ ì§€í–¥ ë¡œê·¸
        if cross_bleed_rate > self.DOD_CRITERIA['boundary_cross_bleed_rate']:
            msg = (f"BOUNDARY_CROSS_BLEED: rate={cross_bleed_rate:.3f} > "
                   f"{self.DOD_CRITERIA['boundary_cross_bleed_rate']:.3f} "
                   f"(ëˆ„ìˆ˜ ì¡°ë¬¸: {cross_bleed_count}ê°œ/{total_articles}ê°œ)")
            self.metrics['regression_flags'].append(msg)
            logger.warning(f"   âš ï¸ {msg}")
            
            # ìƒì„¸ ë¡œê·¸
            for detail in cross_bleed_details[:3]:
                logger.warning(f"      - {detail['article_no']} ë‚´ë¶€ì— {detail['mixed_with']} í˜¼ì…")
        else:
            logger.info(f"   âœ… Boundary Cross-Bleed: rate={cross_bleed_rate:.3f} (ëˆ„ìˆ˜: {cross_bleed_count}/{total_articles})")
    
    # ==========================================
    # DoD ê²€ì¦ ë° ê²°ê³¼ ì €ì¥
    # ==========================================
    
    def calculate_quality_scores(self):
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0~100)"""
        stage = self.metrics['stage_metrics']
        
        scores = {}
        
        # 1. Article Boundary
        scores['article_boundary'] = stage.get('article_boundaries', {}).get('f1_score', 0) * 100
        
        # 2. List Binding
        scores['list_binding'] = stage.get('list_binding', {}).get('fix_rate', 0) * 100
        
        # 3. Table Detection (FP=0ì´ë©´ 100ì )
        fp = stage.get('table_detection', {}).get('false_positive', 0)
        scores['table_detection'] = 100 if fp == 0 else 0
        
        # 4. Amendment Sync
        scores['amendment_sync'] = stage.get('amendment_sync', {}).get('capture_rate', 0) * 100
        
        # 5. Empty Articles
        empty_rate = stage.get('empty_articles', {}).get('empty_rate', 0)
        scores['empty_articles'] = (1 - empty_rate) * 100
        
        # âœ… 6. Hierarchy Preservation
        scores['hierarchy_preservation'] = stage.get('hierarchy_preservation', {}).get('preservation_rate', 0) * 100
        
        # âœ… 7. Boundary Cross-Bleed
        bleed_rate = stage.get('boundary_cross_bleed', {}).get('cross_bleed_rate', 0)
        scores['boundary_cross_bleed'] = (1 - bleed_rate) * 100
        
        # Overall (í‰ê· )
        scores['overall'] = sum(scores.values()) / len(scores)
        
        self.metrics['quality_scores'] = scores
    
    def verify_dod(self):
        """DoD ê²€ì¦"""
        stage = self.metrics['stage_metrics']
        dod_status = {}
        
        # 1. Article Boundary F1
        f1 = stage.get('article_boundaries', {}).get('f1_score', 0)
        dod_status['article_boundary_f1'] = {
            'value': f1,
            'target': self.DOD_CRITERIA['article_boundary_f1'],
            'pass': f1 >= self.DOD_CRITERIA['article_boundary_f1']
        }
        
        # 2. List Binding Fix Rate
        fix_rate = stage.get('list_binding', {}).get('fix_rate', 0)
        dod_status['list_binding_fix_rate'] = {
            'value': fix_rate,
            'target': self.DOD_CRITERIA['list_binding_fix_rate'],
            'pass': fix_rate >= self.DOD_CRITERIA['list_binding_fix_rate']
        }
        
        # 3. Table False Positive
        fp = stage.get('table_detection', {}).get('false_positive', 1)
        dod_status['table_false_positive'] = {
            'value': fp,
            'target': self.DOD_CRITERIA['table_false_positive'],
            'pass': fp == self.DOD_CRITERIA['table_false_positive']
        }
        
        # 4. Amendment Capture Rate
        capture = stage.get('amendment_sync', {}).get('capture_rate', 0)
        dod_status['amendment_capture_rate'] = {
            'value': capture,
            'target': self.DOD_CRITERIA['amendment_capture_rate'],
            'pass': capture >= self.DOD_CRITERIA['amendment_capture_rate']
        }
        
        # 5. Empty Article Rate
        empty = stage.get('empty_articles', {}).get('empty_rate', 1)
        dod_status['empty_article_rate'] = {
            'value': empty,
            'target': self.DOD_CRITERIA['empty_article_rate'],
            'pass': empty == self.DOD_CRITERIA['empty_article_rate']
        }
        
        # âœ… 6. Hierarchy Preservation Rate
        hierarchy = stage.get('hierarchy_preservation', {}).get('preservation_rate', 0)
        dod_status['hierarchy_preservation_rate'] = {
            'value': hierarchy,
            'target': self.DOD_CRITERIA['hierarchy_preservation_rate'],
            'pass': hierarchy >= self.DOD_CRITERIA['hierarchy_preservation_rate']
        }
        
        # âœ… 7. Boundary Cross-Bleed Rate
        bleed = stage.get('boundary_cross_bleed', {}).get('cross_bleed_rate', 1)
        dod_status['boundary_cross_bleed_rate'] = {
            'value': bleed,
            'target': self.DOD_CRITERIA['boundary_cross_bleed_rate'],
            'pass': bleed == self.DOD_CRITERIA['boundary_cross_bleed_rate']
        }
        
        self.metrics['dod_status'] = dod_status
        
        # ì „ì²´ í†µê³¼ ì—¬ë¶€
        all_pass = all(status['pass'] for status in dod_status.values())
        
        if all_pass:
            logger.info("   âœ… DoD ê²€ì¦: ì „ì²´ í†µê³¼ (ë¦´ë¦¬ìŠ¤ ê°€ëŠ¥)")
        else:
            failed = [k for k, v in dod_status.items() if not v['pass']]
            logger.error(f"   âŒ DoD ê²€ì¦: ì‹¤íŒ¨ í•­ëª© {len(failed)}ê°œ - {failed}")
    
    def save(self, filename: Optional[str] = None):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        self.calculate_quality_scores()
        self.verify_dod()
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"metrics_{self.metrics['doc_id']}_{timestamp}.json"
        
        output_path = self.output_dir / filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.metrics, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥: {output_path}")
    
    def get_summary(self) -> Dict[str, Any]:
        """ìš”ì•½ ë°˜í™˜"""
        self.calculate_quality_scores()
        self.verify_dod()
        
        return {
            'doc_id': self.metrics['doc_id'],
            'doc_type': self.metrics['doc_type'],
            'metrics': {
                'article_boundary_f1': self.metrics['stage_metrics'].get('article_boundaries', {}).get('f1_score', 0),
                'list_binding_fix_rate': self.metrics['stage_metrics'].get('list_binding', {}).get('fix_rate', 0),
                'table_false_positive': self.metrics['stage_metrics'].get('table_detection', {}).get('false_positive', 0),
                'amendment_capture_rate': self.metrics['stage_metrics'].get('amendment_sync', {}).get('capture_rate', 0),
                'empty_article_rate': self.metrics['stage_metrics'].get('empty_articles', {}).get('empty_rate', 0),
                'hierarchy_preservation_rate': self.metrics['stage_metrics'].get('hierarchy_preservation', {}).get('preservation_rate', 0),
                'boundary_cross_bleed_rate': self.metrics['stage_metrics'].get('boundary_cross_bleed', {}).get('cross_bleed_rate', 0)
            },
            'quality_scores': self.metrics['quality_scores'],
            'dod_status': self.metrics['dod_status'],
            'dod_pass': all(status['pass'] for status in self.metrics['dod_status'].values()),
            'regression_flags': self.metrics['regression_flags']
        }