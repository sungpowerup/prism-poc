"""
PRISM Phase 2.8 - Element Classifier
CV ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± + VLM ê²€ì¦ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-21
Version: 2.0
"""

import cv2
import numpy as np
from PIL import Image
from typing import Dict, Tuple, Optional, List
import logging
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ClassificationResult:
    """ë¶„ë¥˜ ê²°ê³¼"""
    element_type: str  # 'chart', 'table', 'text', 'diagram', 'image'
    confidence: float  # 0.0 ~ 1.0
    features: Dict[str, float]  # íŠ¹ì§• ì ìˆ˜
    method: str  # 'cv_heuristic', 'vlm', 'hybrid'


class ElementClassifier:
    """
    Element ìë™ ë¶„ë¥˜ê¸° (CV + VLM í•˜ì´ë¸Œë¦¬ë“œ)
    
    ë‹¨ê³„:
    1. CV ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ë¶„ë¥˜ (ë¹ ë¦„, 80% ì •í™•ë„)
    2. ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ VLM ê²€ì¦ (ëŠë¦¼, 95% ì •í™•ë„)
    3. ìµœì¢… ê²°ì •
    """
    
    def __init__(self, use_vlm: bool = True, vlm_threshold: float = 0.7):
        """
        Args:
            use_vlm: VLM ê²€ì¦ ì‚¬ìš© ì—¬ë¶€
            vlm_threshold: VLM ê²€ì¦ íŠ¸ë¦¬ê±° ì„ê³„ê°’ (ì´í•˜ë©´ VLM í˜¸ì¶œ)
        """
        self.use_vlm = use_vlm
        self.vlm_threshold = vlm_threshold
        
        # VLM ì„œë¹„ìŠ¤ (lazy loading)
        self._vlm_service = None
    
    @property
    def vlm_service(self):
        """VLM ì„œë¹„ìŠ¤ lazy loading"""
        if self._vlm_service is None and self.use_vlm:
            try:
                from core.vlm_service import VLMService
                self._vlm_service = VLMService()
                logger.info("âœ… VLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ VLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_vlm = False
        
        return self._vlm_service
    
    def classify(
        self,
        image: Image.Image,
        use_vlm_fallback: bool = True
    ) -> ClassificationResult:
        """
        Element ë¶„ë¥˜
        
        Args:
            image: PIL Image
            use_vlm_fallback: ì‹ ë¢°ë„ ë‚®ì„ ë•Œ VLM ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ClassificationResult
        """
        
        # Step 1: CV ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ë¶„ë¥˜
        cv_result = self._classify_cv(image)
        
        logger.info(
            f"ğŸ” CV ë¶„ë¥˜: {cv_result.element_type} "
            f"(ì‹ ë¢°ë„: {cv_result.confidence:.2f})"
        )
        
        # Step 2: ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ VLM ê²€ì¦
        if (self.use_vlm and 
            use_vlm_fallback and 
            cv_result.confidence < self.vlm_threshold):
            
            logger.info("ğŸ¤– ì‹ ë¢°ë„ ë‚®ìŒ â†’ VLM ê²€ì¦ ì‹œì‘...")
            
            try:
                vlm_result = self._classify_vlm(image)
                
                logger.info(
                    f"âœ… VLM ë¶„ë¥˜: {vlm_result.element_type} "
                    f"(ì‹ ë¢°ë„: {vlm_result.confidence:.2f})"
                )
                
                # VLM ê²°ê³¼ ìš°ì„  (ë” ì •í™•í•¨)
                return vlm_result
            
            except Exception as e:
                logger.warning(f"âš ï¸ VLM ë¶„ë¥˜ ì‹¤íŒ¨: {e}, CV ê²°ê³¼ ì‚¬ìš©")
        
        # Step 3: CV ê²°ê³¼ ë°˜í™˜
        return cv_result
    
    def _classify_cv(self, image: Image.Image) -> ClassificationResult:
        """CV ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ë¶„ë¥˜"""
        
        # PIL â†’ OpenCV
        img_array = np.array(image)
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_cv = img_array
        
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY) if len(img_cv.shape) == 3 else img_cv
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = {
            'has_axes': self._detect_axes(gray),
            'has_grid': self._detect_grid_lines(gray),
            'has_legend': self._detect_legend(img_cv),
            'has_table_lines': self._detect_table_lines(gray),
            'has_boxes': self._detect_boxes(gray),
            'has_arrows': self._detect_arrows(gray),
            'text_density': self._estimate_text_density(gray),
            'color_variance': self._calculate_color_variance(img_cv),
            'edge_density': self._calculate_edge_density(gray)
        }
        
        # ë¶„ë¥˜ ë¡œì§
        element_type, confidence = self._classify_from_features(features)
        
        return ClassificationResult(
            element_type=element_type,
            confidence=confidence,
            features=features,
            method='cv_heuristic'
        )
    
    def _classify_from_features(
        self,
        features: Dict[str, float]
    ) -> Tuple[str, float]:
        """íŠ¹ì§• ê¸°ë°˜ ë¶„ë¥˜"""
        
        scores = {
            'chart': 0.0,
            'table': 0.0,
            'diagram': 0.0,
            'text': 0.0,
            'image': 0.0
        }
        
        # ì°¨íŠ¸ ì ìˆ˜
        if features['has_axes'] > 0.5:
            scores['chart'] += 0.4
        if features['has_grid'] > 0.3:
            scores['chart'] += 0.3
        if features['has_legend'] > 0.3:
            scores['chart'] += 0.3
        if features['color_variance'] > 0.4:
            scores['chart'] += 0.2
        
        # í‘œ ì ìˆ˜
        if features['has_table_lines'] > 0.6:
            scores['table'] += 0.7
        if features['text_density'] > 0.5:
            scores['table'] += 0.2
        if features['edge_density'] > 0.5:
            scores['table'] += 0.1
        
        # ë‹¤ì´ì–´ê·¸ë¨ ì ìˆ˜
        if features['has_boxes'] > 0.5:
            scores['diagram'] += 0.4
        if features['has_arrows'] > 0.4:
            scores['diagram'] += 0.4
        if 0.2 < features['text_density'] < 0.5:
            scores['diagram'] += 0.2
        
        # í…ìŠ¤íŠ¸ ì ìˆ˜
        if features['text_density'] > 0.7:
            scores['text'] += 0.6
        if features['edge_density'] < 0.3:
            scores['text'] += 0.2
        if features['color_variance'] < 0.2:
            scores['text'] += 0.2
        
        # ì´ë¯¸ì§€ ì ìˆ˜ (ê¸°ë³¸ê°’)
        if features['color_variance'] > 0.6:
            scores['image'] += 0.4
        if features['edge_density'] > 0.6:
            scores['image'] += 0.3
        if features['text_density'] < 0.2:
            scores['image'] += 0.3
        
        # ìµœê³  ì ìˆ˜ ì„ íƒ
        best_type = max(scores, key=scores.get)
        confidence = min(scores[best_type], 1.0)
        
        # ìµœì†Œ ì‹ ë¢°ë„ ë³´ì¥
        if confidence < 0.3:
            confidence = 0.3
        
        return best_type, confidence
    
    def _detect_axes(self, gray: np.ndarray) -> float:
        """ì¶• ê°ì§€ (ì°¨íŠ¸ íŠ¹ì§•)"""
        
        # Hough Line Transform
        edges = cv2.Canny(gray, 50, 150)
        lines = cv2.HoughLinesP(
            edges, 1, np.pi/180, threshold=50,
            minLineLength=gray.shape[1] * 0.3,
            maxLineGap=10
        )
        
        if lines is None:
            return 0.0
        
        # ìˆ˜í‰/ìˆ˜ì§ì„  ë¹„ìœ¨
        h_lines = 0
        v_lines = 0
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
            
            if angle < 10 or angle > 170:
                h_lines += 1
            elif 80 < angle < 100:
                v_lines += 1
        
        # ì¶•ì´ ìˆìœ¼ë©´ ìˆ˜í‰+ìˆ˜ì§ì„ ì´ ë§ìŒ
        axis_score = min((h_lines + v_lines) / 10, 1.0)
        
        return axis_score
    
    def _detect_grid_lines(self, gray: np.ndarray) -> float:
        """ê²©ìì„  ê°ì§€ (ì°¨íŠ¸ íŠ¹ì§•)"""
        
        # ì–‡ì€ ì„  ê°ì§€
        edges = cv2.Canny(gray, 30, 100)
        lines = cv2.HoughLinesP(
            edges, 1, np.pi/180, threshold=30,
            minLineLength=gray.shape[1] * 0.2,
            maxLineGap=20
        )
        
        if lines is None or len(lines) < 5:
            return 0.0
        
        # í‰í–‰ì„  ê°œìˆ˜
        grid_score = min(len(lines) / 15, 1.0)
        
        return grid_score
    
    def _detect_legend(self, img: np.ndarray) -> float:
        """ë²”ë¡€ ê°ì§€ (ì°¨íŠ¸ íŠ¹ì§•)"""
        
        # ìƒ‰ìƒ ë¸”ë¡ + í…ìŠ¤íŠ¸ íŒ¨í„´ ê°ì§€
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ì‘ì€ ìƒ‰ìƒ ì˜ì—­ì´ í…ìŠ¤íŠ¸ ì˜†ì— ìˆìŒ
        
        # HSV ë³€í™˜
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # ë‹¤ì–‘í•œ ìƒ‰ìƒ ì¡´ì¬ ì—¬ë¶€
        unique_colors = len(np.unique(hsv[:, :, 0])) / 180
        
        legend_score = min(unique_colors, 1.0) * 0.5
        
        return legend_score
    
    def _detect_table_lines(self, gray: np.ndarray) -> float:
        """í‘œ ì„  ê°ì§€"""
        
        # ìˆ˜í‰/ìˆ˜ì§ ì„  ê°ì§€
        edges = cv2.Canny(gray, 50, 150)
        
        # ìˆ˜í‰ì„  ì»¤ë„
        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        h_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, h_kernel)
        
        # ìˆ˜ì§ì„  ì»¤ë„
        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        v_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, v_kernel)
        
        # êµì°¨ì  ê°œìˆ˜
        intersections = cv2.bitwise_and(h_lines, v_lines)
        intersection_count = np.sum(intersections > 0)
        
        # ì •ê·œí™”
        table_score = min(intersection_count / 100, 1.0)
        
        return table_score
    
    def _detect_boxes(self, gray: np.ndarray) -> float:
        """ë°•ìŠ¤ ê°ì§€ (ë‹¤ì´ì–´ê·¸ë¨ íŠ¹ì§•)"""
        
        # ì»¨íˆ¬ì–´ ê°ì§€
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(
            edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        # ì‚¬ê°í˜• ë¹„ìœ¨
        rectangles = 0
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 100:  # ë„ˆë¬´ ì‘ì€ ê²ƒ ì œì™¸
                continue
            
            # ê·¼ì‚¬ ë‹¤ê°í˜•
            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.04 * peri, True)
            
            if len(approx) == 4:  # ì‚¬ê°í˜•
                rectangles += 1
        
        box_score = min(rectangles / 10, 1.0)
        
        return box_score
    
    def _detect_arrows(self, gray: np.ndarray) -> float:
        """í™”ì‚´í‘œ ê°ì§€ (ë‹¤ì´ì–´ê·¸ë¨ íŠ¹ì§•)"""
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ì‚¼ê°í˜• + ì„ 
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(
            edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        triangles = 0
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 50 or area > 500:
                continue
            
            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.04 * peri, True)
            
            if len(approx) == 3:  # ì‚¼ê°í˜•
                triangles += 1
        
        arrow_score = min(triangles / 5, 1.0)
        
        return arrow_score
    
    def _estimate_text_density(self, gray: np.ndarray) -> float:
        """í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì •"""
        
        # ì ì‘í˜• ì„ê³„ê°’
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # ì‘ì€ ì»´í¬ë„ŒíŠ¸ ë¹„ìœ¨ (í…ìŠ¤íŠ¸ëŠ” ì‘ì€ ìš”ì†Œê°€ ë§ìŒ)
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary)
        
        small_components = np.sum(stats[:, cv2.CC_STAT_AREA] < 200)
        text_density = min(small_components / 100, 1.0)
        
        return text_density
    
    def _calculate_color_variance(self, img: np.ndarray) -> float:
        """ìƒ‰ìƒ ë¶„ì‚° ê³„ì‚°"""
        
        if len(img.shape) == 2:
            return 0.0
        
        # HSV ìƒ‰ìƒ ì±„ë„ì˜ í‘œì¤€í¸ì°¨
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        h_std = np.std(hsv[:, :, 0])
        
        # ì •ê·œí™” (0-180 ë²”ìœ„)
        color_variance = min(h_std / 90, 1.0)
        
        return color_variance
    
    def _calculate_edge_density(self, gray: np.ndarray) -> float:
        """ì—£ì§€ ë°€ë„ ê³„ì‚°"""
        
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        
        return min(edge_ratio * 10, 1.0)
    
    def _classify_vlm(self, image: Image.Image) -> ClassificationResult:
        """VLM ê¸°ë°˜ ë¶„ë¥˜ (ë†’ì€ ì •í™•ë„)"""
        
        import io
        
        # PIL â†’ bytes
        img_buffer = io.BytesIO()
        image.save(img_buffer, format='PNG')
        image_bytes = img_buffer.getvalue()
        
        # VLM í”„ë¡¬í”„íŠ¸
        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. chart - ì°¨íŠ¸, ê·¸ë˜í”„ (ë§‰ëŒ€, ì„ , íŒŒì´, ì‚°ì ë„ ë“±. ì¶•ê³¼ ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆìŒ)
2. table - í‘œ (í–‰ê³¼ ì—´ë¡œ êµ¬ì„±ëœ ë°ì´í„°)
3. diagram - ë‹¤ì´ì–´ê·¸ë¨ (í”Œë¡œìš°ì°¨íŠ¸, ì•„í‚¤í…ì²˜, ë„¤íŠ¸ì›Œí¬ ë“±. ë°•ìŠ¤ì™€ í™”ì‚´í‘œ)
4. text - í…ìŠ¤íŠ¸ ë¸”ë¡ (ì£¼ë¡œ ë¬¸ìë¡œ êµ¬ì„±)
5. image - ì¼ë°˜ ì´ë¯¸ì§€ (ì‚¬ì§„, ìŠ¤í¬ë¦°ìƒ·, ì¼ëŸ¬ìŠ¤íŠ¸)

í•œ ë‹¨ì–´ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš” (chart, table, diagram, text, image ì¤‘ í•˜ë‚˜):"""
        
        # VLM API í˜¸ì¶œ
        result = self.vlm_service.generate_caption(
            image_data=image_bytes,
            element_type='image',
            custom_prompt=prompt
        )
        
        # ì‘ë‹µ íŒŒì‹±
        element_type = result['caption'].strip().lower()
        
        # ìœ íš¨ì„± ê²€ì¦
        valid_types = ['chart', 'table', 'diagram', 'text', 'image']
        if element_type not in valid_types:
            logger.warning(f"âš ï¸ VLM ì‘ë‹µ ì´ìƒ: '{element_type}', ê¸°ë³¸ê°’ 'image' ì‚¬ìš©")
            element_type = 'image'
        
        return ClassificationResult(
            element_type=element_type,
            confidence=0.95,  # VLMì€ ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„
            features={},
            method='vlm'
        )


# ========== í…ŒìŠ¤íŠ¸ ì½”ë“œ ==========

if __name__ == '__main__':
    
    # í…ŒìŠ¤íŠ¸
    classifier = ElementClassifier(use_vlm=True)
    
    test_image = Image.open('input/test_chart.png')
    result = classifier.classify(test_image)
    
    print(f"\në¶„ë¥˜ ê²°ê³¼:")
    print(f"  íƒ€ì…: {result.element_type}")
    print(f"  ì‹ ë¢°ë„: {result.confidence:.2f}")
    print(f"  ë°©ë²•: {result.method}")
    print(f"\níŠ¹ì§•:")
    for key, value in result.features.items():
        print(f"  {key}: {value:.2f}")