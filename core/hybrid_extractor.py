"""
core/hybrid_extractor.py
PRISM Phase 0.3.4 P0 - Hybrid Extractor (Fallback í’ˆì§ˆ ê°œì„ )

âœ… Phase 0.3.4 P0 ê¸´ê¸‰ ìˆ˜ì •:
1. call_with_image() í˜¸ì¶œë¡œ ë³€ê²½ (VLM ì •í•©)
2. Fallback ê²°ê³¼ í’ˆì§ˆ ìµœì†Œì„  ë³´ì¥:
   - í˜ì´ì§€ ë²ˆí˜¸ ì œê±° (402-1, 402-2 ë“±)
   - ê¸°ë³¸ ê³µë°± ë³µì› (ì¡°ë¬¸ ë²ˆí˜¸/ê´„í˜¸ ê¸°ì¤€)
   - í—¤ë” ì¤‘ë³µ ì œê±°
3. Safe ëª¨ë“ˆ ì‚¬ìš©

âš ï¸ P0 ìˆ˜ì • ì´ìœ :
- Fallback ê²°ê³¼ê°€ "ë‹¨ì–´ ì‚¬ì´ ê³µë°± ì—†ìŒ" ìƒíƒœ
- RAG/ì²­í‚¹ ì™„ì „ ë¬´ë ¥í™”
- GPT ë¶„ì„: "P0-2 Fallback ìµœì†Œ í’ˆì§ˆì„  ì˜ë¬´"

Author: ì´ì„œì˜ (Backend Lead) + ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-08
Version: Phase 0.3.4 P0
"""

import logging
import re
import unicodedata
from typing import Dict, Any, List, Optional

import pypdf
from pathlib import Path

# âœ… Phase 0.3.4 P0: Safe ëª¨ë“ˆ ì‚¬ìš©
try:
    from .quick_layout_analyzer import QuickLayoutAnalyzer
    from .prompt_rules import PromptRules
    from .post_merge_normalizer_safe import PostMergeNormalizer
    from .typo_normalizer_safe import TypoNormalizer
    from .kvs_normalizer import KVSNormalizer
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from quick_layout_analyzer import QuickLayoutAnalyzer
    from prompt_rules import PromptRules
    from post_merge_normalizer_safe import PostMergeNormalizer
    from typo_normalizer_safe import TypoNormalizer
    from kvs_normalizer import KVSNormalizer

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 0.3.4 P0 í†µí•© ì¶”ì¶œê¸°
    
    âœ… Phase 0.3.4 P0 ê°œì„ :
    - VLM ì¸í„°í˜ì´ìŠ¤ ì •í•© (call_with_image)
    - Fallback í’ˆì§ˆ ìµœì†Œì„  ë³´ì¥
    - Safe ëª¨ë“ˆ ì‚¬ìš©
    """
    
    STATUTE_KEYWORDS = [
        'ì¡°', 'í•­', 'í˜¸', 'ì§ì›', 'ê·œì •', 'ì„ìš©', 'ì±„ìš©',
        'ìŠ¹ì§„', 'ì „ë³´', 'íœ´ì§', 'ë©´ì§', 'í•´ì„', 'íŒŒë©´',
        'ì¸ì‚¬', 'ë³´ìˆ˜', 'ê¸‰ì—¬', 'ìˆ˜ë‹¹', 'ë³µë¬´', 'ì§•ê³„',
        'ìœ„ì›íšŒ'
    ]
    
    # âœ… P0-2: í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´
    PAGE_NUMBER_PATTERN = re.compile(r'\b\d{3,4}-\d{1,2}\b')
    
    def __init__(
        self,
        vlm_service,
        pdf_path: str,
        allow_tables: bool = False
    ):
        """ì´ˆê¸°í™”"""
        self.vlm_service = vlm_service
        self.pdf_path = pdf_path
        self.allow_tables = allow_tables
        
        self.layout_analyzer = QuickLayoutAnalyzer()
        self.prompt_rules = PromptRules()
        self.post_normalizer = PostMergeNormalizer()
        self.typo_normalizer = TypoNormalizer()
        
        self.vlm_success_count = 0
        self.fallback_count = 0
        
        logger.info("âœ… HybridExtractor Phase 0.3.4 P0 ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - PDF: {pdf_path}")
        logger.info(f"   - í‘œ í—ˆìš©: {allow_tables}")
        logger.info(f"   - Safe Mode: í™œì„±í™”")
    
    def extract(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """
        âœ… Phase 0.3.4 P0: í˜ì´ì§€ë³„ ì¶”ì¶œ
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            ì¶”ì¶œ ê²°ê³¼
        """
        logger.info(f"   ğŸ” í˜ì´ì§€ {page_num} ì¶”ì¶œ ì‹œì‘")
        
        # Step 1: ë ˆì´ì•„ì›ƒ ë¶„ì„
        hints = self.layout_analyzer.analyze(image_data)
        hints['allow_tables'] = self.allow_tables
        
        # Step 2: í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.prompt_rules.build_prompt(hints)
        
        # Step 3: âœ… P0-1 ìˆ˜ì •: call_with_image() ì‚¬ìš©
        try:
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¡°ë¬¸ ë²ˆí˜¸ ê²€ì¦ìš©)
            ocr_text = hints.get('ocr_text', '')
            
            # VLM í˜¸ì¶œ
            content = self.vlm_service.call_with_image(
                image_data=image_data,
                prompt=prompt,
                page_num=page_num,
                ocr_text=ocr_text
            )
            
            if content and len(content.strip()) >= 50:
                self.vlm_success_count += 1
                source = 'vlm'
                logger.info(f"      âœ… VLM ì„±ê³µ: {len(content)}ì")
            else:
                logger.warning(f"      âš ï¸ VLM ì‘ë‹µ ë¶€ì¡± â†’ Fallback")
                content = self._fallback_extraction(page_num)
                self.fallback_count += 1
                source = 'fallback'
        
        except Exception as e:
            logger.warning(f"      âš ï¸ VLM ì‹¤íŒ¨: {e}, Fallback ì‚¬ìš©")
            content = self._fallback_extraction(page_num)
            self.fallback_count += 1
            source = 'fallback'
        
        # Step 4: í›„ì²˜ë¦¬
        if content:
            # ì •ê·œí™”
            content = self.post_normalizer.normalize(content, 'statute')
            content = self.typo_normalizer.normalize(content, 'statute')
            
            # ì¤‘ë³µ ì œê±°
            content = self._deduplicate_lines(content)
        
        # Step 5: í’ˆì§ˆ ì ìˆ˜
        quality_score = self._calculate_quality(content, hints)
        
        logger.info(f"      âœ… ì¶”ì¶œ ì™„ë£Œ: {len(content)}ì, í’ˆì§ˆ={quality_score}/100, source={source}")
        
        return {
            'content': content,
            'source': source,
            'quality_score': quality_score,
            'page_num': page_num,
            'hints': hints
        }
    
    def _fallback_extraction(self, page_num: int) -> str:
        """
        âœ… P0-2: Fallback í…ìŠ¤íŠ¸ ì¶”ì¶œ (í’ˆì§ˆ ìµœì†Œì„  ë³´ì¥)
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            í’ˆì§ˆ ê°œì„ ëœ í…ìŠ¤íŠ¸
        """
        try:
            with open(self.pdf_path, 'rb') as f:
                reader = pypdf.PdfReader(f)
                
                if page_num - 1 < len(reader.pages):
                    page = reader.pages[page_num - 1]
                    text = page.extract_text()
                    
                    if text and len(text.strip()) > 0:
                        # âœ… P0-2: Fallback í’ˆì§ˆ ê°œì„ 
                        text = self._improve_fallback_quality(text)
                        return text.strip()
        
        except Exception as e:
            logger.error(f"      âŒ Fallback ì˜¤ë¥˜: {e}")
        
        return ""
    
    def _improve_fallback_quality(self, text: str) -> str:
        """
        âœ… P0-2: Fallback í’ˆì§ˆ ìµœì†Œì„  ë³´ì¥
        
        GPT ë¶„ì„ ê¸°ì¤€:
        - í˜ì´ì§€ ë²ˆí˜¸ ì œê±°
        - ê¸°ë³¸ ê³µë°± ë³µì›
        - í—¤ë” ì¤‘ë³µ ì œê±°
        
        Args:
            text: ì›ë³¸ Fallback í…ìŠ¤íŠ¸
        
        Returns:
            í’ˆì§ˆ ê°œì„ ëœ í…ìŠ¤íŠ¸
        """
        logger.info("      ğŸ”§ Fallback í’ˆì§ˆ ê°œì„  ì‹œì‘")
        
        # 1. í˜ì´ì§€ ë²ˆí˜¸ ì œê±° (402-1, 402-2 ë“±)
        text = self.PAGE_NUMBER_PATTERN.sub('', text)
        
        # 2. "ì¸ì‚¬ê·œì •" ì¤‘ë³µ í—¤ë” ì œê±° (í˜ì´ì§€ë§ˆë‹¤ ë°˜ë³µë˜ëŠ” ê²½ìš°)
        lines = text.split('\n')
        seen_headers = set()
        cleaned_lines = []
        
        for line in lines:
            line_stripped = line.strip()
            
            # ì¤‘ë³µ í—¤ë” ì²´í¬
            if line_stripped in ['ì¸ì‚¬ê·œì •', '402-1', '402-2', '402-3']:
                if line_stripped in seen_headers:
                    continue  # ì¤‘ë³µ ì œê±°
                seen_headers.add(line_stripped)
            
            cleaned_lines.append(line)
        
        text = '\n'.join(cleaned_lines)
        
        # 3. ê¸°ë³¸ ê³µë°± ë³µì› (ì¡°ë¬¸ ë²ˆí˜¸/ê´„í˜¸ ê¸°ì¤€)
        # íŒ¨í„´: "ì œ1ì¡°(ëª©ì )ì´ê·œì •ì€" â†’ "ì œ1ì¡°(ëª©ì ) ì´ ê·œì •ì€"
        
        # 3-1. ì¡°ë¬¸ ë²ˆí˜¸ ë’¤ ê³µë°±
        text = re.sub(r'(ì œ\d+ì¡°(?:ì˜\d+)?)\(', r'\1 (', text)
        
        # 3-2. ê´„í˜¸ ë‹«ê¸° ë’¤ í•œê¸€ ì• ê³µë°±
        text = re.sub(r'\)([ê°€-í£])', r') \1', text)
        
        # 3-3. ë§ˆì¹¨í‘œ ë’¤ í•œê¸€ ì• ê³µë°±
        text = re.sub(r'\.([ê°€-í£])', r'. \1', text)
        
        # 3-4. ìˆ«ì ë’¤ í•œê¸€ ì• ê³µë°± (ê°œì • ì´ë ¥)
        text = re.sub(r'(\d{4}\.\d{1,2}\.\d{1,2})\.([ê°€-í£])', r'\1. \2', text)
        
        # 4. ê°œì • ì´ë ¥ ì¤„ êµ¬ë¶„
        # "ì œ37ì°¨ê°œì •2019.05.27.ì œ38ì°¨ê°œì •" â†’ "ì œ37ì°¨ ê°œì • 2019.05.27.\nì œ38ì°¨ ê°œì •"
        text = re.sub(r'(ì œ\d+ì°¨)ê°œì •', r'\1 ê°œì • ', text)
        text = re.sub(r'(\d{4}\.\d{1,2}\.\d{1,2}\.)(ì œ\d+ì°¨)', r'\1\n\2', text)
        
        # 5. ê³¼ë„í•œ ê³µë°± ì •ë¦¬
        text = re.sub(r' {2,}', ' ', text)
        
        logger.info("      âœ… Fallback í’ˆì§ˆ ê°œì„  ì™„ë£Œ")
        
        return text
    
    def _calculate_quality(self, content: str, hints: Dict[str, Any]) -> int:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not content or len(content.strip()) == 0:
            return 0
        
        score = 100
        
        # ê¸¸ì´ ì²´í¬
        if len(content) < 50:
            score -= 30
        
        # í•œê¸€ ë¹„ìœ¨
        korean_chars = len(re.findall(r'[ê°€-í£]', content))
        if korean_chars < len(content) * 0.3:
            score -= 20
        
        # âœ… P0-2: í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ ê°ì 
        page_markers = self.PAGE_NUMBER_PATTERN.findall(content)
        if page_markers:
            score -= 10
            logger.warning(f"      âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ ì”ì¡´: {len(page_markers)}ê°œ")
        
        return max(0, min(100, score))
    
    def _detect_doc_type_v2(self, content: str, hints: Dict[str, Any]) -> str:
        """
        ë¬¸ì„œ íƒ€ì… íƒì§€ v2
        
        Args:
            content: ì¶”ì¶œëœ ë‚´ìš©
            hints: ë ˆì´ì•„ì›ƒ íŒíŠ¸
        
        Returns:
            'statute', 'report', 'presentation', 'general'
        """
        # ì¡°ë¬¸ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        keyword_count = sum(1 for kw in self.STATUTE_KEYWORDS if kw in content)
        
        # ì¡°ë¬¸ í—¤ë” ê²€ìƒ‰
        article_pattern = re.compile(r'ì œ\s?\d+ì¡°')
        article_count = len(article_pattern.findall(content))
        
        # ê·œì • íŒì •
        if article_count >= 2 or keyword_count >= 5:
            return 'statute'
        
        # í‘œ ë§ìœ¼ë©´ ë³´ê³ ì„œ
        if hints.get('has_table', False):
            return 'report'
        
        return 'general'
    
    def _deduplicate_lines(self, text: str) -> str:
        """
        ì¤‘ë³µ ë¼ì¸ ì œê±°
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì¤‘ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        lines = text.split('\n')
        seen = set()
        result = []
        
        for line in lines:
            line_stripped = line.strip()
            
            if line_stripped and line_stripped not in seen:
                seen.add(line_stripped)
                result.append(line)
        
        return '\n'.join(result)
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        total = self.vlm_success_count + self.fallback_count
        
        return {
            'vlm_success': self.vlm_success_count,
            'fallback': self.fallback_count,
            'total': total,
            'fallback_ratio': self.fallback_count / total if total > 0 else 0
        }