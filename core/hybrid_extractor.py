"""
core/hybrid_extractor.py
PRISM Phase 5.3.2 - Hybrid Extractor (5ëŒ€ ì•ˆì „ê°€ë“œ ì ìš©)

âœ… Phase 5.3.2 ê¸´ê¸‰ íŒ¨ì¹˜:
1. âœ… Replace ìš°ì„  ë¨¸ì§€ ì „ëµ (ì¤‘ë³µ ì œê±°)
2. âœ… Conflict Detector (ìˆ˜ì¹˜ ì¼ê´€ì„± ì²´í¬)
3. âœ… Loop Cut (ê²½ë¡œ ë£¨í”„ ì œê±°)
4. âœ… 7-gram ì¤‘ë³µ ì œê±°
5. âœ… [RETRY] ì„¹ì…˜ êµì²´ ì „ëµ

GPT ì œì•ˆ 100% ë°˜ì˜

Author: ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-27
Version: 5.3.2
"""

import logging
import re
import json
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from collections import Counter

# Phase 5.3.2 ëª¨ë“ˆ import
from .quick_layout_analyzer import QuickLayoutAnalyzer
from .prompt_rules import PromptRules
from .kvs_normalizer import KVSNormalizer

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 5.3.2 í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œê¸° (5ëŒ€ ì•ˆì „ê°€ë“œ)
    
    GPT ì œì•ˆ 100% ë°˜ì˜:
    1. Replace ìš°ì„  ë¨¸ì§€ (append â†’ replace)
    2. Conflict Detector (ìˆ˜ì¹˜ ì¼ê´€ì„±)
    3. Loop Cut (ê²½ë¡œ ë£¨í”„ ì œê±°)
    4. 7-gram ì¤‘ë³µ ì œê±°
    5. [RETRY] ì„¹ì…˜ êµì²´
    
    ì „ëµ:
    1. QuickLayoutAnalyzerë¡œ êµ¬ì¡° íŒíŠ¸ íšë“
    2. PromptRules DSLë¡œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
    3. VLM 1íšŒ í˜¸ì¶œë¡œ ì™„ì „ ì¶”ì¶œ
    4. 5ëŒ€ ì•ˆì „ê°€ë“œ ì ìš©
    5. PromptRulesë¡œ ê°•í™” ê²€ì¦
    6. í™˜ê° ê°ì§€ ì‹œ ì²´ì¸ ì»· ë˜ëŠ” ì¬ì¶”ì¶œ
    7. KVS ë³„ë„ ì¶”ì¶œ ë° ì €ì¥
    """
    
    def __init__(self, vlm_service):
        """
        Args:
            vlm_service: VLMServiceV50 ì¸ìŠ¤í„´ìŠ¤
        """
        self.vlm = vlm_service
        self.analyzer = QuickLayoutAnalyzer()
        self.max_retries = 1
        logger.info("âœ… HybridExtractor v5.3.2 ì´ˆê¸°í™” (5ëŒ€ ì•ˆì „ê°€ë“œ)")
    
    def extract(self, image_data: str, page_num: int = 1) -> Dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            image_data: Base64 ì¸ì½”ë”© ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            {
                'content': str,
                'kvs': Dict,
                'confidence': float,
                'doc_type': str,
                'hints': Dict,
                'quality_score': float,
                'validation': Dict,
                'metrics': Dict,
                'conflict_notes': List[str]  # âœ… ì‹ ê·œ
            }
        """
        logger.info(f"ğŸ¯ Page {page_num}: Phase 5.3.2 Hybrid ì¶”ì¶œ ì‹œì‘ (5ëŒ€ ì•ˆì „ê°€ë“œ)")
        
        import time
        start_time = time.time()
        conflict_notes = []
        
        try:
            # Step 1: CV íŒíŠ¸ ìƒì„±
            cv_start = time.time()
            hints = self.analyzer.analyze(image_data)
            cv_time = time.time() - cv_start
            logger.info(f"   ğŸ“ CV íŒíŠ¸ ({cv_time:.2f}ì´ˆ): {hints}")
            
            # Step 2: DSL ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± (ë„ë©”ì¸ ê°€ë“œ ì ìš©)
            prompt = PromptRules.build_prompt(hints)
            logger.debug(f"   ğŸ“ DSL í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len(prompt)} ê¸€ì")
            
            # Step 3: VLM ì¶”ì¶œ
            vlm_start = time.time()
            content = self._call_vlm(image_data, prompt)
            vlm_time = time.time() - vlm_start
            logger.info(f"   âœ… VLM ì¶”ì¶œ ì™„ë£Œ ({vlm_time:.2f}ì´ˆ): {len(content)} ê¸€ì")
            
            # Step 4: ì˜¤íƒˆì êµì •
            content = PromptRules.correct_typos(content)
            
            # âœ… ì•ˆì „ê°€ë“œ #3: Loop Cut (ê²½ë¡œ ë£¨í”„ ì œê±°)
            content = self._cut_route_loops(content, hints)
            
            # âœ… ì•ˆì „ê°€ë“œ #1: í™˜ê° íŒ¨í„´ ê²€ì¶œ + ì²´ì¸ ì»·
            content = self._cut_hallucination_chains(content)
            
            # Step 5: ê°•í™” ê²€ì¦
            validation = PromptRules.validate_extraction(content, hints)
            
            retry_count = 0
            if not validation['passed'] and retry_count < self.max_retries:
                logger.warning(f"   âš ï¸ ê²€ì¦ ì‹¤íŒ¨: {validation['missing']}")
                logger.info(f"   â™»ï¸ ì¬ì¶”ì¶œ ì‹œì‘ (ì‹œë„ {retry_count + 1}/{self.max_retries})")
                
                # Step 6: ì¬ì¶”ì¶œ
                retry_start = time.time()
                content = self._focused_reextraction(
                    image_data,
                    hints,
                    content,
                    validation['missing']
                )
                retry_time = time.time() - retry_start
                logger.info(f"   âœ… ì¬ì¶”ì¶œ ì™„ë£Œ ({retry_time:.2f}ì´ˆ): {len(content)} ê¸€ì")
                
                # âœ… ì¬ì¶”ì¶œ í›„ì—ë„ Loop Cut + í™˜ê° ê²€ì¶œ
                content = self._cut_route_loops(content, hints)
                content = self._cut_hallucination_chains(content)
                
                # ì¬ê²€ì¦
                validation = PromptRules.validate_extraction(content, hints)
                retry_count += 1
            
            # âœ… ì•ˆì „ê°€ë“œ #4: 7-gram ì¤‘ë³µ ì œê±°
            content = self._deduplicate_7gram(content)
            
            # Step 7: KVS ì¶”ì¶œ
            kvs = self._extract_kvs(content, hints)
            
            # Step 7.5: KVS ì •ê·œí™”
            if kvs:
                kvs = KVSNormalizer.normalize_kvs(kvs)
                logger.info(f"   ğŸ“Š KVS ì •ê·œí™” ì™„ë£Œ: {len(kvs)}ê°œ í•­ëª©")
            
            # âœ… ì•ˆì „ê°€ë“œ #2: Conflict Detector (ìˆ˜ì¹˜ ì¼ê´€ì„± ì²´í¬)
            content, conflict_notes = self._detect_conflicts(content, kvs)
            
            if conflict_notes:
                logger.warning(f"   âš ï¸ ìˆ˜ì¹˜ ì¶©ëŒ ê°ì§€: {len(conflict_notes)}ê±´")
                for note in conflict_notes:
                    logger.warning(f"      - {note}")
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality(content, hints, validation, conflict_notes)
            
            # ê´€ì¸¡ì„± ë©”íŠ¸ë¦­
            total_time = time.time() - start_time
            metrics = {
                'cv_time': cv_time,
                'vlm_time': vlm_time,
                'total_time': total_time,
                'retry_count': retry_count,
                'content_length': len(content),
                'kvs_count': len(kvs),
                'conflict_count': len(conflict_notes)  # âœ… ì‹ ê·œ
            }
            
            return {
                'content': content,
                'kvs': kvs,
                'confidence': 0.9 if validation['passed'] and not conflict_notes else 0.7,
                'doc_type': self._infer_doc_type(hints),
                'hints': hints,
                'quality_score': quality_score,
                'validation': validation,
                'metrics': metrics,
                'conflict_notes': conflict_notes  # âœ… ì‹ ê·œ
            }
            
        except Exception as e:
            logger.error(f"   âŒ Hybrid ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _call_vlm(self, image_data: str, prompt: str) -> str:
        """VLM í˜¸ì¶œ (Azure OpenAI ë˜ëŠ” Claude)"""
        return self.vlm.call(image_data, prompt)
    
    def _cut_route_loops(self, content: str, hints: Dict) -> str:
        """
        âœ… ì•ˆì „ê°€ë“œ #3: ê²½ë¡œ ë£¨í”„ ì»· (GPT ì œì•ˆ)
        
        ì „ëµ:
        - ë²„ìŠ¤/ì§€ë„ ë¬¸ì„œì—ë§Œ ì ìš© (ë„ë©”ì¸ ê°€ë“œ)
        - ìê¸°ë°˜ë³µ/ë°±íŠ¸ë˜í‚¹ íŒ¨í„´ íƒì§€
        - ìµœëŒ€ 30 ë…¸ë“œ ì ˆë‹¨ + ìœ ë‹ˆí¬ ì‹œí€€ìŠ¤ë§Œ ìœ ì§€
        
        Args:
            content: Markdown ë‚´ìš©
            hints: CV íŒíŠ¸
        
        Returns:
            ë£¨í”„ ì œê±°ëœ Markdown
        """
        # ë²„ìŠ¤/ì§€ë„ ë¬¸ì„œê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ
        if not hints.get('has_map'):
            return content
        
        # í™”ì‚´í‘œ ì²´ì¸ íŒ¨í„´ ì°¾ê¸°
        route_pattern = r'(\S+)\s*(?:â†’|->)\s*(\S+)'
        routes = re.findall(route_pattern, content)
        
        if len(routes) > 30:
            logger.warning(f"   âš ï¸ ê²½ë¡œ ë£¨í”„ ê°ì§€: {len(routes)} ë…¸ë“œ")
            
            # ìœ ë‹ˆí¬ ì‹œí€€ìŠ¤ë§Œ ì¶”ì¶œ (ìˆœì„œ ë³´ì¡´)
            unique_routes = []
            seen = set()
            
            for start, end in routes:
                edge = (start, end)
                if edge not in seen:
                    unique_routes.append(f"{start} â†’ {end}")
                    seen.add(edge)
                
                # ìµœëŒ€ 30ê°œ ì œí•œ
                if len(unique_routes) >= 30:
                    break
            
            # ì›ë³¸ì—ì„œ ë£¨í”„ ë¶€ë¶„ ì°¾ì•„ êµì²´
            route_section = ' â†’ '.join([r for r in unique_routes])
            
            # ê¸°ì¡´ ê¸´ ì²´ì¸ì„ ìœ ë‹ˆí¬ ì‹œí€€ìŠ¤ë¡œ êµì²´
            content = re.sub(
                r'((?:\S+\s*(?:â†’|->)\s*){30,})',
                route_section,
                content,
                count=1
            )
            
            logger.info(f"   âœ… ê²½ë¡œ ë£¨í”„ ì»·: {len(routes)} â†’ {len(unique_routes)} ë…¸ë“œ")
        
        return content
    
    def _cut_hallucination_chains(self, content: str) -> str:
        """
        âœ… ì•ˆì „ê°€ë“œ #1: í™˜ê° ì²´ì¸ ì»· (Phase 5.3.1 ìœ ì§€)
        
        ì „ëµ:
        - 10íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” í™”ì‚´í‘œ ì²´ì¸ ê²€ì¶œ
        - 15 ë…¸ë“œê¹Œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” "â€¦(ì¤‘ê°„ ìƒëµ)â€¦"
        
        Args:
            content: Markdown ë‚´ìš©
        
        Returns:
            í™˜ê° ì œê±°ëœ Markdown
        """
        # ë°˜ë³µ/ë£¨í”„ íŒ¨í„´ ê°ì§€ (10íšŒ ì´ìƒ)
        loop_pattern = r'(\b[ê°€-í£A-Za-z0-9]{2,15}\b(?:\s*(?:â†’|->)\s*\b[ê°€-í£A-Za-z0-9]{2,15}\b)){10,}'
        
        if re.search(loop_pattern, content):
            logger.warning("   âš ï¸ í™˜ê° ì²´ì¸ íŒ¨í„´ ê°ì§€ - 15 ë…¸ë“œë¡œ ì»·")
            
            # 15 ë…¸ë“œê¹Œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìƒëµ
            content = re.sub(
                r'((?:\S+\s*(?:â†’|->)\s*){15})(?:\S+\s*(?:â†’|->)\s*)+(\S+)',
                r'\1 â€¦(ì¤‘ê°„ ìƒëµ)â€¦ \2',
                content
            )
        
        return content
    
    def _deduplicate_7gram(self, content: str) -> str:
        """
        âœ… ì•ˆì „ê°€ë“œ #4: 7-gram ì¤‘ë³µ ì œê±° (GPT ì œì•ˆ)
        
        ì „ëµ:
        - 7ê°œ ì—°ì† ë‹¨ì–´ê°€ ì¤‘ë³µë˜ë©´ ì œê±°
        - ì²« ë²ˆì§¸ ì¶œí˜„ë§Œ ìœ ì§€
        
        Args:
            content: Markdown ë‚´ìš©
        
        Returns:
            ì¤‘ë³µ ì œê±°ëœ Markdown
        """
        # ë‹¨ì–´ í† í°í™”
        words = content.split()
        
        if len(words) < 7:
            return content
        
        # 7-gram ìƒì„± ë° ì¤‘ë³µ ê²€ì¶œ
        seen_7grams = set()
        keep_indices = set(range(len(words)))
        
        for i in range(len(words) - 6):
            gram = tuple(words[i:i+7])
            
            if gram in seen_7grams:
                # ì¤‘ë³µ ë°œê²¬ - ì´ êµ¬ê°„ ì œê±°
                for j in range(i, i+7):
                    keep_indices.discard(j)
                
                logger.debug(f"   ğŸ” 7-gram ì¤‘ë³µ ì œê±°: {' '.join(gram[:3])}...")
            else:
                seen_7grams.add(gram)
        
        # ìœ ì§€í•  ë‹¨ì–´ë§Œ ì¬ì¡°í•©
        deduped_words = [words[i] for i in sorted(keep_indices)]
        
        if len(deduped_words) < len(words):
            logger.info(f"   âœ… 7-gram ì¤‘ë³µ ì œê±°: {len(words)} â†’ {len(deduped_words)} ë‹¨ì–´")
        
        return ' '.join(deduped_words)
    
    def _detect_conflicts(
        self,
        content: str,
        kvs: Dict[str, str]
    ) -> Tuple[str, List[str]]:
        """
        âœ… ì•ˆì „ê°€ë“œ #2: Conflict Detector (ìˆ˜ì¹˜ ì¼ê´€ì„± ì²´í¬, GPT ì œì•ˆ)
        
        ì „ëµ:
        - ë™ì¼ í•­ëª©ì˜ ìƒì´í•œ ìˆ˜ì¹˜ íƒì§€
        - ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤(KVS > ë³¸ë¬¸)ë¡œ ë‹¨ì¼í™”
        - ì¶©ëŒ ë…¸íŠ¸ ê¸°ë¡
        
        Args:
            content: Markdown ë‚´ìš©
            kvs: KVS ë°ì´í„°
        
        Returns:
            (ìˆ˜ì •ëœ content, conflict_notes)
        """
        conflict_notes = []
        
        # KVSì— ìˆëŠ” í•­ëª©ì˜ ë³¸ë¬¸ ë‚´ ë‹¤ë¥¸ ìˆ˜ì¹˜ ì°¾ê¸°
        for key, kvs_value in kvs.items():
            # ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œ
            kvs_number = re.search(r'\d+[,\d]*', kvs_value)
            if not kvs_number:
                continue
            
            kvs_num_str = kvs_number.group()
            
            # ë³¸ë¬¸ì—ì„œ ë™ì¼ í‚¤ì˜ ë‹¤ë¥¸ ìˆ«ì ì°¾ê¸°
            key_pattern = re.escape(key) + r'[:\s]*(\d+[,\d]*)'
            
            for match in re.finditer(key_pattern, content):
                content_num_str = match.group(1)
                
                # ìˆ˜ì¹˜ ë¶ˆì¼ì¹˜ ì²´í¬
                if content_num_str != kvs_num_str:
                    conflict_notes.append(
                        f"{key}: {content_num_str} (ë³¸ë¬¸) vs {kvs_num_str} (KVS)"
                    )
                    
                    # KVS ê°’ìœ¼ë¡œ êµì²´ (ì‹ ë¢°ë„ ë†’ìŒ)
                    content = content.replace(
                        f"{key}: {content_num_str}",
                        f"{key}: {kvs_num_str}"
                    )
                    content = content.replace(
                        f"{key} {content_num_str}",
                        f"{key} {kvs_num_str}"
                    )
                    
                    logger.warning(
                        f"   âš ï¸ ìˆ˜ì¹˜ ì¶©ëŒ í•´ì†Œ: '{key}' "
                        f"{content_num_str} â†’ {kvs_num_str}"
                    )
        
        return content, conflict_notes
    
    def _focused_reextraction(
        self,
        image_data: str,
        hints: Dict,
        prev_content: str,
        missing: list[str]
    ) -> str:
        """
        ëˆ„ë½ ìš”ì†Œ ì§‘ì¤‘ ì¬ì¶”ì¶œ
        
        ì „ëµ: PromptRules v5.3.2ì˜ ê°•í™”ëœ retry í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        
        Args:
            image_data: Base64 ì´ë¯¸ì§€
            hints: CV íŒíŠ¸
            prev_content: ì´ì „ ì¶”ì¶œ ë‚´ìš©
            missing: ëˆ„ë½ëœ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë³‘í•©ëœ Markdown
        """
        # âœ… Phase 5.3.2: ê°•í™”ëœ ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        retry_prompt = PromptRules.build_retry_prompt(hints, missing, prev_content)
        
        # VLM ì¬í˜¸ì¶œ
        additional = self._call_vlm(image_data, retry_prompt)
        
        # âœ… ì•ˆì „ê°€ë“œ #5: Replace ë¨¸ì§€
        merged = self._merge_content_replace(prev_content, additional)
        
        return merged
    
    def _merge_content_replace(self, prev: str, additional: str) -> str:
        """
        âœ… ì•ˆì „ê°€ë“œ #5: Replace ìš°ì„  ë¨¸ì§€ (GPT ì œì•ˆ)
        
        ë³€ê²½:
        - append â†’ replace (ì¤‘ë³µ ë°©ì§€)
        - [RETRY] ì„¹ì…˜ì„ ê¸°ì¡´ ì„¹ì…˜ê³¼ êµì²´
        - í™˜ê° íŒ¨í„´ ì¬ê²€ì¶œ
        
        Args:
            prev: ê¸°ì¡´ ë‚´ìš©
            additional: ì¬ì¶”ì¶œ ë‚´ìš©
        
        Returns:
            ë³‘í•©ëœ Markdown
        """
        # [RETRY] ì„¹ì…˜ ì¶”ì¶œ
        retry_sections = self._extract_retry_sections(additional)
        
        if not retry_sections:
            logger.warning("   âš ï¸ [RETRY] ì„¹ì…˜ ì—†ìŒ - ê¸°ì¡´ ë‚´ìš© ìœ ì§€")
            return prev
        
        # ê¸°ì¡´ ë‚´ìš©ì—ì„œ ë™ì¼ ì„¹ì…˜ êµì²´
        result = prev
        
        for section_type, section_content in retry_sections.items():
            # ì„¹ì…˜ íƒ€ì…ë³„ íŒ¨í„´
            if section_type == 'table':
                # ê¸°ì¡´ í‘œ ì œê±° í›„ ì‹ ê·œ í‘œ ì‚½ì…
                result = re.sub(r'\|.+?\|[\s\S]*?\n\n', '', result, count=1)
                result += f"\n\n{section_content}\n\n"
                logger.info(f"   âœ… [RETRY] í‘œ êµì²´")
            
            elif section_type == 'diagram':
                # ê¸°ì¡´ ë‹¤ì´ì–´ê·¸ë¨ ì œê±° í›„ ì‹ ê·œ ì‚½ì…
                result = re.sub(
                    r'###?\s*ë‹¤ì´ì–´ê·¸ë¨[\s\S]*?(?=\n##|\Z)',
                    '',
                    result,
                    count=1
                )
                result += f"\n\n{section_content}\n\n"
                logger.info(f"   âœ… [RETRY] ë‹¤ì´ì–´ê·¸ë¨ êµì²´")
            
            elif section_type == 'map':
                # ê¸°ì¡´ ì§€ë„ ì •ë³´ ì œê±° í›„ ì‹ ê·œ ì‚½ì…
                result = re.sub(
                    r'###?\s*(?:ì§€ë„|ê²½ë¡œ)[\s\S]*?(?=\n##|\Z)',
                    '',
                    result,
                    count=1
                )
                result += f"\n\n{section_content}\n\n"
                logger.info(f"   âœ… [RETRY] ì§€ë„ ì •ë³´ êµì²´")
        
        # âœ… í™˜ê° íŒ¨í„´ ì¬ê²€ì¶œ
        loop_pattern = r'(\b[ê°€-í£A-Za-z0-9]{2,15}\b(?:\s*(?:â†’|->)\s*\b[ê°€-í£A-Za-z0-9]{2,15}\b)){10,}'
        
        if re.search(loop_pattern, result):
            logger.warning("   âš ï¸ ì¬ì¶”ì¶œì—ë„ í™˜ê° íŒ¨í„´ - ê¸°ì¡´ ë‚´ìš©ë§Œ ë°˜í™˜")
            return prev
        
        logger.info("   âœ… [RETRY] ì„¹ì…˜ Replace ë³‘í•© ì„±ê³µ")
        return result
    
    def _extract_retry_sections(self, additional: str) -> Dict[str, str]:
        """
        [RETRY] ì„¹ì…˜ì„ íƒ€ì…ë³„ë¡œ ì¶”ì¶œ
        
        Returns:
            {
                'table': 'í‘œ ë‚´ìš©',
                'diagram': 'ë‹¤ì´ì–´ê·¸ë¨ ë‚´ìš©',
                'map': 'ì§€ë„ ë‚´ìš©'
            }
        """
        sections = {}
        lines = additional.splitlines()
        
        current_section = None
        section_lines = []
        
        for line in lines:
            # [RETRY] ë§ˆì»¤ ê°ì§€
            if '[RETRY]' in line:
                # ì„¹ì…˜ íƒ€ì… ì¶”ë¡ 
                if 'í‘œ' in line or 'table' in line.lower():
                    current_section = 'table'
                elif 'ë‹¤ì´ì–´ê·¸ë¨' in line or 'diagram' in line.lower():
                    current_section = 'diagram'
                elif 'ì§€ë„' in line or 'map' in line.lower():
                    current_section = 'map'
                
                section_lines = [line]
                continue
            
            # ì„¹ì…˜ ìˆ˜ì§‘ ì¤‘
            if current_section:
                section_lines.append(line)
                
                # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ ì‹œ ì¢…ë£Œ
                if line.startswith('##') and '[RETRY]' not in line:
                    sections[current_section] = '\n'.join(section_lines[:-1])
                    current_section = None
                    section_lines = []
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì²˜ë¦¬
        if current_section and section_lines:
            sections[current_section] = '\n'.join(section_lines)
        
        return sections
    
    def _extract_kvs(self, content: str, hints: Dict) -> Dict[str, str]:
        """
        Key-Value Structured ë°ì´í„° ì¶”ì¶œ
        
        (Phase 5.3.1 ìœ ì§€)
        
        Returns:
            {
                'ë°°ì°¨ê°„ê²©': '27ë¶„',
                'ì²«ì°¨': '05:30',
                'ë§‰ì°¨': '22:40',
                ...
            }
        """
        if not hints.get('has_numbers'):
            return {}
        
        kvs = {}
        
        # KVS íŒ¨í„´ ë§¤ì¹­
        patterns = [
            (r'([ê°€-í£a-zA-Z\s]+):\s*([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+[ê°€-í£]*)', 1, 2),
            (r'(ë°°ì°¨ê°„ê²©|ì²«ì°¨|ë§‰ì°¨|ë…¸ì„ ë²ˆí˜¸)\s+([0-9:ë¶„]+)', 1, 2),
            (r'([ê°€-í£]+)ëŠ”\s+([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+)', 1, 2),
            (r'([ê°€-í£]+)ê°€\s+([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+)', 1, 2),
        ]
        
        for pattern, key_group, val_group in patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                key = match.group(key_group).strip()
                value = match.group(val_group).strip()
                
                # ë¹ˆ ê°’ í•„í„°ë§
                if not value or value == ':':
                    continue
                
                # ì¤‘ìš” í‚¤ë§Œ ì €ì¥
                important_keys = ['ë°°ì°¨ê°„ê²©', 'ì²«ì°¨', 'ë§‰ì°¨', 'ë…¸ì„ ë²ˆí˜¸', 'ë³€ê²½ ì „', 'ë³€ê²½ í›„']
                if any(ik in key for ik in important_keys):
                    if key in kvs:
                        if len(value) > len(kvs[key]):
                            kvs[key] = value
                    else:
                        kvs[key] = value
        
        return kvs
    
    def _calculate_quality(
        self,
        content: str,
        hints: Dict,
        validation: Dict,
        conflict_notes: List[str]
    ) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì¶©ëŒ í˜ë„í‹° ì¶”ê°€)"""
        base_score = 100.0
        
        # ê¸¸ì´ ì²´í¬
        if len(content) < 100:
            base_score -= 40
        elif len(content) < 500:
            base_score -= 20
        
        # ê²€ì¦ ì ìˆ˜ ë°˜ì˜
        if validation['scores']:
            avg_validation = sum(validation['scores'].values()) / len(validation['scores'])
            base_score = (base_score + avg_validation) / 2
        
        # ê²½ê³  í˜ë„í‹°
        warning_penalty = len(validation.get('warnings', [])) * 5
        base_score -= warning_penalty
        
        # âœ… ì¶©ëŒ í˜ë„í‹° (GPT ì œì•ˆ)
        conflict_penalty = len(conflict_notes) * 10
        base_score -= conflict_penalty
        
        return max(0.0, min(100.0, base_score))
    
    def _infer_doc_type(self, hints: Dict) -> str:
        """íŒíŠ¸ë¡œ ë¬¸ì„œ íƒ€ì… ì¶”ë¡ """
        if hints['has_map'] and hints['diagram_count'] > 0:
            return 'diagram'
        elif hints['has_table']:
            return 'chart_statistics'
        elif hints['has_text'] and not hints['has_table']:
            return 'text_document'
        else:
            return 'mixed'
    
    def save_kvs_payload(
        self,
        kvs: Dict[str, str],
        doc_id: str,
        page_num: int,
        output_dir: Path
    ) -> Optional[Path]:
        """
        KVS ë³„ë„ í˜ì´ë¡œë“œ ì €ì¥
        
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if not kvs:
            return None
        
        payload = {
            'doc_id': doc_id,
            'page': page_num,
            'chunk_id': f'{doc_id}_p{page_num}_kvs',
            'type': 'kvs',
            'kvs': kvs,
            'rank_hint': 3
        }
        
        output_path = output_dir / f'{doc_id}_p{page_num}_kvs.json'
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ KVS í˜ì´ë¡œë“œ ì €ì¥: {output_path}")
        return output_path