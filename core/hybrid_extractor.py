"""
core/hybrid_extractor.py
PRISM Phase 5.7.8.2 - Hybrid Extractor (ê¸´ê¸‰ íŒ¨ì¹˜ - doc_type ê°•ì œ ì„¤ì •)

âœ… Phase 5.7.8.2 ê¸´ê¸‰ ìˆ˜ì •:
1. doc_typeì„ 'statute'ë¡œ ê°•ì œ ì„¤ì • (ê·œì • ë¬¸ì„œ ê¸°ë³¸)
2. ê·œì • í‚¤ì›Œë“œ ê°ì§€ ê°•í™”
3. ë¡œê¹… ê°œì„ 

ğŸ¯ í•´ê²° ë¬¸ì œ:
- doc_type='general'ë¡œ ì¸í•œ ì‚¬ì „ ë¯¸ì ìš©
- "1ëª…ì˜ì§ì›ì—ê²Œ", "ë¶€ì—¬í• ìˆ˜ìˆëŠ”", "ì‚¬ ì œ" ë¯¸ìˆ˜ì •

Author: ì´ì„œì˜ (Backend Lead) + ê¸´ê¸‰ ì§„ë‹¨
Date: 2025-11-05
Version: 5.7.8.2 Emergency Hotfix
"""

import logging
import re
import unicodedata
from typing import Dict, Any, List, Optional

# âœ… Phase 5.7.6: pypdf (BSD-3)
import pypdf
from pathlib import Path

# Phase 5.7.4 imports
try:
    from .quick_layout_analyzer import QuickLayoutAnalyzer
    from .prompt_rules import PromptRules
    from .post_merge_normalizer import PostMergeNormalizer
    from .typo_normalizer import TypoNormalizer
    from .kvs_normalizer import KVSNormalizer
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from quick_layout_analyzer import QuickLayoutAnalyzer
    from prompt_rules import PromptRules
    from post_merge_normalizer import PostMergeNormalizer
    from typo_normalizer import TypoNormalizer
    from kvs_normalizer import KVSNormalizer

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 5.7.8.2 í†µí•© ì¶”ì¶œê¸° (doc_type ê°•ì œ ì„¤ì •)
    
    âœ… Phase 5.7.8.2 ê°œì„ :
    - doc_typeì„ 'statute'ë¡œ ê°•ì œ ì„¤ì •
    - ê·œì • í‚¤ì›Œë“œ ê°ì§€ ê°•í™”
    - ë¡œê¹… ê°œì„ 
    
    Fallback ì „ëµ:
    1. VLM ì‹¤íŒ¨ (0ì) â†’ pypdf ì‹œë„
    2. pypdf ì„±ê³µ ì‹œ â†’ ì¸ë¼ì¸ ë§ˆì»¤ ì œê±° + ì •ê·œí™”
    3. ëª¨ë‘ ì‹¤íŒ¨ â†’ ë¹ˆ í˜ì´ì§€ ì²˜ë¦¬
    """
    
    # âœ… Phase 5.7.8.2: ê·œì • í‚¤ì›Œë“œ í™•ì¥
    STATUTE_KEYWORDS = [
        'ì¡°', 'í•­', 'í˜¸', 'ëª©', 'ê°œì •', 'ì‹ ì„¤', 'ì‚­ì œ',
        'ê·œì •', 'ë²•ë ¹', 'ì •ê´€', 'ì§ì›', 'ì„ìš©', 'ì±„ìš©',
        'ì œ1ì¡°', 'ì œ2ì¡°', 'ì œ3ì¡°', 'ì œ4ì¡°', 'ì œ5ì¡°',
        'ì œ1ì¥', 'ì œ2ì¥', 'ì´ì¹™', 'ë¶€ì¹™'
    ]
    
    def __init__(self, vlm_service, pdf_path: str = None):
        """
        Args:
            vlm_service: VLMServiceV50 ì¸ìŠ¤í„´ìŠ¤
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (Fallbackìš©)
        """
        self.vlm_service = vlm_service
        self.pdf_path = pdf_path
        
        # Phase 5.7.4 components
        self.layout_analyzer = QuickLayoutAnalyzer()
        self.post_normalizer = PostMergeNormalizer()
        self.typo_normalizer = TypoNormalizer()
        
        # Phase 5.7.4 í†µê³„
        self.fallback_count = 0
        self.vlm_success_count = 0
        self.total_pages = 0
        
        logger.info("âœ… HybridExtractor v5.7.8.2 ì´ˆê¸°í™” ì™„ë£Œ (doc_type ê°•ì œ ì„¤ì •)")
        logger.info("   - pypdf (BSD-3) Fallback")
        logger.info("   - doc_type='statute' ê°•ì œ ì ìš©")
        logger.info("   - ê·œì • í‚¤ì›Œë“œ ê°ì§€ ê°•í™”")
    
    def extract(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """
        Phase 5.7.8.2 í˜ì´ì§€ ì¶”ì¶œ (doc_type ê°•ì œ)
        
        (Phase 5.7.7.1 í”Œë¡œìš° ìœ ì§€)
        """
        logger.info(f"   ğŸ”§ HybridExtractor v5.7.8.2 ì¶”ì¶œ ì‹œì‘ (í˜ì´ì§€ {page_num})")
        
        self.total_pages += 1
        
        # Step 1: CV íŒíŠ¸
        hints = self.layout_analyzer.analyze(image_data)
        
        # Step 2: í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = PromptRules.build_prompt(hints)
        
        # Step 3: VLM í˜¸ì¶œ
        import time
        start_time = time.time()
        
        try:
            content = self.vlm_service.call(image_data, prompt)
            vlm_time = time.time() - start_time
            
            logger.info(f"      â±ï¸ VLM: {vlm_time:.2f}ì´ˆ ({len(content)} ê¸€ì)")
        
        except Exception as e:
            logger.error(f"      âŒ VLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            content = ""
        
        # Step 4: ê²€ì¦
        is_valid = self._validate_content(content)
        
        logger.info(f"      âœ… ê²€ì¦: {is_valid}")
        
        # âœ… Phase 5.7.7.2: Fallback + ì¸ë¼ì¸ ë§ˆì»¤ ì œê±°
        if not is_valid:
            logger.warning(f"      âš ï¸ VLM ì¶”ì¶œ ì‹¤íŒ¨: {len(content)}ì < 10ì")
            
            # Fallback ì‹œë„
            fallback_content = self._fallback_extract(page_num)
            
            if fallback_content:
                content = fallback_content
                self.fallback_count += 1
                source = "pypdf_fallback"
                confidence = 0.7
            else:
                # ë¹ˆ í˜ì´ì§€
                return {
                    'content': '',
                    'is_empty': True,
                    'source': 'empty',
                    'confidence': 0.0,
                    'quality_score': 0,
                    'kvs': {},
                    'metrics': {}
                }
        else:
            self.vlm_success_count += 1
            source = "vlm"
            confidence = 1.0
        
        # âœ… Phase 5.7.8.2: doc_type ê°•ì œ ì„¤ì •
        doc_type = self._detect_doc_type(content, hints)
        
        logger.info(f"      ğŸ“‹ ë¬¸ì„œ íƒ€ì…: {doc_type}")
        
        # Step 5: í›„ì²˜ë¦¬ (Phase 5.7.8.2 doc_type ì „ë‹¬)
        # PostMergeNormalizer (v5.7.8.1 - OrderedDict)
        content = self.post_normalizer.normalize(content, doc_type)
        
        # TypoNormalizer (v5.7.8.1 - OrderedDict)
        content = self.typo_normalizer.normalize(content, doc_type)
        
        # ì¤‘ë³µ ì œê±°
        content = self._deduplicate_lines(content)
        
        logger.info(f"      ğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ ({len(content)} ê¸€ì)")
        
        # Step 6: KVS ì¶”ì¶œ
        kvs_raw = hints.get('kvs', [])
        kvs = KVSNormalizer.normalize_kvs(kvs_raw)
        
        logger.info(f"      ğŸ’¾ KVS: {len(kvs)}ê°œ")
        
        # Step 7: í’ˆì§ˆ ì ìˆ˜
        if source == "vlm":
            quality_score = 100
        else:
            quality_score = 70  # Fallback
        
        logger.info(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: í’ˆì§ˆ {quality_score}/100 (ì¶œì²˜: {source}, íƒ€ì…: {doc_type})")
        
        return {
            'content': content,
            'source': source,
            'confidence': confidence,
            'quality_score': quality_score,
            'kvs': kvs,
            'metrics': {
                'page_num': page_num,
                'char_count': len(content),
                'source': source,
                'doc_type': doc_type  # âœ… ì¶”ê°€
            }
        }
    
    def _detect_doc_type(self, content: str, hints: Dict[str, Any]) -> str:
        """
        âœ… Phase 5.7.8.2: ë¬¸ì„œ íƒ€ì… ê°ì§€ (ê·œì • ìš°ì„ )
        
        ì „ëµ:
        1. hintsì—ì„œ doc_type í™•ì¸
        2. ê·œì • í‚¤ì›Œë“œ ê°ì§€
        3. ê¸°ë³¸ê°’: 'statute' (ê·œì • ë¬¸ì„œ ìš°ì„ )
        
        Args:
            content: ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            hints: ë ˆì´ì•„ì›ƒ íŒíŠ¸
        
        Returns:
            'statute', 'general', 'bus_diagram', 'table'
        """
        # 1) hintsì—ì„œ í™•ì¸
        hint_type = hints.get('doc_type')
        if hint_type in ['statute', 'bus_diagram', 'table']:
            logger.debug(f"      doc_type from hints: {hint_type}")
            return hint_type
        
        # 2) ê·œì • í‚¤ì›Œë“œ ê°ì§€
        keyword_count = sum(1 for keyword in self.STATUTE_KEYWORDS if keyword in content)
        
        if keyword_count >= 3:
            logger.debug(f"      doc_type detected: statute (keywords: {keyword_count})")
            return 'statute'
        
        # 3) ì¡°ë¬¸ íŒ¨í„´ ê°ì§€
        article_pattern = r'ì œ\s*\d+\s*ì¡°'
        article_matches = re.findall(article_pattern, content)
        
        if len(article_matches) >= 1:
            logger.debug(f"      doc_type detected: statute (articles: {len(article_matches)})")
            return 'statute'
        
        # 4) ê¸°ë³¸ê°’: 'statute' (ê·œì • ë¬¸ì„œ ìš°ì„ )
        logger.debug("      doc_type default: statute")
        return 'statute'
    
    def _fallback_extract(self, page_num: int) -> str:
        """
        âœ… Phase 5.7.7.2: Fallback í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¸ë¼ì¸ ë§ˆì»¤ ì œê±°)
        
        ì „ëµ:
        1. pypdf ì‹œë„ (ë¹ ë¦„, êµ¬ì¡° ë³´ì¡´ ìš°ìˆ˜)
        2. âœ… ì¸ë¼ì¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±° ê°•í™” (ë¯¸ì†¡ ì œì•ˆ)
        3. ì •ê·œí™” ì ìš©
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸
        
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´)
        """
        if not self.pdf_path:
            logger.error("      âŒ Fallback ë¶ˆê°€: PDF ê²½ë¡œ ì—†ìŒ")
            return ""
        
        logger.info(f"      ğŸ”„ Fallback ì‹œë„ (í˜ì´ì§€ {page_num})...")
        
        # âœ… 1ì°¨ Fallback: pypdf
        text = self._extract_with_pypdf(page_num)
        
        if text and len(text) >= 10:
            logger.info(f"      âœ… pypdf ì¶”ì¶œ ì„±ê³µ: {len(text)}ì")
            
            # âœ… Phase 5.7.7.2: ì¸ë¼ì¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±° ê°•í™” (ë¯¸ì†¡ ì œì•ˆ)
            text = self._remove_inline_page_markers(text)
            text = self._strip_page_dividers(text)
            text = self._normalize_fallback_text(text)
            
            logger.info(f"      âœ… Fallback ì„±ê³µ: {len(text)} ê¸€ì")
            return text
        
        logger.warning(f"      âš ï¸ Fallback ì‹¤íŒ¨: í…ìŠ¤íŠ¸ ì—†ìŒ")
        return ""
    
    def _extract_with_pypdf(self, page_num: int) -> str:
        """
        âœ… Phase 5.7.6: pypdf ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        try:
            with open(self.pdf_path, 'rb') as f:
                reader = pypdf.PdfReader(f)
                
                if page_num - 1 >= len(reader.pages):
                    return ""
                
                page = reader.pages[page_num - 1]
                text = page.extract_text()
                
                return text
        
        except Exception as e:
            logger.error(f"      âŒ pypdf ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _remove_inline_page_markers(self, content: str) -> str:
        """
        âœ… Phase 5.7.7.3: ì¸ë¼ì¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±° ê°•í™” (ë¯¸ì†¡ ì œì•ˆ)
        
        ë¬¸ì œ:
        - "402-2" + "1." â†’ "402-21."ë¡œ í•©ì³ì§
        - "402-3" + "ìš©ì„" â†’ "402-3ìš©ì„"ë¡œ í•©ì³ì§ (ì‹ ê·œ ë°œê²¬)
        - í˜ì´ì§€ ë²ˆí˜¸ê°€ í•­ëª© ë²ˆí˜¸ ë˜ëŠ” í•œê¸€ê³¼ ê²°í•©
        
        í•´ê²°:
        - ì¸ë¼ì¸ íŒ¨í„´ ê°ì§€ ë° ì œê±° ê°•í™”
        - "402-21." â†’ "1."ë¡œ ë³µêµ¬
        - "402-3ìš©ì„" â†’ "ìš©ì„"ë¡œ ë³µêµ¬
        
        Args:
            content: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì •ì œëœ í…ìŠ¤íŠ¸
        """
        # 1) í˜ì´ì§€ ë§ˆì»¤ + í•­ëª© ë²ˆí˜¸ íŒ¨í„´
        # "402-21." â†’ "1."
        content = re.sub(r'\b\d{3,4}-\d{1,2}\s*(\d+[.)])', r'\1', content)
        
        # 2) í˜ì´ì§€ ë§ˆì»¤ + ê³µë°± + í•­ëª© ë²ˆí˜¸
        # "402-2 1." â†’ "1."
        content = re.sub(r'\b\d{3,4}-\d{1,2}\s+(\d+[.)])', r'\1', content)
        
        # âœ… Phase 5.7.7.3: 3) í˜ì´ì§€ ë§ˆì»¤ + í•œê¸€ ê²°í•© (ì‹ ê·œ)
        # "402-3ìš©ì„" â†’ "ìš©ì„"
        content = re.sub(r'\b\d{3,4}-\d{1,2}([ê°€-í£])', r'\1', content)
        
        # 4) í˜ì´ì§€ ë§ˆì»¤ë§Œ ë‹¨ë… (ì¤„ ì¤‘ê°„)
        # "...ë‚´ìš© 402-2 ë‚´ìš©..." â†’ "...ë‚´ìš© ë‚´ìš©..."
        content = re.sub(r'\s+\d{3,4}-\d{1,2}\s+', ' ', content)
        
        logger.debug(f"      ì¸ë¼ì¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±° ì™„ë£Œ (Phase 5.7.8.2)")
        return content
    
    def _strip_page_dividers(self, content: str) -> str:
        """
        âœ… Phase 5.7.7.1: í˜ì´ì§€ êµ¬ë¶„ì ì œê±° ê°•í™” (ë¯¸ì†¡ ì œì•ˆ)
        
        ê°œì„  ì‚¬í•­:
        - "ì¸ì‚¬ê·œì •" í—¤ë” ì œê±° ì¶”ê°€
        - "402-1", "402-2", "402-3" íŒ¨í„´ ê°•í™”
        - ë‹¨ë… ìˆ«ì ì œê±° ê°•í™”
        
        Args:
            content: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì •ì œëœ í…ìŠ¤íŠ¸
        """
        lines = content.split('\n')
        filtered_lines = []
        
        # âœ… Phase 5.7.7.1: í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ ê°•í™”
        page_patterns = [
            r'^[-=*_]{3,}$',  # ---, ===, ***, ___
            r'^Page\s+\d+\s*$',  # Page 1, Page 2
            r'^\d{1,2}$',  # ë‹¨ë… ìˆ«ì (1, 2, 3)
            r'^[0-9]{3,4}-[0-9]{1,2}$',  # 402-1, 402-2 (ì •í™•íˆ ë§¤ì¹­)
            r'^ì¸ì‚¬ê·œì •$',  # "ì¸ì‚¬ê·œì •" í—¤ë” (ë¯¸ì†¡ ì œì•ˆ)
        ]
        
        for line in lines:
            stripped = line.strip()
            
            # íŒ¨í„´ ë§¤ì¹­
            is_divider = any(re.match(pattern, stripped) for pattern in page_patterns)
            
            if not is_divider:
                filtered_lines.append(line)
            else:
                logger.debug(f"      í˜ì´ì§€ ë§ˆì»¤ ì œê±°: '{stripped}'")
        
        logger.debug(f"      í˜ì´ì§€ ë§ˆì»¤ ì œê±° ì™„ë£Œ: {len(lines)} â†’ {len(filtered_lines)} ì¤„")
        return '\n'.join(filtered_lines)
    
    def _normalize_fallback_text(self, text: str) -> str:
        """
        âœ… Phase 5.7.6: Fallback í…ìŠ¤íŠ¸ ì •ê·œí™”
        
        pypdfëŠ” ì¤„ë°”ê¿ˆì´ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ ë³´ì •
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        # 1) ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
        text = unicodedata.normalize('NFKC', text)
        
        # 2) ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # 3) ë„ì–´ì“°ê¸° ì •ë¦¬
        text = re.sub(r' {2,}', ' ', text)
        
        return text
    
    def _validate_content(self, content: str) -> bool:
        """
        ë‚´ìš© ê²€ì¦
        
        Args:
            content: VLM ì¶”ì¶œ í…ìŠ¤íŠ¸
        
        Returns:
            ìœ íš¨ ì—¬ë¶€
        """
        # ìµœì†Œ ê¸¸ì´ ì²´í¬
        if len(content) < 10:
            return False
        
        # í•œê¸€ í¬í•¨ ì²´í¬
        if not re.search(r'[ê°€-í£]', content):
            return False
        
        return True
    
    def _deduplicate_lines(self, content: str) -> str:
        """
        ì¤‘ë³µ ë¼ì¸ ì œê±°
        
        Args:
            content: ì›ë³¸ í…ìŠ¤íŠ¸
        
        Returns:
            ì¤‘ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        lines = content.split('\n')
        seen = set()
        unique_lines = []
        
        for line in lines:
            stripped = line.strip()
            
            if stripped and stripped not in seen:
                unique_lines.append(line)
                seen.add(stripped)
            elif not stripped:
                unique_lines.append(line)
        
        return '\n'.join(unique_lines)
    
    def get_fallback_stats(self) -> Dict[str, Any]:
        """
        Phase 5.7.4 Fallback í†µê³„
        
        Returns:
            í†µê³„ ì •ë³´
        """
        fallback_rate = self.fallback_count / max(1, self.total_pages)
        
        return {
            'vlm_success_count': self.vlm_success_count,
            'fallback_count': self.fallback_count,
            'total_pages': self.total_pages,
            'fallback_rate': fallback_rate
        }