"""
core/hybrid_extractor.py
PRISM Phase 5.6.0 - Hybrid Extractor (Integrated)

âœ… Phase 5.6.0 í†µí•© (GPT + íŒ€ ì˜ê²¬ ë°˜ì˜):
1. Post-merge Normalizer (ë¬¸ì¥ ê²°ì†)
2. Statute-aware Chunker (ì¡°ë¬¸ ì²­í‚¹)
3. Typo Normalizer (ì˜¤íƒˆì êµì •)

(Phase 5.5.1 ê¸°ëŠ¥ ìœ ì§€)
- í‘œ í¬ë§· ê°ì§€ ë³´ìˆ˜í™”
- ì¤‘ë³µ ì œê±° ì•ˆì „í™”
- ê²€ì¦ ê°•í™”

Author: ì´ì„œì˜ (Backend Lead)  
Date: 2025-10-27
Version: 5.6.0
"""

import logging
import re
from typing import Dict, Any, List

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 5.6.0 í†µí•© ì¶”ì¶œê¸°
    
    í”Œë¡œìš°:
    1. QuickLayoutAnalyzer â†’ CV íŒíŠ¸
    2. PromptRules â†’ DSL í”„ë¡¬í”„íŠ¸
    3. VLMService â†’ Markdown ì¶”ì¶œ
    4. Validation â†’ ê²€ì¦
    5. Retry â†’ ì¬ì¶”ì¶œ
    6. Merge â†’ Replace ë³‘í•©
    7. âœ… PostMergeNormalizer â†’ ë¬¸ì¥ ê²°ì†
    8. âœ… TypoNormalizer â†’ ì˜¤íƒˆì êµì •
    9. Dedup â†’ ì¤‘ë³µ ì œê±°
    10. KVSNormalizer â†’ KVS ì •ê·œí™”
    """
    
    def __init__(self, vlm_service, analyzer=None, prompt_rules=None, kvs_normalizer=None):
        """ì´ˆê¸°í™”"""
        self.vlm = vlm_service
        
        if analyzer is None:
            from .quick_layout_analyzer import QuickLayoutAnalyzer
            self.analyzer = QuickLayoutAnalyzer()
        else:
            self.analyzer = analyzer
        
        if prompt_rules is None:
            from .prompt_rules import PromptRules
            self.prompt_rules = PromptRules
        else:
            self.prompt_rules = prompt_rules
        
        if kvs_normalizer is None:
            from .kvs_normalizer import KVSNormalizer
            self.kvs_normalizer = KVSNormalizer
        else:
            self.kvs_normalizer = kvs_normalizer
        
        # âœ… Phase 5.6.0: ìƒˆ ì»´í¬ë„ŒíŠ¸
        from .post_merge_normalizer import PostMergeNormalizer
        from .typo_normalizer import TypoNormalizer
        
        self.post_normalizer = PostMergeNormalizer()
        self.typo_normalizer = TypoNormalizer()
        
        logger.info("âœ… HybridExtractor v5.6.0 ì´ˆê¸°í™” ì™„ë£Œ (Integrated)")
    
    def extract(self, image_data: str, page_num: int = 1) -> Dict[str, Any]:
        """í˜ì´ì§€ ì¶”ì¶œ"""
        import time
        start_time = time.time()
        
        logger.info(f"   ğŸ”§ HybridExtractor v5.6.0 ì¶”ì¶œ ì‹œì‘ (í˜ì´ì§€ {page_num})")
        
        try:
            # Step 1: CV íŒíŠ¸
            cv_start = time.time()
            hints = self.analyzer.analyze(image_data)
            cv_time = time.time() - cv_start
            
            # Step 2: í”„ë¡¬í”„íŠ¸
            prompt_start = time.time()
            prompt = self.prompt_rules.build_prompt(hints)
            prompt_time = time.time() - prompt_start
            
            # Step 3: VLM
            vlm_start = time.time()
            content = self.vlm.call(image_data, prompt)
            vlm_time = time.time() - vlm_start
            logger.info(f"      â±ï¸ VLM: {vlm_time:.2f}ì´ˆ ({len(content)} ê¸€ì)")
            
            # Step 4: ê²€ì¦
            validation = self._validate_content(content, hints)
            logger.info(f"      âœ… ê²€ì¦: {validation['passed']}")
            
            # Step 5: ì¬ì¶”ì¶œ
            retry_count = 0
            if not validation['passed'] and 'TABLE_FORBIDDEN_USED' in validation['violations']:
                logger.info(f"      ğŸ”„ í‘œ ê¸ˆì§€ ì¬ì¶”ì¶œ")
                
                retry_start = time.time()
                retry_content = self._retry_with_table_forbidden(image_data, hints)
                retry_time = time.time() - retry_start
                retry_count = 1
                
                content = self._replace_merge(content, retry_content)
                logger.info(f"      ğŸ”€ Replace ë³‘í•© ì™„ë£Œ")
                
                validation = self._validate_content(content, hints)
            
            # âœ… Step 6: Post-merge Normalizer (Phase 5.6.0)
            doc_type = self._determine_doc_type(hints)
            content = self.post_normalizer.normalize(content, doc_type)
            
            # âœ… Step 7: Typo Normalizer (Phase 5.6.0)
            content = self.typo_normalizer.normalize(content, doc_type)
            
            # Step 8: ì¤‘ë³µ ì œê±°
            content = self._dedup_by_sentences(content)
            logger.info(f"      ğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ ({len(content)} ê¸€ì)")
            
            # Step 9: KVS
            kvs = self._extract_kvs(content)
            if kvs:
                kvs = self.kvs_normalizer.normalize_kvs(kvs)
                logger.info(f"      ğŸ’¾ KVS: {len(kvs)}ê°œ")
            
            # Step 10: í’ˆì§ˆ
            quality_score = self._calculate_quality(content, validation)
            
            total_time = time.time() - start_time
            
            result = {
                'content': content,
                'doc_type': doc_type,
                'confidence': validation['confidence'],
                'quality_score': quality_score,
                'hints': hints,
                'validation': validation,
                'kvs': kvs,
                'metrics': {
                    'cv_time': cv_time,
                    'prompt_time': prompt_time,
                    'vlm_time': vlm_time,
                    'total_time': total_time,
                    'retry_count': retry_count
                }
            }
            
            logger.info(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: í’ˆì§ˆ {quality_score:.0f}/100")
            return result
        
        except Exception as e:
            logger.error(f"   âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _validate_content(self, content: str, hints: Dict[str, Any]) -> Dict[str, Any]:
        """ë‚´ìš© ê²€ì¦"""
        violations = []
        scores = {}
        
        ocr_text = hints.get('ocr_text', '')
        
        from .prompt_rules import PromptRules
        table_confidence = PromptRules._calculate_table_confidence(hints, ocr_text)
        is_statute_mode = PromptRules._detect_statute_mode(hints, ocr_text)
        
        # í‘œ ê¸ˆì§€ ìœ„ë°˜ ê²€ì‚¬
        has_table = self._has_table_format_conservative(content)
        
        if is_statute_mode:
            if has_table and table_confidence < 3:
                violations.append('TABLE_FORBIDDEN_USED')
                logger.debug(f"         [ìœ„ë°˜] ê·œì • ëª¨ë“œ í‘œ ì‚¬ìš©")
        else:
            if has_table and table_confidence < 2:
                violations.append('TABLE_FORBIDDEN_USED')
                logger.debug(f"         [ìœ„ë°˜] ì¼ë°˜ ëª¨ë“œ í‘œ ì‚¬ìš©")
        
        # ê¸¸ì´
        char_count = len(content)
        if char_count < 50:
            violations.append('TOO_SHORT')
            scores['length'] = 0
        else:
            scores['length'] = min(100, char_count / 10)
        
        # êµ¬ì¡°
        headers = re.findall(r'^#+\s+', content, re.MULTILINE)
        if len(headers) >= 2:
            scores['structure'] = 100
        elif len(headers) == 1:
            scores['structure'] = 70
        else:
            violations.append('NO_STRUCTURE')
            scores['structure'] = 30
        
        # ë©”íƒ€ ì„¤ëª…
        meta_patterns = ['ì´ ì´ë¯¸ì§€ëŠ”', 'ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤', 'ì•„ë˜ëŠ”', 'í•„ìš”í•˜ì‹ ', 'ë§ì”€í•´ ì£¼ì„¸ìš”']
        has_meta = any(re.search(p, content) for p in meta_patterns)
        if has_meta:
            violations.append('HAS_META_DESC')
            scores['meta'] = 0
        else:
            scores['meta'] = 100
        
        confidence = sum(scores.values()) / max(1, len(scores))
        confidence = max(0.0, min(100.0, confidence)) / 100.0
        
        passed = len(violations) == 0
        
        return {
            'passed': passed,
            'violations': violations,
            'confidence': confidence,
            'scores': scores
        }
    
    def _has_table_format_conservative(self, content: str) -> bool:
        """ë³´ìˆ˜ì  í‘œ í˜•ì‹ ê°ì§€"""
        lines = [l.strip() for l in content.splitlines() if l.strip()]
        
        # Markdown í‘œ: í—¤ë”-êµ¬ë¶„ì„ -ë°ì´í„° ì—°ì† ë¸”ë¡
        blocks = 0
        for i in range(len(lines) - 2):
            if '|' in lines[i]:
                if set(lines[i+1].replace('|', '').strip()) <= set('- '):
                    if '|' in lines[i+2]:
                        blocks += 1
                        logger.debug(f"         Markdown í‘œ ë¸”ë¡ ê°ì§€: ì¤„ {i}-{i+2}")
        
        if blocks >= 1:
            logger.debug(f"         í‘œ í˜•ì‹: Markdown í‘œ {blocks}ê°œ ë¸”ë¡")
            return True
        
        # CSV-like
        csv_run = 0
        for i, line in enumerate(lines):
            if line.count(',') >= 3:
                alnum_ratio = sum(c.isalnum() for c in line) / max(1, len(line))
                if alnum_ratio > 0.5:
                    csv_run += 1
                    if csv_run >= 3:
                        logger.debug(f"         í‘œ í˜•ì‹: CSV-like ì¤„ {i-2}-{i}")
                        return True
                else:
                    csv_run = 0
            else:
                csv_run = 0
        
        logger.debug(f"         í‘œ í˜•ì‹: ì—†ìŒ (ë³´ìˆ˜ì  ê²€ì‚¬)")
        return False
    
    def _retry_with_table_forbidden(self, image_data: str, hints: Dict[str, Any]) -> str:
        """í‘œ ê¸ˆì§€ ì¬ì¶”ì¶œ"""
        retry_prompt = """**CRITICAL: í‘œ ì‚¬ìš© ê¸ˆì§€**

ì´ì „ ì¶œë ¥ì— í‘œê°€ ìˆì—ˆì§€ë§Œ, ì´ í˜ì´ì§€ëŠ” í‘œê°€ ì•„ë‹™ë‹ˆë‹¤.

**ì ˆëŒ€ ê¸ˆì§€:**
- Markdown í‘œ (|, ---) ì ˆëŒ€ ê¸ˆì§€
- CSV í˜•ì‹ (,) ì ˆëŒ€ ê¸ˆì§€

**ë°˜ë“œì‹œ ì‚¬ìš©:**
- ë¬¸ë‹¨: ë³¸ë¬¸ ì„¤ëª…
- ë¶ˆë¦¿ ëª©ë¡: - ë˜ëŠ” 1. 2. 3.

**ì˜ˆì‹œ:**
```
**ê°œì • ì´ë ¥:**
- ì œ37ì°¨ ê°œì •: 2019.05.27
- ì œ38ì°¨ ê°œì •: 2019.07.01
```

ë‹¤ì‹œ ì¶”ì¶œí•˜ì„¸ìš”.
"""
        
        retry_content = self.vlm.call(image_data, retry_prompt)
        return retry_content
    
    def _replace_merge(self, original: str, retry: str) -> str:
        """Replace ë³‘í•©"""
        merged = retry
        logger.debug(f"         Replace: {len(original)} â†’ {len(merged)} ê¸€ì")
        return merged
    
    def _dedup_by_sentences(self, text: str) -> str:
        """ë¬¸ì¥ ë‹¨ìœ„ ì¤‘ë³µ ì œê±°"""
        sents = [s.strip() for s in re.split(r'(?<=[.!?ã€‚])\s+|\n{2,}', text) if s.strip()]
        
        seen = set()
        out = []
        
        for s in sents:
            key = re.sub(r'\s+', ' ', s)[:160]
            
            if key not in seen:
                seen.add(key)
                out.append(s)
        
        result = "\n\n".join(out)
        
        logger.debug(f"         ì¤‘ë³µ ì œê±°: {len(sents)}ë¬¸ì¥ â†’ {len(out)}ë¬¸ì¥")
        return result
    
    def _extract_kvs(self, content: str) -> Dict[str, str]:
        """KVS ì¶”ì¶œ"""
        kvs = {}
        
        patterns = [
            r'[\*\*]?(.+?)[\*\*]?:\s*(.+)',
            r'â€¢\s*(.+?):\s*(.+)',
            r'-\s*(.+?):\s*(.+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            for key, value in matches:
                key = key.strip().strip('*')
                value = value.strip()
                if key and value and len(key) < 50 and len(value) < 200:
                    kvs[key] = value
        
        return kvs
    
    def _determine_doc_type(self, hints: Dict[str, Any]) -> str:
        """ë¬¸ì„œ íƒ€ì… íŒë³„"""
        ocr_text = hints.get('ocr_text', '')
        from .prompt_rules import PromptRules
        
        if PromptRules._detect_statute_mode(hints, ocr_text):
            return 'statute'
        elif hints.get('has_map') and len(hints.get('bus_keywords', [])) >= 2:
            return 'bus_diagram'
        elif hints.get('has_table'):
            return 'table'
        else:
            return 'general'
    
    def _calculate_quality(self, content: str, validation: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜"""
        score = validation['confidence'] * 100
        
        if len(content) > 500:
            score += 10
        
        if validation['scores'].get('structure', 0) == 100:
            score += 10
        
        return max(0.0, min(100.0, score))