"""
core/hybrid_extractor.py
PRISM Phase 5.7.2.2 Hotfix - Hybrid Extractor (Pipeline Fix)

âœ… Phase 5.7.2.2 ê¸´ê¸‰ ìˆ˜ì • (GPT ì˜ê²¬ 100% ë°˜ì˜):
1. í˜ì´ì§€ êµ¬ë¶„ì ì œê±° - OCR ì§í›„ ì‹¤í–‰
2. ë¹ˆ í˜ì´ì§€ëŠ” Skip (ì‹¤íŒ¨ë¡œ ì¹´ìš´íŠ¸ ì•ˆí•¨)
3. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFKC) ì¶”ê°€
4. ë¡œê·¸ ë ˆë²¨ ì¡°ì • (INFO)

(Phase 5.6.1 ê¸°ëŠ¥ ìœ ì§€)

Author: ì´ì„œì˜ (Backend Lead) + GPT(ë¯¸ì†¡) ì˜ê²¬ ë°˜ì˜  
Date: 2025-10-31
Version: 5.7.2.2 Hotfix
"""

import logging
import re
import unicodedata
from typing import Dict, Any, List

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 5.7.2.2 í†µí•© ì¶”ì¶œê¸° (Pipeline Hotfix)
    
    í”Œë¡œìš°:
    0. âœ… _strip_page_dividers â†’ í˜ì´ì§€ êµ¬ë¶„ì ì œê±° (Phase 5.7.2.2)
    1. QuickLayoutAnalyzer â†’ CV íŒíŠ¸
    2. PromptRules â†’ DSL í”„ë¡¬í”„íŠ¸
    3. VLMService â†’ Markdown ì¶”ì¶œ
    4. Validation â†’ ê²€ì¦
    5. âœ… Empty Guard â†’ ë¹ˆ í˜ì´ì§€ Skip (Phase 5.7.2.2)
    6. Retry â†’ ì¬ì¶”ì¶œ
    7. Merge â†’ Replace ë³‘í•©
    8. PostMergeNormalizer v5.6.1 â†’ ë¬¸ì¥ ê²°ì† ê°•í™”
    9. TypoNormalizer v5.6.1 â†’ ì˜¤íƒˆì êµì • í™•ì¥
    10. Dedup â†’ ì¤‘ë³µ ì œê±°
    11. KVSNormalizer â†’ KVS ì •ê·œí™”
    12. Amendment Extractor â†’ ê°œì • ë©”ëª¨ ì¶”ì¶œ
    """
    
    # âœ… Phase 5.7.2.2: í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´
    PAGE_DIVIDER_PATTERNS = [
        re.compile(r'^#{0,3}\s*Page\s+\d+\s*$', re.IGNORECASE),
        re.compile(r'^Page\s+\d+\s*$', re.IGNORECASE),
        re.compile(r'^[-â€”â€“_]{3,}\s*$'),
        re.compile(r'^\*{3,}\s*$'),
        re.compile(r'^={3,}\s*$'),
    ]
    
    def __init__(self, vlm_service, analyzer=None, prompt_rules=None, kvs_normalizer=None):
        """ì´ˆê¸°í™”"""
        self.vlm = vlm_service
        
        if analyzer is None:
            from .quick_layout_analyzer import QuickLayoutAnalyzer
            self.analyzer = QuickLayoutAnalyzer()
        else:
            self.analyzer = analyzer
        
        if prompt_rules is None:
            from .prompt_rules import PromptRules
            self.prompt_rules = PromptRules
        else:
            self.prompt_rules = prompt_rules
        
        if kvs_normalizer is None:
            from .kvs_normalizer import KVSNormalizer
            self.kvs_normalizer = KVSNormalizer
        else:
            self.kvs_normalizer = kvs_normalizer
        
        # Phase 5.6.1: ìƒˆ ì»´í¬ë„ŒíŠ¸ (v5.6.1)
        from .post_merge_normalizer import PostMergeNormalizer
        from .typo_normalizer import TypoNormalizer
        
        self.post_normalizer = PostMergeNormalizer()
        self.typo_normalizer = TypoNormalizer()
        
        logger.info("âœ… HybridExtractor v5.7.2.2 ì´ˆê¸°í™” ì™„ë£Œ (Pipeline Hotfix)")
    
    def extract(self, image_data: str, page_num: int = 1) -> Dict[str, Any]:
        """í˜ì´ì§€ ì¶”ì¶œ"""
        import time
        start_time = time.time()
        
        logger.info(f"   ğŸ”§ HybridExtractor v5.7.2.2 ì¶”ì¶œ ì‹œì‘ (í˜ì´ì§€ {page_num})")
        
        try:
            # Step 1: CV íŒíŠ¸
            cv_start = time.time()
            hints = self.analyzer.analyze(image_data)
            cv_time = time.time() - cv_start
            
            # Step 2: í”„ë¡¬í”„íŠ¸
            prompt_start = time.time()
            prompt = self.prompt_rules.build_prompt(hints)
            prompt_time = time.time() - prompt_start
            
            # Step 3: VLM
            vlm_start = time.time()
            content = self.vlm.call(image_data, prompt)
            vlm_time = time.time() - vlm_start
            logger.info(f"      â±ï¸ VLM: {vlm_time:.2f}ì´ˆ ({len(content)} ê¸€ì)")
            
            # âœ… Step 3.5: í˜ì´ì§€ êµ¬ë¶„ì ì œê±° (Phase 5.7.2.2)
            content_before_clean = len(content)
            content = self._strip_page_dividers(content)
            if len(content) < content_before_clean:
                logger.info(f"      ğŸ§¹ í˜ì´ì§€ êµ¬ë¶„ì ì œê±°: {content_before_clean}ì â†’ {len(content)}ì")
            
            # Step 4: ê²€ì¦
            validation = self._validate_content(content, hints)
            logger.info(f"      âœ… ê²€ì¦: {validation['passed']}")
            
            # âœ… Step 5: ë¹ˆ í˜ì´ì§€ Skip (Phase 5.7.2.2 ê°œì„ )
            visible_chars = len([c for c in content if c.strip()])
            if visible_chars < 10:
                logger.info(f"      â„¹ï¸ ë¹ˆ í˜ì´ì§€ Skip (ê°€ì‹œë¬¸ì {visible_chars}ì)")
                return {
                    'content': '',
                    'doc_type': 'empty',
                    'confidence': 0.0,
                    'quality_score': 0.0,
                    'hints': hints,
                    'validation': {'passed': False, 'violations': ['EMPTY_PAGE'], 'confidence': 0.0},
                    'kvs': [],
                    'amendment_notes': [],
                    'quality_indicators': {
                        'statute_mode': False,
                        'table_confidence': 0.0,
                        'amendment_count': 0
                    },
                    'metrics': {
                        'cv_time': cv_time,
                        'prompt_time': prompt_time,
                        'vlm_time': vlm_time,
                        'total_time': time.time() - start_time,
                        'retry_count': 0
                    },
                    'is_empty': True  # âœ… ë¹ˆ í˜ì´ì§€ í”Œë˜ê·¸
                }
            
            # Step 6: ì¬ì¶”ì¶œ (í‘œ ê¸ˆì§€)
            retry_count = 0
            if not validation['passed'] and 'TABLE_FORBIDDEN_USED' in validation['violations']:
                logger.info(f"      ğŸ”„ í‘œ ê¸ˆì§€ ì¬ì¶”ì¶œ")
                
                retry_start = time.time()
                retry_content = self._retry_with_table_forbidden(image_data, hints)
                retry_time = time.time() - retry_start
                retry_count = 1
                
                content = self._replace_merge(content, retry_content)
                logger.info(f"      ğŸ”€ Replace ë³‘í•© ì™„ë£Œ")
                
                validation = self._validate_content(content, hints)
            
            # Step 7: Post-merge Normalizer v5.6.1 (Phase 5.6.1)
            doc_type = self._determine_doc_type(hints)
            content = self.post_normalizer.normalize(content, doc_type)
            
            # Step 8: Typo Normalizer v5.6.1 (Phase 5.6.1)
            content = self.typo_normalizer.normalize(content, doc_type)
            
            # Step 9: ì¤‘ë³µ ì œê±°
            content = self._dedup_by_sentences(content)
            logger.info(f"      ğŸ§¹ ì¤‘ë³µ ì œê±° ì™„ë£Œ ({len(content)} ê¸€ì)")
            
            # Step 10: KVS
            kvs = self._extract_kvs(content)
            if kvs:
                kvs = self.kvs_normalizer.normalize_kvs(kvs)
                logger.info(f"      ğŸ’¾ KVS: {len(kvs)}ê°œ")
            
            # Step 11: ê°œì • ë©”ëª¨ ì¶”ì¶œ (Phase 5.6.1)
            amendment_notes = self._extract_amendment_notes(content)
            
            # Step 12: í’ˆì§ˆ
            quality_score = self._calculate_quality(content, validation)
            
            # Step 13: í’ˆì§ˆ ì§€í‘œ 3ì¢… (Phase 5.6.1)
            ocr_text = hints.get('ocr_text', '')
            quality_indicators = {
                'statute_mode': self.prompt_rules._detect_statute_mode(hints, ocr_text),
                'table_confidence': self.prompt_rules._calculate_table_confidence(hints, ocr_text),
                'amendment_count': len(amendment_notes)
            }
            
            total_time = time.time() - start_time
            
            result = {
                'content': content,
                'doc_type': doc_type,
                'confidence': validation['confidence'],
                'quality_score': quality_score,
                'hints': hints,
                'validation': validation,
                'kvs': kvs,
                'amendment_notes': amendment_notes,
                'quality_indicators': quality_indicators,
                'metrics': {
                    'cv_time': cv_time,
                    'prompt_time': prompt_time,
                    'vlm_time': vlm_time,
                    'total_time': total_time,
                    'retry_count': retry_count
                },
                'is_empty': False  # âœ… ì •ìƒ í˜ì´ì§€ í”Œë˜ê·¸
            }
            
            logger.info(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: í’ˆì§ˆ {quality_score:.0f}/100")
            return result
        
        except Exception as e:
            logger.error(f"   âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _strip_page_dividers(self, text: str) -> str:
        """
        âœ… Phase 5.7.2.2: í˜ì´ì§€ êµ¬ë¶„ì ì œê±°
        
        ì œê±° ëŒ€ìƒ:
        - # Page 1, ## Page 2, Page 3
        - ---, ***, ===
        
        íŠ¹ì§•:
        - ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFKC)
        - ì¤„ ë‹¨ìœ„ ì™„ì „ ë§¤ì¹˜
        - ì›ë¬¸ ë³´ì¡´ (raw line ìœ ì§€)
        """
        cleaned = []
        for raw_line in text.splitlines():
            # ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (ë³´ì´ì§€ ì•ŠëŠ” ë¬¸ì ì œê±°)
            normalized = unicodedata.normalize('NFKC', raw_line).strip()
            
            # í˜ì´ì§€ êµ¬ë¶„ì íŒ¨í„´ ë§¤ì¹˜
            if any(p.match(normalized) for p in self.PAGE_DIVIDER_PATTERNS):
                continue  # ì´ ì¤„ì€ ì œê±°
            
            # ì›ë¬¸ ë³´ì¡´
            cleaned.append(raw_line)
        
        return "\n".join(cleaned)
    
    def _validate_content(self, content: str, hints: Dict[str, Any]) -> Dict[str, Any]:
        """ë‚´ìš© ê²€ì¦"""
        violations = []
        scores = {}
        
        ocr_text = hints.get('ocr_text', '')
        
        from .prompt_rules import PromptRules
        table_confidence = PromptRules._calculate_table_confidence(hints, ocr_text)
        is_statute_mode = PromptRules._detect_statute_mode(hints, ocr_text)
        
        # í‘œ ê¸ˆì§€ ê²€ì‚¬
        if is_statute_mode and table_confidence > 0.3:
            if '|' in content[:500] or content.count('|') > 10:
                violations.append('TABLE_FORBIDDEN_USED')
                scores['table_forbidden'] = 0.0
            else:
                scores['table_forbidden'] = 1.0
        
        # êµ¬ì¡° ë³´ì¡´
        article_count = content.count('ì œ') + content.count('ì¡°')
        if article_count >= 2:
            scores['structure'] = 1.0
        elif article_count == 1:
            scores['structure'] = 0.5
        else:
            scores['structure'] = 0.3
        
        # ê¸¸ì´ ê²€ì‚¬
        if len(content) < 50:
            violations.append('TOO_SHORT')
            scores['length'] = 0.3
        elif len(content) < 200:
            scores['length'] = 0.7
        else:
            scores['length'] = 1.0
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = sum(scores.values()) / max(len(scores), 1)
        
        return {
            'passed': len(violations) == 0,
            'violations': violations,
            'scores': scores,
            'confidence': confidence
        }
    
    def _retry_with_simple_prompt(self, image_data: str) -> str:
        """ê°„ë‹¨ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì¶”ì¶œ"""
        simple_prompt = "ì´ í˜ì´ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."
        return self.vlm.call(image_data, simple_prompt)
    
    def _retry_with_table_forbidden(self, image_data: str, hints: Dict[str, Any]) -> str:
        """í‘œ ê¸ˆì§€ ì¬ì¶”ì¶œ"""
        forbidden_prompt = self.prompt_rules.build_prompt(hints)
        forbidden_prompt += "\n\nâš ï¸ ì¤‘ìš”: í‘œ í˜•ì‹(|)ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ëª¨ë“  ë‚´ìš©ì„ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        return self.vlm.call(image_data, forbidden_prompt)
    
    def _replace_merge(self, original: str, retry: str) -> str:
        """Replace ë³‘í•©"""
        if len(retry) > len(original) * 0.8:
            return retry
        return original
    
    def _determine_doc_type(self, hints: Dict[str, Any]) -> str:
        """ë¬¸ì„œ íƒ€ì… íŒì •"""
        ocr_text = hints.get('ocr_text', '')
        
        from .prompt_rules import PromptRules
        is_statute = PromptRules._detect_statute_mode(hints, ocr_text)
        
        if is_statute:
            return 'statute'
        return 'general'
    
    def _dedup_by_sentences(self, content: str) -> str:
        """ë¬¸ì¥ ë‹¨ìœ„ ì¤‘ë³µ ì œê±°"""
        lines = content.split('\n')
        seen = set()
        result = []
        
        for line in lines:
            normalized = line.strip()
            if not normalized:
                result.append(line)
                continue
            
            if normalized not in seen:
                seen.add(normalized)
                result.append(line)
        
        return '\n'.join(result)
    
    def _extract_kvs(self, content: str) -> List[Dict[str, str]]:
        """KVS ì¶”ì¶œ"""
        kvs = []
        
        # ê´„í˜¸ íŒ¨í„´: ì œ1ì¡°(ëª©ì )
        for match in re.finditer(r'(ì œ\s?\d+ì¡°)\s*\(([^)]+)\)', content):
            kvs.append({
                'key': match.group(1),
                'value': match.group(2),
                'type': 'article_title'
            })
        
        # ê°œì •ì¼ íŒ¨í„´
        for match in re.finditer(r'(ê°œì •|ì‹ ì„¤|ì‚­ì œ)\s*(\d{4}\.\d{1,2}\.\d{1,2})', content):
            kvs.append({
                'key': match.group(1),
                'value': match.group(2),
                'type': 'amendment_date'
            })
        
        return kvs
    
    def _extract_amendment_notes(self, content: str) -> List[str]:
        """âœ… Phase 5.6.1: ê°œì • ë©”ëª¨ ì¶”ì¶œ"""
        notes = []
        
        # íŒ¨í„´ 1: [ê°œì • 2024.1.1]
        for match in re.finditer(r'\[([^]]+\d{4}\.\d{1,2}\.\d{1,2}[^]]*)\]', content):
            notes.append(match.group(1))
        
        # íŒ¨í„´ 2: (ê°œì • 2024.1.1)
        for match in re.finditer(r'\(([^)]+\d{4}\.\d{1,2}\.\d{1,2}[^)]*)\)', content):
            if 'ê°œì •' in match.group(1) or 'ì‹ ì„¤' in match.group(1) or 'ì‚­ì œ' in match.group(1):
                notes.append(match.group(1))
        
        return list(set(notes))
    
    def _calculate_quality(self, content: str, validation: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ê²€ì¦ í†µê³¼ ì—¬ë¶€ (40ì )
        if validation['passed']:
            score += 40
        
        # ì‹ ë¢°ë„ (30ì )
        score += validation['confidence'] * 30
        
        # ê¸¸ì´ (20ì )
        if len(content) >= 500:
            score += 20
        elif len(content) >= 200:
            score += 15
        elif len(content) >= 100:
            score += 10
        
        # êµ¬ì¡° (10ì )
        structure_score = validation['scores'].get('structure', 0)
        score += structure_score * 10
        
        return min(score, 100)