"""
core/hybrid_extractor.py
PRISM Phase 5.3.1 - Hybrid Extractor (ê¸´ê¸‰ íŒ¨ì¹˜)

âœ… Phase 5.3.1 ìˆ˜ì •:
1. í™˜ê° íŒ¨í„´ ê²€ì¶œ + ì²´ì¸ ì»· (30 ë…¸ë“œ ì´ë‚´)
2. _merge_content() [RETRY] ì„¹ì…˜ë§Œ ì¶”ì¶œ
3. ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ê°•í™” (PromptRules v5.3.1 ì‚¬ìš©)
4. KVS ì¶”ì¶œ ì •ê·œì‹ ìœ ì§€ (v5.3.0 ë²„ê·¸ ìˆ˜ì • ìœ ì§€)

Author: ë°•ì¤€í˜¸ (AI/ML Lead) + GPT ì œì•ˆ ë°˜ì˜
Date: 2025-10-27
Version: 5.3.1
"""

import logging
import re
import json
from typing import Dict, Any, Optional
from pathlib import Path

# Phase 5.3.1 ëª¨ë“ˆ import
from .quick_layout_analyzer import QuickLayoutAnalyzer
from .prompt_rules import PromptRules
from .kvs_normalizer import KVSNormalizer

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 5.3.1 í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œê¸° (ê¸´ê¸‰ íŒ¨ì¹˜)
    
    GPT ì œì•ˆ ë°˜ì˜:
    1. í™˜ê° íŒ¨í„´ ê²€ì¶œ + ì²´ì¸ ì»· (30 ë…¸ë“œ ì´ë‚´)
    2. _merge_content() [RETRY] ì„¹ì…˜ë§Œ ì¶”ì¶œ
    3. ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ê°•í™”
    
    ì „ëµ:
    1. QuickLayoutAnalyzerë¡œ êµ¬ì¡° íŒíŠ¸ íšë“
    2. PromptRules DSLë¡œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
    3. VLM 1íšŒ í˜¸ì¶œë¡œ ì™„ì „ ì¶”ì¶œ
    4. PromptRulesë¡œ ê°•í™” ê²€ì¦
    5. í™˜ê° ê°ì§€ ì‹œ ì²´ì¸ ì»· ë˜ëŠ” ì¬ì¶”ì¶œ
    6. KVS ë³„ë„ ì¶”ì¶œ ë° ì €ì¥
    """
    
    def __init__(self, vlm_service):
        """
        Args:
            vlm_service: VLMServiceV50 ì¸ìŠ¤í„´ìŠ¤
        """
        self.vlm = vlm_service
        self.analyzer = QuickLayoutAnalyzer()
        self.max_retries = 1
        logger.info("âœ… HybridExtractor v5.3.1 ì´ˆê¸°í™” (ê¸´ê¸‰ íŒ¨ì¹˜)")
    
    def extract(self, image_data: str, page_num: int = 1) -> Dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            image_data: Base64 ì¸ì½”ë”© ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            {
                'content': str,
                'kvs': Dict,
                'confidence': float,
                'doc_type': str,
                'hints': Dict,
                'quality_score': float,
                'validation': Dict,
                'metrics': Dict
            }
        """
        logger.info(f"ğŸ¯ Page {page_num}: Phase 5.3.1 Hybrid ì¶”ì¶œ ì‹œì‘")
        
        import time
        start_time = time.time()
        
        try:
            # Step 1: CV íŒíŠ¸ ìƒì„±
            cv_start = time.time()
            hints = self.analyzer.analyze(image_data)
            cv_time = time.time() - cv_start
            logger.info(f"   ğŸ“ CV íŒíŠ¸ ({cv_time:.2f}ì´ˆ): {hints}")
            
            # Step 2: DSL ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = PromptRules.build_prompt(hints)
            logger.debug(f"   ğŸ“ DSL í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len(prompt)} ê¸€ì")
            
            # Step 3: VLM ì¶”ì¶œ
            vlm_start = time.time()
            content = self._call_vlm(image_data, prompt)
            vlm_time = time.time() - vlm_start
            logger.info(f"   âœ… VLM ì¶”ì¶œ ì™„ë£Œ ({vlm_time:.2f}ì´ˆ): {len(content)} ê¸€ì")
            
            # Step 4: ì˜¤íƒˆì êµì •
            content = PromptRules.correct_typos(content)
            
            # âœ… Phase 5.3.1: í™˜ê° íŒ¨í„´ ê²€ì¶œ + ì²´ì¸ ì»· (GPT ì œì•ˆ)
            content = self._cut_hallucination_chains(content)
            
            # Step 5: ê°•í™” ê²€ì¦
            validation = PromptRules.validate_extraction(content, hints)
            
            retry_count = 0
            if not validation['passed'] and retry_count < self.max_retries:
                logger.warning(f"   âš ï¸ ê²€ì¦ ì‹¤íŒ¨: {validation['missing']}")
                logger.info(f"   â™»ï¸ ì¬ì¶”ì¶œ ì‹œì‘ (ì‹œë„ {retry_count + 1}/{self.max_retries})")
                
                # Step 6: ì¬ì¶”ì¶œ
                retry_start = time.time()
                content = self._focused_reextraction(
                    image_data,
                    hints,
                    content,
                    validation['missing']
                )
                retry_time = time.time() - retry_start
                logger.info(f"   âœ… ì¬ì¶”ì¶œ ì™„ë£Œ ({retry_time:.2f}ì´ˆ): {len(content)} ê¸€ì")
                
                # âœ… ì¬ì¶”ì¶œ í›„ì—ë„ í™˜ê° ê²€ì¶œ
                content = self._cut_hallucination_chains(content)
                
                # ì¬ê²€ì¦
                validation = PromptRules.validate_extraction(content, hints)
                retry_count += 1
            
            # Step 7: KVS ì¶”ì¶œ
            kvs = self._extract_kvs(content, hints)
            
            # Step 7.5: KVS ì •ê·œí™”
            if kvs:
                kvs = KVSNormalizer.normalize_kvs(kvs)
                logger.info(f"   ğŸ“Š KVS ì •ê·œí™” ì™„ë£Œ: {len(kvs)}ê°œ í•­ëª©")
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality(content, hints, validation)
            
            # ê´€ì¸¡ì„± ë©”íŠ¸ë¦­
            total_time = time.time() - start_time
            metrics = {
                'cv_time': cv_time,
                'vlm_time': vlm_time,
                'total_time': total_time,
                'retry_count': retry_count,
                'content_length': len(content),
                'kvs_count': len(kvs)
            }
            
            return {
                'content': content,
                'kvs': kvs,
                'confidence': 0.9 if validation['passed'] else 0.7,
                'doc_type': self._infer_doc_type(hints),
                'hints': hints,
                'quality_score': quality_score,
                'validation': validation,
                'metrics': metrics
            }
            
        except Exception as e:
            logger.error(f"   âŒ Hybrid ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _call_vlm(self, image_data: str, prompt: str) -> str:
        """VLM í˜¸ì¶œ (Azure OpenAI ë˜ëŠ” Claude)"""
        return self.vlm.call(image_data, prompt)
    
    def _cut_hallucination_chains(self, content: str) -> str:
        """
        âœ… Phase 5.3.1: í™˜ê° ì²´ì¸ ì»· (GPT ì œì•ˆ)
        
        ì „ëµ:
        - 10íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” í™”ì‚´í‘œ ì²´ì¸ ê²€ì¶œ
        - 15 ë…¸ë“œê¹Œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” "â€¦(ì¤‘ê°„ ìƒëµ)â€¦"
        
        Args:
            content: Markdown ë‚´ìš©
        
        Returns:
            í™˜ê° ì œê±°ëœ Markdown
        """
        # ë°˜ë³µ/ë£¨í”„ íŒ¨í„´ ê°ì§€ (10íšŒ ì´ìƒ)
        loop_pattern = r'(\b[ê°€-í£A-Za-z0-9]{2,15}\b(?:\s*(?:â†’|->)\s*\b[ê°€-í£A-Za-z0-9]{2,15}\b)){10,}'
        
        if re.search(loop_pattern, content):
            logger.warning("   âš ï¸ í™˜ê° ì²´ì¸ íŒ¨í„´ ê°ì§€ - 30 ë…¸ë“œë¡œ ì»·")
            
            # 15 ë…¸ë“œê¹Œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìƒëµ
            content = re.sub(
                r'((?:\S+\s*(?:â†’|->)\s*){15})(?:\S+\s*(?:â†’|->)\s*)+(\S+)',
                r'\1 â€¦(ì¤‘ê°„ ìƒëµ)â€¦ \2',
                content
            )
        
        return content
    
    def _focused_reextraction(
        self,
        image_data: str,
        hints: Dict,
        prev_content: str,
        missing: list[str]
    ) -> str:
        """
        ëˆ„ë½ ìš”ì†Œ ì§‘ì¤‘ ì¬ì¶”ì¶œ
        
        ì „ëµ: PromptRules v5.3.1ì˜ ê°•í™”ëœ retry í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        
        Args:
            image_data: Base64 ì´ë¯¸ì§€
            hints: CV íŒíŠ¸
            prev_content: ì´ì „ ì¶”ì¶œ ë‚´ìš©
            missing: ëˆ„ë½ëœ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë³‘í•©ëœ Markdown
        """
        # âœ… Phase 5.3.1: ê°•í™”ëœ ì¬ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        retry_prompt = PromptRules.build_retry_prompt(hints, missing, prev_content)
        
        # VLM ì¬í˜¸ì¶œ
        additional = self._call_vlm(image_data, retry_prompt)
        
        # ê¸°ì¡´ + ì¶”ê°€ ë³‘í•©
        merged = self._merge_content(prev_content, additional)
        
        return merged
    
    def _merge_content(self, prev: str, additional: str) -> str:
        """
        âœ… Phase 5.3.1: [RETRY] ì„¹ì…˜ë§Œ ì¶”ì¶œ + í™˜ê° ì°¨ë‹¨ (GPT ì œì•ˆ)
        
        ì „ëµ:
        1. additionalì—ì„œ [RETRY] í—¤ë” ì´í›„ë§Œ ì¶”ì¶œ
        2. ë³‘í•© í›„ í™˜ê° íŒ¨í„´ ì¬ê²€ì¶œ
        3. í™˜ê°ì´ë©´ ê¸°ì¡´ ë‚´ìš©ë§Œ ë°˜í™˜
        
        Args:
            prev: ê¸°ì¡´ ë‚´ìš©
            additional: ì¬ì¶”ì¶œ ë‚´ìš©
        
        Returns:
            ë³‘í•©ëœ Markdown
        """
        # [RETRY] ì„¹ì…˜ë§Œ ì¶”ì¶œ
        in_retry = False
        retry_lines = []
        
        for line in additional.splitlines():
            if '[RETRY]' in line:
                in_retry = True
            
            if in_retry:
                retry_lines.append(line)
        
        if not retry_lines:
            logger.warning("   âš ï¸ [RETRY] ì„¹ì…˜ ì—†ìŒ - ê¸°ì¡´ ë‚´ìš© ìœ ì§€")
            return prev
        
        # ë³‘í•©
        merged = prev + '\n\n' + '\n'.join(retry_lines)
        
        # âœ… í™˜ê° íŒ¨í„´ ì¬ê²€ì¶œ (GPT ì œì•ˆ)
        loop_pattern = r'(\b[ê°€-í£A-Za-z0-9]{2,15}\b(?:\s*(?:â†’|->)\s*\b[ê°€-í£A-Za-z0-9]{2,15}\b)){10,}'
        
        if re.search(loop_pattern, merged):
            logger.warning("   âš ï¸ ì¬ì¶”ì¶œì—ë„ í™˜ê° íŒ¨í„´ - ê¸°ì¡´ ë‚´ìš©ë§Œ ë°˜í™˜")
            return prev
        
        logger.info("   âœ… [RETRY] ì„¹ì…˜ ë³‘í•© ì„±ê³µ")
        return merged
    
    def _extract_kvs(self, content: str, hints: Dict) -> Dict[str, str]:
        """
        Key-Value Structured ë°ì´í„° ì¶”ì¶œ
        
        (Phase 5.3.0 ë²„ê·¸ ìˆ˜ì • ìœ ì§€)
        
        Returns:
            {
                'ë°°ì°¨ê°„ê²©': '27ë¶„',
                'ì²«ì°¨': '05:30',
                'ë§‰ì°¨': '22:40',
                ...
            }
        """
        if not hints.get('has_numbers'):
            return {}
        
        kvs = {}
        
        # KVS íŒ¨í„´ ë§¤ì¹­ (v5.3.0 ë²„ê·¸ ìˆ˜ì • ìœ ì§€)
        patterns = [
            (r'([ê°€-í£a-zA-Z\s]+):\s*([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+[ê°€-í£]*)', 1, 2),
            (r'(ë°°ì°¨ê°„ê²©|ì²«ì°¨|ë§‰ì°¨|ë…¸ì„ ë²ˆí˜¸)\s+([0-9:ë¶„]+)', 1, 2),
            (r'([ê°€-í£]+)ëŠ”\s+([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+)', 1, 2),
            (r'([ê°€-í£]+)ê°€\s+([0-9:ë¶„ì›%ëª…ëŒ€ì´ˆ]+)', 1, 2),
        ]
        
        for pattern, key_group, val_group in patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                key = match.group(key_group).strip()
                value = match.group(val_group).strip()
                
                # ë¹ˆ ê°’ í•„í„°ë§
                if not value or value == ':':
                    continue
                
                # ì¤‘ìš” í‚¤ë§Œ ì €ì¥
                important_keys = ['ë°°ì°¨ê°„ê²©', 'ì²«ì°¨', 'ë§‰ì°¨', 'ë…¸ì„ ë²ˆí˜¸', 'ë³€ê²½ ì „', 'ë³€ê²½ í›„']
                if any(ik in key for ik in important_keys):
                    if key in kvs:
                        if len(value) > len(kvs[key]):
                            kvs[key] = value
                    else:
                        kvs[key] = value
        
        return kvs
    
    def _calculate_quality(
        self,
        content: str,
        hints: Dict,
        validation: Dict
    ) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        base_score = 100.0
        
        # ê¸¸ì´ ì²´í¬
        if len(content) < 100:
            base_score -= 40
        elif len(content) < 500:
            base_score -= 20
        
        # ê²€ì¦ ì ìˆ˜ ë°˜ì˜
        if validation['scores']:
            avg_validation = sum(validation['scores'].values()) / len(validation['scores'])
            base_score = (base_score + avg_validation) / 2
        
        # ê²½ê³  í˜ë„í‹°
        warning_penalty = len(validation.get('warnings', [])) * 5
        base_score -= warning_penalty
        
        return max(0.0, min(100.0, base_score))
    
    def _infer_doc_type(self, hints: Dict) -> str:
        """íŒíŠ¸ë¡œ ë¬¸ì„œ íƒ€ì… ì¶”ë¡ """
        if hints['has_map'] and hints['diagram_count'] > 0:
            return 'diagram'
        elif hints['has_table']:
            return 'chart_statistics'
        elif hints['has_text'] and not hints['has_table']:
            return 'text_document'
        else:
            return 'mixed'
    
    def save_kvs_payload(
        self,
        kvs: Dict[str, str],
        doc_id: str,
        page_num: int,
        output_dir: Path
    ) -> Optional[Path]:
        """
        KVS ë³„ë„ í˜ì´ë¡œë“œ ì €ì¥
        
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if not kvs:
            return None
        
        payload = {
            'doc_id': doc_id,
            'page': page_num,
            'chunk_id': f'{doc_id}_p{page_num}_kvs',
            'type': 'kvs',
            'kvs': kvs,
            'rank_hint': 3
        }
        
        output_path = output_dir / f'{doc_id}_p{page_num}_kvs.json'
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ KVS í˜ì´ë¡œë“œ ì €ì¥: {output_path}")
        return output_path