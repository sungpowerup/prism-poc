"""
core/hybrid_extractor.py
PRISM Phase 0 Hotfix - Hybrid Extractor with Revision Detection

âœ… Phase 0 ê¸´ê¸‰ ìˆ˜ì •:
1. _detect_revision_table() 2ì¶• ê°ì§€ (OCR + ë‚ ì§œ íŒ¨í„´)
2. call_with_retry() ì‚¬ìš©ìœ¼ë¡œ VLM ì•ˆì •í™”
3. ê°œì •ì´ë ¥ í˜ì´ì§€ì— page_role="revision_table" ì „ë‹¬

Author: ì´ì„œì˜ (Backend Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-11-06
Version: Phase 0 Hotfix
"""

import logging
import re
import unicodedata
from typing import Dict, Any, List, Optional

import pypdf
from pathlib import Path

try:
    from .quick_layout_analyzer import QuickLayoutAnalyzer
    from .prompt_rules import PromptRules
    from .post_merge_normalizer import PostMergeNormalizer
    from .typo_normalizer import TypoNormalizer
    from .kvs_normalizer import KVSNormalizer
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from quick_layout_analyzer import QuickLayoutAnalyzer
    from prompt_rules import PromptRules
    from post_merge_normalizer import PostMergeNormalizer
    from typo_normalizer import TypoNormalizer
    from kvs_normalizer import KVSNormalizer

logger = logging.getLogger(__name__)


class HybridExtractor:
    """
    Phase 0 í†µí•© ì¶”ì¶œê¸° (ê°œì •ì´ë ¥ ê°ì§€ + VLM ì¬ì‹œë„)
    
    âœ… Phase 0 ê°œì„ :
    1. ê°œì •ì´ë ¥ ê°ì§€ - 2ì¶• (OCR + ë‚ ì§œ)
    2. VLM ì¬ì‹œë„ - call_with_retry()
    3. í˜ì´ì§€ ì—­í•  ì „ë‹¬ - revision_table
    
    í”Œë¡œìš°:
    1. QuickLayoutAnalyzer: ë ˆì´ì•„ì›ƒ ë¶„ì„ + OCR
    2. ê°œì •ì´ë ¥ ê°ì§€ (1í˜ì´ì§€ë§Œ, 2ì¶•)
    3. VLM ì‹œë„ (call_with_retry)
    4. Fallback (pypdf)
    5. í›„ì²˜ë¦¬ (PostMergeNormalizer, TypoNormalizer)
    6. doc_type ì¡°ê±´ë¶€ ìŠ¹ê¸‰
    """
    
    STATUTE_KEYWORDS = [
        'ì¡°', 'í•­', 'í˜¸', 'ì§ì›', 'ê·œì •', 'ì„ìš©', 'ì±„ìš©',
        'ìŠ¹ì§„', 'ì „ë³´', 'íœ´ì§', 'ë©´ì§', 'í•´ì„', 'íŒŒë©´',
        'ì¸ì‚¬', 'ë³´ìˆ˜', 'ê¸‰ì—¬', 'ìˆ˜ë‹¹', 'ë³µë¬´', 'ì§•ê³„',
        'ìœ„ì›íšŒ'
    ]
    
    def __init__(
        self,
        vlm_service,
        pdf_path: str,
        allow_tables: bool = False
    ):
        """ì´ˆê¸°í™”"""
        self.vlm_service = vlm_service
        self.pdf_path = pdf_path
        self.allow_tables = allow_tables
        
        self.layout_analyzer = QuickLayoutAnalyzer()
        self.prompt_rules = PromptRules()
        self.post_normalizer = PostMergeNormalizer()
        self.typo_normalizer = TypoNormalizer()
        
        self.vlm_success_count = 0
        self.fallback_count = 0
        
        logger.info("âœ… HybridExtractor Phase 0 ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - PDF: {pdf_path}")
        logger.info(f"   - í‘œ í—ˆìš©: {allow_tables}")
    
    def extract(self, image_data: str, page_num: int) -> Dict[str, Any]:
        """
        âœ… Phase 0: í˜ì´ì§€ë³„ ì¶”ì¶œ (ê°œì •ì´ë ¥ ê°ì§€ + VLM ì¬ì‹œë„)
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            ì¶”ì¶œ ê²°ê³¼
        """
        logger.info(f"   ğŸ” í˜ì´ì§€ {page_num} ì¶”ì¶œ ì‹œì‘")
        
        # Step 1: ë ˆì´ì•„ì›ƒ ë¶„ì„ (OCR í¬í•¨)
        hints = self.layout_analyzer.analyze(image_data)
        
        # Step 2: âœ… Phase 0 - ê°œì •ì´ë ¥ ê°ì§€ (2ì¶•)
        has_revision_table = self._detect_revision_table(hints, page_num)
        
        if has_revision_table:
            logger.info(f"      ğŸ“‹ ê°œì •ì´ë ¥ í‘œ ê°ì§€ (í˜ì´ì§€ {page_num})")
            hints['allow_tables'] = True
            page_role = "revision_table"
        else:
            page_role = "general"
        
        # Step 3: VLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.prompt_rules.build_prompt(hints)
        
        # Step 4: âœ… Phase 0 - VLM ì¬ì‹œë„ (call_with_retry)
        if hasattr(self.vlm_service, 'call_with_retry'):
            logger.info(f"      ğŸ”„ VLM ì¬ì‹œë„ ë¡œì§ ì‚¬ìš© (í˜ì´ì§€ ì—­í• : {page_role})")
            
            vlm_result = self.vlm_service.call_with_retry(
                image_data=image_data,
                prompt=prompt,
                page_role=page_role
            )
            
            content = vlm_result['content']
            
            if vlm_result['fallback']:
                logger.warning(f"      âš ï¸ VLM ì¬ì‹œë„ ì‹¤íŒ¨ â†’ Fallback")
                content = self._fallback_extract(page_num)
                self.fallback_count += 1
                source = "fallback"
                confidence = 0.7
            else:
                if vlm_result['retry_count'] > 0:
                    logger.info(f"      âœ… VLM ì¬ì‹œë„ {vlm_result['retry_count']}íšŒ ë§Œì— ì„±ê³µ")
                self.vlm_success_count += 1
                source = "vlm"
                confidence = 1.0
        
        else:
            # êµ¬ë²„ì „ vlm_service (callë§Œ ìˆìŒ)
            logger.warning("      âš ï¸ call_with_retry ì—†ìŒ - ë‹¨ì¼ ì‹œë„")
            
            try:
                response = self.vlm_service.call(image_data, prompt)
                
                if response and len(response.strip()) >= 50:
                    content = response
                    self.vlm_success_count += 1
                    source = "vlm"
                    confidence = 1.0
                else:
                    logger.warning(f"      âš ï¸ VLM ë¹ˆ ì‘ë‹µ â†’ Fallback")
                    content = self._fallback_extract(page_num)
                    self.fallback_count += 1
                    source = "fallback"
                    confidence = 0.7
            
            except Exception as e:
                logger.error(f"      âŒ VLM ì˜¤ë¥˜: {e} â†’ Fallback")
                content = self._fallback_extract(page_num)
                self.fallback_count += 1
                source = "fallback"
                confidence = 0.5
        
        # Step 5: doc_type ì¡°ê±´ë¶€ ìŠ¹ê¸‰
        doc_type = self._detect_doc_type_v2(content, hints)
        logger.info(f"      ğŸ“‹ ë¬¸ì„œ íƒ€ì…: {doc_type}")
        
        # Step 6: í›„ì²˜ë¦¬
        content = self.post_normalizer.normalize(content, doc_type)
        content = self.typo_normalizer.normalize(content, doc_type)
        content = self._deduplicate_lines(content)
        
        logger.info(f"      ğŸ§¹ í›„ì²˜ë¦¬ ì™„ë£Œ ({len(content)} ê¸€ì)")
        
        # Step 7: KVS ì¶”ì¶œ
        kvs_raw = hints.get('kvs', [])
        kvs = KVSNormalizer.normalize_kvs(kvs_raw)
        
        logger.info(f"      ğŸ’¾ KVS: {len(kvs)}ê°œ")
        
        # Step 8: í’ˆì§ˆ ì ìˆ˜
        if source == "vlm":
            quality_score = 100
        else:
            quality_score = 70
        
        logger.info(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: í’ˆì§ˆ {quality_score}/100 (ì¶œì²˜: {source}, íƒ€ì…: {doc_type})")
        
        return {
            'content': content,
            'source': source,
            'confidence': confidence,
            'quality_score': quality_score,
            'kvs': kvs,
            'is_empty': len(content.strip()) < 50,
            'metrics': {
                'page_num': page_num,
                'char_count': len(content),
                'source': source,
                'doc_type': doc_type,
                'has_revision_table': has_revision_table
            }
        }
    
    def _detect_revision_table(self, hints: Dict[str, Any], page_num: int) -> bool:
        """
        âœ… Phase 0: ê°œì •ì´ë ¥ í‘œ ê°ì§€ (2ì¶•)
        
        ì „ëµ:
        - ì¶• A: OCR í…ìŠ¤íŠ¸ì—ì„œ "ì œ\d+ì°¨\s*ê°œì •" 3ê°œ ì´ìƒ
        - ì¶• B: ë‚ ì§œ íŒ¨í„´ (YYYY.MM.DD | YYYY-MM-DD | YYYY) 3ê°œ ì´ìƒ
        
        Args:
            hints: ë ˆì´ì•„ì›ƒ íŒíŠ¸ (OCR í¬í•¨)
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            True if ê°œì •ì´ë ¥ í‘œ ì¡´ì¬
        """
        # 1í˜ì´ì§€ë§Œ ì²´í¬ (ì¼ë¶€ ë¬¸ì„œëŠ” 2í˜ì´ì§€ì—ë„ ê°€ëŠ¥)
        if page_num not in (1, 2):
            return False
        
        # hintsì—ì„œ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = hints.get('ocr_text', '') or hints.get('text', '')
        
        if not text:
            return False
        
        # ì¶• A: "ì œ\d+ì°¨ ê°œì •" íŒ¨í„´
        revision_pattern = re.compile(r'ì œ\s*\d+\s*ì°¨\s*ê°œì •', re.MULTILINE)
        revision_matches = revision_pattern.findall(text)
        ocr_hit = len(revision_matches) >= 3
        
        # ì¶• B: ë‚ ì§œ íŒ¨í„´ (ë‹¤ì–‘í•œ í˜•ì‹)
        date_pattern = re.compile(
            r'\b('
            r'\d{4}\.\d{1,2}\.\d{1,2}|'  # 2019.05.27
            r'\d{4}-\d{1,2}-\d{1,2}|'    # 2019-05-27
            r'[\'\'(]?\d{4}[\'\')\.]?'    # 2019, '2019', (2019)
            r')\b'
        )
        date_matches = date_pattern.findall(text)
        date_hit = len(date_matches) >= 3
        
        # 2ì¶• ì¤‘ í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ê°œì •ì´ë ¥ í‘œë¡œ íŒë‹¨
        is_revision_table = ocr_hit or date_hit
        
        if is_revision_table:
            logger.info(f"      âœ… ê°œì •ì´ë ¥ ê°ì§€ (OCR={len(revision_matches)}ê°œ, ë‚ ì§œ={len(date_matches)}ê°œ)")
        
        return is_revision_table
    
    def _detect_doc_type_v2(self, content: str, hints: Dict[str, Any]) -> str:
        """
        ë¬¸ì„œ íƒ€ì… ì¡°ê±´ë¶€ ìŠ¹ê¸‰
        
        Args:
            content: ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            hints: ë ˆì´ì•„ì›ƒ íŒíŠ¸
        
        Returns:
            'statute', 'general', 'bus_diagram', 'table'
        """
        hint_type = hints.get('doc_type')
        
        # ì¡°ê±´ë¶€ statute ìŠ¹ê¸‰
        if hint_type != 'statute':
            has_article = bool(re.search(r'ì œ\s*\d+\s*ì¡°', content))
            has_chapter = bool(re.search(r'ì œ\s*\d+\s*ì¥', content))
            has_spirit = 'ê¸°ë³¸ ì •ì‹ ' in content or 'ê¸°ë³¸ì •ì‹ ' in content
            
            if has_article or has_chapter or has_spirit:
                logger.debug(f"      doc_type ìŠ¹ê¸‰: {hint_type} â†’ statute")
                return 'statute'
        
        if hint_type in ['statute', 'bus_diagram', 'table']:
            return hint_type
        
        return 'general'
    
    def _fallback_extract(self, page_num: int) -> str:
        """
        Fallback í…ìŠ¤íŠ¸ ì¶”ì¶œ (pypdf)
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
        
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        try:
            with open(self.pdf_path, 'rb') as f:
                pdf_reader = pypdf.PdfReader(f)
                page = pdf_reader.pages[page_num - 1]
                text = page.extract_text()
            
            if not text or len(text.strip()) < 20:
                logger.warning(f"      âš ï¸ Fallback ì¶”ì¶œ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ ë¶€ì¡±")
                return ""
            
            # ì¸ë¼ì¸ í˜ì´ì§€ ë§ˆì»¤ ì œê±°
            text = re.sub(r'\b(\d{3,4})-(\d{1,2})\s*(?=(\d+[.)]|[""]))', r'\1-\2\n', text)
            text = re.sub(r'[ \t]+(\n)', r'\1', text)
            
            # ì •ê·œí™”
            text = self._normalize_fallback_text(text)
            
            logger.debug(f"      Fallback ì¶”ì¶œ: {len(text)} ê¸€ì")
            
            return text
        
        except Exception as e:
            logger.error(f"      âŒ Fallback ì˜¤ë¥˜: {e}")
            return ""
    
    def _normalize_fallback_text(self, text: str) -> str:
        """Fallback í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        text = unicodedata.normalize('NFKC', text)
        text = re.sub(r' {2,}', ' ', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        text = text.strip()
        return text
    
    def _deduplicate_lines(self, content: str) -> str:
        """ì¤‘ë³µ ë¼ì¸ ì œê±°"""
        lines = content.split('\n')
        seen = set()
        deduped = []
        
        for line in lines:
            if not line.strip():
                deduped.append(line)
                continue
            
            line_key = line.strip()
            if line_key not in seen:
                seen.add(line_key)
                deduped.append(line)
        
        return '\n'.join(deduped)
    
    def get_fallback_stats(self) -> Dict[str, Any]:
        """Fallback í†µê³„"""
        total = self.vlm_success_count + self.fallback_count
        
        if total == 0:
            fallback_rate = 0.0
        else:
            fallback_rate = self.fallback_count / total
        
        return {
            'vlm_success_count': self.vlm_success_count,
            'fallback_count': self.fallback_count,
            'total_pages': total,
            'fallback_rate': fallback_rate
        }