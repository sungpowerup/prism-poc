"""
PRISM Phase 2.2 - Enhanced Pipeline with Claude Vision

ê°œì„  ì‚¬í•­:
- Claude Vision APIë¡œ í‘œ ì¶”ì¶œ (95%+ ì •í™•ë„)
- Fallback: PaddleOCR â†’ Claude Vision
- í•œê¸€ ì¸ì‹ ìµœì í™”

Author: ì´ì„œì˜ (Backend Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-13
"""

import os
import time
from pathlib import Path
from typing import List, Dict, Optional
from PIL import Image
import fitz  # PyMuPDF
from paddleocr import PaddleOCR

from models.layout_detector import LayoutDetector, DocumentElement, ElementType
from core.text_extractor import TextExtractor
from core.table_extractor_fallback import FallbackTableExtractor
from core.claude_vision_table_extractor import ClaudeVisionTableExtractor, ExtractedTable
from core.image_captioner import ImageCaptioner
from core.intelligent_chunker import IntelligentChunker
from core.document_analyzer import DocumentAnalyzer


class Phase2Pipeline:
    """
    PRISM Phase 2.2 íŒŒì´í”„ë¼ì¸ (Claude Vision í†µí•©)
    
    ì²˜ë¦¬ ë‹¨ê³„:
    1. Layout Detection (Detectron2 ë˜ëŠ” Mock)
    2. Text Extraction (PaddleOCR)
    3. â­ Table Parsing (Claude Vision + Fallback)
    4. Image Captioning (VLM - ì„ íƒ)
    5. Intelligent Chunking
    """
    
    def __init__(
        self,
        use_vlm: bool = False,
        vlm_provider: str = "claude",
        chunk_size: int = 512,
        chunk_overlap: int = 50,
        use_claude_table_extraction: bool = True
    ):
        """
        Args:
            use_vlm: VLM ì‚¬ìš© ì—¬ë¶€ (ì´ë¯¸ì§€ ìº¡ì…˜ìš©)
            vlm_provider: VLM ì œê³µì
            chunk_size: ì²­í¬ í¬ê¸°
            chunk_overlap: ì²­í¬ ì˜¤ë²„ë©
            use_claude_table_extraction: Claude Visionìœ¼ë¡œ í‘œ ì¶”ì¶œ ì—¬ë¶€
        """
        print("Initializing PRISM Phase 2.2 Pipeline (Claude Vision)...")
        
        # 1. Layout Detector
        self.layout_detector = LayoutDetector()
        
        # 2. Text Extractor
        self.text_extractor = TextExtractor(use_ocr_fallback=True)
        
        # 3. PaddleOCR
        print("Loading PaddleOCR...")
        self.ocr = PaddleOCR(
            use_angle_cls=True,
            lang='korean',
            show_log=False,
            det_db_thresh=0.3,
            det_db_box_thresh=0.5,
            det_db_unclip_ratio=1.6,
            rec_batch_num=6,
            use_space_char=True,
            drop_score=0.3
        )
        print("âœ… PaddleOCR loaded")
        
        # 4. â­ Claude Vision Table Extractor (ì‹ ê·œ!)
        self.use_claude_table_extraction = use_claude_table_extraction
        if use_claude_table_extraction:
            self.claude_table_extractor = ClaudeVisionTableExtractor()
            if self.claude_table_extractor.client:
                print("âœ… Claude Vision Table Extractor enabled")
            else:
                print("âš ï¸  Claude Vision disabled (no API key)")
                self.use_claude_table_extraction = False
        
        # 5. Fallback Table Extractor
        self.fallback_table_extractor = FallbackTableExtractor(
            min_cols=2,
            min_rows=2,
            alignment_threshold=20.0
        )
        print("âœ… Fallback Table Extractor loaded")
        
        # 6. Image Captioner (ì„ íƒ)
        self.use_vlm = use_vlm
        if use_vlm:
            self.image_captioner = ImageCaptioner(
                provider=vlm_provider,
                require_key=False
            )
        else:
            self.image_captioner = None
        
        # 7. Intelligent Chunker
        self.chunker = IntelligentChunker(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # 8. Document Analyzer
        self.analyzer = DocumentAnalyzer()
        
        print("âœ… Phase 2.2 Pipeline ready (with Claude Vision)\n")
    
    def process(
        self,
        pdf_path: str,
        max_pages: int = 10,
        output_dir: str = "output"
    ) -> Dict:
        """
        PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            max_pages: ì²˜ë¦¬í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # PDF ì—´ê¸°
        doc = fitz.open(pdf_path)
        total_pages = min(len(doc), max_pages)
        
        print("=" * 60)
        print(f"Processing: {Path(pdf_path).name}")
        print(f"Pages: {total_pages}")
        print("=" * 60)
        print()
        
        # Step 1: Layout Detection
        print(f"ğŸ” Step 1/5: Detecting layout...")
        elements = []
        page_images = []  # â­ í˜ì´ì§€ ì´ë¯¸ì§€ ì €ì¥ (í‘œ ì¶”ì¶œìš©)
        
        for page_num in range(total_pages):
            page = doc[page_num]
            pix = page.get_pixmap(dpi=150)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            page_images.append(img)
            
            print(f"Analyzing page {page_num + 1}/{total_pages}...")
            page_elements = self.layout_detector.detect(img, page_num + 1)
            elements.extend(page_elements)
        
        print(f"âœ“ Found {len(elements)} elements")
        print()
        
        # Step 2: Text Extraction
        print(f"ğŸ“ Step 2/5: Extracting text...")
        texts = []
        ocr_results = []
        
        for page_num in range(total_pages):
            import numpy as np
            result = self.ocr.ocr(np.array(page_images[page_num]), cls=True)
            
            if result and result[0]:
                for line in result[0]:
                    bbox_coords = line[0]
                    text_data = line[1]
                    text = text_data[0]
                    confidence = text_data[1]
                    
                    texts.append({
                        "page_num": page_num + 1,
                        "text": text,
                        "bbox": bbox_coords,
                        "confidence": confidence
                    })
                
                ocr_results.append((page_num + 1, result[0]))
        
        print(f"âœ“ Extracted {len(texts)} text blocks")
        print()
        
        # Step 3: â­ Table Parsing (Claude Vision!)
        print(f"ğŸ“Š Step 3/5: Parsing tables with Claude Vision...")
        tables = self._parse_tables_claude_vision(
            elements, 
            ocr_results, 
            page_images
        )
        print(f"âœ“ Parsed {len(tables)} tables")
        print()
        
        # Step 4: Image Captioning
        print(f"ğŸ–¼ï¸  Step 4/5: Generating image captions...")
        captions = []
        if self.use_vlm and self.image_captioner:
            captions = self._generate_captions(elements, doc)
        else:
            print("âš ï¸  VLM disabled, skipping captions")
        print(f"âœ“ Generated {len(captions)} captions")
        print()
        
        # Step 5: Intelligent Chunking
        print(f"ğŸ§© Step 5/5: Intelligent chunking...")
        
        class SimpleStructure:
            pass
        
        structure = SimpleStructure()
        result = self.chunker.chunk(structure, texts, tables, captions)
        print(f"âœ“ Created {len(result.chunks)} chunks")
        print()
        
        # ê²°ê³¼ ì €ì¥
        self._save_results(pdf_path, result, output_dir)
        
        elapsed = time.time() - start_time
        print("=" * 60)
        print("âœ… Processing complete!")
        print(f"Time: {elapsed:.1f}s")
        print(f"Output: {output_dir}")
        print("=" * 60)
        print()
        
        doc.close()
        
        return {
            "elements": len(elements),
            "texts": len(texts),
            "tables": len(tables),
            "captions": len(captions),
            "chunks": len(result.chunks),
            "statistics": result.statistics,
            "elapsed_time": elapsed
        }
    
    def _parse_tables_claude_vision(
        self,
        elements: List[DocumentElement],
        ocr_results: List[tuple],
        page_images: List[Image.Image]
    ) -> List[ExtractedTable]:
        """
        í‘œ íŒŒì‹± (Claude Vision ìš°ì„ )
        
        ì „ëµ:
        1. Claude Visionìœ¼ë¡œ ë¨¼ì € ì‹œë„ (95%+ ì •í™•ë„)
        2. ì‹¤íŒ¨ ì‹œ Fallback Extractor ì‚¬ìš©
        """
        tables = []
        
        # 1. â­ Claude Vision ìš°ì„ 
        if self.use_claude_table_extraction and self.claude_table_extractor.client:
            print("  ğŸ¤– Using Claude Vision for table extraction...")
            
            for page_num, page_image in enumerate(page_images, start=1):
                # OCR boxesë¥¼ íŒíŠ¸ë¡œ ì „ë‹¬
                ocr_boxes = None
                for ocr_page_num, ocr_result in ocr_results:
                    if ocr_page_num == page_num:
                        ocr_boxes = [
                            {"text": item[1][0], "bbox": item[0]}
                            for item in ocr_result
                        ]
                        break
                
                page_tables = self.claude_table_extractor.extract_tables_from_page(
                    page_image,
                    page_num,
                    ocr_boxes
                )
                
                tables.extend(page_tables)
            
            if len(tables) > 0:
                print(f"  âœ… Claude Vision extracted {len(tables)} table(s)")
                return tables
            else:
                print("  â„¹ï¸  Claude Vision found no tables, trying Fallback...")
        
        # 2. Fallback Extractor
        print("  ğŸ”„ Using Fallback Table Extractor...")
        for page_num, ocr_result in ocr_results:
            ocr_dicts = []
            for item in ocr_result:
                bbox = item[0]
                text_data = item[1]
                text = text_data[0]
                
                ocr_dicts.append({
                    "text": text,
                    "bbox": bbox
                })
            
            page_tables = self.fallback_table_extractor.extract_tables(
                ocr_dicts, page_num
            )
            
            if page_tables:
                print(f"  âœ… Fallback found {len(page_tables)} tables on page {page_num}")
            
            tables.extend(page_tables)
        
        return tables
    
    def _generate_captions(
        self,
        elements: List[DocumentElement],
        doc
    ) -> List:
        """ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±"""
        captions = []
        
        for element in elements:
            if not self.image_captioner.should_caption(element):
                continue
            
            page = doc[element.page_number - 1]
            pix = page.get_pixmap(dpi=150)
            page_img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            
            caption = self.image_captioner.generate_caption(
                page_img, element
            )
            if caption:
                captions.append(caption)
        
        return captions
    
    def _save_results(
        self,
        pdf_path: str,
        result,
        output_dir: str
    ) -> None:
        """ê²°ê³¼ ì €ì¥"""
        import json
        
        pdf_name = Path(pdf_path).stem
        output_path = Path(output_dir) / f"{pdf_name}_chunks.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ Saved: {output_path}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python phase2_pipeline.py <pdf_path> [max_pages]")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    max_pages = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    pipeline = Phase2Pipeline(
        use_vlm=False,
        chunk_size=512,
        chunk_overlap=50,
        use_claude_table_extraction=True
    )
    
    result = pipeline.process(pdf_path, max_pages=max_pages)
    
    print("\nğŸ“Š Summary:")
    print(f"  Elements: {result['elements']}")
    print(f"  Texts: {result['texts']}")
    print(f"  Tables: {result['tables']}")
    print(f"  Chunks: {result['chunks']}")