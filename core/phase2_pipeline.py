"""
PRISM Phase 2.1 - Enhanced Pipeline

ê°œì„  ì‚¬í•­:
- Fallback Table Extractor í†µí•©
- ê°œì„ ëœ Intelligent Chunker í†µí•©
- í‘œ ì¶”ì¶œ í’ˆì§ˆ í–¥ìƒ

Author: ì´ì„œì˜ (Backend Lead) + ë°•ì¤€í˜¸ (AI/ML Lead)
Date: 2025-10-13
"""

import os
import time
from pathlib import Path
from typing import List, Dict, Optional
from PIL import Image
import fitz  # PyMuPDF

from models.layout_detector import LayoutDetector, DocumentElement, ElementType
from core.text_extractor import PaddleOCRExtractor
from core.table_extractor_fallback import FallbackTableExtractor, ExtractedTable
from core.image_captioner import ImageCaptioner
from core.intelligent_chunker import IntelligentChunker
from core.document_analyzer import DocumentAnalyzer


class Phase2Pipeline:
    """
    PRISM Phase 2.1 íŒŒì´í”„ë¼ì¸ (ê°œì„ )
    
    ì²˜ë¦¬ ë‹¨ê³„:
    1. Layout Detection (Detectron2 ë˜ëŠ” Mock)
    2. Text Extraction (PaddleOCR)
    3. â­ Table Parsing (Detectron2 + Fallback)
    4. Image Captioning (VLM - ì„ íƒ)
    5. â­ Intelligent Chunking (ê°œì„ )
    """
    
    def __init__(
        self,
        use_vlm: bool = False,
        vlm_provider: str = "claude",
        chunk_size: int = 512,
        chunk_overlap: int = 50
    ):
        """
        Args:
            use_vlm: VLM ì‚¬ìš© ì—¬ë¶€
            vlm_provider: VLM ì œê³µì (claude/azure/ollama)
            chunk_size: ì²­í¬ í¬ê¸°
            chunk_overlap: ì²­í¬ ì˜¤ë²„ë©
        """
        print("Initializing PRISM Phase 2.1 Pipeline...")
        
        # 1. Layout Detector
        self.layout_detector = LayoutDetector()
        
        # 2. Text Extractor
        self.text_extractor = PaddleOCRExtractor()
        
        # 3. â­ Fallback Table Extractor (ì‹ ê·œ)
        self.fallback_table_extractor = FallbackTableExtractor(
            min_cols=3,
            min_rows=2,
            alignment_threshold=10.0
        )
        print("âœ… Fallback Table Extractor loaded")
        
        # 4. Image Captioner (ì„ íƒ)
        self.use_vlm = use_vlm
        if use_vlm:
            self.image_captioner = ImageCaptioner(
                provider=vlm_provider,
                require_key=False
            )
        else:
            self.image_captioner = None
        
        # 5. â­ Intelligent Chunker (ê°œì„ )
        self.chunker = IntelligentChunker(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # 6. Document Analyzer
        self.analyzer = DocumentAnalyzer()
        
        print("âœ… Pipeline initialized successfully\n")
    
    def process(
        self,
        pdf_path: str,
        output_dir: str = "data/processed",
        max_pages: Optional[int] = None
    ) -> Dict:
        """
        PDF ì²˜ë¦¬
        
        Args:
            pdf_path: PDF ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        print("=" * 60)
        print("PRISM Phase 2.1 - Document Processing")
        print("=" * 60)
        print(f"Input: {pdf_path}")
        print(f"Max pages: {max_pages or 'All'}")
        print("=" * 60)
        print()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # PDF ë¡œë“œ
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        if max_pages:
            total_pages = min(total_pages, max_pages)
        
        # Step 1: Layout Detection
        print(f"ğŸ“„ Step 1/5: Analyzing document structure...")
        elements = []
        for page_num in range(total_pages):
            page = doc[page_num]
            pix = page.get_pixmap(dpi=150)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            
            print(f"Analyzing page {page_num + 1}/{total_pages}...")
            page_elements = self.layout_detector.detect(img, page_num + 1)
            elements.extend(page_elements)
        
        print(f"âœ“ Found {len(elements)} elements")
        print()
        
        # Step 2: Text Extraction
        print(f"ğŸ“ Step 2/5: Extracting text...")
        texts = []
        ocr_results = []  # â­ OCR ê²°ê³¼ ì €ì¥ (í‘œ ì¶”ì¶œìš©)
        
        for page_num in range(total_pages):
            page = doc[page_num]
            pix = page.get_pixmap(dpi=150)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            
            # OCR ì¶”ì¶œ
            extracted, ocr_result = self.text_extractor.extract(img, page_num + 1)
            texts.extend(extracted)
            ocr_results.append((page_num + 1, ocr_result))
        
        print(f"âœ“ Extracted {len(texts)} text blocks")
        print()
        
        # Step 3: â­ Table Parsing (ê°œì„ )
        print(f"ğŸ“Š Step 3/5: Parsing tables...")
        tables = self._parse_tables_enhanced(elements, ocr_results)
        print(f"âœ“ Parsed {len(tables)} tables")
        print()
        
        # Step 4: Image Captioning
        print(f"ğŸ–¼ï¸  Step 4/5: Generating image captions...")
        captions = []
        if self.use_vlm and self.image_captioner:
            captions = self._generate_captions(elements, doc)
        else:
            print("âš ï¸  VLM disabled, skipping captions")
        print(f"âœ“ Generated {len(captions)} captions")
        print()
        
        # Step 5: â­ Intelligent Chunking (ê°œì„ )
        print(f"ğŸ§© Step 5/5: Intelligent chunking...")
        structure = self.analyzer.analyze_structure(elements)
        result = self.chunker.chunk(structure, texts, tables, captions)
        print(f"âœ“ Created {len(result.chunks)} chunks")
        print()
        
        # ê²°ê³¼ ì €ì¥
        self._save_results(pdf_path, result, output_dir)
        
        elapsed = time.time() - start_time
        print("=" * 60)
        print("âœ… Processing complete!")
        print(f"Time: {elapsed:.1f}s")
        print(f"Output: {output_dir}")
        print("=" * 60)
        print()
        
        return {
            "elements": len(elements),
            "texts": len(texts),
            "tables": len(tables),
            "captions": len(captions),
            "chunks": len(result.chunks),
            "statistics": result.statistics,
            "elapsed_time": elapsed
        }
    
    def _parse_tables_enhanced(
        self,
        elements: List[DocumentElement],
        ocr_results: List[tuple]
    ) -> List[ExtractedTable]:
        """
        í‘œ íŒŒì‹± (ê°œì„ )
        
        ì „ëµ:
        1. Detectron2ê°€ TABLEì„ íƒì§€í•˜ë©´ ìš°ì„  ì‚¬ìš©
        2. íƒì§€ ì‹¤íŒ¨ ì‹œ Fallback Extractor ì‚¬ìš©
        """
        tables = []
        
        # 1. Detectron2 íƒì§€ í‘œ
        detectron_tables = [e for e in elements if e.type == ElementType.TABLE]
        
        if detectron_tables:
            print(f"  âœ… Detectron2 found {len(detectron_tables)} tables")
            for table_element in detectron_tables:
                # TODO: Detectron2 í‘œë¥¼ êµ¬ì¡°í™”
                # í˜„ì¬ëŠ” placeholder
                pass
        
        # 2. â­ Fallback Extractor (OCR ê¸°ë°˜)
        for page_num, ocr_result in ocr_results:
            # OCR ê²°ê³¼ë¥¼ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            ocr_dicts = []
            for item in ocr_result:
                if isinstance(item, dict):
                    ocr_dicts.append(item)
                elif isinstance(item, tuple) and len(item) >= 2:
                    # (bbox, (text, confidence)) í˜•ì‹
                    bbox, text_data = item[0], item[1]
                    text = text_data[0] if isinstance(text_data, tuple) else str(text_data)
                    ocr_dicts.append({
                        "text": text,
                        "bbox": bbox
                    })
            
            # Fallback Extractorë¡œ í‘œ ì¶”ì¶œ
            page_tables = self.fallback_table_extractor.extract_tables(
                ocr_dicts, page_num
            )
            
            if page_tables:
                print(f"  âœ… Fallback found {len(page_tables)} tables on page {page_num}")
            
            tables.extend(page_tables)
        
        return tables
    
    def _generate_captions(
        self,
        elements: List[DocumentElement],
        doc
    ) -> List:
        """ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±"""
        captions = []
        
        for element in elements:
            if not self.image_captioner.should_caption(element):
                continue
            
            # í˜ì´ì§€ ì´ë¯¸ì§€ ë¡œë“œ
            page = doc[element.page_number - 1]
            pix = page.get_pixmap(dpi=150)
            page_img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            
            # ìº¡ì…˜ ìƒì„±
            caption = self.image_captioner.generate_caption(
                page_img, element
            )
            if caption:
                captions.append(caption)
        
        return captions
    
    def _save_results(
        self,
        pdf_path: str,
        result,
        output_dir: str
    ) -> None:
        """ê²°ê³¼ ì €ì¥"""
        import json
        
        pdf_name = Path(pdf_path).stem
        output_path = Path(output_dir) / f"{pdf_name}_chunks.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ Saved: {output_path}")


# CLI
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python phase2_pipeline.py <pdf_path> [max_pages]")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    max_pages = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    pipeline = Phase2Pipeline(
        use_vlm=False,  # VLM ë¹„í™œì„±í™” (í…ŒìŠ¤íŠ¸ìš©)
        chunk_size=512,
        chunk_overlap=50
    )
    
    result = pipeline.process(pdf_path, max_pages=max_pages)
    
    print("\nğŸ“Š Summary:")
    print(f"  Elements: {result['elements']}")
    print(f"  Texts: {result['texts']}")
    print(f"  Tables: {result['tables']}")
    print(f"  Chunks: {result['chunks']}")
    print(f"\n  Statistics:")
    for k, v in result['statistics'].items():
        print(f"    {k}: {v}")