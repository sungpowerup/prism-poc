"""
Multi VLM Provider Service
Claude + Azure OpenAI + Ollama í†µí•©
"""

import os
import base64
import time
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
import requests

logger = logging.getLogger(__name__)


# ========== ì¶”ìƒ í´ë˜ìŠ¤ ==========
class VLMProvider(ABC):
    """VLM í”„ë¡œë°”ì´ë” ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """í”„ë¡œë°”ì´ë” ì´ë¦„"""
        pass
    
    @abstractmethod
    def get_info(self) -> Dict[str, Any]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        pass
    
    @abstractmethod
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """ìº¡ì…˜ ìƒì„±"""
        pass


# ========== Claude Provider ==========
class ClaudeProvider(VLMProvider):
    """Anthropic Claude í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.api_key = os.getenv("ANTHROPIC_API_KEY", "")
        self.model = "claude-sonnet-4-20250514"
        self.base_url = "https://api.anthropic.com/v1/messages"
    
    def is_available(self) -> bool:
        """API í‚¤ ì¡´ì¬ ì—¬ë¶€"""
        return bool(self.api_key and self.api_key.startswith("sk-ant-"))
    
    def get_name(self) -> str:
        return "Claude 3.5 Sonnet"
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'name': self.get_name(),
            'provider': 'Anthropic',
            'model': self.model,
            'speed': 'âš¡âš¡âš¡ ë§¤ìš° ë¹ ë¦„ (1-2ì´ˆ)',
            'quality': 'â­â­â­â­â­ ìµœê³ ',
            'cost': 'ğŸ’° ìœ ë£Œ ($0.003/image)',
            'internet': 'âœ… í•„ìš”',
            'gpu': 'âŒ ë¶ˆí•„ìš”'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Claude API í˜¸ì¶œ"""
        
        if not self.is_available():
            raise RuntimeError("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # API í˜¸ì¶œ
            from anthropic import Anthropic
            client = Anthropic(api_key=self.api_key)
            
            response = client.messages.create(
                model=self.model,
                max_tokens=1024,
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": image_base64,
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ],
                }],
            )
            
            caption = response.content[0].text.strip()
            processing_time = time.time() - start_time
            
            # ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = (input_tokens * 3 / 1_000_000) + (output_tokens * 15 / 1_000_000)
            
            return {
                'caption': caption,
                'confidence': 0.95,
                'processing_time': processing_time,
                'model': self.model,
                'provider': 'Claude',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens
                },
                'cost_usd': cost_usd
            }
            
        except Exception as e:
            logger.error(f"Claude API ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        type_names = {
            'chart': 'ì°¨íŠ¸',
            'table': 'í‘œ',
            'image': 'ì´ë¯¸ì§€',
            'diagram': 'ë‹¤ì´ì–´ê·¸ë¨'
        }
        
        type_name = type_names.get(element_type, 'ìš”ì†Œ')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

{extracted_text[:1000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬, ì´ {type_name}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš©: ì œëª©, í•µì‹¬ ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ, ì‹œê°ì  ìš”ì†Œ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            return f"""ì´ {type_name} ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ë‚´ìš©: ì œëª©, ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""


# ========== Azure OpenAI Provider ==========
class AzureOpenAIProvider(VLMProvider):
    """Azure OpenAI í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
        self.endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "")
        self.deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4-vision")
        self.api_version = "2024-02-15-preview"
    
    def is_available(self) -> bool:
        """API í‚¤ì™€ ì—”ë“œí¬ì¸íŠ¸ ì¡´ì¬ ì—¬ë¶€"""
        return bool(self.api_key and self.endpoint)
    
    def get_name(self) -> str:
        return "Azure OpenAI GPT-4V"
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'name': self.get_name(),
            'provider': 'Microsoft Azure',
            'model': self.deployment,
            'speed': 'âš¡âš¡ ë¹ ë¦„ (1-3ì´ˆ)',
            'quality': 'â­â­â­â­ ìš°ìˆ˜',
            'cost': 'ğŸ’°ğŸ’° ìœ ë£Œ ($0.01/image)',
            'internet': 'âœ… í•„ìš”',
            'gpu': 'âŒ ë¶ˆí•„ìš”',
            'special': 'ğŸ›ï¸ ê³µê³µê¸°ê´€ ìŠ¹ì¸ ê°€ëŠ¥'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Azure OpenAI API í˜¸ì¶œ"""
        
        if not self.is_available():
            raise RuntimeError("Azure OpenAI ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # API URL
            url = f"{self.endpoint}/openai/deployments/{self.deployment}/chat/completions?api-version={self.api_version}"
            
            # ìš”ì²­ ë°ì´í„°
            data = {
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 1000
            }
            
            # API í˜¸ì¶œ
            response = requests.post(
                url,
                headers={
                    "api-key": self.api_key,
                    "Content-Type": "application/json"
                },
                json=data,
                timeout=60
            )
            
            if response.status_code != 200:
                raise Exception(f"Azure API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            
            result = response.json()
            caption = result['choices'][0]['message']['content'].strip()
            processing_time = time.time() - start_time
            
            # í† í° ì‚¬ìš©ëŸ‰
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            
            # ë¹„ìš© ê³„ì‚° (GPT-4V ê¸°ì¤€)
            cost_usd = (input_tokens * 0.01 / 1000) + (output_tokens * 0.03 / 1000)
            
            return {
                'caption': caption,
                'confidence': 0.90,
                'processing_time': processing_time,
                'model': self.deployment,
                'provider': 'Azure OpenAI',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens
                },
                'cost_usd': cost_usd
            }
            
        except Exception as e:
            logger.error(f"Azure OpenAI API ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„± (Claudeì™€ ë™ì¼)"""
        type_names = {
            'chart': 'ì°¨íŠ¸',
            'table': 'í‘œ',
            'image': 'ì´ë¯¸ì§€',
            'diagram': 'ë‹¤ì´ì–´ê·¸ë¨'
        }
        
        type_name = type_names.get(element_type, 'ìš”ì†Œ')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

{extracted_text[:1000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬, ì´ {type_name}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš©: ì œëª©, í•µì‹¬ ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ, ì‹œê°ì  ìš”ì†Œ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            return f"""ì´ {type_name} ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ë‚´ìš©: ì œëª©, ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""


# ========== Ollama Provider ==========
class OllamaProvider(VLMProvider):
    """Ollama ë¡œì»¬ í”„ë¡œë°”ì´ë”"""
    
    # íƒ€ì„ì•„ì›ƒ ì„¤ì •
    TIMEOUTS = {
        'llava:7b': 60,
        'llama3.2-vision:11b': 120,
        'llama3.2-vision:latest': 120,
        'default': 60
    }
    
    def __init__(self):
        self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.preferred_model = os.getenv("OLLAMA_MODEL", "llava:7b")
        self.available_models: List[str] = []
        self.current_model: Optional[str] = None
        
        # ì´ˆê¸°í™”
        self._initialize()
    
    def _initialize(self):
        """Ollama ì´ˆê¸°í™”"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                self.available_models = [
                    model['name'] 
                    for model in data.get('models', [])
                    if 'vision' in model['name'].lower() or 'llava' in model['name'].lower()
                ]
                
                if self.preferred_model in self.available_models:
                    self.current_model = self.preferred_model
                elif self.available_models:
                    self.current_model = self.available_models[0]
                
                if self.current_model:
                    logger.info(f"Ollama ì´ˆê¸°í™”: {self.current_model}")
        except Exception as e:
            logger.warning(f"Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def is_available(self) -> bool:
        """Ollama ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return bool(self.current_model)
    
    def get_name(self) -> str:
        return f"Ollama ({self.current_model or 'N/A'})"
    
    def get_info(self) -> Dict[str, Any]:
        model_info = {
            'llava:7b': {
                'vram': '4GB',
                'speed': 'âš¡ ë³´í†µ (10-30ì´ˆ)',
                'quality': 'â­â­â­ ë³´í†µ'
            },
            'llama3.2-vision:11b': {
                'vram': '8GB',
                'speed': 'âš¡âš¡ ëŠë¦¼ (30-60ì´ˆ)',
                'quality': 'â­â­â­â­ ì¢‹ìŒ'
            }
        }
        
        info = model_info.get(self.current_model, {
            'vram': 'Unknown',
            'speed': 'âš¡ ë³´í†µ',
            'quality': 'â­â­â­ ë³´í†µ'
        })
        
        return {
            'name': self.get_name(),
            'provider': 'Ollama (Local)',
            'model': self.current_model or 'N/A',
            'speed': info['speed'],
            'quality': info['quality'],
            'cost': 'ğŸ’° ë¬´ë£Œ',
            'internet': 'âŒ ë¶ˆí•„ìš”',
            'gpu': 'âš ï¸ ê¶Œì¥ (4GB+)',
            'vram': info['vram']
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Ollama API í˜¸ì¶œ"""
        
        if not self.is_available():
            raise RuntimeError("Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ollama pull llava:7b' ì‹¤í–‰")
        
        start_time = time.time()
        timeout = self.TIMEOUTS.get(self.current_model, self.TIMEOUTS['default'])
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # API í˜¸ì¶œ
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.current_model,
                    "prompt": prompt,
                    "images": [image_base64],
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 300
                    }
                },
                timeout=timeout
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
            
            result = response.json()
            caption = result.get('response', '').strip()
            processing_time = time.time() - start_time
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(caption, extracted_text, element_type)
            
            return {
                'caption': caption,
                'confidence': confidence,
                'processing_time': processing_time,
                'model': self.current_model,
                'provider': 'Ollama',
                'usage': {
                    'input_tokens': 0,
                    'output_tokens': 0
                },
                'cost_usd': 0.0
            }
            
        except requests.exceptions.Timeout:
            raise TimeoutError(
                f"Ollama íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ). "
                f"ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ GPUë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )
        except Exception as e:
            logger.error(f"Ollama ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„± (ë™ì¼)"""
        type_names = {
            'chart': 'ì°¨íŠ¸',
            'table': 'í‘œ',
            'image': 'ì´ë¯¸ì§€',
            'diagram': 'ë‹¤ì´ì–´ê·¸ë¨'
        }
        
        type_name = type_names.get(element_type, 'ìš”ì†Œ')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

{extracted_text[:1000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬, ì´ {type_name}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš©
2. êµ¬ì¡°
3. ì˜ë¯¸

í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            return f"""ì´ {type_name} ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ë‚´ìš©
2. êµ¬ì¡°
3. ì˜ë¯¸

í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
    
    def _calculate_confidence(self, caption: str, extracted_text: str, element_type: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        if not caption or len(caption) < 20:
            return 0.3
        
        confidence = 0.5
        
        if extracted_text:
            ocr_words = set(extracted_text.lower().split())
            caption_words = set(caption.lower().split())
            if ocr_words and caption_words:
                overlap = len(ocr_words & caption_words)
                confidence += min(0.3, overlap / len(ocr_words) * 0.5)
        
        if len(caption) > 100:
            confidence += 0.1
        
        return min(0.95, max(0.1, confidence))


# ========== ë©€í‹° í”„ë¡œë°”ì´ë” ë§¤ë‹ˆì € ==========
class MultiVLMService:
    """ë©€í‹° VLM í”„ë¡œë°”ì´ë” ë§¤ë‹ˆì €"""
    
    def __init__(self):
        # í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
        self.providers = {
            'claude': ClaudeProvider(),
            'azure': AzureOpenAIProvider(),
            'ollama': OllamaProvider()
        }
        
        # ê¸°ë³¸ í”„ë¡œë°”ì´ë” ì„¤ì •
        self.current_provider_key = self._get_default_provider()
        
        logger.info(f"MultiVLMService ì´ˆê¸°í™”: {self.current_provider_key}")
    
    def _get_default_provider(self) -> str:
        """ê¸°ë³¸ í”„ë¡œë°”ì´ë” ê²°ì •"""
        # .envì—ì„œ ì„¤ì •ëœ ê¸°ë³¸ í”„ë¡œë°”ì´ë”
        default = os.getenv("DEFAULT_VLM_PROVIDER", "auto")
        
        if default != "auto" and default in self.providers:
            if self.providers[default].is_available():
                return default
        
        # ìë™ ì„ íƒ: Claude > Azure > Ollama
        for key in ['claude', 'azure', 'ollama']:
            if self.providers[key].is_available():
                return key
        
        # ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€ëŠ¥
        return 'ollama'  # ê¸°ë³¸ê°’
    
    def get_available_providers(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë” ëª©ë¡"""
        result = []
        for key, provider in self.providers.items():
            result.append({
                'key': key,
                'name': provider.get_name(),
                'available': provider.is_available(),
                'info': provider.get_info()
            })
        return result
    
    def set_provider(self, provider_key: str):
        """í”„ë¡œë°”ì´ë” ë³€ê²½"""
        if provider_key not in self.providers:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œë°”ì´ë”: {provider_key}")
        
        if not self.providers[provider_key].is_available():
            raise RuntimeError(f"{provider_key} í”„ë¡œë°”ì´ë”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.current_provider_key = provider_key
        logger.info(f"í”„ë¡œë°”ì´ë” ë³€ê²½: {provider_key}")
    
    def get_current_provider(self) -> VLMProvider:
        """í˜„ì¬ í”„ë¡œë°”ì´ë” ë°˜í™˜"""
        return self.providers[self.current_provider_key]
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """í˜„ì¬ í”„ë¡œë°”ì´ë”ë¡œ ìº¡ì…˜ ìƒì„±"""
        provider = self.get_current_provider()
        
        if not provider.is_available():
            raise RuntimeError(
                f"{provider.get_name()} í”„ë¡œë°”ì´ë”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                f"ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
            )
        
        return await provider.generate_caption(
            image_base64=image_base64,
            element_type=element_type,
            extracted_text=extracted_text
        )