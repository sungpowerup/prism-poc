"""
Multi VLM Provider Service
Claude + Azure OpenAI + Ollama í†µí•©
"""

import os
import base64
import time
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
import requests
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)


# ========== ì¶”ìƒ í´ë˜ìŠ¤ ==========
class VLMProvider(ABC):
    """VLM í”„ë¡œë°”ì´ë” ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def is_available(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """í”„ë¡œë°”ì´ë” ì´ë¦„"""
        pass
    
    @abstractmethod
    def get_info(self) -> Dict[str, Any]:
        """í”„ë¡œë°”ì´ë” ì •ë³´"""
        pass
    
    @abstractmethod
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """ìº¡ì…˜ ìƒì„±"""
        pass


# ========== Claude Provider (REST API ì§ì ‘ í˜¸ì¶œ) ==========
class ClaudeProvider(VLMProvider):
    """Anthropic Claude í”„ë¡œë°”ì´ë” - REST API ì§ì ‘ í˜¸ì¶œ"""
    
    def __init__(self):
        self.api_key = os.getenv("ANTHROPIC_API_KEY", "")
        self.model = "claude-sonnet-4-20250514"
        self.base_url = "https://api.anthropic.com/v1/messages"
        self.executor = ThreadPoolExecutor(max_workers=3)
    
    def is_available(self) -> bool:
        """API í‚¤ ì¡´ì¬ ì—¬ë¶€"""
        return bool(self.api_key and self.api_key.startswith("sk-ant-"))
    
    def get_name(self) -> str:
        return "Claude Sonnet 4"
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'name': self.get_name(),
            'provider': 'Anthropic',
            'model': self.model,
            'speed': 'âš¡âš¡âš¡ ë§¤ìš° ë¹ ë¦„ (1-2ì´ˆ)',
            'quality': 'â­â­â­â­â­ ìµœê³ ',
            'cost': 'ğŸ’° ìœ ë£Œ ($0.003/image)',
            'internet': 'âœ… í•„ìš”',
            'gpu': 'âŒ ë¶ˆí•„ìš”'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Claude API í˜¸ì¶œ - REST API ì§ì ‘ ì‚¬ìš©"""
        
        if not self.is_available():
            raise RuntimeError("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # ìš”ì²­ ë³¸ë¬¸ êµ¬ì„±
            payload = {
                "model": self.model,
                "max_tokens": 1024,
                "messages": [{
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": image_base64,
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ],
                }],
            }
            
            # í—¤ë” êµ¬ì„±
            headers = {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            
            # ë¹„ë™ê¸°ë¡œ requests í˜¸ì¶œ (ThreadPoolExecutor ì‚¬ìš©)
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                self.executor,
                lambda: requests.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=30
                )
            )
            
            # ì‘ë‹µ í™•ì¸
            if response.status_code != 200:
                error_msg = f"Claude API ì˜¤ë¥˜ (HTTP {response.status_code}): {response.text}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ì‘ë‹µ íŒŒì‹±
            result = response.json()
            caption = result['content'][0]['text'].strip()
            processing_time = time.time() - start_time
            
            # ë¹„ìš© ê³„ì‚°
            usage = result.get('usage', {})
            input_tokens = usage.get('input_tokens', 0)
            output_tokens = usage.get('output_tokens', 0)
            cost_usd = (input_tokens * 3 / 1_000_000) + (output_tokens * 15 / 1_000_000)
            
            logger.info(
                f"Claude ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, "
                f"{input_tokens}+{output_tokens} tokens, ${cost_usd:.4f}"
            )
            
            return {
                'caption': caption,
                'confidence': 0.95,
                'processing_time': processing_time,
                'model': self.model,
                'provider': 'Claude',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens
                },
                'cost_usd': cost_usd
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Claude API ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            logger.error(f"Claude API ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        type_names = {
            'chart': 'ì°¨íŠ¸',
            'table': 'í‘œ',
            'image': 'ì´ë¯¸ì§€',
            'diagram': 'ë‹¤ì´ì–´ê·¸ë¨'
        }
        
        type_name = type_names.get(element_type, 'ìš”ì†Œ')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

{extracted_text[:1000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬, ì´ {type_name}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš©: ì œëª©, í•µì‹¬ ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ, ì‹œê°ì  ìš”ì†Œ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            return f"""ì´ {type_name} ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ë‚´ìš©: ì œëª©, ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""


# ========== Azure OpenAI Provider ==========
class AzureOpenAIProvider(VLMProvider):
    """Azure OpenAI GPT-4V í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
        self.endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "")
        self.deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
        # âœ… API Versionì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ë„ë¡ ìˆ˜ì •
        self.api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
        self.executor = ThreadPoolExecutor(max_workers=3)
    
    def is_available(self) -> bool:
        """API í‚¤ì™€ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸"""
        return bool(self.api_key and self.endpoint)
    
    def get_name(self) -> str:
        return "Azure OpenAI GPT-4"
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'name': self.get_name(),
            'provider': 'Azure OpenAI',
            'model': self.deployment,
            'speed': 'âš¡âš¡ ë¹ ë¦„ (2-3ì´ˆ)',
            'quality': 'â­â­â­â­ ìš°ìˆ˜',
            'cost': 'ğŸ’°ğŸ’° ìœ ë£Œ ($0.01/image)',
            'internet': 'âœ… í•„ìš” (í•œêµ­ ë¦¬ì „ ê°€ëŠ¥)',
            'gpu': 'âŒ ë¶ˆí•„ìš”'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Azure OpenAI API í˜¸ì¶œ"""
        
        if not self.is_available():
            raise RuntimeError("Azure OpenAI API ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # URL êµ¬ì„± (âœ… self.api_version ì‚¬ìš©)
            url = f"{self.endpoint}/openai/deployments/{self.deployment}/chat/completions?api-version={self.api_version}"
            
            # ìš”ì²­ ë³¸ë¬¸
            payload = {
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            # í—¤ë”
            headers = {
                "Content-Type": "application/json",
                "api-key": self.api_key
            }
            
            # ë¹„ë™ê¸° í˜¸ì¶œ
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                self.executor,
                lambda: requests.post(url, headers=headers, json=payload, timeout=30)
            )
            
            # ì‘ë‹µ í™•ì¸
            if response.status_code != 200:
                error_msg = f"Azure OpenAI ì˜¤ë¥˜ (HTTP {response.status_code}): {response.text}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ì‘ë‹µ íŒŒì‹±
            result = response.json()
            caption = result['choices'][0]['message']['content'].strip()
            processing_time = time.time() - start_time
            
            # í† í° ì‚¬ìš©ëŸ‰
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            cost_usd = (input_tokens * 10 / 1_000_000) + (output_tokens * 30 / 1_000_000)
            
            logger.info(
                f"Azure OpenAI ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, "
                f"{input_tokens}+{output_tokens} tokens, ${cost_usd:.4f}"
            )
            
            return {
                'caption': caption,
                'confidence': 0.90,
                'processing_time': processing_time,
                'model': self.deployment,
                'provider': 'Azure OpenAI',
                'usage': {
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens
                },
                'cost_usd': cost_usd
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Azure OpenAI ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"Azure OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            logger.error(f"Azure OpenAI ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„± (Claudeì™€ ë™ì¼)"""
        type_names = {
            'chart': 'ì°¨íŠ¸',
            'table': 'í‘œ',
            'image': 'ì´ë¯¸ì§€',
            'diagram': 'ë‹¤ì´ì–´ê·¸ë¨'
        }
        
        type_name = type_names.get(element_type, 'ìš”ì†Œ')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

{extracted_text[:1000]}

ìœ„ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬, ì´ {type_name}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš©: ì œëª©, í•µì‹¬ ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ, ì‹œê°ì  ìš”ì†Œ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            return f"""ì´ {type_name} ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. ë‚´ìš©: ì œëª©, ë°ì´í„°
2. êµ¬ì¡°: ë ˆì´ì•„ì›ƒ
3. ì˜ë¯¸: í•µì‹¬ ë©”ì‹œì§€

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""


# ========== Ollama Local Provider ==========
class OllamaProvider(VLMProvider):
    """Ollama (LLaVA) ë¡œì»¬ í”„ë¡œë°”ì´ë”"""
    
    def __init__(self):
        self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model = os.getenv("OLLAMA_MODEL", "llava:7b")
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        # ì´ˆê¸°í™” ë¡œê·¸
        logger.info(f"Ollama ì´ˆê¸°í™”: {self.model}")
    
    def is_available(self) -> bool:
        """Ollama ì„œë²„ ë™ì‘ í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            if response.status_code == 200:
                models = response.json().get('models', [])
                return any(m['name'] == self.model for m in models)
            return False
        except:
            return False
    
    def get_name(self) -> str:
        return f"Ollama ({self.model})"
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'name': self.get_name(),
            'provider': 'Ollama (Local)',
            'model': self.model,
            'speed': 'âš¡ ëŠë¦¼ (5-10ì´ˆ, GPU í•„ìš”)',
            'quality': 'â­â­â­ ë³´í†µ',
            'cost': 'ğŸ’° ë¬´ë£Œ (ì „ê¸°ë£Œë§Œ)',
            'internet': 'âŒ ë¶ˆí•„ìš” (ì™„ì „ ì˜¤í”„ë¼ì¸)',
            'gpu': 'âœ… í•„ìš” (8GB VRAM)'
        }
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """Ollama API í˜¸ì¶œ"""
        
        if not self.is_available():
            raise RuntimeError(
                f"Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ê±°ë‚˜ {self.model} ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. "
                f"'ollama pull {self.model}' ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
            )
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(element_type, extracted_text)
            
            # ìš”ì²­ ë³¸ë¬¸
            url = f"{self.base_url}/api/generate"
            payload = {
                "model": self.model,
                "prompt": prompt,
                "images": [image_base64],
                "stream": False
            }
            
            # ë¹„ë™ê¸° í˜¸ì¶œ
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                self.executor,
                lambda: requests.post(url, json=payload, timeout=60)
            )
            
            # ì‘ë‹µ í™•ì¸
            if response.status_code != 200:
                error_msg = f"Ollama ì˜¤ë¥˜ (HTTP {response.status_code}): {response.text}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ì‘ë‹µ íŒŒì‹±
            result = response.json()
            caption = result.get('response', '').strip()
            processing_time = time.time() - start_time
            
            logger.info(f"Ollama ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
            
            return {
                'caption': caption,
                'confidence': 0.75,
                'processing_time': processing_time,
                'model': self.model,
                'provider': 'Ollama',
                'usage': {
                    'input_tokens': 0,
                    'output_tokens': 0
                },
                'cost_usd': 0.0
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Ollama ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"Ollama í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            logger.error(f"Ollama ì˜¤ë¥˜: {e}")
            raise
    
    def _build_prompt(self, element_type: str, extracted_text: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        type_names = {
            'chart': 'chart',
            'table': 'table',
            'image': 'image',
            'diagram': 'diagram'
        }
        
        type_name = type_names.get(element_type, 'element')
        
        if extracted_text and len(extracted_text) > 10:
            return f"""Analyze this {type_name}. OCR text: {extracted_text[:500]}

Describe:
1. Main content and title
2. Layout structure
3. Key message

Answer in Korean, clearly and concisely."""
        else:
            return f"""Describe this {type_name}:

1. Content and title
2. Layout
3. Key message

Answer in Korean, clearly and concisely."""


# ========== Multi VLM Service ==========
class MultiVLMService:
    """ë©€í‹° VLM í†µí•© ì„œë¹„ìŠ¤"""
    
    def __init__(self, default_provider: str = "claude"):
        """
        ì´ˆê¸°í™”
        
        Args:
            default_provider: ê¸°ë³¸ í”„ë¡œë°”ì´ë” (claude/azure_openai/ollama)
        """
        # í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
        self.providers = {
            'claude': ClaudeProvider(),
            'azure_openai': AzureOpenAIProvider(),
            'ollama': OllamaProvider()
        }
        
        # ê¸°ë³¸ í”„ë¡œë°”ì´ë” ì„¤ì •
        if default_provider in self.providers:
            self.current_provider_key = default_provider
        else:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ í”„ë¡œë°”ì´ë”
            for key, provider in self.providers.items():
                if provider.is_available():
                    self.current_provider_key = key
                    break
            else:
                self.current_provider_key = 'claude'  # fallback
        
        logger.info(f"MultiVLMService ì´ˆê¸°í™”: {self.current_provider_key}")
    
    def get_available_providers(self) -> Dict[str, Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë” ëª©ë¡"""
        result = {}
        for key, provider in self.providers.items():
            info = provider.get_info()
            info['available'] = provider.is_available()
            result[key] = info
        return result
    
    def set_provider(self, provider_key: str):
        """í”„ë¡œë°”ì´ë” ë³€ê²½"""
        if provider_key not in self.providers:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œë°”ì´ë”: {provider_key}")
        
        self.current_provider_key = provider_key
        logger.info(f"í”„ë¡œë°”ì´ë” ë³€ê²½: {provider_key}")
    
    def get_current_provider(self) -> VLMProvider:
        """í˜„ì¬ í”„ë¡œë°”ì´ë” ë°˜í™˜"""
        return self.providers[self.current_provider_key]
    
    async def generate_caption(
        self,
        image_base64: str,
        element_type: str = "image",
        extracted_text: str = ""
    ) -> Dict[str, Any]:
        """í˜„ì¬ í”„ë¡œë°”ì´ë”ë¡œ ìº¡ì…˜ ìƒì„±"""
        provider = self.get_current_provider()
        
        if not provider.is_available():
            raise RuntimeError(
                f"{provider.get_name()} í”„ë¡œë°”ì´ë”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                f"ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
            )
        
        return await provider.generate_caption(
            image_base64=image_base64,
            element_type=element_type,
            extracted_text=extracted_text
        )