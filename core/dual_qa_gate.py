"""
dual_qa_gate.py - PDF â†” VLM/LawMode ì´ì¤‘ ê²€ì¦
Phase 0.7.5 Annex Fallback (ê¸´ê¸‰ í•«í”½ìŠ¤)

âœ… Phase 0.7.5 í•«í”½ìŠ¤:
- í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜ QA ì¶”ê°€
- Annex í˜ì´ì§€: ì¡°ë¬¸ 0ê°œ + í…ìŠ¤íŠ¸ 90%+ â†’ í†µê³¼
- ë¡œê·¸ ê°œì„ : coverage í‘œì‹œ

Author: ì •ìˆ˜ì•„ (QA Lead) + GPT + CEO í”¼ë“œë°±
Date: 2025-11-16
Version: Phase 0.7.5 Annex Fallback
"""

import re
import logging
from typing import Dict, Any, Set, Literal

logger = logging.getLogger(__name__)

SourceType = Literal["vlm", "lawmode"]


class DualQAGate:
    """
    Phase 0.7.5 DualQA Gate
    
    âœ… Phase 0.7.5: Annex Fallback ì§€ì›
    - í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜ QA ì¶”ê°€
    - ì¡°ë¬¸ 0ê°œ + í…ìŠ¤íŠ¸ 90%+ â†’ í†µê³¼
    """
    
    ARTICLE_STRICT = re.compile(
        r'ì œ\s*(\d+)\s*ì¡°(?:ì˜\s*(\d+))?\s*\(',
        re.MULTILINE
    )
    
    ARTICLE_LOOSE = re.compile(
        r'ì œ\s*(\d+)\s*ì¡°(?:ì˜\s*(\d+))?(?=\s|$)',
        re.MULTILINE
    )
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        logger.info("âœ… DualQA Gate ì´ˆê¸°í™” (Phase 0.7.5 Annex Fallback)")
    
    def validate(
        self,
        pdf_text: str,
        processed_text: str,
        source: SourceType = "vlm",
        min_match_rate: float = 0.95,
        min_coverage: float = 0.90  # âœ… Phase 0.7.5: í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì„ê³„ê°’
    ) -> Dict[str, Any]:
        """
        âœ… Phase 0.7.5: PDF â†” ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì´ì¤‘ ê²€ì¦ (Annex Fallback ì§€ì›)
        
        Args:
            pdf_text: PDF ì›ë³¸ í…ìŠ¤íŠ¸
            processed_text: VLM ë˜ëŠ” LawModeë¡œ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
            source: "vlm" ë˜ëŠ” "lawmode"
            min_match_rate: ìµœì†Œ ë§¤ì¹­ë¥  (ê¸°ë³¸: 0.95)
            min_coverage: ìµœì†Œ í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (ê¸°ë³¸: 0.90) - âœ… Phase 0.7.5
        
        Returns:
            {
                'pdf_articles': Set[str],
                'processed_articles': Set[str],
                'matched': Set[str],
                'missing_in_processed': Set[str],
                'extra_in_processed': Set[str],
                'match_rate': float,
                'text_coverage': float,  # âœ… Phase 0.7.5
                'qa_flags': List[str],
                'is_pass': bool
            }
        """
        source_label = "VLM" if source == "vlm" else "LawMode"
        
        logger.info("ğŸ”¬ DualQA ê²€ì¦ ì‹œì‘ (Phase 0.7.5 Annex Fallback)")
        logger.info(f"   ğŸ“Š ì†ŒìŠ¤: {source_label}")
        logger.info(f"   ğŸ“ ìµœì†Œ ë§¤ì¹­ë¥ : {min_match_rate*100:.1f}%")
        logger.info(f"   ğŸ“ ìµœì†Œ ì»¤ë²„ë¦¬ì§€: {min_coverage*100:.1f}%")  # âœ… Phase 0.7.5
        
        # 1. PDF ì¡°ë¬¸ í—¤ë” ì¶”ì¶œ
        pdf_articles = self._extract_article_headers(pdf_text, source="PDF")
        
        # 2. ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì¡°ë¬¸ í—¤ë” ì¶”ì¶œ
        processed_articles = self._extract_article_headers(
            processed_text, 
            source=source_label
        )
        
        # 3. ë§¤ì¹­
        matched = pdf_articles & processed_articles
        missing_in_processed = pdf_articles - processed_articles
        extra_in_processed = processed_articles - pdf_articles
        
        # 4. ë§¤ì¹­ë¥ 
        if len(pdf_articles) > 0:
            match_rate = len(matched) / len(pdf_articles)
        else:
            match_rate = 0.0
        
        # âœ… Phase 0.7.5: í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
        pdf_len = len(pdf_text.strip())
        processed_len = len(processed_text.strip())
        
        if pdf_len > 0:
            text_coverage = processed_len / pdf_len
        else:
            text_coverage = 0.0
        
        logger.info(f"   ğŸ“Š í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {text_coverage:.1%} ({processed_len} / {pdf_len}ì)")
        
        # 5. QA í”Œë˜ê·¸
        qa_flags = []
        
        # âœ… Phase 0.7.5: Annex ëª¨ë“œ íŒë‹¨
        is_annex_mode = (len(pdf_articles) == 0 and pdf_len > 500)
        
        if is_annex_mode:
            logger.info(f"   ğŸ”„ Annex ëª¨ë“œ ê°ì§€ (ì¡°ë¬¸ 0ê°œ + í…ìŠ¤íŠ¸ {pdf_len}ì)")
            
            # Annex ëª¨ë“œ: í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜ QA
            if text_coverage < min_coverage:
                qa_flags.append('low_coverage')
                logger.error(f"      âŒ í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡±: {text_coverage:.1%} < {min_coverage:.1%}")
            else:
                logger.info(f"      âœ… Annex ëª¨ë“œ QA í†µê³¼ (ì»¤ë²„ë¦¬ì§€: {text_coverage:.1%})")
        
        else:
            # ë²•ì¡°ë¬¸ ëª¨ë“œ: ê¸°ì¡´ ë¡œì§
            if match_rate < min_match_rate:
                qa_flags.append('low_match_rate')
            
            if missing_in_processed:
                qa_flags.append('processed_missing_articles')
            
            if extra_in_processed:
                qa_flags.append('processed_extra_articles')
        
        # 6. í†µê³¼ ì—¬ë¶€
        if is_annex_mode:
            # Annex ëª¨ë“œ: í…ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë§Œ ì²´í¬
            is_pass = (text_coverage >= min_coverage)
        else:
            # ë²•ì¡°ë¬¸ ëª¨ë“œ: ê¸°ì¡´ ë¡œì§
            is_pass = (match_rate >= min_match_rate and len(qa_flags) == 0)
        
        # ë¡œê·¸ ì¶œë ¥
        logger.info("âœ… DualQA ê²€ì¦ ì™„ë£Œ (Phase 0.7.5):")
        logger.info(f"   ğŸ“Š [PDF] ì¡°ë¬¸: {len(pdf_articles)}ê°œ")
        logger.info(f"   ğŸ“Š [{source_label}] ì¡°ë¬¸: {len(processed_articles)}ê°œ")
        logger.info(f"   ğŸ“Š ì¼ì¹˜: {len(matched)}ê°œ")
        logger.info(f"   ğŸ“Š ë§¤ì¹­ë¥ : {match_rate:.1%}")
        
        if missing_in_processed:
            logger.error(f"   âŒ [{source_label}] ëˆ„ë½: {sorted(missing_in_processed)}")
        
        if extra_in_processed:
            logger.warning(f"   âš ï¸ [{source_label}] ì¶”ê°€: {sorted(extra_in_processed)}")
        
        if qa_flags:
            logger.error(f"   ğŸš¨ QA í”Œë˜ê·¸: {qa_flags}")
            logger.error(f"      â†’ ì›ë¬¸ ë¶ˆì¼ì¹˜! ìˆ˜ë™ ê²€ìˆ˜ í•„ìš”í•©ë‹ˆë‹¤!")
        else:
            if is_annex_mode:
                logger.info(f"   âœ… Annex ëª¨ë“œ QA í†µê³¼ (ì»¤ë²„ë¦¬ì§€: {text_coverage:.1%})")
            else:
                logger.info("   âœ… ì›ë¬¸ ì¼ì¹˜ (QA í†µê³¼)")
        
        result = {
            'pdf_articles': pdf_articles,
            'processed_articles': processed_articles,
            'matched': matched,
            'missing_in_processed': missing_in_processed,
            'extra_in_processed': extra_in_processed,
            'match_rate': match_rate,
            'text_coverage': text_coverage,  # âœ… Phase 0.7.5
            'qa_flags': qa_flags,
            'is_pass': is_pass,
            'is_annex_mode': is_annex_mode,  # âœ… Phase 0.7.5
            'source': source_label
        }
        
        return result
    
    def _extract_article_headers(self, text: str, source: str = "") -> Set[str]:
        """ì¡°ë¬¸ í—¤ë” ì¶”ì¶œ"""
        headers = set()
        
        # 1. Strict íŒ¨í„´
        for m in self.ARTICLE_STRICT.finditer(text):
            matched = m.group(0).split('(')[0].strip()
            matched = re.sub(r'\s+', '', matched)
            headers.add(matched)
        
        # 2. Loose íŒ¨í„´
        for m in self.ARTICLE_LOOSE.finditer(text):
            matched = m.group(0).strip()
            matched = re.sub(r'\s+', '', matched)
            headers.add(matched)
        
        if source:
            logger.info(f"   ğŸ“– [{source}] ì¡°ë¬¸ í—¤ë”: {len(headers)}ê°œ")
        
        return headers


def extract_pdf_text_layer(pdf_path: str) -> str:
    """PDF í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì¶”ì¶œ"""
    try:
        from pypdf import PdfReader
        
        reader = PdfReader(pdf_path)
        text_parts = []
        
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text_parts.append(page_text)
        
        full_text = '\n\n'.join(text_parts)
        
        logger.info(f"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ:")
        logger.info(f"   í˜ì´ì§€: {len(reader.pages)}ê°œ")
        logger.info(f"   í…ìŠ¤íŠ¸: {len(full_text)}ì")
        
        return full_text
    
    except Exception as e:
        logger.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""