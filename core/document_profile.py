"""
document_profile.py - ë¬¸ì„œ í”„ë¡œíŒŒì¼ ì‹œìŠ¤í…œ
Phase 0.5 "Standardization"

GPT ì„¤ê³„: ë¬¸ì„œ íƒ€ì…ë³„ ì²˜ë¦¬ ì „ëµ + íŒ¨í„´ + QA ê¸°ì¤€

Author: ë°•ì¤€í˜¸ (AI/ML Lead) + GPT ì„¤ê³„
Date: 2025-11-14
Version: Phase 0.5
"""

import re
import logging
from dataclasses import dataclass, field
from typing import Pattern, List, Dict, Any, Literal

logger = logging.getLogger(__name__)

# ëª¨ë“œ íƒ€ì…
Mode = Literal["law", "vlm"]


@dataclass
class DocumentProfile:
    """
    ë¬¸ì„œ í”„ë¡œíŒŒì¼
    
    ë¬¸ì„œ íƒ€ì…ë³„ ì²˜ë¦¬ ì „ëµ + íŒ¨í„´ + QA ê¸°ì¤€ì„ í•˜ë‚˜ë¡œ ë¬¶ìŒ
    """
    
    # ê¸°ë³¸ ì •ë³´
    id: str
    name: str
    mode: Mode
    description: str
    
    # êµ¬ì¡° ì¸ì‹ íŒ¨í„´
    chapter_pattern: Pattern
    article_pattern: Pattern
    article_loose_pattern: Pattern
    basic_spirit_pattern: Pattern | None = None
    
    # ë…¸ì´ì¦ˆ ì œê±° íŒ¨í„´
    page_header_patterns: List[Pattern] = field(default_factory=list)
    inline_noise_patterns: List[Pattern] = field(default_factory=list)
    
    # QA ê¸°ì¤€
    qa_min_match_ratio: float = 0.95
    allow_extra_articles: bool = True  # ì œ7ì¡°ì˜2 ê°™ì€ íŒŒìƒ ì¡°ë¬¸ í—ˆìš©
    
    # ì²˜ë¦¬ ì „ëµ
    strategy: Dict[str, Any] = field(default_factory=dict)


# ============================================
# í”„ë¡œíŒŒì¼ ì •ì˜
# ============================================

# 1. ì¸ì‚¬ê·œì • í”„ë¡œíŒŒì¼ (ê¸°ë³¸)
LAW_HR_PROFILE = DocumentProfile(
    id="law_kor_hr_v1",
    name="êµ­ë¬¸ ì¸ì‚¬ê·œì • ê¸°ë³¸ í”„ë¡œíŒŒì¼",
    mode="law",
    description="í•œêµ­ ê³µê³µ/ê³µê¸°ì—… ì¸ì‚¬ê·œì •, ì·¨ì—…ê·œì¹™ ë“± ì¡°ë¬¸ êµ¬ì¡° ë¬¸ì„œ",
    
    # íŒ¨í„´
    chapter_pattern=re.compile(r'ì œ\s*\d+\s*ì¥', re.MULTILINE),
    article_pattern=re.compile(r'ì œ\d+ì¡°(?:ì˜\d+)?', re.MULTILINE),
    article_loose_pattern=re.compile(r'ì œ\s*\d+\s*ì¡°(?:ì˜\s*\d+)?', re.MULTILINE),
    basic_spirit_pattern=re.compile(
        r'[\sâŸ¨<\[]*(ê¸°\s*ë³¸\s*ì •\s*ì‹ )[\s\]>âŸ©]*',
        re.MULTILINE | re.IGNORECASE
    ),
    
    # ë…¸ì´ì¦ˆ ì œê±°
    page_header_patterns=[
        re.compile(r'^\s*\d{3}-\d+\s*$', re.MULTILINE),  # 402-3
        re.compile(r'^\s*ì¸ì‚¬\s*ê·œì •\s*$', re.MULTILINE),
        re.compile(r'^\s*(ì¸ì‚¬\s*ê·œì •)\s*\d{3}-\d+\s*$', re.MULTILINE),
    ],
    inline_noise_patterns=[
        re.compile(r'(ì¸ì‚¬\s*ê·œì •)\s*\d{3}-\d+'),
    ],
    
    # QA
    qa_min_match_ratio=0.95,
    allow_extra_articles=True,
    
    # ì „ëµ
    strategy={
        "source_of_truth": "pdf_text",   # PDF í…ìŠ¤íŠ¸ê°€ ì§„ì‹¤
        "vlm_role": "table_only",        # VLMì€ í‘œ/ì´ë¯¸ì§€ë§Œ
        "chunk_unit": "article",         # ì¡°ë¬¸ ë‹¨ìœ„ ì²­í‚¹
        "preserve_structure": True,      # ì¥/ì ˆ/ì¡° êµ¬ì¡° ë³´ì¡´
    }
)

# 2. ì¼ë°˜ ë²•ë ¹ í”„ë¡œíŒŒì¼
LAW_GENERIC_PROFILE = DocumentProfile(
    id="law_kor_generic_v1",
    name="êµ­ë¬¸ ë²•ë ¹ ì¼ë°˜ í”„ë¡œíŒŒì¼",
    mode="law",
    description="ë²•ë¥ , ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ë“± ì¼ë°˜ ë²•ë ¹ ë¬¸ì„œ",
    
    chapter_pattern=re.compile(r'ì œ\s*\d+\s*[ì¥ì ˆ]', re.MULTILINE),
    article_pattern=re.compile(r'ì œ\d+ì¡°(?:ì˜\d+)?', re.MULTILINE),
    article_loose_pattern=re.compile(r'ì œ\s*\d+\s*ì¡°(?:ì˜\s*\d+)?', re.MULTILINE),
    
    page_header_patterns=[
        re.compile(r'^\s*\d+\s*$', re.MULTILINE),  # ë‹¨ìˆœ í˜ì´ì§€ ë²ˆí˜¸
    ],
    
    qa_min_match_ratio=0.95,
    allow_extra_articles=True,
    
    strategy={
        "source_of_truth": "pdf_text",
        "chunk_unit": "article",
        "preserve_structure": True,
    }
)

# 3. ì•½ê´€ í”„ë¡œíŒŒì¼
LAW_TERMS_PROFILE = DocumentProfile(
    id="law_kor_terms_v1",
    name="êµ­ë¬¸ ì•½ê´€ í”„ë¡œíŒŒì¼",
    mode="law",
    description="ì´ìš©ì•½ê´€, ê³„ì•½ì•½ê´€ ë“±",
    
    chapter_pattern=re.compile(r'ì œ\s*\d+\s*[ì¥ì¡°]', re.MULTILINE),
    article_pattern=re.compile(r'ì œ\d+ì¡°', re.MULTILINE),
    article_loose_pattern=re.compile(r'ì œ\s*\d+\s*ì¡°', re.MULTILINE),
    
    qa_min_match_ratio=0.90,  # ì•½ê´€ì€ ì¡°ê¸ˆ ëŠìŠ¨í•˜ê²Œ
    allow_extra_articles=False,
    
    strategy={
        "source_of_truth": "pdf_text",
        "chunk_unit": "article",
    }
)

# 4. VLM ê¸°ë³¸ í”„ë¡œíŒŒì¼ (ì¼ë°˜ ë¬¸ì„œìš©)
VLM_GENERAL_PROFILE = DocumentProfile(
    id="vlm_general_v1",
    name="VLM ì¼ë°˜ ë¬¸ì„œ í”„ë¡œíŒŒì¼",
    mode="vlm",
    description="ë³´ê³ ì„œ, PPT, ììœ  í˜•ì‹ ë¬¸ì„œ",
    
    # VLM ëª¨ë“œëŠ” íŒ¨í„´ ëŠìŠ¨í•˜ê²Œ
    chapter_pattern=re.compile(r'#{1,3}\s*.+', re.MULTILINE),
    article_pattern=re.compile(r'ì œ\d+ì¡°', re.MULTILINE),
    article_loose_pattern=re.compile(r'ì œ\s*\d+\s*ì¡°', re.MULTILINE),
    
    qa_min_match_ratio=0.80,  # VLMì€ ëŠìŠ¨í•˜ê²Œ
    
    strategy={
        "source_of_truth": "vlm",
        "vlm_role": "primary",
        "chunk_unit": "semantic",
    }
)


# ============================================
# í”„ë¡œíŒŒì¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬
# ============================================

PROFILES: Dict[str, DocumentProfile] = {
    "law_hr": LAW_HR_PROFILE,
    "law_generic": LAW_GENERIC_PROFILE,
    "law_terms": LAW_TERMS_PROFILE,
    "vlm_general": VLM_GENERAL_PROFILE,
}


def get_profile(profile_id: str) -> DocumentProfile:
    """
    í”„ë¡œíŒŒì¼ ì¡°íšŒ
    
    Args:
        profile_id: í”„ë¡œíŒŒì¼ ID
    
    Returns:
        DocumentProfile
    """
    if profile_id not in PROFILES:
        logger.warning(f"âš ï¸ í”„ë¡œíŒŒì¼ '{profile_id}' ì—†ìŒ. ê¸°ë³¸ í”„ë¡œíŒŒì¼ ì‚¬ìš©")
        return LAW_HR_PROFILE
    
    profile = PROFILES[profile_id]
    logger.info(f"âœ… í”„ë¡œíŒŒì¼ ë¡œë“œ: {profile.name} ({profile.id})")
    
    return profile


def auto_detect_profile(text: str, filename: str = "") -> DocumentProfile:
    """
    ë¬¸ì„œ íƒ€ì… ìë™ ê°ì§€ â†’ í”„ë¡œíŒŒì¼ ì¶”ì²œ
    
    Args:
        text: ë¬¸ì„œ í…ìŠ¤íŠ¸
        filename: íŒŒì¼ëª…
    
    Returns:
        ì¶”ì²œ í”„ë¡œíŒŒì¼
    """
    # íŒŒì¼ëª… ê¸°ë°˜ íŒíŠ¸
    if any(keyword in filename.lower() for keyword in ['ì¸ì‚¬', 'hr', 'ê·œì •', 'ê·œì¹™']):
        logger.info("ğŸ“ íŒŒì¼ëª… ê¸°ë°˜ ê°ì§€: ì¸ì‚¬ê·œì •")
        return LAW_HR_PROFILE
    
    if any(keyword in filename.lower() for keyword in ['ì•½ê´€', 'terms']):
        logger.info("ğŸ“ íŒŒì¼ëª… ê¸°ë°˜ ê°ì§€: ì•½ê´€")
        return LAW_TERMS_PROFILE
    
    # í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒíŠ¸
    if 'ê¸°ë³¸ì •ì‹ ' in text or 'ê¸° ë³¸ ì • ì‹ ' in text:
        logger.info("ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì§€: ê·œì •/ë²•ë ¹ (ê¸°ë³¸ì •ì‹  ë°œê²¬)")
        return LAW_HR_PROFILE
    
    # ì¡°ë¬¸ ë°€ë„
    article_count = len(re.findall(r'ì œ\d+ì¡°', text))
    if article_count > 5:
        logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì§€: ë²•ë ¹ (ì¡°ë¬¸ {article_count}ê°œ)")
        return LAW_GENERIC_PROFILE
    
    # ê¸°ë³¸ê°’: VLM ëª¨ë“œ
    logger.info("ğŸ“ ê¸°ë³¸ í”„ë¡œíŒŒì¼ ì„ íƒ: VLM ì¼ë°˜ ë¬¸ì„œ")
    return VLM_GENERAL_PROFILE


# ============================================
# í…ŒìŠ¤íŠ¸
# ============================================

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    
    # í”„ë¡œíŒŒì¼ ì¡°íšŒ
    profile = get_profile("law_hr")
    print(f"\ní”„ë¡œíŒŒì¼: {profile.name}")
    print(f"ëª¨ë“œ: {profile.mode}")
    print(f"QA ê¸°ì¤€: {profile.qa_min_match_ratio * 100}%")
    print(f"ì „ëµ: {profile.strategy}")
    
    # ìë™ ê°ì§€
    sample_text = """
    ê¸°ë³¸ì •ì‹ 
    ì´ ê·œì •ì€ í•œêµ­ë†ì–´ì´Œê³µì‚¬ ì§ì›ì˜ ì¸ì‚¬ê´€ë¦¬ì— ê´€í•œ ì‚¬í•­ì„ ì •í•œë‹¤.
    
    ì œ1ì¡°(ëª©ì ) ...
    ì œ2ì¡°(ì ìš©ë²”ìœ„) ...
    """
    
    detected = auto_detect_profile(sample_text, "ì¸ì‚¬ê·œì •_2025.pdf")
    print(f"\nìë™ ê°ì§€: {detected.name}")