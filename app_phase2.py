"""
PRISM Phase 2 - Streamlit Web App

Phase 2 íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤

Author: ìµœë™í˜„ (Frontend Lead)
Date: 2025-10-12
"""

import streamlit as st
import time
import json
from pathlib import Path
import shutil

# Phase 2 ëª¨ë“ˆ
from core.phase2_pipeline import Phase2Pipeline


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PRISM Phase 2",
    page_icon="ğŸ”·",
    layout="wide"
)

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOAD_DIR = Path("data/uploads")
PROCESSED_DIR = Path("data/processed")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)


def main():
    """ë©”ì¸ ì•±"""
    
    # í—¤ë”
    st.title("ğŸ”· PRISM Phase 2")
    st.markdown("**ì§€ëŠ¥í˜• ë¬¸ì„œ íŒŒì‹± ë° ì²­í‚¹ í”Œë«í¼**")
    
    # íƒ­
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ Upload", "âš™ï¸ Process", "ğŸ“Š Results"])
    
    # Tab 1: íŒŒì¼ ì—…ë¡œë“œ
    with tab1:
        st.header("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=["pdf"],
            help="ìµœëŒ€ 10MBê¹Œì§€ ì§€ì›"
        )
        
        if uploaded_file:
            # íŒŒì¼ ì €ì¥
            file_path = UPLOAD_DIR / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            st.session_state["uploaded_file"] = str(file_path)
            st.session_state["filename"] = uploaded_file.name
            
            # íŒŒì¼ ì •ë³´
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("íŒŒì¼ëª…", uploaded_file.name)
            with col2:
                st.metric("í¬ê¸°", f"{uploaded_file.size / 1024:.1f} KB")
            with col3:
                st.metric("íƒ€ì…", "PDF")
    
    # Tab 2: ì²˜ë¦¬
    with tab2:
        st.header("âš™ï¸ ë¬¸ì„œ ì²˜ë¦¬")
        
        if "uploaded_file" not in st.session_state:
            st.warning("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
            return
        
        # ì„¤ì •
        col1, col2 = st.columns(2)
        with col1:
            max_pages = st.number_input(
                "ì²˜ë¦¬í•  ìµœëŒ€ í˜ì´ì§€",
                min_value=1,
                max_value=100,
                value=10,
                help="ì „ì²´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ë ¤ë©´ ì¶©ë¶„íˆ í° ê°’ ì…ë ¥"
            )
        
        with col2:
            vlm_provider = st.selectbox(
                "VLM Provider",
                ["claude", "azure", "ollama"],
                help="ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì— ì‚¬ìš©í•  VLM"
            )
        
        # ì²˜ë¦¬ ë²„íŠ¼
        if st.button("ğŸš€ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘", type="primary"):
            process_document(
                st.session_state["uploaded_file"],
                max_pages,
                vlm_provider
            )
    
    # Tab 3: ê²°ê³¼
    with tab3:
        st.header("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
        
        if not (PROCESSED_DIR / "chunks.json").exists():
            st.info("ì²˜ë¦¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        show_results()


def process_document(pdf_path: str, max_pages: int, vlm_provider: str):
    """ë¬¸ì„œ ì²˜ë¦¬"""
    
    # ì§„í–‰ ìƒí™©
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        status_text.text("íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        pipeline = Phase2Pipeline(
            vlm_provider=vlm_provider,
            dpi=200,
            chunk_size=512
        )
        progress_bar.progress(10)
        
        # ë¬¸ì„œ ì²˜ë¦¬
        status_text.text("ë¬¸ì„œ ë¶„ì„ ì¤‘...")
        result = pipeline.process(pdf_path, max_pages)
        progress_bar.progress(100)
        
        # ê²°ê³¼ ì €ì¥
        st.session_state["result"] = result
        
        # ì„±ê³µ ë©”ì‹œì§€
        st.success("âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì²˜ë¦¬ í˜ì´ì§€", result["pages_processed"])
        with col2:
            st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", result["elements"]["text_blocks"])
        with col3:
            st.metric("í‘œ", result["elements"]["tables"])
        with col4:
            st.metric("ì²­í¬", result["chunks"]["total_chunks"])
        
        # ì²˜ë¦¬ ì‹œê°„
        st.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.1f}ì´ˆ")
        
    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        with st.expander("ì—ëŸ¬ ìƒì„¸"):
            st.code(traceback.format_exc())


def show_results():
    """ê²°ê³¼ í‘œì‹œ"""
    
    # chunks.json ë¡œë“œ
    chunks_path = PROCESSED_DIR / "chunks.json"
    with open(chunks_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    chunks = data.get("chunks", [])
    statistics = data.get("statistics", {})
    
    # í†µê³„
    st.subheader("ğŸ“ˆ í†µê³„")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì „ì²´ ì²­í¬", statistics.get("total_chunks", 0))
    with col2:
        st.metric("í…ìŠ¤íŠ¸ ì²­í¬", statistics.get("text_chunks", 0))
    with col3:
        st.metric("í‘œ ì²­í¬", statistics.get("table_chunks", 0))
    with col4:
        st.metric("ì´ë¯¸ì§€ ì²­í¬", statistics.get("image_chunks", 0))
    
    # ì²­í¬ ëª©ë¡
    st.subheader("ğŸ“„ ì²­í¬ ëª©ë¡")
    
    # í•„í„°
    chunk_type = st.selectbox(
        "ì²­í¬ íƒ€ì…",
        ["all", "text", "table", "image"]
    )
    
    # í•„í„°ë§
    filtered_chunks = chunks
    if chunk_type != "all":
        filtered_chunks = [c for c in chunks if c["type"] == chunk_type]
    
    st.info(f"í‘œì‹œ ì¤‘: {len(filtered_chunks)} / {len(chunks)} ì²­í¬")
    
    # ì²­í¬ í‘œì‹œ
    for i, chunk in enumerate(filtered_chunks[:50]):  # ìµœëŒ€ 50ê°œ
        with st.expander(f"[{chunk['type'].upper()}] {chunk['chunk_id']} (Page {chunk['page_num']})"):
            st.markdown("**Content:**")
            st.text_area(
                f"chunk_{i}",
                chunk["content"],
                height=150,
                key=f"chunk_content_{i}",
                label_visibility="collapsed"
            )
            
            st.markdown("**Metadata:**")
            st.json(chunk["metadata"])
            
            if chunk.get("has_embedding"):
                st.info("âœ… ì„ë² ë”© í¬í•¨")
    
    if len(filtered_chunks) > 50:
        st.warning(f"âš ï¸ ì²˜ìŒ 50ê°œë§Œ í‘œì‹œë¨ ({len(filtered_chunks) - 50}ê°œ ë” ìˆìŒ)")
    
    # ë‹¤ìš´ë¡œë“œ
    st.subheader("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # chunks.json ë‹¤ìš´ë¡œë“œ
        with open(chunks_path, "r", encoding="utf-8") as f:
            chunks_json = f.read()
        
        st.download_button(
            "ğŸ“¥ chunks.json ë‹¤ìš´ë¡œë“œ",
            chunks_json,
            file_name="chunks.json",
            mime="application/json"
        )
    
    with col2:
        # report.md ë‹¤ìš´ë¡œë“œ (ìˆìœ¼ë©´)
        report_path = PROCESSED_DIR / "report.md"
        if report_path.exists():
            with open(report_path, "r", encoding="utf-8") as f:
                report_md = f.read()
            
            st.download_button(
                "ğŸ“¥ report.md ë‹¤ìš´ë¡œë“œ",
                report_md,
                file_name="report.md",
                mime="text/markdown"
            )


if __name__ == "__main__":
    main()