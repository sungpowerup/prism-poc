"""
app.py
PRISM Phase 5.7.6.1 ê¸´ê¸‰ íŒ¨ì¹˜

âœ… ìˆ˜ì • ì‚¬í•­:
1. ì„ì‹œ íŒŒì¼ ì‚­ì œ ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
2. finally ë¸”ë¡ ì¶”ê°€
3. íŒŒì¼ í•¸ë“¤ ì•ˆì „ ì¢…ë£Œ

Author: ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-02
Version: 5.7.6.1 Hotfix
"""

import streamlit as st
import logging
import sys
from pathlib import Path
import os
import time

# âœ… ë¡œê±° ì´ˆê¸°í™” (ìµœìƒë‹¨)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('prism.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# âœ… core ëª¨ë“ˆ import (Phase 5.7.6)
try:
    from core.pdf_processor import PDFProcessor
    from core.vlm_service import VLMServiceV50
    from core.pipeline import Phase53Pipeline
    logger.info("âœ… ëª¨ë“  core ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    logger.error(f"âŒ core ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    st.error(f"âŒ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()


def main():
    st.title("ğŸ¯ PRISM Phase 5.7.6.1 - ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ (ê¸´ê¸‰ íŒ¨ì¹˜)")
    
    # ì´ˆê¸°í™”
    try:
        pdf_processor = PDFProcessor()
        vlm_service = VLMServiceV50(provider="azure_openai")
        logger.info("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ", type=['pdf'])
    
    if uploaded_file is not None:
        # âœ… session_stateë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬ ê²°ê³¼ ìºì‹±
        file_key = f"{uploaded_file.name}_{uploaded_file.size}"
        
        if 'last_processed_file' not in st.session_state or st.session_state['last_processed_file'] != file_key:
            # ìƒˆ íŒŒì¼ì´ê±°ë‚˜ ì•„ì§ ì²˜ë¦¬ ì•ˆ í–ˆìœ¼ë©´ ì²˜ë¦¬
            with st.spinner('ğŸ”„ PDF ì²˜ë¦¬ ì¤‘...'):
                temp_path = None
                
                try:
                    # âœ… Phase 5.7.6.1: ì„ì‹œ íŒŒì¼ ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€)
                    temp_filename = f"temp_{int(time.time())}_{uploaded_file.name}"
                    temp_path = Path(temp_filename)
                    
                    with open(temp_path, 'wb') as f:
                        f.write(uploaded_file.getvalue())
                    
                    logger.info(f"âœ… ì„ì‹œ íŒŒì¼ ì €ì¥: {temp_path}")
                    
                    # Pipeline ì´ˆê¸°í™” ë° ì²˜ë¦¬
                    pipeline = Phase53Pipeline(pdf_processor, vlm_service)
                    result = pipeline.process_pdf(str(temp_path))
                    
                    # âœ… ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
                    st.session_state['last_processed_file'] = file_key
                    st.session_state['result'] = result
                    st.session_state['processing_error'] = None
                    
                    logger.info("âœ… ì²˜ë¦¬ ì™„ë£Œ ë° ê²°ê³¼ ì €ì¥")
                    
                except Exception as e:
                    logger.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                    st.session_state['processing_error'] = str(e)
                    st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return
                
                finally:
                    # âœ… Phase 5.7.6.1: ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ
                    if temp_path and temp_path.exists():
                        try:
                            # ì ì‹œ ëŒ€ê¸° (íŒŒì¼ í•¸ë“¤ í•´ì œ ëŒ€ê¸°)
                            time.sleep(0.5)
                            
                            # ì‚­ì œ ì‹œë„
                            temp_path.unlink()
                            logger.info(f"âœ… ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
                        
                        except PermissionError as pe:
                            # Windows íŒŒì¼ ì ê¸ˆ ì˜¤ë¥˜ - ë¬´ì‹œ
                            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (íŒŒì¼ ì ê¸ˆ): {temp_path}")
                            logger.warning("   â†’ ì‹œìŠ¤í…œì´ ë‚˜ì¤‘ì— ìë™ ì •ë¦¬í•  ì˜ˆì •")
                        
                        except Exception as cleanup_e:
                            logger.error(f"âŒ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {cleanup_e}")
        
        # âœ… ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©
        if 'processing_error' in st.session_state and st.session_state['processing_error']:
            st.error(f"âŒ ì´ì „ ì²˜ë¦¬ ì˜¤ë¥˜: {st.session_state['processing_error']}")
            return
        
        if 'result' not in st.session_state:
            st.warning("âš ï¸ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        result = st.session_state['result']
        
        # âœ… ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
        st.success('âœ… ì²˜ë¦¬ ì™„ë£Œ!')
        
        # ===== ê²°ê³¼ í‘œì‹œ =====
        
        # 1. í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            valid_pages = result.get('pages_success', 0)
            total_pages = result.get('pages_total', 0)
            st.metric("ğŸ“„ í˜ì´ì§€", f"{valid_pages}/{total_pages}")
        
        with col2:
            markdown_len = len(result.get('markdown', ''))
            st.metric("ğŸ“ ì¶”ì¶œ ê¸€ì", f"{markdown_len:,}ì")
        
        with col3:
            chunk_count = len(result.get('chunks', []))
            st.metric("âœ‚ï¸ ì²­í¬", f"{chunk_count}ê°œ")
        
        with col4:
            overall_score = result.get('overall_score', 0)
            st.metric("ğŸ¯ ì¢…í•© ì ìˆ˜", f"{overall_score:.0f}/100")
        
        # 2. Fallback í†µê³„
        fallback_stats = result.get('fallback_stats', {})
        fallback_count = fallback_stats.get('fallback_count', 0)
        
        if fallback_count > 0:
            fallback_rate = fallback_stats.get('fallback_rate', 0)
            st.info(f"ğŸ”„ Fallback ì‚¬ìš©: {fallback_count}í˜ì´ì§€ ({fallback_rate:.1%})")
        
        # 3. í’ˆì§ˆ í‰ê°€
        with st.expander("ğŸ“Š í’ˆì§ˆ í‰ê°€ ìƒì„¸", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("ì›ë³¸ ì¶©ì‹¤ë„", f"{result.get('fidelity_score', 0):.0f}/100")
                st.metric("ì²­í‚¹ í’ˆì§ˆ", f"{result.get('chunking_score', 0):.0f}/100")
                st.metric("RAG ì í•©ë„", f"{result.get('rag_score', 0):.0f}/100")
            
            with col2:
                st.metric("ë²”ìš©ì„±", f"{result.get('universality_score', 0):.0f}/100")
                st.metric("ê²½ìŸë ¥", f"{result.get('competitive_score', 0):.0f}/100")
                st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result.get('processing_time', 0):.1f}ì´ˆ")
        
        # 4. ì²­í¬ í‘œì‹œ
        st.subheader("âœ‚ï¸ ìƒì„±ëœ ì²­í¬")
        
        chunks = result.get('chunks', [])
        
        if chunks:
            for i, chunk in enumerate(chunks):
                # metadata ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                metadata = chunk.get('metadata', {})
                char_count = metadata.get('char_count', len(chunk.get('content', '')))
                article_no = metadata.get('article_no', '?')
                article_title = metadata.get('article_title', '')
                
                # ì²­í¬ ì œëª© ìƒì„±
                if article_title:
                    chunk_title = f"ì²­í¬ {i+1}: {article_no} ({article_title}) - {char_count}ì"
                else:
                    chunk_title = f"ì²­í¬ {i+1}: {article_no} - {char_count}ì"
                
                with st.expander(chunk_title):
                    st.text(chunk.get('content', ''))
                    
                    # metadata í‘œì‹œ
                    if metadata:
                        st.caption(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {metadata}")
        else:
            st.warning("âš ï¸ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ===== ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ =====
        st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            markdown = result.get('markdown', '')
            if markdown:
                st.download_button(
                    label="ğŸ“¥ Markdown ë‹¤ìš´ë¡œë“œ",
                    data=markdown,
                    file_name=f"{uploaded_file.name}_markdown.md",
                    mime="text/markdown",
                    key="download_markdown"
                )
        
        with col2:
            if chunks:
                import json
                chunks_json = json.dumps(chunks, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ ì²­í¬ JSON ë‹¤ìš´ë¡œë“œ",
                    data=chunks_json,
                    file_name=f"{uploaded_file.name}_chunks.json",
                    mime="application/json",
                    key="download_chunks"
                )


if __name__ == "__main__":
    main()