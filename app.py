"""
app.py - PRISM Phase 0.6 "Elegance & Refinement"
GPT í”¼ë“œë°± 100% ë°˜ì˜: ì¥ ë¶„ë¦¬ + ì¤„ë°”ê¿ˆ ì •ë¦¬ + ë¡œê·¸ ê°œì„ 

âœ… Phase 0.6 ì£¼ìš” ë³€ê²½ (GPT ê¶Œì¥):
1. ì¥(Chapter) ë…ë¦½ ì²­í¬ ìƒì„± + articleì— chapter_number ì°¸ì¡°
2. ì¤„ë°”ê¿ˆ ì •ë¦¬ (LawMode ì „ìš©, idempotent)
3. DualQA ë¡œê·¸ ê°œì„  ([PDF] vs [LawMode] ëª…í™•í™”)

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ + GPT ì„¤ê³„
Date: 2025-11-14
Version: Phase 0.6
"""

import streamlit as st
import logging
import sys
from pathlib import Path
import json
import uuid
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('prism.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ëª¨ë“ˆ Import
try:
    from core.pdf_processor import PDFProcessor
    from core.vlm_service import VLMServiceV50
    from core.hybrid_extractor import HybridExtractor
    from core.semantic_chunker import SemanticChunker
    from core.dual_qa_gate import DualQAGate, extract_pdf_text_layer
    from core.utils_fs import safe_temp_path, safe_remove
    
    logger.info("âœ… ëª¨ë“ˆ import ì„±ê³µ (Phase 0.6)")
    
except Exception as e:
    logger.error(f"âŒ Import ì‹¤íŒ¨: {e}")
    st.error(f"âŒ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

# LawParser Import (Phase 0.6 ë²„ì „)
try:
    from core.law_parser import LawParser
    LAW_MODE_AVAILABLE = True
    logger.info("âœ… LawParser ë¡œë“œ ì„±ê³µ (Phase 0.6)")
except ImportError:
    LAW_MODE_AVAILABLE = False
    logger.warning("âš ï¸ LawParser ë¯¸ì„¤ì¹˜")

# DocumentProfile Import (Phase 0.5+)
try:
    from core.document_profile import auto_detect_profile, get_profile
    PROFILE_AVAILABLE = True
    logger.info("âœ… DocumentProfile ë¡œë“œ ì„±ê³µ")
except ImportError:
    PROFILE_AVAILABLE = False
    logger.warning("âš ï¸ DocumentProfile ë¯¸ì„¤ì¹˜")


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def to_review_md(chunks: list, markdown: str = None) -> str:
    """
    âœ… Phase 0.6: ë¦¬ë·°ìš© Markdown ìƒì„± (ì¥ ì²­í¬ ì§€ì›)
    """
    lines = []
    
    if markdown and ('ì œ37ì°¨' in markdown or 'ê°œì •' in markdown[:200]):
        lines.append("# ì¸ì‚¬ê·œì •\n## ê°œì • ì´ë ¥\n")
    
    for chunk in chunks:
        content = chunk['content']
        chunk_type = chunk['metadata']['type']
        
        if chunk_type == 'basic':
            lines.append("\n## ê¸°ë³¸ì •ì‹ \n")
            lines.append(content.replace('ê¸°ë³¸ì •ì‹ ', '', 1).strip())
        
        # âœ… Phase 0.6: ì¥(Chapter) ì²­í¬ ì²˜ë¦¬
        elif chunk_type == 'chapter':
            chapter_num = chunk['metadata'].get('chapter_number', '')
            chapter_title = chunk['metadata'].get('chapter_title', '')
            lines.append(f"\n## {chapter_num} {chapter_title}\n")
        
        elif chunk_type in ['article', 'article_loose']:
            header_match = re.search(r'(ì œ\s*\d+ì¡°(?:ì˜\d+)?[^\n]*)', content)
            if header_match:
                header = header_match.group(1)
                body = content[header_match.end():].strip()
                lines.append(f"\n### {header}\n")
                lines.append(body)
            else:
                lines.append(content)
        
        else:
            lines.append(content)
    
    return '\n'.join(lines)


# VLM ëª¨ë“œ ì²˜ë¦¬
def process_document_vlm_mode(pdf_path: str, pdf_text: str, max_pages: int = 20):
    """VLM íŒŒì´í”„ë¼ì¸"""
    
    st.info("ğŸ”¬ VLM ëª¨ë“œ: Azure OpenAI GPT-4 Vision ì²˜ë¦¬ ì¤‘...")
    progress_bar = st.progress(0)
    
    try:
        # PDF ì²˜ë¦¬
        pdf_processor = PDFProcessor()
        pages = pdf_processor.process_pdf(pdf_path)
        progress_bar.progress(25)
        
        if len(pages) > max_pages:
            st.warning(f"âš ï¸ ìµœëŒ€ {max_pages}í˜ì´ì§€ê¹Œì§€ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            pages = pages[:max_pages]
        
        # VLM ì²˜ë¦¬
        vlm_service = VLMServiceV50(provider='azure_openai')
        extractor = HybridExtractor(vlm_service)
        markdown_text = extractor.extract(pages)
        progress_bar.progress(50)
        
        # ì²­í‚¹
        st.info("ğŸ§© ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ ì¤‘...")
        chunker = SemanticChunker()
        chunks = chunker.chunk(markdown_text)
        st.success(f"âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        # âœ… Phase 0.6: DualQA ê²€ì¦ (source="vlm")
        st.info("ğŸ”¬ DualQA ê²€ì¦ ì¤‘...")
        qa_gate = DualQAGate()
        qa_result = qa_gate.validate(
            pdf_text=pdf_text,
            processed_text=markdown_text,
            source="vlm"  # âœ… Phase 0.6: ì†ŒìŠ¤ ëª…ì‹œ
        )
        
        match_rate = qa_result.get('match_rate', 0.0)
        qa_flags = qa_result.get('qa_flags', [])
        is_qa_pass = qa_result.get('is_pass', False)
        
        progress_bar.progress(100)
        
        return {
            'markdown': markdown_text,
            'chunks': chunks,
            'qa_result': qa_result,
            'is_qa_pass': is_qa_pass,
            'mode': 'VLM'
        }
    
    except Exception as e:
        logger.error(f"âŒ VLM ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise


# LawMode ì²˜ë¦¬ (Phase 0.6 ì—…ê·¸ë ˆì´ë“œ)
def process_document_law_mode(pdf_path: str, pdf_text: str, document_title: str):
    """
    âœ… Phase 0.6: LawMode íŒŒì´í”„ë¼ì¸ (GPT í”¼ë“œë°± ë°˜ì˜)
    
    - ì¥(Chapter) ë…ë¦½ ì²­í¬ ìƒì„±
    - ì¤„ë°”ê¿ˆ ì •ë¦¬ (normalize_linebreaks=True)
    - DualQA source="lawmode"
    """
    
    st.info("ğŸ“œ LawMode Phase 0.6: ê·œì •/ë²•ë ¹ íŒŒì‹± ì¤‘...")
    progress_bar = st.progress(0)
    
    # âœ… Phase 0.5+: DocumentProfile ìë™ ê°ì§€ (ì˜µì…˜)
    if PROFILE_AVAILABLE:
        profile = auto_detect_profile(pdf_text, document_title)
        st.info(f"ğŸ“ ë¬¸ì„œ í”„ë¡œíŒŒì¼: {profile.name}")
    
    # âœ… Phase 0.6: LawParser (ì¥ ë¶„ë¦¬ + ì¤„ë°”ê¿ˆ ì •ë¦¬)
    parser = LawParser()
    parsed_result = parser.parse(
        pdf_text=pdf_text,
        document_title=document_title,
        clean_artifacts=True,  # Phase 0.5: í˜ì´ì§€ ì•„í‹°íŒ©íŠ¸ ì œê±°
        normalize_linebreaks=True  # âœ… Phase 0.6: ì¤„ë°”ê¿ˆ ì •ë¦¬ (GPT ê¶Œì¥)
    )
    progress_bar.progress(50)
    
    # âœ… Phase 0.6: ì²­í¬ ë³€í™˜ (ì¥ ë…ë¦½ ì²­í¬ í¬í•¨)
    chunks = parser.to_chunks(parsed_result)
    progress_bar.progress(75)
    
    # Markdown ìƒì„±
    markdown_lines = []
    
    # ê¸°ë³¸ì •ì‹ 
    if parsed_result['basic_spirit']:
        markdown_lines.append("## ê¸°ë³¸ì •ì‹ \n")
        markdown_lines.append(parsed_result['basic_spirit'])
        markdown_lines.append("")
    
    # âœ… Phase 0.6: ì¥ê³¼ ì¡°ë¬¸ (section_order ê¸°ì¤€ ì •ë ¬)
    # ì´ë¯¸ to_chunks()ì—ì„œ ì •ë ¬ë˜ì–´ ìˆìŒ
    for chunk in chunks:
        chunk_type = chunk['metadata']['type']
        
        if chunk_type == 'chapter':
            # ì¥ í—¤ë”
            chapter_num = chunk['metadata']['chapter_number']
            chapter_title = chunk['metadata']['chapter_title']
            markdown_lines.append(f"## {chapter_num} {chapter_title}\n")
        
        elif chunk_type == 'article':
            # ì¡°ë¬¸
            article_num = chunk['metadata']['article_number']
            article_title = chunk['metadata']['article_title']
            markdown_lines.append(f"### {article_num}({article_title})\n")
            
            # ë³¸ë¬¸ (ì¡°ë¬¸ ë²ˆí˜¸ ì œê±°)
            body = chunk['content']
            if f"{article_num}({article_title})" in body:
                body = body.replace(f"{article_num}({article_title})", '', 1).strip()
            
            markdown_lines.append(body)
            markdown_lines.append("")
    
    markdown_text = '\n'.join(markdown_lines)
    
    # âœ… Phase 0.6: DualQA ê²€ì¦ (source="lawmode")
    st.info("ğŸ”¬ DualQA ê²€ì¦ ì¤‘...")
    qa_gate = DualQAGate()
    qa_result = qa_gate.validate(
        pdf_text=pdf_text,
        processed_text=markdown_text,
        source="lawmode"  # âœ… Phase 0.6: ì†ŒìŠ¤ ëª…ì‹œ (GPT ê¶Œì¥)
    )
    
    match_rate = qa_result.get('match_rate', 0.0)
    qa_flags = qa_result.get('qa_flags', [])
    is_qa_pass = qa_result.get('is_pass', False)
    
    progress_bar.progress(100)
    
    return {
        'markdown': markdown_text,
        'chunks': chunks,
        'qa_result': qa_result,
        'is_qa_pass': is_qa_pass,
        'mode': 'LawMode',
        'parsed_result': parsed_result  # âœ… Phase 0.6: íŒŒì‹± ìƒì„¸ ì •ë³´
    }


# Streamlit UI
def main():
    st.set_page_config(
        page_title="PRISM Phase 0.6",
        page_icon="ğŸ”·",
        layout="wide"
    )
    
    st.title("ğŸ”· PRISM Phase 0.6 \"Elegance & Refinement\"")
    st.caption("GPT í”¼ë“œë°± 100% ë°˜ì˜: ì¥ ë¶„ë¦¬ + ì¤„ë°”ê¿ˆ ì •ë¦¬ + ë¡œê·¸ ê°œì„ ")
    
    # ì‚¬ì´ë“œë°”: ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # LawMode í† ê¸€
        use_law_mode = st.checkbox(
            "ğŸ“œ LawMode ì‚¬ìš© (ê·œì •/ë²•ë ¹ ì „ìš©)",
            value=LAW_MODE_AVAILABLE,
            disabled=not LAW_MODE_AVAILABLE,
            help="PDF í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •í™•í•œ ì¡°ë¬¸ ì¶”ì¶œ + ì¥ ë¶„ë¦¬ + ì¤„ë°”ê¿ˆ ì •ë¦¬"
        )
        
        if not LAW_MODE_AVAILABLE:
            st.warning("âš ï¸ LawParser ë¯¸ì„¤ì¹˜")
        
        st.divider()
        
        # Phase 0.6 ë³€ê²½ì‚¬í•­
        with st.expander("âœ¨ Phase 0.6 ë³€ê²½ì‚¬í•­"):
            st.markdown("""
            **GPT í”¼ë“œë°± 100% ë°˜ì˜:**
            
            1ï¸âƒ£ **ì¥(Chapter) í—¤ë” ë¶„ë¦¬**
            - `type="chapter"` ë…ë¦½ ì²­í¬ ìƒì„±
            - Articleì— `chapter_number` ì°¸ì¡° ì¶”ê°€
            - RAGì—ì„œ "ì œ2ì¥ ì±„ìš©" ë‹¨ìœ„ ì§ˆì˜ ê°€ëŠ¥
            
            2ï¸âƒ£ **ì¤„ë°”ê¿ˆ ì •ë¦¬ (LawMode ì „ìš©)**
            - "ì±„\\nìš©ì„" â†’ "ì±„ìš©ì„"
            - ë¬¸ì¥/êµ¬ì¡° ì¤„ë°”ê¿ˆ ë³´ì¡´
            - Idempotent êµ¬í˜„
            
            3ï¸âƒ£ **ë¡œê·¸ ê°œì„ **
            - [PDF] vs [LawMode] ëª…í™•í•œ prefix
            - ìƒˆë²½ 2ì‹œ ë””ë²„ê¹… í¸ì˜ì„± ê·¹ëŒ€í™”
            """)
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=['pdf'],
        help="ê·œì •/ë²•ë ¹ ë¬¸ì„œ ê¶Œì¥ (LawMode)"
    )
    
    if not uploaded_file:
        st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
        
        # Phase 0.6 ë°ëª¨
        with st.expander("ğŸ¯ Phase 0.6 ì£¼ìš” ê°œì„  ì‚¬í•­"):
            st.markdown("""
            ### 1. ì¥(Chapter) ë…ë¦½ ì²­í¬
            
            **Before (Phase 0.5):**
            ```
            ì œ6ì¡°(ì†Œê¸‰ì„ìš©ì˜ ê¸ˆì§€)
            ...
            ì œ2ì¥ ì±„ìš©  â† ì¡°ë¬¸ì— ë¶™ì–´ìˆìŒ
            ```
            
            **After (Phase 0.6):**
            ```json
            [
              {"type": "article", "article_number": "ì œ6ì¡°", ...},
              {"type": "chapter", "chapter_number": "ì œ2ì¥", "chapter_title": "ì±„ìš©"}
            ]
            ```
            
            ---
            
            ### 2. ì¤„ë°”ê¿ˆ ì •ë¦¬
            
            **Before:**
            ```
            ...ì±„
            ìš©ì„ ì‹¤ì‹œí•˜ì—¬...
            ```
            
            **After:**
            ```
            ...ì±„ìš©ì„ ì‹¤ì‹œí•˜ì—¬...
            ```
            
            ---
            
            ### 3. ë¡œê·¸ ê°œì„ 
            
            **Before:**
            ```
            ğŸ“– VLM ì¡°ë¬¸ í—¤ë”: 9ê°œ
            ```
            
            **After:**
            ```
            ğŸ“– [PDF] ì¡°ë¬¸ í—¤ë”: 9ê°œ
            ğŸ“– [LawMode] ì¡°ë¬¸ í—¤ë”: 9ê°œ
            ```
            """)
        
        return
    
    # ë¬¸ì„œ ì²˜ë¦¬
    try:
        # PDF ì„ì‹œ ì €ì¥
        pdf_path = safe_temp_path('.pdf')
        with open(pdf_path, 'wb') as f:
            f.write(uploaded_file.read())
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pdf_text = extract_pdf_text_layer(pdf_path)
        
        if not pdf_text:
            st.error("âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            return
        
        # ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ
        if use_law_mode:
            result = process_document_law_mode(
                pdf_path=pdf_path,
                pdf_text=pdf_text,
                document_title=uploaded_file.name
            )
        else:
            result = process_document_vlm_mode(
                pdf_path=pdf_path,
                pdf_text=pdf_text
            )
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"âœ… {result['mode']} ì²˜ë¦¬ ì™„ë£Œ!")
        
        # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ì„±
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“Š í’ˆì§ˆ ê²€ì¦",
            "ğŸ“„ Markdown",
            "ğŸ§© ì²­í¬ (JSON)",
            "ğŸ“– ë¦¬ë·°ìš©"
        ])
        
        with tab1:
            st.subheader("ğŸ”¬ DualQA ê²€ì¦ ê²°ê³¼")
            
            qa_result = result['qa_result']
            match_rate = qa_result['match_rate']
            qa_flags = qa_result['qa_flags']
            is_pass = result['is_qa_pass']
            
            # âœ… Phase 0.6: ì†ŒìŠ¤ í‘œì‹œ
            source_label = qa_result.get('source', result['mode'])
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "ë§¤ì¹­ë¥ ",
                    f"{match_rate*100:.1f}%",
                    delta=f"{match_rate*100-95:.1f}%" if match_rate < 0.95 else None,
                    delta_color="normal" if match_rate >= 0.95 else "inverse"
                )
            
            with col2:
                st.metric("PDF ì¡°ë¬¸", len(qa_result['pdf_articles']))
            
            with col3:
                st.metric(f"{source_label} ì¡°ë¬¸", len(qa_result['processed_articles']))
            
            if is_pass:
                st.success("âœ… QA í†µê³¼ - ì›ë¬¸ ì¼ì¹˜")
            else:
                st.error("âŒ QA ì‹¤íŒ¨ - ì›ë¬¸ ë¶ˆì¼ì¹˜")
                
                if qa_flags:
                    st.warning(f"âš ï¸ QA í”Œë˜ê·¸: {qa_flags}")
            
            # âœ… Phase 0.6: LawMode ìƒì„¸ ì •ë³´
            if use_law_mode and 'parsed_result' in result:
                st.divider()
                st.subheader("ğŸ“œ LawMode Phase 0.6 íŒŒì‹± ìƒì„¸")
                
                parsed = result['parsed_result']
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ì¥(Chapter)", parsed['total_chapters'])
                with col2:
                    st.metric("ì´ ì¡°ë¬¸", parsed['total_articles'])
                with col3:
                    st.metric("ê¸°ë³¸ì •ì‹ ", f"{len(parsed['basic_spirit'])}ì")
                
                # âœ… Phase 0.6: ì¥ ëª©ë¡ í‘œì‹œ
                if parsed['chapters']:
                    with st.expander("ğŸ“‚ ì¥(Chapter) ëª©ë¡"):
                        for chapter in parsed['chapters']:
                            st.write(f"- **{chapter.number}** {chapter.title}")
        
        with tab2:
            st.subheader("ğŸ“„ Markdown")
            st.code(result['markdown'], language='markdown')
            st.download_button(
                "ğŸ’¾ Markdown ë‹¤ìš´ë¡œë“œ",
                data=result['markdown'],
                file_name=f"{uploaded_file.name}_phase06.md",
                mime="text/markdown"
            )
        
        with tab3:
            st.subheader("ğŸ§© ì²­í¬ (JSON)")
            
            # âœ… Phase 0.6: ì²­í¬ í†µê³„
            chunk_types = {}
            for chunk in result['chunks']:
                chunk_type = chunk['metadata']['type']
                chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
            
            st.write(f"**ì´ ì²­í¬ ìˆ˜**: {len(result['chunks'])}ê°œ")
            st.write(f"**ì²­í¬ íƒ€ì… ë¶„í¬**: {chunk_types}")
            
            st.json(result['chunks'], expanded=False)
            
            st.download_button(
                "ğŸ’¾ JSON ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(result['chunks'], ensure_ascii=False, indent=2),
                file_name=f"{uploaded_file.name}_chunks_phase06.json",
                mime="application/json"
            )
        
        with tab4:
            st.subheader("ğŸ“– ë¦¬ë·°ìš© Markdown")
            review_md = to_review_md(result['chunks'], result['markdown'])
            st.markdown(review_md)
            st.download_button(
                "ğŸ’¾ ë¦¬ë·°ìš© ë‹¤ìš´ë¡œë“œ",
                data=review_md,
                file_name=f"{uploaded_file.name}_review_phase06.md",
                mime="text/markdown"
            )
    
    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        if 'pdf_path' in locals():
            safe_remove(pdf_path)


if __name__ == '__main__':
    main()