"""
PRISM Phase 2.7 - Streamlit Web Application
PDF ë¬¸ì„œ ì§€ëŠ¥í˜• ì²˜ë¦¬ UI

Author: ìµœë™í˜„ (Frontend Lead)
Date: 2025-10-20
Update: Phase27Pipeline.process_pdf() í˜¸ì¶œ ìˆ˜ì •
"""

import streamlit as st
import os
import json
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from dotenv import load_dotenv

from core.phase27_pipeline import Phase27Pipeline

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PRISM Phase 2.7",
    page_icon="ğŸ”·",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #1f77b4;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .chunk-card {
        background-color: #ffffff;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border: 1px solid #e0e0e0;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .chunk-header {
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 0.5rem;
    }
    .chunk-content {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.3rem;
        font-family: monospace;
        white-space: pre-wrap;
        margin-top: 0.5rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 0.3rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
        padding: 1rem;
        border-radius: 0.3rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================

if 'pdf_path' not in st.session_state:
    st.session_state.pdf_path = None

if 'result' not in st.session_state:
    st.session_state.result = None

if 'processing' not in st.session_state:
    st.session_state.processing = False

# ============================================================
# VLM Provider ì„ íƒ
# ============================================================

def get_available_providers() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ VLM Provider ëª©ë¡"""
    providers = []
    
    # Claude
    if os.getenv('ANTHROPIC_API_KEY'):
        providers.append('claude')
    
    # Azure OpenAI
    if os.getenv('AZURE_OPENAI_API_KEY') and os.getenv('AZURE_OPENAI_ENDPOINT'):
        providers.append('azure_openai')
    
    # Ollama (ë¡œì»¬)
    providers.append('ollama')
    
    return providers

# ============================================================
# ë©”ì¸ UI
# ============================================================

st.markdown('<div class="main-header">ğŸ”· PRISM Phase 2.7</div>', unsafe_allow_html=True)
st.markdown('<div class="info-box">ğŸ“š <b>ì°¨ì„¸ëŒ€ ì§€ëŠ¥í˜• ë¬¸ì„œ ì²˜ë¦¬ í”Œë«í¼</b><br>PDF â†’ ë ˆì´ì•„ì›ƒ ê°ì§€ â†’ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ â†’ ì§€ëŠ¥í˜• ì²­í‚¹</div>', unsafe_allow_html=True)

# ============================================================
# ì‚¬ì´ë“œë°”: ì„¤ì •
# ============================================================

with st.sidebar:
    st.markdown("## âš™ï¸ ì„¤ì •")
    
    # VLM Provider ì„ íƒ
    available_providers = get_available_providers()
    
    if not available_providers:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ VLM Providerê°€ ì—†ìŠµë‹ˆë‹¤!")
        st.stop()
    
    provider_names = {
        'claude': 'ğŸ¤– Claude (Anthropic)',
        'azure_openai': 'â˜ï¸ Azure OpenAI',
        'ollama': 'ğŸ  Ollama (Local)'
    }
    
    vlm_provider = st.selectbox(
        "VLM Provider",
        options=available_providers,
        format_func=lambda x: provider_names.get(x, x),
        index=0
    )
    
    st.markdown("---")
    
    # ì •ë³´ í‘œì‹œ
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    st.info(f"""
    **ì„ íƒëœ Provider:** {provider_names.get(vlm_provider, vlm_provider)}
    
    **ì²˜ë¦¬ ë‹¨ê³„:**
    1. PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
    2. ë ˆì´ì•„ì›ƒ ê°ì§€ (VLM)
    3. ì˜ì—­ë³„ ì¶”ì¶œ (OCR + VLM)
    4. ì§€ëŠ¥í˜• ì²­í‚¹
    """)
    
    # ë„ì›€ë§
    with st.expander("ğŸ’¡ ì‚¬ìš© ë°©ë²•"):
        st.markdown("""
        1. **VLM Provider ì„ íƒ**
           - Claude: ìµœê³  í’ˆì§ˆ (ê¶Œì¥)
           - Azure OpenAI: ì—”í„°í”„ë¼ì´ì¦ˆ
           - Ollama: ë¡œì»¬/íì‡„ë§
        
        2. **PDF íŒŒì¼ ì—…ë¡œë“œ**
           - ìµœëŒ€ í¬ê¸°: 200MB
           - ìµœëŒ€ í˜ì´ì§€: 20í˜ì´ì§€
        
        3. **ì²˜ë¦¬ ì‹œì‘**
           - ìë™ìœ¼ë¡œ ë ˆì´ì•„ì›ƒ ê°ì§€
           - ì˜ì—­ë³„ ì»¨í…ì¸  ì¶”ì¶œ
           - ì§€ëŠ¥í˜• ì²­í‚¹ ìˆ˜í–‰
        
        4. **ê²°ê³¼ í™•ì¸**
           - Before/After ë¹„êµ
           - JSON/Markdown ë‹¤ìš´ë¡œë“œ
        """)

# ============================================================
# ë©”ì¸ ì˜ì—­: íŒŒì¼ ì—…ë¡œë“œ
# ============================================================

st.markdown('<div class="section-header">ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ</div>', unsafe_allow_html=True)

uploaded_file = st.file_uploader(
    "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
    type=['pdf'],
    help="ìµœëŒ€ 200MB, 20í˜ì´ì§€ ì´í•˜"
)

if uploaded_file:
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.success(f"âœ… íŒŒì¼ ì„ íƒë¨: **{uploaded_file.name}**")
    
    with col2:
        file_size_mb = uploaded_file.size / (1024 * 1024)
        st.metric("íŒŒì¼ í¬ê¸°", f"{file_size_mb:.2f} MB")
    
    with col3:
        if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", type="primary", disabled=st.session_state.processing):
            st.session_state.processing = True
            process_document(uploaded_file, vlm_provider)
            st.session_state.processing = False

# ============================================================
# ë¬¸ì„œ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================

def process_document(uploaded_file, vlm_provider):
    """ë¬¸ì„œ ì²˜ë¦¬"""
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    try:
        # ì…ë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        input_dir = Path("input")
        input_dir.mkdir(exist_ok=True)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        # íŒŒì¼ ì €ì¥
        input_path = input_dir / uploaded_file.name
        with open(input_path, "wb") as f:
            f.write(uploaded_file.getvalue())
        
        st.session_state.pdf_path = str(input_path)
        
        status_placeholder.info(f"âœ… íŒŒì¼ ì €ì¥: {input_path}")
        
        # Pipeline ì´ˆê¸°í™”
        status_placeholder.info(f"âš™ï¸ Pipeline ì´ˆê¸°í™” ì¤‘ (Provider: {vlm_provider})...")
        
        pipeline = Phase27Pipeline(vlm_provider=vlm_provider)
        
        # ì²˜ë¦¬ ì‹œì‘
        status_placeholder.info(f"ğŸ”„ {vlm_provider.upper()}ë¡œ ì²˜ë¦¬ ì¤‘...")
        progress_placeholder.progress(0, text="ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...")
        
        start_time = datetime.now()
        
        # âœ… ìˆ˜ì •: process() â†’ process_pdf()
        result = pipeline.process_pdf(
            pdf_path=str(input_path),
            output_dir=str(output_dir)
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # ê²°ê³¼ ì €ì¥
        st.session_state.result = result
        
        progress_placeholder.progress(100, text="âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        status_placeholder.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ)")
        
        # ê²°ê³¼ ë Œë”ë§
        render_results(result, duration)
        
    except Exception as e:
        progress_placeholder.empty()
        status_placeholder.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.code(traceback.format_exc())

# ============================================================
# ê²°ê³¼ ë Œë”ë§
# ============================================================

def render_results(result: Dict, duration: float):
    """ê²°ê³¼ í‘œì‹œ"""
    
    st.markdown("---")
    st.markdown('<div class="section-header">ğŸ“Š ì²˜ë¦¬ ê²°ê³¼</div>', unsafe_allow_html=True)
    
    # ë©”íƒ€ë°ì´í„°
    meta = result.get('metadata', {})
    
    # ìƒë‹¨ ë©”íŠ¸ë¦­
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ğŸ“„ ì´ í˜ì´ì§€", meta.get('total_pages', 0))
    
    with col2:
        st.metric("ğŸ“¦ ì´ ì²­í¬", meta.get('total_chunks', 0))
    
    with col3:
        st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{duration:.1f}ì´ˆ")
    
    with col4:
        chunk_types = meta.get('chunk_types', {})
        st.metric("ğŸ“ í…ìŠ¤íŠ¸", chunk_types.get('text', 0))
    
    with col5:
        st.metric("ğŸ“Š ì°¨íŠ¸", chunk_types.get('chart', 0))
    
    # ì²­í¬ íƒ€ì…ë³„ í†µê³„
    st.markdown("### ğŸ“ˆ ì²­í¬ íƒ€ì…ë³„ í†µê³„")
    
    chunk_types = meta.get('chunk_types', {})
    
    if chunk_types:
        cols = st.columns(len(chunk_types))
        for i, (chunk_type, count) in enumerate(chunk_types.items()):
            with cols[i]:
                st.metric(
                    label=chunk_type.upper(),
                    value=count,
                    delta=f"{count / meta.get('total_chunks', 1) * 100:.1f}%"
                )
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.markdown("---")
    st.markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # JSON ë‹¤ìš´ë¡œë“œ
        json_str = json.dumps(result, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ",
            data=json_str,
            file_name=f"prism_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col2:
        # Markdown ë‹¤ìš´ë¡œë“œ
        md_content = convert_to_markdown(result)
        st.download_button(
            label="ğŸ“ Markdown ë‹¤ìš´ë¡œë“œ",
            data=md_content,
            file_name=f"prism_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
    
    # ì²­í¬ ìƒì„¸
    st.markdown("---")
    st.markdown("### ğŸ“‹ ì²­í¬ ìƒì„¸ ë³´ê¸°")
    
    chunks = result.get('chunks', [])
    
    if not chunks:
        st.warning("âš ï¸ ì¶”ì¶œëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•„í„°ë§ ì˜µì…˜
    col1, col2 = st.columns([1, 3])
    
    with col1:
        chunk_type_filter = st.multiselect(
            "ì²­í¬ íƒ€ì… í•„í„°",
            options=list(chunk_types.keys()),
            default=list(chunk_types.keys())
        )
    
    with col2:
        search_query = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì²­í¬ ë‚´ìš© ê²€ìƒ‰...")
    
    # ì²­í¬ ë Œë”ë§
    filtered_chunks = [
        chunk for chunk in chunks
        if chunk['type'] in chunk_type_filter
        and (not search_query or search_query.lower() in chunk['content'].lower())
    ]
    
    st.info(f"ğŸ“¦ ì´ {len(filtered_chunks)}ê°œì˜ ì²­í¬ (ì „ì²´ {len(chunks)}ê°œ ì¤‘)")
    
    for i, chunk in enumerate(filtered_chunks, start=1):
        render_chunk(chunk, i)

# ============================================================
# ì²­í¬ ë Œë”ë§
# ============================================================

def render_chunk(chunk: Dict, index: int):
    """ê°œë³„ ì²­í¬ í‘œì‹œ"""
    
    with st.expander(f"**ì²­í¬ #{index}** - {chunk['chunk_id']} ({chunk['type'].upper()})"):
        
        # ë©”íƒ€ë°ì´í„°
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("í˜ì´ì§€", chunk['page_num'])
        
        with col2:
            st.metric("íƒ€ì…", chunk['type'])
        
        with col3:
            st.metric("í† í°", chunk['metadata']['token_count'])
        
        with col4:
            source = chunk['metadata'].get('source', 'unknown')
            st.metric("ì†ŒìŠ¤", source.upper())
        
        # ê²½ë¡œ
        st.caption(f"**ê²½ë¡œ:** {chunk['metadata']['section_path']}")
        
        # ë‚´ìš©
        st.markdown("#### ğŸ“„ ë‚´ìš©")
        
        if chunk['type'] in ['chart', 'table']:
            # JSON/Markdown í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            st.code(chunk['content'], language='json' if chunk['type'] == 'chart' else 'markdown')
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            st.text_area(
                "ë‚´ìš©",
                value=chunk['content'],
                height=200,
                disabled=True,
                label_visibility="collapsed"
            )

# ============================================================
# Markdown ë³€í™˜
# ============================================================

def convert_to_markdown(result: Dict) -> str:
    """ê²°ê³¼ë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
    lines = []
    
    # í—¤ë”
    lines.append("# PRISM Phase 2.7 - ì²˜ë¦¬ ê²°ê³¼\n")
    
    meta = result.get('metadata', {})
    lines.append(f"**ì²˜ë¦¬ ì¼ì‹œ:** {meta.get('processed_at', 'N/A')}")
    lines.append(f"**ì´ í˜ì´ì§€:** {meta.get('total_pages', 0)}")
    lines.append(f"**ì´ ì²­í¬:** {meta.get('total_chunks', 0)}")
    lines.append(f"**ì²˜ë¦¬ ì‹œê°„:** {meta.get('processing_time_seconds', 0):.2f}ì´ˆ\n")
    
    # ì²­í¬ íƒ€ì… í†µê³„
    lines.append("## ì²­í¬ íƒ€ì…ë³„ í†µê³„\n")
    for chunk_type, count in meta.get('chunk_types', {}).items():
        lines.append(f"- **{chunk_type}**: {count}ê°œ")
    lines.append("\n---\n")
    
    # ì²­í¬ë³„ ë‚´ìš©
    for chunk in result.get('chunks', []):
        lines.append(f"## ğŸ“ {chunk['chunk_id']}\n")
        lines.append(f"**í˜ì´ì§€:** {chunk['page_num']} | **íƒ€ì…:** {chunk['type']} | **í† í°:** {chunk['metadata']['token_count']}")
        lines.append(f"**ê²½ë¡œ:** {chunk['metadata']['section_path']}\n")
        lines.append("### ë‚´ìš©\n")
        lines.append(chunk['content'])
        lines.append("\n---\n")
    
    return '\n'.join(lines)

# ============================================================
# í‘¸í„°
# ============================================================

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem 0;">
    <p><strong>PRISM Phase 2.7</strong> - ì°¨ì„¸ëŒ€ ì§€ëŠ¥í˜• ë¬¸ì„œ ì²˜ë¦¬ í”Œë«í¼</p>
    <p>Powered by Claude Sonnet 4 | Â© 2025 PRISM Team</p>
</div>
""", unsafe_allow_html=True)