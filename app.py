"""
app.py
PRISM Phase 0.3.1 - Safe Mode Application

âš ï¸ Phase 0.3.1 ìˆ˜ì •:
1. ê¸°ì¡´ pipeline.py ì‚¬ìš© (Safe ëª¨ë“ˆ ìë™ ë¡œë“œ)
2. ë²„ì „ í™•ì¸ ì½”ë“œ ì¶”ê°€
3. ì›ë³¸ ì¶©ì‹¤ë„ ìš°ì„ 

Author: ë§ˆì°½ìˆ˜ì‚° íŒ€
Date: 2025-11-07
Version: Phase 0.3.1 (Safe Mode)
"""

import streamlit as st
import logging
import sys
from pathlib import Path
import os
import time
import importlib
import json

# âœ… ë¡œê±° ì´ˆê¸°í™” (ìµœìƒë‹¨)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('prism.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# âš ï¸ Phase 0.3.1: ìºì‹œ ë¬´íš¨í™”
importlib.invalidate_caches()

# âœ… core ëª¨ë“ˆ import
try:
    from core.pdf_processor import PDFProcessor
    from core.vlm_service import VLMServiceV50
    from core.pipeline import Phase53Pipeline  # âš ï¸ ê¸°ì¡´ pipeline ì‚¬ìš©
    
    logger.info("âœ… ëª¨ë“  core ëª¨ë“ˆ import ì„±ê³µ")
    
    # âš ï¸ Phase 0.3.1: ë²„ì „ í™•ì¸ (Safe ëª¨ë“ˆ ì²´í¬)
    try:
        from core.typo_normalizer_safe import TypoNormalizer
        from core.post_merge_normalizer_safe import PostMergeNormalizer
        
        tn_version = getattr(TypoNormalizer, 'VERSION', 'UNKNOWN')
        tn_dict_size = len(getattr(TypoNormalizer, 'STATUTE_TERMS', {}))
        tn_block_size = len(getattr(TypoNormalizer, 'BLOCKED_REPLACEMENTS', set()))
        
        logger.info(f"ğŸ” TypoNormalizer: {tn_version}")
        logger.info(f"   ğŸ“– ì‚¬ì „: {tn_dict_size}ê°œ")
        logger.info(f"   ğŸš« ê¸ˆì§€: {tn_block_size}ê°œ")
        
        pm_version = getattr(PostMergeNormalizer, 'VERSION', 'UNKNOWN')
        logger.info(f"ğŸ” PostMergeNormalizer: {pm_version}")
        
        # ë²„ì „ í™•ì¸
        if 'Safe Mode' in tn_version and tn_dict_size >= 20 and tn_block_size >= 10:
            logger.info("âœ… Phase 0.3.1 Hotfix í™•ì¸ë¨!")
            safe_mode_enabled = True
        else:
            logger.warning(f"âš ï¸ Phase 0.3.1 Hotfix ë¯¸í™•ì¸: version={tn_version}, dict={tn_dict_size}, block={tn_block_size}")
            safe_mode_enabled = False
    except ImportError:
        logger.warning("âš ï¸ Safe Normalizers ì—†ìŒ - ê¸°ë³¸ ë²„ì „ ì‚¬ìš©")
        tn_version = "Phase 0.3 (ê¸°ë³¸)"
        pm_version = "Phase 0.3 (ê¸°ë³¸)"
        tn_dict_size = 15
        tn_block_size = 0
        safe_mode_enabled = False
        
except ImportError as e:
    logger.error(f"âŒ core ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    st.error(f"âŒ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()


def main():
    # ì œëª© (Safe Mode ì—¬ë¶€ í‘œì‹œ)
    if safe_mode_enabled:
        st.title("ğŸ¯ PRISM Phase 0.3.1 - ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ (Safe Mode) âœ…")
    else:
        st.title("ğŸ¯ PRISM Phase 0.3 - ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ âš ï¸")
        st.warning("âš ï¸ Safe Modeê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Safe ëª¨ë“ˆì„ í™•ì¸í•˜ì„¸ìš”.")
    
    # ë²„ì „ ì •ë³´ í‘œì‹œ
    with st.expander("â„¹ï¸ ë²„ì „ ì •ë³´", expanded=False):
        st.write(f"**Safe Mode**: {'âœ… í™œì„±í™”' if safe_mode_enabled else 'âŒ ë¹„í™œì„±í™”'}")
        st.write(f"**TypoNormalizer**: {tn_version}")
        st.write(f"**PostMergeNormalizer**: {pm_version}")
        st.write(f"**ì‚¬ì „ í¬ê¸°**: {tn_dict_size}ê°œ")
        st.write(f"**ê¸ˆì§€ ì¹˜í™˜**: {tn_block_size}ê°œ")
    
    # ì´ˆê¸°í™”
    try:
        pdf_processor = PDFProcessor()
        vlm_service = VLMServiceV50(provider="azure_openai")
        logger.info("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ", type=['pdf'])
    
    if uploaded_file is not None:
        # session_stateë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬ ê²°ê³¼ ìºì‹±
        file_key = f"{uploaded_file.name}_{uploaded_file.size}"
        
        if 'last_processed_file' not in st.session_state or st.session_state['last_processed_file'] != file_key:
            # ìƒˆ íŒŒì¼ì´ê±°ë‚˜ ì•„ì§ ì²˜ë¦¬ ì•ˆ í–ˆìœ¼ë©´ ì²˜ë¦¬
            status_text = "ğŸ”„ PDF ì²˜ë¦¬ ì¤‘... (Phase 0.3.1 Safe Mode)" if safe_mode_enabled else "ğŸ”„ PDF ì²˜ë¦¬ ì¤‘..."
            
            with st.spinner(status_text):
                temp_path = None
                
                try:
                    # ì„ì‹œ íŒŒì¼ ì €ì¥
                    temp_filename = f"temp_{int(time.time())}_{uploaded_file.name}"
                    temp_path = Path(temp_filename)
                    
                    with open(temp_path, 'wb') as f:
                        f.write(uploaded_file.getvalue())
                    
                    logger.info(f"âœ… ì„ì‹œ íŒŒì¼ ì €ì¥: {temp_path}")
                    
                    # Pipeline ì´ˆê¸°í™” ë° ì²˜ë¦¬
                    pipeline = Phase53Pipeline(pdf_processor, vlm_service)
                    result = pipeline.process_pdf(str(temp_path))
                    
                    # ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
                    st.session_state['last_processed_file'] = file_key
                    st.session_state['result'] = result
                    st.session_state['processing_error'] = None
                    
                    logger.info("âœ… ì²˜ë¦¬ ì™„ë£Œ ë° ê²°ê³¼ ì €ì¥")
                    
                except Exception as e:
                    logger.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                    st.session_state['processing_error'] = str(e)
                    st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    
                finally:
                    # ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ
                    if temp_path and temp_path.exists():
                        try:
                            time.sleep(0.1)
                            temp_path.unlink()
                            logger.info(f"âœ… ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
                        except PermissionError:
                            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (íŒŒì¼ ì ê¸ˆ): {temp_path}")
                            logger.warning(f"   â†’ ì‹œìŠ¤í…œì´ ë‚˜ì¤‘ì— ìë™ ì •ë¦¬í•  ì˜ˆì •")
                        except Exception as e:
                            logger.error(f"âŒ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")
        
        # ê²°ê³¼ í‘œì‹œ
        if 'result' in st.session_state and st.session_state['result']:
            result = st.session_state['result']
            
            if result.get('success'):
                st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                
                # í†µê³„ ì •ë³´
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ“„ í˜ì´ì§€ ìˆ˜", result.get('pages_count', 0))
                with col2:
                    st.metric("âœ‚ï¸ ì²­í¬ ìˆ˜", len(result.get('chunks', [])))
                with col3:
                    st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", f"{result.get('elapsed_time', 0):.1f}ì´ˆ")
                
                # ì²´í¬ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
                st.subheader("ğŸ“Š í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸")
                
                checklist = result.get('checklist', {})
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    fidelity = checklist.get('fidelity', 0)
                    st.metric("ì›ë³¸ ì¶©ì‹¤ë„", f"{fidelity}/100", 
                             delta="ëª©í‘œ: 95ì " if fidelity >= 95 else "ê°œì„  í•„ìš”",
                             delta_color="normal" if fidelity >= 95 else "inverse")
                with col2:
                    chunking = checklist.get('chunking', 0)
                    st.metric("ì²­í‚¹ í’ˆì§ˆ", f"{chunking}/100")
                with col3:
                    rag = checklist.get('rag_readiness', 0)
                    st.metric("RAG ì í•©ë„", f"{rag}/100")
                
                col4, col5, col6 = st.columns(3)
                with col4:
                    generality = checklist.get('generality', 0)
                    st.metric("ë²”ìš©ì„±", f"{generality}/100")
                with col5:
                    competitive = checklist.get('competitive_edge', 0)
                    st.metric("ê²½ìŸë ¥", f"{competitive}/100")
                with col6:
                    overall = checklist.get('overall', 0)
                    st.metric("ğŸ¯ ì¢…í•©", f"{overall}/100",
                             delta="ëª©í‘œ: 95ì " if overall >= 95 else "ê°œì„  í•„ìš”",
                             delta_color="normal" if overall >= 95 else "inverse")
                
                # Markdown ë¯¸ë¦¬ë³´ê¸°
                st.subheader("ğŸ“ Markdown ë¯¸ë¦¬ë³´ê¸°")
                markdown = result.get('markdown', '')
                
                if markdown:
                    # ì²˜ìŒ 1000ìë§Œ í‘œì‹œ
                    preview = markdown[:1000]
                    if len(markdown) > 1000:
                        preview += "\n\n... (ìƒëµ) ..."
                    
                    st.text_area("", preview, height=300, disabled=True)
                    
                    # ì „ì²´ ë³´ê¸°
                    with st.expander("ğŸ“„ ì „ì²´ Markdown ë³´ê¸°"):
                        st.markdown(markdown)
                
                # ì²­í¬ ë¯¸ë¦¬ë³´ê¸°
                st.subheader("âœ‚ï¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°")
                chunks = result.get('chunks', [])
                
                if chunks:
                    # ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ í‘œì‹œ
                    for i, chunk in enumerate(chunks[:3], 1):
                        with st.expander(f"ì²­í¬ {i}: {chunk.get('id', '')}"):
                            st.write("**ë©”íƒ€ë°ì´í„°:**")
                            st.json(chunk.get('metadata', {}))
                            st.write("**ë‚´ìš©:**")
                            st.text(chunk.get('content', ''))
                    
                    if len(chunks) > 3:
                        st.info(f"ğŸ“‹ ì´ {len(chunks)}ê°œ ì²­í¬ (ì „ì²´ëŠ” JSON ë‹¤ìš´ë¡œë“œì—ì„œ í™•ì¸)")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if markdown:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        md_filename = f"{uploaded_file.name.replace('.pdf', '')}_{timestamp}_markdown.md"
                        
                        st.download_button(
                            label="ğŸ“¥ Markdown ë‹¤ìš´ë¡œë“œ",
                            data=markdown,
                            file_name=md_filename,
                            mime="text/markdown",
                            key="download_markdown"
                        )
                
                with col2:
                    if chunks:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        json_filename = f"{uploaded_file.name.replace('.pdf', '')}_{timestamp}_chunks.json"
                        
                        chunks_json = json.dumps(chunks, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ğŸ“¥ ì²­í¬ JSON ë‹¤ìš´ë¡œë“œ",
                            data=chunks_json,
                            file_name=json_filename,
                            mime="application/json",
                            key="download_chunks"
                        )
            else:
                st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        elif 'processing_error' in st.session_state and st.session_state['processing_error']:
            st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {st.session_state['processing_error']}")


if __name__ == "__main__":
    main()