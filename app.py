"""
app.py - PRISM Phase 0.4.0 P0-4 Final (Fixed v2)
QA Gatekeeper + LawMode í†µí•©

âœ… Phase 0.4.0 P0-4 Final (Fixed v2):
1. HybridExtractor í˜ì´ì§€ë³„ í˜¸ì¶œ ë°©ì‹ ìˆ˜ì •
2. DualQAGate.validate() íŒŒë¼ë¯¸í„° ìˆ˜ì • (chunks ì œê±°) â† ğŸ”§ FIX v2

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€
Date: 2025-11-13
Version: Phase 0.4.0 P0-4 Final (Fixed v2)
"""

import streamlit as st
import logging
import sys
from pathlib import Path
import json
import uuid
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('prism.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ëª¨ë“ˆ Import
try:
    from core.pdf_processor import PDFProcessor
    from core.vlm_service import VLMServiceV50
    from core.hybrid_extractor import HybridExtractor
    from core.semantic_chunker import SemanticChunker
    from core.dual_qa_gate import DualQAGate, extract_pdf_text_layer
    from core.utils_fs import safe_temp_path, safe_remove
    
    logger.info("âœ… ëª¨ë“ˆ import ì„±ê³µ (Phase 0.4.0 P0-4 Fixed v2)")
    
except Exception as e:
    logger.error(f"âŒ Import ì‹¤íŒ¨: {e}")
    st.error(f"âŒ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

# LawParser Import
try:
    from core.law_parser import LawParser
    LAW_MODE_AVAILABLE = True
    logger.info("âœ… LawParser ë¡œë“œ ì„±ê³µ")
except ImportError:
    LAW_MODE_AVAILABLE = False
    logger.warning("âš ï¸ LawParser ë¯¸ì„¤ì¹˜")


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def to_review_md(chunks: list, markdown: str = None) -> str:
    """ë¦¬ë·°ìš© Markdown ìƒì„±"""
    lines = []
    
    if markdown and ('ì œ37ì°¨' in markdown or 'ê°œì •' in markdown[:200]):
        lines.append("# ì¸ì‚¬ê·œì •\n## ê°œì • ì´ë ¥\n")
    
    for chunk in chunks:
        content = chunk['content']
        chunk_type = chunk['metadata']['type']
        
        if chunk_type == 'basic':
            lines.append("\n## ê¸°ë³¸ì •ì‹ \n")
            lines.append(content.replace('ê¸°ë³¸ì •ì‹ ', '', 1).strip())
        elif chunk_type in ['article', 'article_loose']:
            header_match = re.search(r'(ì œ\s*\d+ì¡°(?:ì˜\d+)?)\s*\(([^)]+)\)', content)
            if header_match:
                lines.append(f"\n### {header_match.group(1)}({header_match.group(2)})\n")
                lines.append(content[header_match.end():].strip())
    
    return '\n'.join(lines)


# VLM ëª¨ë“œ ì²˜ë¦¬
def process_document_vlm_mode(pdf_path: str, pdf_text: str, max_pages: int = 20):
    """VLM ì¤‘ì‹¬ íŒŒì´í”„ë¼ì¸"""
    
    st.info("ğŸ“„ PDF ì´ë¯¸ì§€ ë³€í™˜ ì¤‘...")
    pdf_processor = PDFProcessor()
    images = pdf_processor.pdf_to_images(pdf_path, max_pages=max_pages)
    st.success(f"âœ… {len(images)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
    
    vlm_service = VLMServiceV50(provider='azure_openai')
    extractor = HybridExtractor(vlm_service=vlm_service, pdf_path=pdf_path)
    
    st.info("ğŸ¤– VLM ë¬¸ì„œ ì¶”ì¶œ ì¤‘...")
    progress_bar = st.progress(0)
    
    # í˜ì´ì§€ë³„ í˜¸ì¶œ
    all_pages = []
    for i, image_item in enumerate(images, 1):
        if isinstance(image_item, tuple):
            image_data = image_item[0]
        else:
            image_data = image_item
        
        # base64 ë³€í™˜
        from PIL import Image
        import base64
        from io import BytesIO
        
        if isinstance(image_data, Image.Image):
            buffered = BytesIO()
            image_data.save(buffered, format="PNG")
            image_data = base64.b64encode(buffered.getvalue()).decode()
        
        page_result = extractor.extract(image_data=image_data, page_num=i)
        all_pages.append(page_result)
        progress_bar.progress(int((i / len(images)) * 70))
    
    markdown_text = '\n\n'.join([p['content'] for p in all_pages])
    progress_bar.progress(75)
    
    st.info("âœ‚ï¸ ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ ì¤‘...")
    chunker = SemanticChunker()
    chunks = chunker.chunk(markdown_text)
    st.success(f"âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
    
    # ğŸ”§ Fixed v2: chunks íŒŒë¼ë¯¸í„° ì œê±°
    st.info("ğŸ”¬ DualQA ê²€ì¦ ì¤‘...")
    qa_gate = DualQAGate()
    qa_result = qa_gate.validate(pdf_text=pdf_text, vlm_markdown=markdown_text)
    
    match_rate = qa_result.get('match_rate', 0.0)
    qa_flags = qa_result.get('qa_flags', [])
    is_qa_pass = (match_rate >= 0.95 and len(qa_flags) == 0)
    
    progress_bar.progress(100)
    
    return {
        'markdown': markdown_text,
        'chunks': chunks,
        'qa_result': qa_result,
        'is_qa_pass': is_qa_pass,
        'mode': 'VLM'
    }


# LawMode ì²˜ë¦¬
def process_document_law_mode(pdf_path: str, pdf_text: str, document_title: str):
    """LawMode íŒŒì´í”„ë¼ì¸"""
    
    st.info("ğŸ“œ LawMode: PDF í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¡°ë¬¸ íŒŒì‹± ì¤‘...")
    progress_bar = st.progress(0)
    
    parser = LawParser()
    parsed_result = parser.parse(pdf_text=pdf_text, document_title=document_title)
    progress_bar.progress(50)
    
    chunks = parser.to_chunks(parsed_result)
    progress_bar.progress(75)
    
    markdown_lines = []
    if parsed_result['basic_spirit']:
        markdown_lines.append("# ê¸°ë³¸ì •ì‹ \n" + parsed_result['basic_spirit'])
    
    for article in parsed_result['articles']:
        markdown_lines.append(f"\n## {article.number}({article.title or ''})\n{article.body}")
    
    final_md = '\n'.join(markdown_lines)
    
    # ğŸ”§ Fixed v2: chunks íŒŒë¼ë¯¸í„° ì œê±°
    st.info("ğŸ”¬ DualQA ê²€ì¦ ì¤‘...")
    qa_gate = DualQAGate()
    qa_result = qa_gate.validate(pdf_text=pdf_text, vlm_markdown=final_md)
    
    match_rate = qa_result.get('match_rate', 0.0)
    qa_flags = qa_result.get('qa_flags', [])
    is_qa_pass = (match_rate >= 0.95 and len(qa_flags) == 0)
    
    progress_bar.progress(100)
    
    return {
        'markdown': final_md,
        'chunks': chunks,
        'qa_result': qa_result,
        'is_qa_pass': is_qa_pass,
        'mode': 'LawMode',
        'parsed_result': parsed_result
    }


# Streamlit UI
def main():
    st.set_page_config(page_title="PRISM P0-4", page_icon="ğŸ”·", layout="wide")
    
    st.title("ğŸ”· PRISM - Intelligent Document Processor")
    st.caption("Phase 0.4.0 P0-4 Final (Fixed v2)")
    
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        if LAW_MODE_AVAILABLE:
            use_law_mode = st.checkbox("ğŸ“œ LawMode (ê·œì •/ë²•ë ¹ ì „ìš©)", value=False)
            if use_law_mode:
                st.success("âœ… LawMode í™œì„±í™”")
        else:
            use_law_mode = False
            st.warning("âš ï¸ LawMode ë¯¸ì„¤ì¹˜")
        
        debug_mode = st.checkbox("ğŸ”§ ë””ë²„ê¹… ëª¨ë“œ", value=False)
        if debug_mode:
            st.warning("âš ï¸ QA ê²€ì¦ ë¬´ì‹œ")
        
        if not use_law_mode:
            max_pages = st.slider("ìµœëŒ€ í˜ì´ì§€", 1, 20, 20)
        else:
            max_pages = 999
    
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=['pdf'])
    
    if not uploaded_file:
        st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
        return
    
    if st.button("ğŸš€ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘", type="primary"):
        pdf_path = safe_temp_path(".pdf")
        
        try:
            with open(pdf_path, 'wb') as f:
                f.write(uploaded_file.read())
            
            filename = uploaded_file.name
            st.success(f"âœ… íŒŒì¼ ì €ì¥: {filename}")
            
            st.info("ğŸ“„ PDF ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            pdf_text = extract_pdf_text_layer(pdf_path)
            
            if use_law_mode:
                result = process_document_law_mode(pdf_path, pdf_text, filename)
            else:
                result = process_document_vlm_mode(pdf_path, pdf_text, max_pages)
            
            if not result:
                st.error("âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨")
                return
            
            is_qa_pass = result['is_qa_pass']
            qa_result = result['qa_result']
            match_rate = qa_result.get('match_rate', 0.0)
            qa_flags = qa_result.get('qa_flags', [])
            
            st.divider()
            
            if not is_qa_pass:
                st.error(f"""
                ğŸš¨ **QA ê²€ì¦ ì‹¤íŒ¨**
                
                - ì²˜ë¦¬ ëª¨ë“œ: {result['mode']}
                - ë§¤ì¹­ë¥ : {match_rate:.1%} (ê¸°ì¤€: 95%)
                - QA í”Œë˜ê·¸: {len(qa_flags)}ê°œ
                
                âš ï¸ RAG ì‚¬ìš© ê¸ˆì§€!
                {"ğŸ’¡ LawModeë¥¼ í™œì„±í™”í•˜ì„¸ìš”" if not use_law_mode else ""}
                """)
                
                if not debug_mode:
                    st.warning("ğŸ“¥ **ë‹¤ìš´ë¡œë“œ ì°¨ë‹¨ë¨** - ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™” í•„ìš”")
            else:
                st.success(f"""
                âœ… **QA ê²€ì¦ í†µê³¼**
                
                - ì²˜ë¦¬ ëª¨ë“œ: {result['mode']}
                - ë§¤ì¹­ë¥ : {match_rate:.1%}
                
                RAG ì‚¬ìš© ê°€ëŠ¥!
                """)
            
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“„ Markdown", "ğŸ“¦ JSON", "ğŸ“‹ ë¦¬ë·°ìš©", "ğŸ”¬ DualQA"])
            
            filename_base = Path(filename).stem
            
            with tab1:
                st.text_area("Markdown ê²°ê³¼", result['markdown'], height=400)
                if is_qa_pass or debug_mode:
                    st.download_button(
                        f"â¬‡ï¸ Markdown ({result['mode']})",
                        result['markdown'],
                        file_name=f"{filename_base}_{result['mode']}.md"
                    )
                else:
                    st.button("â¬‡ï¸ ë‹¤ìš´ë¡œë“œ (ì°¨ë‹¨ë¨)", disabled=True)
            
            with tab2:
                json_str = json.dumps(result['chunks'], ensure_ascii=False, indent=2)
                st.text_area("JSON ê²°ê³¼", json_str, height=400)
                if is_qa_pass or debug_mode:
                    st.download_button(
                        f"â¬‡ï¸ JSON ({result['mode']})",
                        json_str,
                        file_name=f"{filename_base}_{result['mode']}.json"
                    )
                else:
                    st.button("â¬‡ï¸ JSON (ì°¨ë‹¨ë¨)", disabled=True)
            
            with tab3:
                review_md = to_review_md(result['chunks'], result.get('markdown'))
                st.text_area("ë¦¬ë·°ìš© Markdown", review_md, height=400)
                if is_qa_pass or debug_mode:
                    st.download_button(
                        f"â¬‡ï¸ ë¦¬ë·°ìš© ({result['mode']})",
                        review_md,
                        file_name=f"{filename_base}_review.md"
                    )
            
            with tab4:
                st.subheader(f"ğŸ”¬ DualQA ê²€ì¦ ({result['mode']})")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PDF ì¡°ë¬¸", qa_result['pdf_count'])
                with col2:
                    st.metric("ì¶”ì¶œ ì¡°ë¬¸", qa_result['vlm_count'])
                with col3:
                    st.metric("ë§¤ì¹­ë¥ ", f"{match_rate:.1%}")
                
                if qa_result['missing_in_vlm']:
                    st.error(f"âŒ {result['mode']} ëˆ„ë½")
                    st.json(qa_result['missing_in_vlm'])
                
                if not qa_flags:
                    st.success("âœ… ì›ë³¸ê³¼ ì™„ì „ ì¼ì¹˜!")
                else:
                    st.warning(f"âš ï¸ QA í”Œë˜ê·¸: {qa_flags}")
                
                if use_law_mode and 'parsed_result' in result:
                    st.divider()
                    st.subheader("ğŸ“œ LawMode íŒŒì‹± ìƒì„¸")
                    parsed = result['parsed_result']
                    st.write(f"**ì´ ì¡°ë¬¸ ìˆ˜**: {parsed['total_articles']}ê°œ")
                    st.write(f"**ê¸°ë³¸ì •ì‹ **: {len(parsed['basic_spirit'])}ì")
        
        finally:
            safe_remove(pdf_path)


if __name__ == '__main__':
    main()