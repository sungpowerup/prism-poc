"""
PRISM Phase 2.1 - Chunking Quality Tests

ì²­í‚¹ í’ˆì§ˆ ìë™ ê²€ì¦ í…ŒìŠ¤íŠ¸

Author: ì •ìˆ˜ì•„ (QA Lead)
Date: 2025-10-13
"""

import sys
import json
from pathlib import Path


def load_chunks(json_path: str):
    """ì²­í¬ íŒŒì¼ ë¡œë“œ"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def test_table_preservation(data):
    """
    í…ŒìŠ¤íŠ¸ 1: í‘œê°€ ë…ë¦½ ì²­í¬ë¡œ ìœ ì§€ë˜ëŠ”ê°€?
    
    ê¸°ëŒ€:
    - table_chunks > 0
    - ê° í‘œ ì²­í¬ëŠ” type="table"
    """
    print("\nğŸ§ª Test 1: Table Preservation")
    print("-" * 60)
    
    stats = data.get("statistics", {})
    table_chunks = stats.get("table_chunks", 0)
    
    if table_chunks == 0:
        print("âŒ FAIL: No table chunks found")
        print("   Expected: At least 1 table chunk")
        print("   Actual: 0")
        return False
    
    # ì‹¤ì œ í‘œ ì²­í¬ í™•ì¸
    chunks = data.get("chunks", [])
    actual_table_chunks = [c for c in chunks if c.get("type") == "table"]
    
    if len(actual_table_chunks) != table_chunks:
        print(f"âŒ FAIL: Mismatch between stats and actual chunks")
        print(f"   Stats: {table_chunks}")
        print(f"   Actual: {len(actual_table_chunks)}")
        return False
    
    print(f"âœ… PASS: Found {table_chunks} table chunk(s)")
    
    # í‘œ ì²­í¬ ë‚´ìš© ê²€ì¦
    for i, chunk in enumerate(actual_table_chunks):
        content = chunk.get("content", "")
        
        # Markdown í‘œ í˜•ì‹ì¸ê°€?
        if "|" not in content or "---" not in content:
            print(f"âš ï¸  WARNING: Table chunk {i+1} may not be in Markdown format")
        else:
            print(f"   âœ“ Table {i+1}: Valid Markdown format")
    
    return True


def test_sentence_completeness(data):
    """
    í…ŒìŠ¤íŠ¸ 2: ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•ŠëŠ”ê°€?
    
    ê¸°ëŒ€:
    - ì²­í¬ê°€ ë¶ˆì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ì§€ ì•ŠìŒ
    - "ë‹¤, ", "ë©°, ", "ê³ , " ë“±ìœ¼ë¡œ ëë‚˜ì§€ ì•ŠìŒ
    """
    print("\nğŸ§ª Test 2: Sentence Completeness")
    print("-" * 60)
    
    chunks = data.get("chunks", [])
    text_chunks = [c for c in chunks if c.get("type") == "text"]
    
    if not text_chunks:
        print("âš ï¸  SKIP: No text chunks to test")
        return True
    
    incomplete_endings = ["ë‹¤, ", "ë©°, ", "ê³ , ", "ì„, ", "ë¥¼, ", "ì˜, ", "ì—, "]
    problematic_chunks = []
    
    for chunk in text_chunks:
        content = chunk.get("content", "")
        
        for ending in incomplete_endings:
            if content.rstrip().endswith(ending):
                problematic_chunks.append({
                    "chunk_id": chunk.get("chunk_id"),
                    "ending": ending,
                    "preview": content[-50:]
                })
                break
    
    if problematic_chunks:
        print(f"âŒ FAIL: Found {len(problematic_chunks)} incomplete chunks")
        for prob in problematic_chunks[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
            print(f"   â€¢ {prob['chunk_id']}: ends with '{prob['ending']}'")
            print(f"     Preview: ...{prob['preview']}")
        return False
    
    print(f"âœ… PASS: All {len(text_chunks)} text chunks are complete")
    return True


def test_chunk_size_consistency(data):
    """
    í…ŒìŠ¤íŠ¸ 3: ì²­í¬ í¬ê¸°ê°€ ì¼ê´€ì ì¸ê°€?
    
    ê¸°ëŒ€:
    - ëŒ€ë¶€ë¶„ì˜ ì²­í¬ê°€ ëª©í‘œ í¬ê¸° ë²”ìœ„ ë‚´
    - í‘œ ì²­í¬ëŠ” ì˜ˆì™¸ (í¬ê¸° ë¬´ê´€)
    """
    print("\nğŸ§ª Test 3: Chunk Size Consistency")
    print("-" * 60)
    
    chunks = data.get("chunks", [])
    text_chunks = [c for c in chunks if c.get("type") == "text"]
    
    if not text_chunks:
        print("âš ï¸  SKIP: No text chunks to test")
        return True
    
    target_size = 512  # ê¸°ë³¸ ëª©í‘œ
    min_size = target_size * 0.5  # ìµœì†Œ 50%
    max_size = target_size * 1.5  # ìµœëŒ€ 150%
    
    sizes = []
    out_of_range = []
    
    for chunk in text_chunks:
        metadata = chunk.get("metadata", {})
        token_count = metadata.get("token_count", 0)
        
        sizes.append(token_count)
        
        if token_count < min_size or token_count > max_size:
            out_of_range.append({
                "chunk_id": chunk.get("chunk_id"),
                "size": token_count
            })
    
    avg_size = sum(sizes) / len(sizes) if sizes else 0
    
    print(f"   Target: {target_size} tokens")
    print(f"   Range: {min_size:.0f} - {max_size:.0f} tokens")
    print(f"   Actual avg: {avg_size:.0f} tokens")
    
    if len(out_of_range) > len(text_chunks) * 0.2:
        # 20% ì´ìƒì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì‹¤íŒ¨
        print(f"âŒ FAIL: {len(out_of_range)} chunks out of range (>{20}%)")
        for chunk in out_of_range[:3]:
            print(f"   â€¢ {chunk['chunk_id']}: {chunk['size']} tokens")
        return False
    
    print(f"âœ… PASS: {len(text_chunks) - len(out_of_range)}/{len(text_chunks)} chunks in range")
    return True


def test_table_structure(data):
    """
    í…ŒìŠ¤íŠ¸ 4: í‘œ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ê°€?
    
    ê¸°ëŒ€:
    - Markdown í˜•ì‹
    - í—¤ë” í–‰ ì¡´ì¬
    - êµ¬ë¶„ì„  ì¡´ì¬
    """
    print("\nğŸ§ª Test 4: Table Structure")
    print("-" * 60)
    
    chunks = data.get("chunks", [])
    table_chunks = [c for c in chunks if c.get("type") == "table"]
    
    if not table_chunks:
        print("âš ï¸  SKIP: No table chunks to test")
        return True
    
    valid_tables = 0
    
    for chunk in table_chunks:
        content = chunk.get("content", "")
        chunk_id = chunk.get("chunk_id", "unknown")
        
        # Markdown í‘œ ê²€ì¦
        lines = content.strip().split('\n')
        
        # ìµœì†Œ 3ì¤„ (í—¤ë” + êµ¬ë¶„ì„  + ë°ì´í„°)
        if len(lines) < 3:
            print(f"âš ï¸  WARNING: {chunk_id} has too few lines ({len(lines)})")
            continue
        
        # êµ¬ë¶„ì„  í™•ì¸
        has_separator = any("---" in line for line in lines)
        if not has_separator:
            print(f"âš ï¸  WARNING: {chunk_id} missing separator line")
            continue
        
        # ëª¨ë“  í–‰ì´ '|'ë¥¼ í¬í•¨í•˜ëŠ”ê°€
        all_have_pipe = all("|" in line for line in lines)
        if not all_have_pipe:
            print(f"âš ï¸  WARNING: {chunk_id} has lines without '|'")
            continue
        
        valid_tables += 1
        
        # ë©”íƒ€ë°ì´í„° ì¶œë ¥
        metadata = chunk.get("metadata", {})
        rows = metadata.get("rows", "?")
        cols = metadata.get("columns", "?")
        print(f"   âœ“ {chunk_id}: {rows}x{cols} table")
    
    if valid_tables == len(table_chunks):
        print(f"âœ… PASS: All {valid_tables} tables have valid structure")
        return True
    else:
        print(f"âš ï¸  PARTIAL: {valid_tables}/{len(table_chunks)} tables are valid")
        return valid_tables > 0


def test_no_content_loss(data):
    """
    í…ŒìŠ¤íŠ¸ 5: ë‚´ìš© ì†ì‹¤ì´ ì—†ëŠ”ê°€?
    
    ê¸°ëŒ€:
    - ëª¨ë“  ì²­í¬ì— ë‚´ìš©ì´ ìˆìŒ
    - ë¹ˆ ì²­í¬ ì—†ìŒ
    """
    print("\nğŸ§ª Test 5: No Content Loss")
    print("-" * 60)
    
    chunks = data.get("chunks", [])
    
    if not chunks:
        print("âŒ FAIL: No chunks generated")
        return False
    
    empty_chunks = [c for c in chunks if not c.get("content", "").strip()]
    
    if empty_chunks:
        print(f"âŒ FAIL: Found {len(empty_chunks)} empty chunks")
        for chunk in empty_chunks[:3]:
            print(f"   â€¢ {chunk.get('chunk_id', 'unknown')}")
        return False
    
    print(f"âœ… PASS: All {len(chunks)} chunks have content")
    return True


def run_all_tests(json_path: str):
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 60)
    print("PRISM Chunking Quality Tests")
    print("=" * 60)
    print(f"File: {json_path}")
    
    try:
        data = load_chunks(json_path)
    except FileNotFoundError:
        print(f"\nâŒ ERROR: File not found: {json_path}")
        return False
    except json.JSONDecodeError as e:
        print(f"\nâŒ ERROR: Invalid JSON: {e}")
        return False
    
    # í†µê³„ ì¶œë ¥
    stats = data.get("statistics", {})
    print("\nğŸ“Š Statistics:")
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        test_table_preservation,
        test_sentence_completeness,
        test_chunk_size_consistency,
        test_table_structure,
        test_no_content_loss
    ]
    
    results = []
    for test_func in tests:
        try:
            result = test_func(data)
            results.append(result)
        except Exception as e:
            print(f"\nâŒ ERROR in {test_func.__name__}: {e}")
            results.append(False)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("Test Summary")
    print("=" * 60)
    
    passed = sum(results)
    total = len(results)
    
    print(f"\nTests: {passed}/{total} passed")
    
    if passed == total:
        print("\nâœ… All tests passed! Chunking quality is excellent.")
        return True
    elif passed >= total * 0.8:
        print(f"\nâš ï¸  {total - passed} test(s) failed, but chunking quality is acceptable.")
        return True
    else:
        print(f"\nâŒ {total - passed} test(s) failed. Chunking quality needs improvement.")
        return False


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python test_chunking_quality.py <chunks.json>")
        sys.exit(1)
    
    json_path = sys.argv[1]
    success = run_all_tests(json_path)
    
    sys.exit(0 if success else 1)