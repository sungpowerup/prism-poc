"""
llm_rewriter.py - PRISM Phase 0.9 LLM Rewriting Engine
GPT ê¶Œì¥ ì•ˆì „ì¥ì¹˜ 3ì¢… + Sanity Check í¬í•¨

âœ… GPT í•µì‹¬ ì›ì¹™:
1. ì—”ì§„ JSONì€ ì ˆëŒ€ ì•ˆ ê±´ë“œë¦¼
2. ë¦¬ë¼ì´íŒ…ì€ ë·° ì „ìš©
3. ì¡°ë¬¸ ë‹¨ìœ„ + ìºì‹œ êµ¬ì¡°

âš ï¸ GPT ê²½ê³ :
"ì˜ë¯¸ í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ ê²ƒ"ì€ ëª©í‘œì§€, ë³´ì¥ì€ ì•„ë‹˜
â†’ Sanity Check ìë™ ê²€ì¦ í•„ìˆ˜

Author: ë§ˆì°½ìˆ˜ì‚°íŒ€ (ë°•ì¤€í˜¸ AI/ML Lead + GPT í”¼ë“œë°±)
Date: 2025-11-14
Version: Phase 0.9
"""

import logging
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import hashlib

logger = logging.getLogger(__name__)


@dataclass
class RewriteValidation:
    """
    âœ… GPT ê¶Œì¥: Sanity Check ê²€ì¦ ê²°ê³¼
    
    "ê°œíŒ ë‚œ ê²°ê³¼ë¥¼ UIë¡œ ì˜¬ë¦¬ëŠ” ì‚¬ê³ ëŠ” ê½¤ ì¤„ì¼ ìˆ˜ ìˆì–´"
    """
    is_valid: bool
    warnings: List[str]
    
    # 4ê°€ì§€ ì²´í¬
    header_preserved: bool
    numbers_intact: bool
    legal_terms_intact: bool
    structure_preserved: bool


class LLMRewriter:
    """
    âœ… Phase 0.9: LLM ë¦¬ë¼ì´íŒ… ì—”ì§„
    
    GPT ê¶Œì¥ êµ¬ì¡°:
    - ì¡°ë¬¸ ë‹¨ìœ„ ì²˜ë¦¬
    - ìºì‹œ êµ¬ì¡°
    - Sanity Check ìë™ ê²€ì¦
    """
    
    # âœ… GPT ê¶Œì¥: ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ (ê¸ˆì§€ ì‚¬í•­ ëª…ì‹œ)
    REWRITE_PROMPT_V2 = """ë‹¹ì‹ ì€ ë²•ë ¹ ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¡°ë¬¸ì„ ì½ê¸° ì‰½ê²Œ ê°œì„ í•˜ë˜, ë‹¤ìŒì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:

âœ… í•„ìˆ˜ ì¤€ìˆ˜:
1. ì¡°ë¬¸ ë²ˆí˜¸/ì œëª©ì€ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€ (ì˜ˆ: "ì œ1ì¡°(ëª©ì )")
2. ë²•ë¥  ìš©ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜ˆ: "ì •ì§", "í•´ì„", "íŒŒë©´", "ì„ìš©", "ìŠ¹ì§„")
3. ìˆ«ì/ë‚ ì§œ/ê¸°ê°„ì€ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€ (ì˜ˆ: "3ë…„", "2025.01.01", "5ì¼")
4. ì˜ë¯¸/ë‚´ìš©ì€ í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ ê²ƒ

âŒ ì ˆëŒ€ ê¸ˆì§€:
1. ë¶€ì •ë¬¸ â†” ê¸ì •ë¬¸ ë³€í™˜ ê¸ˆì§€ ("~í•˜ì§€ ì•„ë‹ˆí•œë‹¤" ê·¸ëŒ€ë¡œ)
2. ì˜ˆì™¸ ê·œì • ê°•ë„ ë³€ê²½ ê¸ˆì§€ ("ë‹¤ë§Œ" â†’ "í•˜ì§€ë§Œ" ê°™ì€ ë³€ê²½ ê¸ˆì§€)
3. ë²•ë¥  ìš©ì–´ ìˆœí™” ê¸ˆì§€ ("í•´ê³ " ê°™ì€ ì¼ë°˜ ìš©ì–´ë¡œ ë°”ê¾¸ì§€ ë§ ê²ƒ)
4. ì¡°ë¬¸ êµ¬ì¡° ì¬ë°°ì¹˜ ê¸ˆì§€ (â‘ â‘¡â‘¢ ìˆœì„œ ìœ ì§€)

âœ… í—ˆìš©ë˜ëŠ” ê²ƒ (ì˜¤ì§ ì´ê²ƒë§Œ):
1. ë„ì–´ì“°ê¸°ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì„ 
2. ë¬¸ì¥ ë¶€í˜¸ ìµœì†Œí•œ ê°œì„  (ì‰¼í‘œ, ë§ˆì¹¨í‘œ)
3. "ê°œì •YYYY.MM.DD" ê°™ì€ ë©”íƒ€ì •ë³´ëŠ” ê·¸ëŒ€ë¡œ

ì…ë ¥ ì¡°ë¬¸:
{article_text}

ì¶œë ¥ í˜•ì‹ (í—¤ë” í¬í•¨):
### {article_number}({article_title})
[ë„ì–´ì“°ê¸°ë§Œ ê°œì„ ëœ ë³¸ë¬¸]
"""
    
    def __init__(
        self,
        provider: str = "azure_openai",
        cache_enabled: bool = True,
        sanity_check_enabled: bool = True
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            provider: LLM ì œê³µì (azure_openai, anthropic, local)
            cache_enabled: ìºì‹œ í™œì„±í™”
            sanity_check_enabled: Sanity Check í™œì„±í™”
        """
        self.provider = provider
        self.cache_enabled = cache_enabled
        self.sanity_check_enabled = sanity_check_enabled
        
        # ìºì‹œ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬)
        self._cache: Dict[str, str] = {}
        
        logger.info(f"âœ… LLMRewriter ì´ˆê¸°í™” (Phase 0.9)")
        logger.info(f"   - Provider: {provider}")
        logger.info(f"   - Cache: {'ON' if cache_enabled else 'OFF'}")
        logger.info(f"   - Sanity Check: {'ON' if sanity_check_enabled else 'OFF'}")
    
    def rewrite_article(
        self,
        article_number: str,
        article_title: str,
        article_body: str,
        document_id: str = "default",
        parser_version: str = "0.8.0"
    ) -> Tuple[str, RewriteValidation]:
        """
        ë‹¨ì¼ ì¡°ë¬¸ ë¦¬ë¼ì´íŒ…
        
        Args:
            article_number: ì¡°ë¬¸ ë²ˆí˜¸ (ì˜ˆ: "ì œ1ì¡°")
            article_title: ì¡°ë¬¸ ì œëª© (ì˜ˆ: "ëª©ì ")
            article_body: ì¡°ë¬¸ ë³¸ë¬¸
            document_id: ë¬¸ì„œ ID (ìºì‹œ í‚¤ìš©)
            parser_version: íŒŒì„œ ë²„ì „ (ìºì‹œ í‚¤ìš©)
        
        Returns:
            (ë¦¬ë¼ì´íŒ…ëœ í…ìŠ¤íŠ¸, ê²€ì¦ ê²°ê³¼)
        """
        
        # âœ… GPT ê¶Œì¥: ì¡°ë¬¸ ë‹¨ìœ„ + ìºì‹œ
        cache_key = self._generate_cache_key(
            document_id, article_number, parser_version
        )
        
        # ìºì‹œ í™•ì¸
        if self.cache_enabled and cache_key in self._cache:
            logger.info(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {article_number}")
            cached_text = self._cache[cache_key]
            validation = self._validate_rewrite(
                original=article_body,
                rewritten=cached_text,
                article_number=article_number,
                article_title=article_title
            )
            return cached_text, validation
        
        # ì›ë³¸ ì¡°ë¬¸ ì „ì²´
        original_text = f"### {article_number}({article_title})\n{article_body}"
        
        logger.info(f"âœ¨ ë¦¬ë¼ì´íŒ… ì‹œì‘: {article_number}({article_title})")
        
        # LLM í˜¸ì¶œ
        try:
            rewritten_text = self._call_llm(
                article_number=article_number,
                article_title=article_title,
                article_body=article_body
            )
            
            logger.info(f"   âœ… LLM ì‘ë‹µ ìˆ˜ì‹  ({len(rewritten_text)}ì)")
        
        except Exception as e:
            logger.error(f"   âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # Fallback: ì›ë³¸ ë°˜í™˜
            rewritten_text = original_text
        
        # âœ… GPT í•„ìˆ˜: Sanity Check
        validation = self._validate_rewrite(
            original=article_body,
            rewritten=rewritten_text,
            article_number=article_number,
            article_title=article_title
        )
        
        if not validation.is_valid:
            logger.warning(f"âš ï¸ Sanity Check ì‹¤íŒ¨: {article_number}")
            for warning in validation.warnings:
                logger.warning(f"   - {warning}")
            
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            rewritten_text = original_text
            logger.info(f"   ğŸ”„ ì›ë³¸ìœ¼ë¡œ í´ë°±")
        
        # ìºì‹œ ì €ì¥
        if self.cache_enabled:
            self._cache[cache_key] = rewritten_text
        
        return rewritten_text, validation
    
    def _call_llm(
        self,
        article_number: str,
        article_title: str,
        article_body: str
    ) -> str:
        """
        LLM API í˜¸ì¶œ
        
        Providerë³„ êµ¬í˜„ ë¶„ê¸°
        """
        
        prompt = self.REWRITE_PROMPT_V2.format(
            article_text=article_body,
            article_number=article_number,
            article_title=article_title
        )
        
        if self.provider == "azure_openai":
            return self._call_azure_openai(prompt)
        
        elif self.provider == "anthropic":
            return self._call_anthropic(prompt)
        
        elif self.provider == "local":
            return self._call_local_model(prompt)
        
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {self.provider}")
    
    def _call_azure_openai(self, prompt: str) -> str:
        """Azure OpenAI API í˜¸ì¶œ"""
        import os
        from openai import AzureOpenAI
        
        client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version="2024-02-15-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        
        response = client.chat.completions.create(
            model=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4"),
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë²•ë ¹ ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í™•ë³´
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
    
    def _call_anthropic(self, prompt: str) -> str:
        """Anthropic Claude API í˜¸ì¶œ"""
        import os
        from anthropic import Anthropic
        
        client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2000,
            temperature=0.1,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        return response.content[0].text.strip()
    
    def _call_local_model(self, prompt: str) -> str:
        """ë¡œì»¬ ëª¨ë¸ í˜¸ì¶œ (í–¥í›„ êµ¬í˜„)"""
        # TODO: ì˜¨í”„ë ˆë¯¸ìŠ¤ ëª¨ë¸ ì—°ë™
        raise NotImplementedError("ë¡œì»¬ ëª¨ë¸ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •")
    
    def _validate_rewrite(
        self,
        original: str,
        rewritten: str,
        article_number: str,
        article_title: str
    ) -> RewriteValidation:
        """
        âœ… GPT í•„ìˆ˜: Sanity Check ìë™ ê²€ì¦
        
        4ê°€ì§€ ì²´í¬:
        1. ì¡°ë¬¸ í—¤ë” ë³´ì¡´ í™•ì¸
        2. ìˆ«ì/ë‚ ì§œ ë³€ê²½ ê°ì§€
        3. ë²•ë¥  ìš©ì–´ ëˆ„ë½ ê°ì§€
        4. ì¡°ë¬¸ êµ¬ì¡° ë³´ì¡´ í™•ì¸
        """
        
        if not self.sanity_check_enabled:
            return RewriteValidation(
                is_valid=True,
                warnings=[],
                header_preserved=True,
                numbers_intact=True,
                legal_terms_intact=True,
                structure_preserved=True
            )
        
        warnings = []
        
        # 1. í—¤ë” ë³´ì¡´ í™•ì¸
        expected_header = f"{article_number}({article_title})"
        header_preserved = expected_header in rewritten
        
        if not header_preserved:
            warnings.append(f"ì¡°ë¬¸ í—¤ë” ëˆ„ë½: {expected_header}")
        
        # 2. ìˆ«ì/ë‚ ì§œ ë³€ê²½ ê°ì§€
        original_numbers = set(re.findall(r'\d+(?:\.\d+)?', original))
        rewritten_numbers = set(re.findall(r'\d+(?:\.\d+)?', rewritten))
        
        numbers_intact = original_numbers == rewritten_numbers
        
        if not numbers_intact:
            missing = original_numbers - rewritten_numbers
            extra = rewritten_numbers - original_numbers
            if missing:
                warnings.append(f"ìˆ«ì ëˆ„ë½: {missing}")
            if extra:
                warnings.append(f"ìˆ«ì ì¶”ê°€: {extra}")
        
        # 3. ë²•ë¥  ìš©ì–´ ëˆ„ë½ ê°ì§€
        legal_terms = [
            'ì •ì§', 'í•´ì„', 'íŒŒë©´', 'ì„ìš©', 'ìŠ¹ì§„', 'ì „ë³´', 'ê²¸ì„',
            'íœ´ì§', 'ë³µì§', 'ë©´ì§', 'ê°•ë“±', 'ì§•ê³„', 'ì±„ìš©', 'ê²°ê²©',
            'ë¶€ì¹™', 'ê°œì •', 'ì‹œí–‰', 'ì œì •'
        ]
        
        original_legal_terms = set([
            term for term in legal_terms if term in original
        ])
        rewritten_legal_terms = set([
            term for term in legal_terms if term in rewritten
        ])
        
        legal_terms_intact = original_legal_terms.issubset(rewritten_legal_terms)
        
        if not legal_terms_intact:
            missing_terms = original_legal_terms - rewritten_legal_terms
            warnings.append(f"ë²•ë¥  ìš©ì–´ ëˆ„ë½: {missing_terms}")
        
        # 4. ì¡°ë¬¸ êµ¬ì¡° ë³´ì¡´ (â‘ â‘¡â‘¢ or 1.2.3.)
        original_clauses = len(re.findall(r'[â‘ -â‘³]|^\d+\.', original, re.MULTILINE))
        rewritten_clauses = len(re.findall(r'[â‘ -â‘³]|^\d+\.', rewritten, re.MULTILINE))
        
        structure_preserved = original_clauses == rewritten_clauses
        
        if not structure_preserved:
            warnings.append(f"í•­ êµ¬ì¡° ë³€ê²½: {original_clauses}ê°œ â†’ {rewritten_clauses}ê°œ")
        
        # ìµœì¢… íŒì •
        is_valid = (
            header_preserved and
            numbers_intact and
            legal_terms_intact and
            structure_preserved
        )
        
        return RewriteValidation(
            is_valid=is_valid,
            warnings=warnings,
            header_preserved=header_preserved,
            numbers_intact=numbers_intact,
            legal_terms_intact=legal_terms_intact,
            structure_preserved=structure_preserved
        )
    
    def _generate_cache_key(
        self,
        document_id: str,
        article_number: str,
        parser_version: str
    ) -> str:
        """
        ìºì‹œ í‚¤ ìƒì„±
        
        Format: {document_id}_{article_number}_{parser_version}
        """
        key = f"{document_id}_{article_number}_{parser_version}"
        # MD5 í•´ì‹œë¡œ ì§§ê²Œ
        return hashlib.md5(key.encode()).hexdigest()
    
    def get_cache_stats(self) -> Dict[str, int]:
        """ìºì‹œ í†µê³„"""
        return {
            'total_cached': len(self._cache),
            'cache_size_bytes': sum(len(v.encode('utf-8')) for v in self._cache.values())
        }
    
    def clear_cache(self) -> None:
        """ìºì‹œ ì´ˆê¸°í™”"""
        self._cache.clear()
        logger.info("ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")


# ============================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================

if __name__ == '__main__':
    # LLM Rewriter ì´ˆê¸°í™”
    rewriter = LLMRewriter(
        provider="azure_openai",
        cache_enabled=True,
        sanity_check_enabled=True
    )
    
    # í…ŒìŠ¤íŠ¸ ì¡°ë¬¸
    article_number = "ì œ1ì¡°"
    article_title = "ëª©ì "
    article_body = "ì´ê·œì •ì€í•œêµ­ë†ì–´ì´Œê³µì‚¬ì§ì›ì—ê²Œì ìš©í• ì¸ì‚¬ê´€ë¦¬ì˜ê¸°ì¤€ì„ì •í•˜ì—¬í•©ë¦¬ì ì´ê³ ì ì •í•œì¸ì‚¬ê´€ë¦¬ë¥¼ê¸°í•˜ê²Œí•˜ëŠ”ê²ƒì„ëª©ì ìœ¼ë¡œí•œë‹¤."
    
    # ë¦¬ë¼ì´íŒ…
    rewritten, validation = rewriter.rewrite_article(
        article_number=article_number,
        article_title=article_title,
        article_body=article_body,
        document_id="ì¸ì‚¬ê·œì •",
        parser_version="0.9.0"
    )
    
    print("âœ… LLMRewriter í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Phase 0.9)")
    print(f"   - Sanity Check: {'âœ… PASS' if validation.is_valid else 'âŒ FAIL'}")
    print(f"   - ìºì‹œ: {rewriter.get_cache_stats()}")
